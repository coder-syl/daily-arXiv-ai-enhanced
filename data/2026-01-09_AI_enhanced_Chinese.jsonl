{"id": "2601.04300", "pdf": "https://arxiv.org/pdf/2601.04300", "abs": "https://arxiv.org/abs/2601.04300", "authors": ["Chenye Meng", "Zejian Li", "Zhongni Liu", "Yize Li", "Changle Xie", "Kaixin Jia", "Ling Yang", "Huanghuang Deng", "Shiying Ding", "Shengyuan Zhang", "Jiayi Li", "Lingyun Sun"], "title": "Beyond Binary Preference: Aligning Diffusion Models to Fine-grained Criteria by Decoupling Attributes", "categories": ["cs.CV"], "comment": null, "summary": "Post-training alignment of diffusion models relies on simplified signals, such as scalar rewards or binary preferences. This limits alignment with complex human expertise, which is hierarchical and fine-grained. To address this, we first construct a hierarchical, fine-grained evaluation criteria with domain experts, which decomposes image quality into multiple positive and negative attributes organized in a tree structure. Building on this, we propose a two-stage alignment framework. First, we inject domain knowledge to an auxiliary diffusion model via Supervised Fine-Tuning. Second, we introduce Complex Preference Optimization (CPO) that extends DPO to align the target diffusion to our non-binary, hierarchical criteria. Specifically, we reformulate the alignment problem to simultaneously maximize the probability of positive attributes while minimizing the probability of negative attributes with the auxiliary diffusion. We instantiate our approach in the domain of painting generation and conduct CPO training with an annotated dataset of painting with fine-grained attributes based on our criteria. Extensive experiments demonstrate that CPO significantly enhances generation quality and alignment with expertise, opening new avenues for fine-grained criteria alignment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5206\u5c42\u7ec6\u7c92\u5ea6\u8bc4\u4ef7\u6807\u51c6\u5e76\u5f15\u5165\u590d\u6742\u504f\u597d\u4f18\u5316\uff08CPO\uff09\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u5728\u7ed8\u753b\u751f\u6210\u4efb\u52a1\u4e2d\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u77e5\u8bc6\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u5bf9\u9f50\u4f9d\u8d56\u4e8e\u7b80\u5316\u7684\u4fe1\u53f7\uff08\u5982\u6807\u91cf\u5956\u52b1\u6216\u4e8c\u5143\u504f\u597d\uff09\uff0c\u96be\u4ee5\u6355\u6349\u4eba\u7c7b\u4e13\u5bb6\u6240\u5177\u5907\u7684\u5c42\u6b21\u5316\u3001\u7ec6\u7c92\u5ea6\u7684\u590d\u6742\u5224\u65ad\u3002", "method": "\u9996\u5148\u4e0e\u9886\u57df\u4e13\u5bb6\u5171\u540c\u6784\u5efa\u4e00\u4e2a\u6811\u72b6\u7ed3\u6784\u7684\u5206\u5c42\u7ec6\u7c92\u5ea6\u56fe\u50cf\u8d28\u91cf\u8bc4\u4ef7\u6807\u51c6\uff1b\u7136\u540e\u91c7\u7528\u4e24\u9636\u6bb5\u5bf9\u9f50\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5c06\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u8f85\u52a9\u6269\u6563\u6a21\u578b\uff0c\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51fa\u590d\u6742\u504f\u597d\u4f18\u5316\uff08CPO\uff09\u65b9\u6cd5\uff0c\u6269\u5c55DPO\u4ee5\u540c\u65f6\u6700\u5927\u5316\u6b63\u5411\u5c5e\u6027\u6982\u7387\u5e76\u6700\u5c0f\u5316\u8d1f\u5411\u5c5e\u6027\u6982\u7387\u3002", "result": "\u5728\u7ed8\u753b\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684CPO\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u548c\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u7684\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6269\u6563\u6a21\u578b\u4e0e\u7ec6\u7c92\u5ea6\u3001\u975e\u4e8c\u5143\u4eba\u7c7b\u504f\u597d\u4e4b\u95f4\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u5f00\u8f9f\u4e86\u5229\u7528\u590d\u6742\u8bc4\u4ef7\u6807\u51c6\u8fdb\u884c\u6a21\u578b\u5bf9\u9f50\u7684\u65b0\u65b9\u5411\u3002", "summary_cn": "\u6269\u6563\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u5bf9\u9f50\u4f9d\u8d56\u4e8e\u7b80\u5316\u7684\u4fe1\u53f7\uff0c\u4f8b\u5982\u6807\u91cf\u5956\u52b1\u6216\u4e8c\u5143\u504f\u597d\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u4e0e\u590d\u6742\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\uff08\u5177\u6709\u5c42\u6b21\u6027\u548c\u7ec6\u7c92\u5ea6\uff09\u7684\u5bf9\u9f50\u80fd\u529b\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u6211\u4eec\u9996\u5148\u4e0e\u9886\u57df\u4e13\u5bb6\u5171\u540c\u6784\u5efa\u4e86\u4e00\u4e2a\u5c42\u6b21\u5316\u3001\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u5c06\u56fe\u50cf\u8d28\u91cf\u5206\u89e3\u4e3a\u591a\u4e2a\u6b63\u5411\u548c\u8d1f\u5411\u5c5e\u6027\uff0c\u5e76\u4ee5\u6811\u72b6\u7ed3\u6784\u7ec4\u7ec7\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u5bf9\u9f50\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff08Supervised Fine-Tuning\uff09\u5c06\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u4e00\u4e2a\u8f85\u52a9\u6269\u6563\u6a21\u578b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51fa\u201c\u590d\u6742\u504f\u597d\u4f18\u5316\u201d\uff08Complex Preference Optimization, CPO\uff09\uff0c\u5c06DPO\u65b9\u6cd5\u6269\u5c55\u81f3\u9002\u7528\u4e8e\u975e\u4e8c\u5143\u3001\u5c42\u6b21\u5316\u7684\u8bc4\u4ef7\u6807\u51c6\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u5c06\u5bf9\u9f50\u95ee\u9898\u91cd\u65b0\u5f62\u5f0f\u5316\uff0c\u4ee5\u5728\u8f85\u52a9\u6269\u6563\u6a21\u578b\u7684\u6307\u5bfc\u4e0b\uff0c\u540c\u65f6\u6700\u5927\u5316\u6b63\u5411\u5c5e\u6027\u7684\u6982\u7387\u5e76\u6700\u5c0f\u5316\u8d1f\u5411\u5c5e\u6027\u7684\u6982\u7387\u3002\u6211\u4eec\u5728\u7ed8\u753b\u751f\u6210\u9886\u57df\u5b9e\u4f8b\u5316\u4e86\u8be5\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6240\u6784\u5efa\u7684\u6807\u51c6\uff0c\u4f7f\u7528\u5e26\u6709\u7ec6\u7c92\u5ea6\u5c5e\u6027\u6807\u6ce8\u7684\u7ed8\u753b\u6570\u636e\u96c6\u8fdb\u884c\u4e86CPO\u8bad\u7ec3\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cCPO\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\u4ee5\u53ca\u4e0e\u4e13\u5bb6\u77e5\u8bc6\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u4e3a\u7ec6\u7c92\u5ea6\u6807\u51c6\u4e0b\u7684\u6a21\u578b\u5bf9\u9f50\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2601.04302", "pdf": "https://arxiv.org/pdf/2601.04302", "abs": "https://arxiv.org/abs/2601.04302", "authors": ["A V Uday Kiran Kandala"], "title": "Embedding Textual Information in Images Using Quinary Pixel Combinations", "categories": ["cs.CV"], "comment": null, "summary": "This paper presents a novel technique for embedding textual data into images using quinary combinations of pixel intensities in RGB space. Existing methods predominantly rely on least and most significant bit (LSB & MSB) manipulation, Pixel Value Differencing (PVD), spatial perturbations in RGB channels, transform domain based methods, Quantization methods, Edge and Region based methods and more recently through deep learning methods and generative AI techniques for hiding textual information in spatial domain of images. Most of them are dependent on pixel intensity flipping over multiple pixels, such as LSB and combination of LSB based methodologies, and on transform coefficients, often resulting in the form of noise. Encoding and Decoding are deterministic in most of the existing approaches and are computationally heavy in case of higher models such as deep learning and gen AI approaches. The proposed method works on quinary pixel intensity combinations in RGB space, where five controlled different pixel intensity variations in each of the R, G, and B channels formulate up to one hundred and twenty five distinct pixel intensity combinations. These combinations are mapped to textual symbols, enabling the representation of uppercase and lowercase alphabetic characters, numeric digits, whitespace, and commonly used special characters. Different metrics such as MSE, MAE, SNR, PSNR, SSIM, Histogram Comparison and Heatmap analysis, were evaluated for both original and encoded images resulting in no significant distortion in the images. Furthermore, the method achieves improved embedding efficiency by encoding a complete textual symbol within a single RGB pixel, in contrast to LSB and MSB based approaches that typically require multiple pixels or multi-step processes, as well as transform and learning based methods that incur higher computational overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eRGB\u7a7a\u95f4\u4e2d\u4e94\u8fdb\u5236\u50cf\u7d20\u5f3a\u5ea6\u7ec4\u5408\u7684\u65b0\u6587\u672c\u5d4c\u5165\u56fe\u50cf\u65b9\u6cd5\uff0c\u6bcf\u4e2aRGB\u50cf\u7d20\u53ef\u7f16\u7801\u4e00\u4e2a\u5b8c\u6574\u5b57\u7b26\uff0c\u907f\u514d\u4e86\u4f20\u7edfLSB/MSB\u3001\u53d8\u6362\u57df\u6216\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u7684\u591a\u50cf\u7d20\u64cd\u4f5c\u6216\u9ad8\u8ba1\u7b97\u5f00\u9500\uff0c\u5b9e\u9a8c\u8868\u660e\u56fe\u50cf\u5931\u771f\u6781\u5c0f\u4e14\u5d4c\u5165\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u9690\u5199\u6280\u672f\uff08\u5982LSB\u3001MSB\u3001PVD\u3001\u53d8\u6362\u57df\u3001\u91cf\u5316\u3001\u8fb9\u7f18\u533a\u57df\u65b9\u6cd5\u53ca\u6df1\u5ea6\u5b66\u4e60\u7b49\uff09\u666e\u904d\u5b58\u5728\u4f9d\u8d56\u591a\u50cf\u7d20\u5f3a\u5ea6\u7ffb\u8f6c\u3001\u5f15\u5165\u566a\u58f0\u3001\u7f16\u7801\u89e3\u7801\u786e\u5b9a\u6027\u5f3a\u6216\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u3001\u4f4e\u5931\u771f\u4e14\u5355\u50cf\u7d20\u5373\u53ef\u5d4c\u5165\u5b8c\u6574\u5b57\u7b26\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5728RGB\u989c\u8272\u7a7a\u95f4\u4e2d\uff0c\u5bf9\u6bcf\u4e2aR\u3001G\u3001B\u901a\u9053\u91c7\u7528\u4e94\u79cd\u53d7\u63a7\u7684\u50cf\u7d20\u5f3a\u5ea6\u53d8\u5316\uff0c\u5f62\u62105\u00d75\u00d75=125\u79cd\u4e0d\u540c\u7684\u50cf\u7d20\u5f3a\u5ea6\u7ec4\u5408\uff0c\u5e76\u5c06\u8fd9\u4e9b\u7ec4\u5408\u6620\u5c04\u5230\u5b57\u6bcd\u3001\u6570\u5b57\u3001\u7a7a\u683c\u548c\u5e38\u7528\u7279\u6b8a\u5b57\u7b26\uff1b\u901a\u8fc7\u5355\u4e2aRGB\u50cf\u7d20\u5373\u53ef\u5b8c\u6210\u4e00\u4e2a\u5b8c\u6574\u6587\u672c\u7b26\u53f7\u7684\u5d4c\u5165\u3002", "result": "\u901a\u8fc7MSE\u3001MAE\u3001SNR\u3001PSNR\u3001SSIM\u3001\u76f4\u65b9\u56fe\u6bd4\u8f83\u548c\u70ed\u529b\u56fe\u5206\u6790\u7b49\u591a\u79cd\u6307\u6807\u8bc4\u4f30\uff0c\u5d4c\u5165\u540e\u56fe\u50cf\u4e0e\u539f\u59cb\u56fe\u50cf\u76f8\u6bd4\u65e0\u663e\u8457\u5931\u771f\uff1b\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728\u5d4c\u5165\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edfLSB/MSB\u53ca\u57fa\u4e8e\u53d8\u6362\u6216\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u4e94\u8fdb\u5236\u50cf\u7d20\u5f3a\u5ea6\u7ec4\u5408\u65b9\u6cd5\u80fd\u9ad8\u6548\u3001\u4f4e\u5931\u771f\u5730\u5c06\u6587\u672c\u5d4c\u5165\u56fe\u50cf\uff0c\u5355\u50cf\u7d20\u5373\u53ef\u8868\u793a\u5b8c\u6574\u5b57\u7b26\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u5f00\u9500\u3001\u56fe\u50cf\u8d28\u91cf\u548c\u5d4c\u5165\u6548\u7387\u65b9\u9762\u7684\u5c40\u9650\u3002", "summary_cn": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528RGB\u7a7a\u95f4\u4e2d\u4e94\u8fdb\u5236\u50cf\u7d20\u5f3a\u5ea6\u7ec4\u5408\u5c06\u6587\u672c\u6570\u636e\u5d4c\u5165\u56fe\u50cf\u7684\u65b0\u6280\u672f\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u6700\u4f4e\u6709\u6548\u4f4d\uff08LSB\uff09\u548c\u6700\u9ad8\u6709\u6548\u4f4d\uff08MSB\uff09\u64cd\u4f5c\u3001\u50cf\u7d20\u503c\u5dee\u5f02\uff08PVD\uff09\u3001RGB\u901a\u9053\u7684\u7a7a\u95f4\u6270\u52a8\u3001\u53d8\u6362\u57df\u65b9\u6cd5\u3001\u91cf\u5316\u65b9\u6cd5\u3001\u57fa\u4e8e\u8fb9\u7f18\u548c\u533a\u57df\u7684\u65b9\u6cd5\uff0c\u4ee5\u53ca\u8fd1\u671f\u5174\u8d77\u7684\u6df1\u5ea6\u5b66\u4e60\u548c\u751f\u6210\u5f0fAI\u6280\u672f\u5728\u56fe\u50cf\u7a7a\u95f4\u57df\u4e2d\u9690\u85cf\u6587\u672c\u4fe1\u606f\u3002\u5176\u4e2d\u5927\u591a\u6570\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8de8\u591a\u4e2a\u50cf\u7d20\u7684\u50cf\u7d20\u5f3a\u5ea6\u7ffb\u8f6c\uff08\u5982LSB\u53ca\u5176\u7ec4\u5408\u65b9\u6cd5\uff09\u6216\u53d8\u6362\u7cfb\u6570\uff0c\u5e38\u5bfc\u81f4\u566a\u58f0\u5f62\u5f0f\u7684\u5931\u771f\uff1b\u4e14\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u7684\u7f16\u7801\u4e0e\u89e3\u7801\u8fc7\u7a0b\u662f\u786e\u5b9a\u6027\u7684\uff0c\u5728\u6df1\u5ea6\u5b66\u4e60\u548c\u751f\u6210\u5f0fAI\u7b49\u9ad8\u7ea7\u6a21\u578b\u4e2d\u8ba1\u7b97\u5f00\u9500\u8f83\u5927\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728RGB\u7a7a\u95f4\u4e2d\u91c7\u7528\u4e94\u8fdb\u5236\u50cf\u7d20\u5f3a\u5ea6\u7ec4\u5408\uff0c\u5373\u5728R\u3001G\u3001B\u6bcf\u4e2a\u901a\u9053\u4e2d\u4f7f\u7528\u4e94\u79cd\u53d7\u63a7\u7684\u4e0d\u540c\u50cf\u7d20\u5f3a\u5ea6\u53d8\u5316\uff0c\u4ece\u800c\u5f62\u6210\u6700\u591a125\u79cd\u4e0d\u540c\u7684\u50cf\u7d20\u5f3a\u5ea6\u7ec4\u5408\u3002\u8fd9\u4e9b\u7ec4\u5408\u88ab\u6620\u5c04\u5230\u6587\u672c\u7b26\u53f7\uff0c\u80fd\u591f\u8868\u793a\u5927\u5c0f\u5199\u5b57\u6bcd\u3001\u6570\u5b57\u3001\u7a7a\u683c\u53ca\u5e38\u7528\u7279\u6b8a\u5b57\u7b26\u3002\u901a\u8fc7MSE\u3001MAE\u3001SNR\u3001PSNR\u3001SSIM\u3001\u76f4\u65b9\u56fe\u6bd4\u8f83\u548c\u70ed\u529b\u56fe\u5206\u6790\u7b49\u591a\u79cd\u6307\u6807\u5bf9\u539f\u59cb\u56fe\u50cf\u548c\u5d4c\u5165\u56fe\u50cf\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u56fe\u50cf\u672a\u51fa\u73b0\u663e\u8457\u5931\u771f\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5355\u4e2aRGB\u50cf\u7d20\u5373\u53ef\u7f16\u7801\u4e00\u4e2a\u5b8c\u6574\u7684\u6587\u672c\u7b26\u53f7\uff0c\u76f8\u8f83\u4e8e\u901a\u5e38\u9700\u8981\u591a\u4e2a\u50cf\u7d20\u6216\u591a\u6b65\u5904\u7406\u7684LSB\u548cMSB\u65b9\u6cd5\uff0c\u4ee5\u53ca\u8ba1\u7b97\u5f00\u9500\u66f4\u9ad8\u7684\u53d8\u6362\u57df\u548c\u5b66\u4e60\u578b\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5d4c\u5165\u6548\u7387\u3002"}}
{"id": "2601.04339", "pdf": "https://arxiv.org/pdf/2601.04339", "abs": "https://arxiv.org/abs/2601.04339", "authors": ["Jiahui Chen", "Philippe Hansen-Estruch", "Xiaochuang Han", "Yushi Hu", "Emily Dinan", "Amita Kamath", "Michal Drozdzal", "Reyhane Askari-Hemmat", "Luke Zettlemoyer", "Marjan Ghazvininejad"], "title": "Unified Text-Image Generation with Weakness-Targeted Post-Training", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unified multimodal generation architectures that jointly produce text and images have recently emerged as a promising direction for text-to-image (T2I) synthesis. However, many existing systems rely on explicit modality switching, generating reasoning text before switching manually to image generation. This separate, sequential inference process limits cross-modal coupling and prohibits automatic multimodal generation. This work explores post-training to achieve fully unified text-image generation, where models autonomously transition from textual reasoning to visual synthesis within a single inference process. We examine the impact of joint text-image generation on T2I performance and the relative importance of each modality during post-training. We additionally explore different post-training data strategies, showing that a targeted dataset addressing specific limitations achieves superior results compared to broad image-caption corpora or benchmark-aligned data. Using offline, reward-weighted post-training with fully self-generated synthetic data, our approach enables improvements in multimodal image generation across four diverse T2I benchmarks, demonstrating the effectiveness of reward-weighting both modalities and strategically designed post-training data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u540e\u8bad\u7ec3\u5b9e\u73b0\u6587\u672c\u4e0e\u56fe\u50cf\u7684\u5b8c\u5168\u7edf\u4e00\u751f\u6210\uff0c\u4f7f\u6a21\u578b\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u81ea\u4e3b\u4ece\u6587\u672c\u63a8\u7406\u8fc7\u6e21\u5230\u89c6\u89c9\u5408\u6210\uff0c\u4ece\u800c\u63d0\u5347\u8de8\u6a21\u6001\u8026\u5408\u4e0eT2I\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7edf\u4e00\u591a\u6a21\u6001\u751f\u6210\u67b6\u6784\u901a\u5e38\u4f9d\u8d56\u663e\u5f0f\u7684\u6a21\u6001\u5207\u6362\uff0c\u5728\u751f\u6210\u63a8\u7406\u6587\u672c\u540e\u518d\u624b\u52a8\u5207\u6362\u81f3\u56fe\u50cf\u751f\u6210\uff0c\u8fd9\u79cd\u5206\u6b65\u3001\u987a\u5e8f\u7684\u63a8\u7406\u8fc7\u7a0b\u9650\u5236\u4e86\u8de8\u6a21\u6001\u8026\u5408\uff0c\u65e0\u6cd5\u5b9e\u73b0\u81ea\u52a8\u5316\u7684\u591a\u6a21\u6001\u751f\u6210\u3002", "method": "\u91c7\u7528\u79bb\u7ebf\u3001\u5956\u52b1\u52a0\u6743\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u5b8c\u5168\u81ea\u751f\u6210\u7684\u5408\u6210\u6570\u636e\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u540e\u8bad\u7ec3\u6570\u636e\u7b56\u7565\uff0c\u5305\u62ec\u9488\u5bf9\u6027\u6570\u636e\u96c6\u3001\u901a\u7528\u56fe\u6587\u8bed\u6599\u548c\u57fa\u51c6\u5bf9\u9f50\u6570\u636e\u3002", "result": "\u5728\u56db\u4e2a\u591a\u6837\u5316\u7684\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u591a\u6a21\u6001\u56fe\u50cf\u751f\u6210\u6027\u80fd\u7684\u63d0\u5347\uff0c\u8868\u660e\u540c\u65f6\u5bf9\u6587\u672c\u548c\u56fe\u50cf\u6a21\u6001\u8fdb\u884c\u5956\u52b1\u52a0\u6743\u4ee5\u53ca\u7cbe\u5fc3\u8bbe\u8ba1\u540e\u8bad\u7ec3\u6570\u636e\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5b8c\u5168\u7edf\u4e00\u7684\u6587\u672c-\u56fe\u50cf\u751f\u6210\u53ef\u901a\u8fc7\u540e\u8bad\u7ec3\u5b9e\u73b0\uff0c\u4e14\u6709\u9488\u5bf9\u6027\u7684\u540e\u8bad\u7ec3\u6570\u636e\u914d\u5408\u53cc\u6a21\u6001\u5956\u52b1\u52a0\u6743\u80fd\u663e\u8457\u63d0\u5347T2I\u751f\u6210\u6548\u679c\u3002", "summary_cn": "\u6700\u8fd1\uff0c\u80fd\u591f\u8054\u5408\u751f\u6210\u6587\u672c\u548c\u56fe\u50cf\u7684\u7edf\u4e00\u591a\u6a21\u6001\u751f\u6210\u67b6\u6784\u5df2\u6210\u4e3a\u6587\u672c\u5230\u56fe\u50cf\uff08T2I\uff09\u5408\u6210\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u7136\u800c\uff0c\u8bb8\u591a\u73b0\u6709\u7cfb\u7edf\u4f9d\u8d56\u663e\u5f0f\u7684\u6a21\u6001\u5207\u6362\u673a\u5236\uff0c\u5373\u5148\u751f\u6210\u63a8\u7406\u6587\u672c\uff0c\u518d\u624b\u52a8\u5207\u6362\u5230\u56fe\u50cf\u751f\u6210\u9636\u6bb5\u3002\u8fd9\u79cd\u5206\u79bb\u7684\u3001\u987a\u5e8f\u5f0f\u7684\u63a8\u7406\u8fc7\u7a0b\u9650\u5236\u4e86\u8de8\u6a21\u6001\u4e4b\u95f4\u7684\u8026\u5408\uff0c\u5e76\u963b\u788d\u4e86\u81ea\u52a8\u5316\u7684\u591a\u6a21\u6001\u751f\u6210\u3002\u672c\u7814\u7a76\u63a2\u7d22\u901a\u8fc7\u540e\u8bad\u7ec3\u5b9e\u73b0\u5b8c\u5168\u7edf\u4e00\u7684\u6587\u672c-\u56fe\u50cf\u751f\u6210\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u5355\u6b21\u63a8\u7406\u8fc7\u7a0b\u4e2d\u81ea\u4e3b\u5730\u4ece\u6587\u672c\u63a8\u7406\u8fc7\u6e21\u5230\u89c6\u89c9\u5408\u6210\u3002\u6211\u4eec\u8003\u5bdf\u4e86\u8054\u5408\u6587\u672c-\u56fe\u50cf\u751f\u6210\u5bf9T2I\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5728\u540e\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5404\u6a21\u6001\u7684\u76f8\u5bf9\u91cd\u8981\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63a2\u7d22\u4e86\u4e0d\u540c\u7684\u540e\u8bad\u7ec3\u6570\u636e\u7b56\u7565\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u9488\u5bf9\u7279\u5b9a\u5c40\u9650\u6027\u8bbe\u8ba1\u7684\u5b9a\u5411\u6570\u636e\u96c6\u76f8\u6bd4\u5e7f\u6cdb\u7684\u56fe\u50cf-\u6807\u9898\u8bed\u6599\u5e93\u6216\u4e0e\u57fa\u51c6\u5bf9\u9f50\u7684\u6570\u636e\u80fd\u53d6\u5f97\u66f4\u4f18\u7684\u6548\u679c\u3002\u901a\u8fc7\u91c7\u7528\u79bb\u7ebf\u3001\u5956\u52b1\u52a0\u6743\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u5b8c\u5168\u81ea\u751f\u6210\u7684\u5408\u6210\u6570\u636e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u56db\u4e2a\u591a\u6837\u5316\u7684T2I\u57fa\u51c6\u4e0a\u5747\u63d0\u5347\u4e86\u591a\u6a21\u6001\u56fe\u50cf\u751f\u6210\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5bf9\u4e24\u4e2a\u6a21\u6001\u540c\u65f6\u8fdb\u884c\u5956\u52b1\u52a0\u6743\u4ee5\u53ca\u6218\u7565\u6027\u8bbe\u8ba1\u540e\u8bad\u7ec3\u6570\u636e\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.04342", "pdf": "https://arxiv.org/pdf/2601.04342", "abs": "https://arxiv.org/abs/2601.04342", "authors": ["Mohsen Ghafoorian", "Amirhossein Habibian"], "title": "ReHyAt: Recurrent Hybrid Attention for Video Diffusion Transformers", "categories": ["cs.CV"], "comment": null, "summary": "Recent advances in video diffusion models have shifted towards transformer-based architectures, achieving state-of-the-art video generation but at the cost of quadratic attention complexity, which severely limits scalability for longer sequences. We introduce ReHyAt, a Recurrent Hybrid Attention mechanism that combines the fidelity of softmax attention with the efficiency of linear attention, enabling chunk-wise recurrent reformulation and constant memory usage. Unlike the concurrent linear-only SANA Video, ReHyAt's hybrid design allows efficient distillation from existing softmax-based models, reducing the training cost by two orders of magnitude to ~160 GPU hours, while being competitive in the quality. Our light-weight distillation and finetuning pipeline provides a recipe that can be applied to future state-of-the-art bidirectional softmax-based models. Experiments on VBench and VBench-2.0, as well as a human preference study, demonstrate that ReHyAt achieves state-of-the-art video quality while reducing attention cost from quadratic to linear, unlocking practical scalability for long-duration and on-device video generation. Project page is available at https://qualcomm-ai-research.github.io/rehyat.", "AI": {"tldr": "ReHyAt \u662f\u4e00\u79cd\u6df7\u5408\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7ed3\u5408\u4e86 softmax \u6ce8\u610f\u529b\u7684\u9ad8\u8d28\u91cf\u4e0e\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u9ad8\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u5e38\u91cf\u5185\u5b58\u4f7f\u7528\u548c\u7ebf\u6027\u590d\u6742\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u5e76\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e Transformer \u7684\u89c6\u9891\u6269\u6563\u6a21\u578b\u56e0\u91c7\u7528\u4e8c\u6b21\u590d\u6742\u5ea6\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u5b58\u5728\u53ef\u6269\u5c55\u6027\u74f6\u9888\u3002", "method": "\u63d0\u51fa ReHyAt\uff08Recurrent Hybrid Attention\uff09\u673a\u5236\uff0c\u878d\u5408 softmax \u6ce8\u610f\u529b\u4e0e\u7ebf\u6027\u6ce8\u610f\u529b\uff0c\u652f\u6301\u5206\u5757\u9012\u5f52\u91cd\u6784\u548c\u5e38\u91cf\u5185\u5b58\u5360\u7528\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u84b8\u998f\u4e0e\u5fae\u8c03\u6d41\u7a0b\u4ece\u73b0\u6709 softmax \u6a21\u578b\u9ad8\u6548\u8fc1\u79fb\u77e5\u8bc6\u3002", "result": "\u5728 VBench \u548c VBench-2.0 \u57fa\u51c6\u53ca\u4eba\u7c7b\u504f\u597d\u7814\u7a76\u4e2d\uff0cReHyAt \u5728\u5c06\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u81f3\u7ebf\u6027\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u89c6\u9891\u751f\u6210\u8d28\u91cf\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u81f3\u7ea6 160 GPU \u5c0f\u65f6\u3002", "conclusion": "ReHyAt \u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u4f4e\u590d\u6742\u5ea6\u7684\u89c6\u9891\u751f\u6210\uff0c\u4e3a\u672a\u6765\u53cc\u5411 softmax \u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u90e8\u7f72\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u957f\u65f6\u957f\u548c\u7aef\u4fa7\u89c6\u9891\u751f\u6210\u4efb\u52a1\u3002", "summary_cn": "\u8fd1\u671f\u89c6\u9891\u6269\u6563\u6a21\u578b\u7684\u7814\u7a76\u8f6c\u5411\u57fa\u4e8e Transformer \u7684\u67b6\u6784\uff0c\u5728\u89c6\u9891\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u4f46\u5176\u6ce8\u610f\u529b\u673a\u5236\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u5bf9\u66f4\u957f\u5e8f\u5217\u7684\u53ef\u6269\u5c55\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86 ReHyAt\uff08Recurrent Hybrid Attention\uff0c\u9012\u5f52\u6df7\u5408\u6ce8\u610f\u529b\uff09\u673a\u5236\uff0c\u8be5\u673a\u5236\u7ed3\u5408\u4e86 softmax \u6ce8\u610f\u529b\u7684\u9ad8\u4fdd\u771f\u5ea6\u4e0e\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u9ad8\u6548\u6027\uff0c\u652f\u6301\u5206\u5757\u9012\u5f52\u91cd\u6784\u5e76\u5b9e\u73b0\u6052\u5b9a\u5185\u5b58\u5360\u7528\u3002\u4e0e\u4ec5\u4f7f\u7528\u7ebf\u6027\u6ce8\u610f\u529b\u7684\u540c\u671f\u5de5\u4f5c SANA Video \u4e0d\u540c\uff0cReHyAt \u7684\u6df7\u5408\u8bbe\u8ba1\u4f7f\u5176\u80fd\u591f\u9ad8\u6548\u5730\u4ece\u73b0\u6709\u7684\u57fa\u4e8e softmax \u7684\u6a21\u578b\u4e2d\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\uff0c\u5c06\u8bad\u7ec3\u6210\u672c\u964d\u4f4e\u4e24\u4e2a\u6570\u91cf\u7ea7\u81f3\u7ea6 160 GPU \u5c0f\u65f6\uff0c\u540c\u65f6\u4fdd\u6301\u5177\u6709\u7ade\u4e89\u529b\u7684\u751f\u6210\u8d28\u91cf\u3002\u6211\u4eec\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u84b8\u998f\u4e0e\u5fae\u8c03\u6d41\u7a0b\u4e3a\u672a\u6765\u6700\u5148\u8fdb\u7684\u53cc\u5411 softmax \u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6848\u3002\u5728 VBench \u548c VBench-2.0 \u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u4eba\u7c7b\u504f\u597d\u7814\u7a76\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0cReHyAt \u5728\u5c06\u6ce8\u610f\u529b\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u4f4e\u81f3\u7ebf\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u89c6\u9891\u751f\u6210\u8d28\u91cf\uff0c\u4ece\u800c\u4e3a\u957f\u65f6\u957f\u89c6\u9891\u751f\u6210\u548c\u7aef\u4fa7\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u53ef\u6269\u5c55\u6027\u3002\u9879\u76ee\u9875\u9762\u89c1 https://qualcomm-ai-research.github.io/rehyat\u3002"}}
{"id": "2601.04348", "pdf": "https://arxiv.org/pdf/2601.04348", "abs": "https://arxiv.org/abs/2601.04348", "authors": ["Diego Revilla", "Pooja Suresh", "Anand Bhojan", "Ooi Wei Tsang"], "title": "SCAR-GS: Spatial Context Attention for Residuals in Progressive Gaussian Splatting", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "Recent advances in 3D Gaussian Splatting have allowed for real-time, high-fidelity novel view synthesis. Nonetheless, these models have significant storage requirements for large and medium-sized scenes, hindering their deployment over cloud and streaming services. Some of the most recent progressive compression techniques for these models rely on progressive masking and scalar quantization techniques to reduce the bitrate of Gaussian attributes using spatial context models. While effective, scalar quantization may not optimally capture the correlations of high-dimensional feature vectors, which can potentially limit the rate-distortion performance.\n  In this work, we introduce a novel progressive codec for 3D Gaussian Splatting that replaces traditional methods with a more powerful Residual Vector Quantization approach to compress the primitive features. Our key contribution is an auto-regressive entropy model, guided by a multi-resolution hash grid, that accurately predicts the conditional probability of each successive transmitted index, allowing for coarse and refinement layers to be compressed with high efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\u7684\u65b0\u578b\u6e10\u8fdb\u5f0f3D\u9ad8\u65af\u6cfc\u6e85\u538b\u7f29\u7f16\u89e3\u7801\u5668\uff0c\u5229\u7528\u591a\u5206\u8fa8\u7387\u54c8\u5e0c\u7f51\u683c\u5f15\u5bfc\u7684\u81ea\u56de\u5f52\u71b5\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u538b\u7f29\u6548\u7387\u3002", "motivation": "\u73b0\u67093D\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b\u5728\u4e2d\u5927\u578b\u573a\u666f\u4e2d\u5b58\u50a8\u9700\u6c42\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e91\u548c\u6d41\u5a92\u4f53\u670d\u52a1\u4e2d\u7684\u90e8\u7f72\uff1b\u800c\u5f53\u524d\u57fa\u4e8e\u6807\u91cf\u91cf\u5316\u7684\u6e10\u8fdb\u538b\u7f29\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u9ad8\u7ef4\u7279\u5f81\u5411\u91cf\u95f4\u7684\u76f8\u5173\u6027\uff0c\u5f71\u54cd\u7387\u5931\u771f\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6e10\u8fdb\u5f0f\u7f16\u89e3\u7801\u5668\uff0c\u91c7\u7528\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\uff08Residual Vector Quantization\uff09\u66ff\u4ee3\u4f20\u7edf\u6807\u91cf\u91cf\u5316\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7531\u591a\u5206\u8fa8\u7387\u54c8\u5e0c\u7f51\u683c\u5f15\u5bfc\u7684\u81ea\u56de\u5f52\u71b5\u6a21\u578b\uff0c\u7528\u4e8e\u51c6\u786e\u9884\u6d4b\u6bcf\u4e2a\u4f20\u8f93\u7d22\u5f15\u7684\u6761\u4ef6\u6982\u7387\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u9ad8\u6548\u538b\u7f29\u7c97\u7565\u5c42\u4e0e\u7ec6\u5316\u5c42\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u89c6\u56fe\u5408\u6210\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u6bd4\u7279\u7387\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\u548c\u81ea\u56de\u5f52\u71b5\u6a21\u578b\uff0c\u672c\u6587\u6709\u6548\u63d0\u5347\u4e863D\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b\u7684\u538b\u7f29\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u4f18\u89e3\u51b3\u65b9\u6848\u3002", "summary_cn": "\u8fd1\u671f3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u7684\u53d1\u5c55\u5b9e\u73b0\u4e86\u5b9e\u65f6\u3001\u9ad8\u4fdd\u771f\u7684\u65b0\u89c6\u89d2\u5408\u6210\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u4e2d\u5927\u578b\u573a\u666f\u4e2d\u5177\u6709\u8f83\u9ad8\u7684\u5b58\u50a8\u9700\u6c42\uff0c\u963b\u788d\u4e86\u5176\u5728\u4e91\u7aef\u548c\u6d41\u5a92\u4f53\u670d\u52a1\u4e2d\u7684\u90e8\u7f72\u3002\u76ee\u524d\u6700\u5148\u8fdb\u7684\u6e10\u8fdb\u538b\u7f29\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6e10\u8fdb\u63a9\u7801\u548c\u6807\u91cf\u91cf\u5316\u6280\u672f\uff0c\u5229\u7528\u7a7a\u95f4\u4e0a\u4e0b\u6587\u6a21\u578b\u6765\u964d\u4f4e\u9ad8\u65af\u5c5e\u6027\u7684\u6bd4\u7279\u7387\u3002\u5c3d\u7ba1\u6709\u6548\uff0c\u4f46\u6807\u91cf\u91cf\u5316\u53ef\u80fd\u65e0\u6cd5\u6700\u4f18\u5730\u6355\u6349\u9ad8\u7ef4\u7279\u5f81\u5411\u91cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4ece\u800c\u53ef\u80fd\u9650\u5236\u7387\u5931\u771f\u6027\u80fd\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u76843D\u9ad8\u65af\u6cfc\u6e85\u6e10\u8fdb\u5f0f\u7f16\u89e3\u7801\u5668\uff0c\u7528\u66f4\u5f3a\u5927\u7684\u6b8b\u5dee\u5411\u91cf\u91cf\u5316\u65b9\u6cd5\u66ff\u4ee3\u4f20\u7edf\u6280\u672f\u4ee5\u538b\u7f29\u56fe\u5143\u7279\u5f81\u3002\u6211\u4eec\u7684\u6838\u5fc3\u8d21\u732e\u662f\u4e00\u79cd\u7531\u591a\u5206\u8fa8\u7387\u54c8\u5e0c\u7f51\u683c\u5f15\u5bfc\u7684\u81ea\u56de\u5f52\u71b5\u6a21\u578b\uff0c\u80fd\u591f\u7cbe\u786e\u9884\u6d4b\u6bcf\u4e2a\u8fde\u7eed\u4f20\u8f93\u7d22\u5f15\u7684\u6761\u4ef6\u6982\u7387\uff0c\u4ece\u800c\u9ad8\u6548\u538b\u7f29\u7c97\u7565\u5c42\u548c\u7ec6\u5316\u5c42\u3002"}}
{"id": "2601.04352", "pdf": "https://arxiv.org/pdf/2601.04352", "abs": "https://arxiv.org/abs/2601.04352", "authors": ["Ibrahim Tanvir", "Alif Ruslan", "Sartaj Solaiman"], "title": "Comparative Analysis of Custom CNN Architectures versus Pre-trained Models and Transfer Learning: A Study on Five Bangladesh Datasets", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "This study presents a comprehensive comparative analysis of custom-built Convolutional Neural Networks (CNNs) against popular pre-trained architectures (ResNet-18 and VGG-16) using both feature extraction and transfer learning approaches. We evaluated these models across five diverse image classification datasets from Bangladesh: Footpath Vision, Auto Rickshaw Detection, Mango Image Classification, Paddy Variety Recognition, and Road Damage Detection. Our experimental results demonstrate that transfer learning with fine-tuning consistently outperforms both custom CNNs built from scratch and feature extraction methods, achieving accuracy improvements ranging from 3% to 76% across different datasets. Notably, ResNet-18 with fine-tuning achieved perfect 100% accuracy on the Road Damage BD dataset. While custom CNNs offer advantages in model size (3.4M parameters vs. 11-134M for pre-trained models) and training efficiency on simpler tasks, pre-trained models with transfer learning provide superior performance, particularly on complex classification tasks with limited training data. This research provides practical insights for practitioners in selecting appropriate deep learning approaches based on dataset characteristics, computational resources, and performance requirements.", "AI": {"tldr": "\u5728\u4e94\u4e2a\u5b5f\u52a0\u62c9\u56fd\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u5fae\u8c03\u7684\u8fc1\u79fb\u5b66\u4e60\uff08\u5c24\u5176\u662fResNet-18\uff09\u663e\u8457\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684\u81ea\u5b9a\u4e49CNN\u548c\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u5728\u90e8\u5206\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe76%\uff0c\u751a\u81f3\u8fbe\u5230100%\uff1b\u5c3d\u7ba1\u81ea\u5b9a\u4e49CNN\u53c2\u6570\u66f4\u5c11\u3001\u8bad\u7ec3\u66f4\u5feb\uff0c\u4f46\u8fc1\u79fb\u5b66\u4e60\u5728\u590d\u6742\u6216\u5c0f\u6837\u672c\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u4e3a\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u9009\u62e9\u5408\u9002\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u81ea\u5b9a\u4e49CNN vs. \u9884\u8bad\u7ec3\u6a21\u578b+\u8fc1\u79fb\u5b66\u4e60\uff09\u7f3a\u4e4f\u9488\u5bf9\u7279\u5b9a\u5730\u533a\uff08\u5982\u5b5f\u52a0\u62c9\u56fd\uff09\u591a\u6837\u6570\u636e\u96c6\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u9009\u578b\u4f9d\u636e\u3002", "method": "\u5bf9\u81ea\u5efaCNN\u4e0e\u4e24\u79cd\u4e3b\u6d41\u9884\u8bad\u7ec3\u6a21\u578b\uff08ResNet-18\u3001VGG-16\uff09\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5206\u522b\u91c7\u7528\u7279\u5f81\u63d0\u53d6\u548c\u5fae\u8c03\u4e24\u79cd\u8fc1\u79fb\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u4e94\u4e2a\u6765\u81ea\u5b5f\u52a0\u62c9\u56fd\u7684\u4e0d\u540c\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5fae\u8c03\u7684\u8fc1\u79fb\u5b66\u4e60\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u53473%-76%\uff1bResNet-18\u5fae\u8c03\u5728Road Damage BD\u6570\u636e\u96c6\u4e0a\u8fbe\u5230100%\u51c6\u786e\u7387\uff1b\u81ea\u5b9a\u4e49CNN\u53c2\u6570\u91cf\uff083.4M\uff09\u8fdc\u5c0f\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\uff0811M-134M\uff09\uff0c\u4e14\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u8bad\u7ec3\u66f4\u5feb\u3002", "conclusion": "\u5bf9\u4e8e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u6216\u6570\u636e\u96c6\u8f83\u7b80\u5355\u7684\u573a\u666f\uff0c\u53ef\u8003\u8651\u8f7b\u91cf\u7ea7\u81ea\u5b9a\u4e49CNN\uff1b\u4f46\u5728\u590d\u6742\u4efb\u52a1\u6216\u8bad\u7ec3\u6570\u636e\u6709\u9650\u65f6\uff0c\u91c7\u7528\u5fae\u8c03\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982ResNet-18\uff09\u80fd\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u662f\u66f4\u4f18\u7684\u9009\u62e9\u3002", "summary_cn": "\u672c\u7814\u7a76\u5bf9\u81ea\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u4e0e\u6d41\u884c\u7684\u9884\u8bad\u7ec3\u67b6\u6784\uff08ResNet-18\u548cVGG-16\uff09\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5bf9\u6bd4\u5206\u6790\uff0c\u91c7\u7528\u4e86\u7279\u5f81\u63d0\u53d6\u548c\u8fc1\u79fb\u5b66\u4e60\u4e24\u79cd\u65b9\u6cd5\u3002\u6211\u4eec\u5728\u4e94\u4e2a\u6765\u81ea\u5b5f\u52a0\u62c9\u56fd\u7684\u4e0d\u540c\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u6a21\u578b\uff1aFootpath Vision\u3001Auto Rickshaw Detection\u3001Mango Image Classification\u3001Paddy Variety Recognition\u548cRoad Damage Detection\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u4ece\u96f6\u5f00\u59cb\u6784\u5efa\u7684\u81ea\u5b9a\u4e49CNN\u548c\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u5347\u5e45\u5ea6\u57283%\u81f376%\u4e4b\u95f4\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u91c7\u7528\u5fae\u8c03\u7684ResNet-18\u5728Road Damage BD\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u5b8c\u7f8e\u7684100%\u51c6\u786e\u7387\u3002\u867d\u7136\u81ea\u5b9a\u4e49CNN\u5728\u6a21\u578b\u89c4\u6a21\uff08340\u4e07\u53c2\u6570\uff0c\u800c\u9884\u8bad\u7ec3\u6a21\u578b\u4e3a1100\u4e07\u81f31.34\u4ebf\u53c2\u6570\uff09\u548c\u7b80\u5355\u4efb\u52a1\u7684\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u590d\u6742\u5206\u7c7b\u4efb\u52a1\uff08\u5c24\u5176\u662f\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff09\u63d0\u4f9b\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002\u672c\u7814\u7a76\u4e3a\u4ece\u4e1a\u8005\u6839\u636e\u6570\u636e\u96c6\u7279\u6027\u3001\u8ba1\u7b97\u8d44\u6e90\u548c\u6027\u80fd\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2601.04359", "pdf": "https://arxiv.org/pdf/2601.04359", "abs": "https://arxiv.org/abs/2601.04359", "authors": ["Kunyang Li", "Mubarak Shah", "Yuzhang Shang"], "title": "PackCache: A Training-Free Acceleration Method for Unified Autoregressive Video Generation via Compact KV-Cache", "categories": ["cs.CV"], "comment": null, "summary": "A unified autoregressive model is a Transformer-based framework that addresses diverse multimodal tasks (e.g., text, image, video) as a single sequence modeling problem under a shared token space. Such models rely on the KV-cache mechanism to reduce attention computation from O(T^2) to O(T); however, KV-cache size grows linearly with the number of generated tokens, and it rapidly becomes the dominant bottleneck limiting inference efficiency and generative length. Unified autoregressive video generation inherits this limitation. Our analysis reveals that KV-cache tokens exhibit distinct spatiotemporal properties: (i) text and conditioning-image tokens act as persistent semantic anchors that consistently receive high attention, and (ii) attention to previous frames naturally decays with temporal distance. Leveraging these observations, we introduce PackCache, a training-free KV-cache management method that dynamically compacts the KV cache through three coordinated mechanisms: condition anchoring that preserves semantic references, cross-frame decay modeling that allocates cache budget according to temporal distance, and spatially preserving position embedding that maintains coherent 3D structure under cache removal. In terms of efficiency, PackCache accelerates end-to-end generation by 1.7-2.2x on 48-frame long sequences, showcasing its strong potential for enabling longer-sequence video generation. Notably, the final four frames - the portion most impacted by the progressively expanding KV-cache and thus the most expensive segment of the clip - PackCache delivers a 2.6x and 3.7x acceleration on A40 and H200, respectively, for 48-frame videos.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPackCache\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684KV\u7f13\u5b58\u7ba1\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u6761\u4ef6\u951a\u5b9a\u3001\u8de8\u5e27\u8870\u51cf\u5efa\u6a21\u548c\u7a7a\u95f4\u4fdd\u7559\u4f4d\u7f6e\u7f16\u7801\uff0c\u663e\u8457\u52a0\u901f\u7edf\u4e00\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\uff0c\u5c24\u5176\u5728\u957f\u5e8f\u5217\u672b\u5c3e\u5e27\u4e0a\u63d0\u901f\u8fbe2.6\u20133.7\u500d\u3002", "motivation": "\u7edf\u4e00\u81ea\u56de\u5f52\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u4f9d\u8d56KV\u7f13\u5b58\u673a\u5236\uff0c\u4f46\u5176\u7f13\u5b58\u5927\u5c0f\u968f\u751f\u6210\u957f\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u6210\u4e3a\u63a8\u7406\u6548\u7387\u548c\u751f\u6210\u957f\u5ea6\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u5c24\u5176\u5728\u89c6\u9891\u751f\u6210\u4e2d\u66f4\u4e3a\u7a81\u51fa\u3002", "method": "\u4f5c\u8005\u5206\u6790KV\u7f13\u5b58\u4e2d\u4e0d\u540ctoken\u7684\u65f6\u7a7a\u7279\u6027\uff0c\u63d0\u51faPackCache\u65b9\u6cd5\uff0c\u5305\u542b\u4e09\u4e2a\u673a\u5236\uff1a\u4fdd\u7559\u8bed\u4e49\u53c2\u8003\u7684\u6761\u4ef6\u951a\u5b9a\u3001\u6839\u636e\u65f6\u95f4\u8ddd\u79bb\u5206\u914d\u7f13\u5b58\u9884\u7b97\u7684\u8de8\u5e27\u8870\u51cf\u5efa\u6a21\uff0c\u4ee5\u53ca\u5728\u7f13\u5b58\u538b\u7f29\u65f6\u7ef4\u63013D\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u7a7a\u95f4\u4fdd\u7559\u4f4d\u7f6e\u5d4c\u5165\u3002", "result": "PackCache\u572848\u5e27\u89c6\u9891\u751f\u6210\u4e2d\u5b9e\u73b01.7\u20132.2\u500d\u7684\u6574\u4f53\u52a0\u901f\uff0c\u5728\u6700\u8017\u65f6\u7684\u6700\u540e\u56db\u5e27\u4e0a\uff0c\u5206\u522b\u5728A40\u548cH200\u4e0a\u8fbe\u52302.6\u500d\u548c3.7\u500d\u52a0\u901f\u3002", "conclusion": "PackCache\u6709\u6548\u7f13\u89e3\u4e86\u7edf\u4e00\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u4e2d\u7684KV\u7f13\u5b58\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u957f\u5e8f\u5217\u751f\u6210\u6548\u7387\uff0c\u5177\u6709\u63a8\u52a8\u66f4\u957f\u89c6\u9891\u751f\u6210\u7684\u6f5c\u529b\u3002", "summary_cn": "\u7edf\u4e00\u81ea\u56de\u5f52\u6a21\u578b\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u6846\u67b6\uff0c\u5c06\u591a\u6837\u5316\u7684\u591a\u6a21\u6001\u4efb\u52a1\uff08\u5982\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\uff09\u89c6\u4e3a\u5171\u4eab\u8bcd\u5143\u7a7a\u95f4\u4e0b\u7684\u5355\u4e00\u5e8f\u5217\u5efa\u6a21\u95ee\u9898\u3002\u8fd9\u7c7b\u6a21\u578b\u4f9d\u8d56KV\u7f13\u5b58\u673a\u5236\u5c06\u6ce8\u610f\u529b\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(T\u00b2)\u964d\u81f3O(T)\uff1b\u7136\u800c\uff0cKV\u7f13\u5b58\u5927\u5c0f\u968f\u751f\u6210\u8bcd\u5143\u6570\u91cf\u7ebf\u6027\u589e\u957f\uff0c\u8fc5\u901f\u6210\u4e3a\u9650\u5236\u63a8\u7406\u6548\u7387\u548c\u751f\u6210\u957f\u5ea6\u7684\u4e3b\u8981\u74f6\u9888\u3002\u7edf\u4e00\u81ea\u56de\u5f52\u89c6\u9891\u751f\u6210\u4e5f\u7ee7\u627f\u4e86\u8fd9\u4e00\u9650\u5236\u3002\u6211\u4eec\u7684\u5206\u6790\u8868\u660e\uff0cKV\u7f13\u5b58\u4e2d\u7684\u8bcd\u5143\u8868\u73b0\u51fa\u660e\u663e\u7684\u65f6\u7a7a\u7279\u6027\uff1a(i) \u6587\u672c\u548c\u6761\u4ef6\u56fe\u50cf\u8bcd\u5143\u4f5c\u4e3a\u6301\u4e45\u7684\u8bed\u4e49\u951a\u70b9\uff0c\u59cb\u7ec8\u83b7\u5f97\u9ad8\u6ce8\u610f\u529b\u6743\u91cd\uff1b(ii) \u5bf9\u5148\u524d\u5e27\u7684\u6ce8\u610f\u529b\u968f\u65f6\u95f4\u8ddd\u79bb\u81ea\u7136\u8870\u51cf\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c2\u5bdf\uff0c\u6211\u4eec\u63d0\u51fa\u4e86PackCache\u2014\u2014\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684KV\u7f13\u5b58\u7ba1\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u79cd\u534f\u540c\u673a\u5236\u52a8\u6001\u538b\u7f29KV\u7f13\u5b58\uff1a\u4fdd\u7559\u8bed\u4e49\u53c2\u8003\u7684\u6761\u4ef6\u951a\u5b9a\u3001\u4f9d\u636e\u65f6\u95f4\u8ddd\u79bb\u5206\u914d\u7f13\u5b58\u9884\u7b97\u7684\u8de8\u5e27\u8870\u51cf\u5efa\u6a21\uff0c\u4ee5\u53ca\u5728\u7f13\u5b58\u79fb\u9664\u8fc7\u7a0b\u4e2d\u7ef4\u6301\u8fde\u8d2f\u4e09\u7ef4\u7ed3\u6784\u7684\u7a7a\u95f4\u4fdd\u7559\u4f4d\u7f6e\u5d4c\u5165\u3002\u5728\u6548\u7387\u65b9\u9762\uff0cPackCache\u572848\u5e27\u957f\u5e8f\u5217\u4e0a\u5b9e\u73b0\u4e861.7\u20132.2\u500d\u7684\u7aef\u5230\u7aef\u751f\u6210\u52a0\u901f\uff0c\u5c55\u73b0\u51fa\u5176\u5728\u652f\u6301\u66f4\u957f\u5e8f\u5217\u89c6\u9891\u751f\u6210\u65b9\u9762\u7684\u5f3a\u5927\u6f5c\u529b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u53d7KV\u7f13\u5b58\u6301\u7eed\u81a8\u80c0\u5f71\u54cd\u6700\u5927\u3001\u56e0\u800c\u8ba1\u7b97\u6210\u672c\u6700\u9ad8\u7684\u6700\u540e\u56db\u5e27\u90e8\u5206\uff0cPackCache\u5728A40\u548cH200\u4e0a\u5206\u522b\u5b9e\u73b0\u4e862.6\u500d\u548c3.7\u500d\u7684\u52a0\u901f\u3002"}}
{"id": "2601.04376", "pdf": "https://arxiv.org/pdf/2601.04376", "abs": "https://arxiv.org/abs/2601.04376", "authors": ["Paraskevi Valergaki", "Vassilis C. Nicodemou", "Iason Oikonomidis", "Antonis Argyros", "Anastasios Roussos"], "title": "Combining facial videos and biosignals for stress estimation during driving", "categories": ["cs.CV"], "comment": "UNDER SUBMISSION TO ICPR 2026", "summary": "Reliable stress recognition from facial videos is challenging due to stress's subjective nature and voluntary facial control. While most methods rely on Facial Action Units, the role of disentangled 3D facial geometry remains underexplored. We address this by analyzing stress during distracted driving using EMOCA-derived 3D expression and pose coefficients. Paired hypothesis tests between baseline and stressor phases reveal that 41 of 56 coefficients show consistent, phase-specific stress responses comparable to physiological markers. Building on this, we propose a Transformer-based temporal modeling framework and assess unimodal, early-fusion, and cross-modal attention strategies. Cross-Modal Attention fusion of EMOCA and physiological signals achieves best performance (AUROC 92\\%, Accuracy 86.7\\%), with EMOCA-gaze fusion also competitive (AUROC 91.8\\%). This highlights the effectiveness of temporal modeling and cross-modal attention for stress recognition.", "AI": {"tldr": "\u672c\u6587\u5229\u7528EMOCA\u63d0\u53d6\u76843D\u9762\u90e8\u8868\u60c5\u4e0e\u59ff\u6001\u7cfb\u6570\uff0c\u5728\u5206\u5fc3\u9a7e\u9a76\u573a\u666f\u4e0b\u5206\u6790\u538b\u529b\u53cd\u5e94\uff0c\u53d1\u73b0\u591a\u6570\u7cfb\u6570\u5177\u6709\u4e0e\u751f\u7406\u6307\u6807\u76f8\u5f53\u7684\u4e00\u81f4\u6027\uff1b\u8fdb\u4e00\u6b65\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u65f6\u5e8f\u5efa\u6a21\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u878d\u5408EMOCA\u4e0e\u751f\u7406\u4fe1\u53f7\uff0c\u5728\u538b\u529b\u8bc6\u522b\u4efb\u52a1\u4e2d\u53d6\u5f97\u6700\u4f18\u6027\u80fd\uff08AUROC 92%\uff0c\u51c6\u786e\u738786.7%\uff09\u3002", "motivation": "\u7531\u4e8e\u538b\u529b\u5177\u6709\u4e3b\u89c2\u6027\u4e14\u4eba\u4eec\u53ef\u81ea\u4e3b\u63a7\u5236\u9762\u90e8\u8868\u60c5\uff0c\u4ece\u9762\u90e8\u89c6\u9891\u4e2d\u53ef\u9760\u5730\u8bc6\u522b\u538b\u529b\u6781\u5177\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u9762\u90e8\u52a8\u4f5c\u5355\u5143\uff08Facial Action Units\uff09\uff0c\u800c\u89e3\u8026\u76843D\u9762\u90e8\u51e0\u4f55\u7279\u5f81\u5728\u538b\u529b\u8bc6\u522b\u4e2d\u7684\u4f5c\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f5c\u8005\u4f7f\u7528EMOCA\u6a21\u578b\u63d0\u53d63D\u9762\u90e8\u8868\u60c5\u548c\u59ff\u6001\u7cfb\u6570\uff0c\u5728\u5206\u5fc3\u9a7e\u9a76\u60c5\u5883\u4e0b\u5bf9\u6bd4\u57fa\u7ebf\u9636\u6bb5\u4e0e\u538b\u529b\u9636\u6bb5\u7684\u6570\u636e\uff1b\u91c7\u7528\u914d\u5bf9\u5047\u8bbe\u68c0\u9a8c\u8bc6\u522b\u51fa\u5177\u6709\u663e\u8457\u76f8\u4f4d\u7279\u5f02\u6027\u54cd\u5e94\u7684\u7cfb\u6570\uff0c\u5e76\u6784\u5efa\u57fa\u4e8eTransformer\u7684\u65f6\u5e8f\u5efa\u6a21\u6846\u67b6\uff0c\u8bc4\u4f30\u5355\u6a21\u6001\u3001\u65e9\u671f\u878d\u5408\u548c\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u4e09\u79cd\u878d\u5408\u7b56\u7565\u3002", "result": "56\u4e2a\u7cfb\u6570\u4e2d\u670941\u4e2a\u5728\u538b\u529b\u9636\u6bb5\u8868\u73b0\u51fa\u4e0e\u751f\u7406\u6307\u6807\u76f8\u5f53\u7684\u4e00\u81f4\u6027\uff1b\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u878d\u5408EMOCA\u4e0e\u751f\u7406\u4fe1\u53f7\u6548\u679c\u6700\u4f73\uff08AUROC 92%\uff0c\u51c6\u786e\u738786.7%\uff09\uff0cEMOCA\u4e0e\u6ce8\u89c6\u4fe1\u606f\u878d\u5408\u4e5f\u8868\u73b0\u4f18\u5f02\uff08AUROC 91.8%\uff09\u3002", "conclusion": "3D\u9762\u90e8\u51e0\u4f55\u7279\u5f81\uff08\u7279\u522b\u662fEMOCA\u7cfb\u6570\uff09\u80fd\u6709\u6548\u53cd\u6620\u538b\u529b\u72b6\u6001\uff1b\u7ed3\u5408\u65f6\u5e8f\u5efa\u6a21\u4e0e\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u53ef\u663e\u8457\u63d0\u5347\u538b\u529b\u8bc6\u522b\u6027\u80fd\uff0c\u4e3a\u975e\u63a5\u89e6\u5f0f\u538b\u529b\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u7531\u4e8e\u538b\u529b\u5177\u6709\u4e3b\u89c2\u6027\u4e14\u4eba\u4eec\u80fd\u591f\u81ea\u4e3b\u63a7\u5236\u9762\u90e8\u8868\u60c5\uff0c\u4ece\u9762\u90e8\u89c6\u9891\u4e2d\u53ef\u9760\u5730\u8bc6\u522b\u538b\u529b\u6781\u5177\u6311\u6218\u6027\u3002\u5c3d\u7ba1\u5927\u591a\u6570\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9762\u90e8\u52a8\u4f5c\u5355\u5143\uff08Facial Action Units\uff09\uff0c\u4f46\u89e3\u8026\u76843D\u9762\u90e8\u51e0\u4f55\u7279\u5f81\u5728\u538b\u529b\u8bc6\u522b\u4e2d\u7684\u4f5c\u7528\u4ecd\u9c9c\u6709\u7814\u7a76\u3002\u672c\u6587\u901a\u8fc7\u4f7f\u7528EMOCA\u63d0\u53d6\u76843D\u8868\u60c5\u4e0e\u59ff\u6001\u7cfb\u6570\uff0c\u5728\u5206\u5fc3\u9a7e\u9a76\u60c5\u5883\u4e0b\u5206\u6790\u538b\u529b\u53cd\u5e94\u3002\u57fa\u7ebf\u9636\u6bb5\u4e0e\u538b\u529b\u9636\u6bb5\u4e4b\u95f4\u7684\u914d\u5bf9\u5047\u8bbe\u68c0\u9a8c\u8868\u660e\uff0c56\u4e2a\u7cfb\u6570\u4e2d\u670941\u4e2a\u5448\u73b0\u51fa\u4e0e\u751f\u7406\u6307\u6807\u76f8\u5f53\u7684\u4e00\u81f4\u6027\u4e14\u5177\u6709\u9636\u6bb5\u7279\u5f02\u6027\u7684\u538b\u529b\u54cd\u5e94\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u65f6\u5e8f\u5efa\u6a21\u6846\u67b6\uff0c\u5e76\u8bc4\u4f30\u4e86\u5355\u6a21\u6001\u3001\u65e9\u671f\u878d\u5408\u4ee5\u53ca\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u7b49\u4e0d\u540c\u878d\u5408\u7b56\u7565\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cEMOCA\u4e0e\u751f\u7406\u4fe1\u53f7\u7684\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u878d\u5408\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff08AUROC\u8fbe92%\uff0c\u51c6\u786e\u7387\u4e3a86.7%\uff09\uff0c\u800cEMOCA\u4e0e\u6ce8\u89c6\u4fe1\u606f\u7684\u878d\u5408\u4e5f\u8868\u73b0\u4f18\u5f02\uff08AUROC\u4e3a91.8%\uff09\u3002\u8be5\u7814\u7a76\u7a81\u663e\u4e86\u65f6\u5e8f\u5efa\u6a21\u4e0e\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u5728\u538b\u529b\u8bc6\u522b\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.04381", "pdf": "https://arxiv.org/pdf/2601.04381", "abs": "https://arxiv.org/abs/2601.04381", "authors": ["Maxim Clouser", "Kia Khezeli", "John Kalantari"], "title": "Few-Shot LoRA Adaptation of a Flow-Matching Foundation Model for Cross-Spectral Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Foundation models for vision are predominantly trained on RGB data, while many safety-critical applications rely on non-visible modalities such as infrared (IR) and synthetic aperture radar (SAR). We study whether a single flow-matching foundation model pre-trained primarily on RGB images can be repurposed as a cross-spectral translator using only a few co-measured examples, and whether the resulting synthetic data can enhance downstream detection. Starting from FLUX.1 Kontext, we insert low-rank adaptation (LoRA) modules and fine-tune them on just 100 paired images per domain for two settings: RGB to IR on the KAIST dataset and RGB to SAR on the M4-SAR dataset. The adapted model translates RGB images into pixel-aligned IR/SAR, enabling us to reuse existing bounding boxes and train object detection models purely in the target modality. Across a grid of LoRA hyperparameters, we find that LPIPS computed on only 50 held-out pairs is a strong proxy for downstream performance: lower LPIPS consistently predicts higher mAP for YOLOv11n on both IR and SAR, and for DETR on KAIST IR test data. Using the best LPIPS-selected LoRA adapter, synthetic IR from external RGB datasets (LLVIP, FLIR ADAS) improves KAIST IR pedestrian detection, and synthetic SAR significantly boosts infrastructure detection on M4-SAR when combined with limited real SAR. Our results suggest that few-shot LoRA adaptation of flow-matching foundation models is a promising path toward foundation-style support for non-visible modalities.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u901a\u8fc7\u5c11\u91cf\u914d\u5bf9\u6837\u672c\uff0c\u5c06\u4e3b\u8981\u5728RGB\u56fe\u50cf\u4e0a\u9884\u8bad\u7ec3\u7684\u6d41\u5339\u914d\u57fa\u7840\u6a21\u578b\uff08FLUX.1 Kontext\uff09\u9002\u914d\u4e3a\u8de8\u5149\u8c31\u7ffb\u8bd1\u5668\uff0c\u4ee5\u751f\u6210\u7ea2\u5916\uff08IR\uff09\u548c\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\uff08SAR\uff09\u56fe\u50cf\uff0c\u5e76\u7528\u4e8e\u63d0\u5347\u4e0b\u6e38\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u3002\u901a\u8fc7\u5728\u6bcf\u4e2a\u57df\u4ec5\u4f7f\u7528100\u5f20\u914d\u5bf9\u56fe\u50cf\u5fae\u8c03\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u6a21\u5757\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u50cf\u7d20\u5bf9\u9f50\u7684IR/SAR\u56fe\u50cf\uff0c\u4ece\u800c\u590d\u7528\u73b0\u6709\u8fb9\u754c\u6846\u8bad\u7ec3\u7eaf\u76ee\u6807\u6a21\u6001\u4e0b\u7684\u68c0\u6d4b\u5668\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4ec5\u752850\u5f20\u4fdd\u7559\u56fe\u50cf\u8ba1\u7b97\u7684LPIPS\u6307\u6807\u53ef\u6709\u6548\u9884\u6d4b\u4e0b\u6e38\u68c0\u6d4b\u6027\u80fd\uff08mAP\uff09\uff0c\u4e14\u5229\u7528\u5916\u90e8RGB\u6570\u636e\u96c6\u751f\u6210\u7684\u5408\u6210IR/SAR\u56fe\u50cf\u663e\u8457\u63d0\u5347\u4e86KAIST IR\u884c\u4eba\u68c0\u6d4b\u548cM4-SAR\u57fa\u7840\u8bbe\u65bd\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u4e3b\u8981\u5728RGB\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u800c\u8bb8\u591a\u5b89\u5168\u5173\u952e\u5e94\u7528\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\u3001\u9065\u611f\uff09\u4f9d\u8d56\u975e\u53ef\u89c1\u5149\u6a21\u6001\uff08\u5982\u7ea2\u5916\u3001SAR\uff09\u3002\u5982\u4f55\u5229\u7528\u73b0\u6709\u5f3a\u5927\u7684RGB\u57fa\u7840\u6a21\u578b\uff0c\u4ee5\u6781\u5c11\u91cf\u6837\u672c\u5feb\u901f\u9002\u914d\u5230\u8fd9\u4e9b\u975e\u53ef\u89c1\u5149\u6a21\u6001\uff0c\u662f\u5b9e\u73b0\u9ad8\u6548\u8de8\u6a21\u6001\u611f\u77e5\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u9884\u8bad\u7ec3\u7684\u6d41\u5339\u914d\u57fa\u7840\u6a21\u578bFLUX.1 Kontext\uff0c\u63d2\u5165\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u6a21\u5757\uff0c\u5e76\u5728KAIST\uff08RGB\u2192IR\uff09\u548cM4-SAR\uff08RGB\u2192SAR\uff09\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u5206\u522b\u4ec5\u4f7f\u7528100\u5f20\u914d\u5bf9\u56fe\u50cf\u8fdb\u884c\u5fae\u8c03\u3002\u5229\u7528\u751f\u6210\u7684\u50cf\u7d20\u5bf9\u9f50\u5408\u6210\u56fe\u50cf\uff0c\u5728\u76ee\u6807\u6a21\u6001\u4e0b\u8bad\u7ec3YOLOv11n\u548cDETR\u7b49\u68c0\u6d4b\u5668\u3002\u901a\u8fc7\u7f51\u683c\u641c\u7d22LoRA\u8d85\u53c2\u6570\uff0c\u5e76\u4ee5LPIPS\u4f5c\u4e3a\u4e0b\u6e38\u6027\u80fd\u7684\u4ee3\u7406\u6307\u6807\u3002", "result": "1. LPIPS\u5728\u4ec550\u5f20\u4fdd\u7559\u56fe\u50cf\u4e0a\u7684\u8868\u73b0\u80fd\u5f3a\u76f8\u5173\u5730\u9884\u6d4b\u4e0b\u6e38\u68c0\u6d4bmAP\uff1b2. \u5229\u7528LLVIP\u3001FLIR ADAS\u7b49\u5916\u90e8RGB\u6570\u636e\u751f\u6210\u7684\u5408\u6210IR\u56fe\u50cf\uff0c\u63d0\u5347\u4e86KAIST IR\u884c\u4eba\u68c0\u6d4b\u6027\u80fd\uff1b3. \u5408\u6210SAR\u56fe\u50cf\u4e0e\u5c11\u91cf\u771f\u5b9eSAR\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86M4-SAR\u4e0a\u7684\u57fa\u7840\u8bbe\u65bd\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "\u5c11\u91cf\u6837\u672c\uff08few-shot\uff09\u7684LoRA\u9002\u914d\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5c06\u6d41\u5339\u914d\u57fa\u7840\u6a21\u578b\u8f6c\u5316\u4e3a\u8de8\u5149\u8c31\u7ffb\u8bd1\u5668\uff0c\u4e3a\u975e\u53ef\u89c1\u5149\u6a21\u6001\u63d0\u4f9b\u7c7b\u4f3c\u57fa\u7840\u6a21\u578b\u7684\u652f\u6301\uff0c\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u6280\u672f\u8def\u5f84\u3002", "summary_cn": "\u89c6\u89c9\u9886\u57df\u7684\u57fa\u7840\u6a21\u578b\u4e3b\u8981\u5728RGB\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u800c\u8bb8\u591a\u5b89\u5168\u5173\u952e\u578b\u5e94\u7528\u5219\u4f9d\u8d56\u4e8e\u7ea2\u5916\uff08IR\uff09\u548c\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\uff08SAR\uff09\u7b49\u975e\u53ef\u89c1\u5149\u6a21\u6001\u3002\u6211\u4eec\u7814\u7a76\u4e86\u662f\u5426\u53ef\u4ee5\u5c06\u4e00\u4e2a\u4e3b\u8981\u5728RGB\u56fe\u50cf\u4e0a\u9884\u8bad\u7ec3\u7684\u6d41\u5339\u914d\u57fa\u7840\u6a21\u578b\uff0c\u4ec5\u901a\u8fc7\u5c11\u91cf\u5171\u6d4b\u6837\u672c\u91cd\u65b0\u7528\u4e8e\u8de8\u5149\u8c31\u7ffb\u8bd1\uff0c\u5e76\u63a2\u7a76\u7531\u6b64\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u80fd\u5426\u63d0\u5347\u4e0b\u6e38\u68c0\u6d4b\u4efb\u52a1\u7684\u6027\u80fd\u3002\u6211\u4eec\u4eceFLUX.1 Kontext\u6a21\u578b\u51fa\u53d1\uff0c\u63d2\u5165\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u6a21\u5757\uff0c\u5e76\u5728\u4e24\u4e2a\u573a\u666f\u4e2d\u5206\u522b\u4ec5\u4f7f\u7528\u6bcf\u57df100\u5f20\u914d\u5bf9\u56fe\u50cf\u8fdb\u884c\u5fae\u8c03\uff1a\u5728KAIST\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0RGB\u5230IR\u7684\u8f6c\u6362\uff0c\u5728M4-SAR\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0RGB\u5230SAR\u7684\u8f6c\u6362\u3002\u7ecf\u8fc7\u9002\u914d\u7684\u6a21\u578b\u80fd\u591f\u5c06RGB\u56fe\u50cf\u7ffb\u8bd1\u4e3a\u50cf\u7d20\u5bf9\u9f50\u7684IR/SAR\u56fe\u50cf\uff0c\u4ece\u800c\u8ba9\u6211\u4eec\u80fd\u591f\u590d\u7528\u73b0\u6709\u7684\u8fb9\u754c\u6846\uff0c\u5e76\u7eaf\u7cb9\u5728\u76ee\u6807\u6a21\u6001\u4e0b\u8bad\u7ec3\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\u3002\u5728\u4e00\u7cfb\u5217LoRA\u8d85\u53c2\u6570\u7684\u7f51\u683c\u641c\u7d22\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u4ec5\u57fa\u4e8e50\u5f20\u4fdd\u7559\u914d\u5bf9\u56fe\u50cf\u8ba1\u7b97\u7684LPIPS\u6307\u6807\u662f\u4e0b\u6e38\u6027\u80fd\u7684\u5f3a\u6709\u529b\u4ee3\u7406\u6307\u6807\uff1a\u66f4\u4f4e\u7684LPIPS\u503c\u59cb\u7ec8\u9884\u793a\u7740YOLOv11n\u5728IR\u548cSAR\u4e0a\u4ee5\u53caDETR\u5728KAIST IR\u6d4b\u8bd5\u6570\u636e\u4e0a\u66f4\u9ad8\u7684mAP\u3002\u5229\u7528\u57fa\u4e8e\u6700\u4f73LPIPS\u9009\u62e9\u7684LoRA\u9002\u914d\u5668\uff0c\u4ece\u5916\u90e8RGB\u6570\u636e\u96c6\uff08LLVIP\u3001FLIR ADAS\uff09\u751f\u6210\u7684\u5408\u6210IR\u56fe\u50cf\u63d0\u5347\u4e86KAIST IR\u884c\u4eba\u68c0\u6d4b\u6027\u80fd\uff1b\u800c\u5408\u6210SAR\u56fe\u50cf\u5728\u4e0e\u6709\u9650\u7684\u771f\u5b9eSAR\u6570\u636e\u7ed3\u5408\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86M4-SAR\u4e0a\u7684\u57fa\u7840\u8bbe\u65bd\u68c0\u6d4b\u6548\u679c\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u6d41\u5339\u914d\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5c11\u91cf\u6837\u672c\u7684LoRA\u9002\u914d\uff0c\u662f\u4e3a\u975e\u53ef\u89c1\u5149\u6a21\u6001\u63d0\u4f9b\u57fa\u7840\u6a21\u578b\u7ea7\u652f\u6301\u7684\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2601.04397", "pdf": "https://arxiv.org/pdf/2601.04397", "abs": "https://arxiv.org/abs/2601.04397", "authors": ["Mohammed Sami Khan", "Fabiha Muniat", "Rowzatul Zannat"], "title": "Performance Analysis of Image Classification on Bangladeshi Datasets", "categories": ["cs.CV"], "comment": null, "summary": "Convolutional Neural Networks (CNNs) have demonstrated remarkable success in image classification tasks; however, the choice between designing a custom CNN from scratch and employing established pre-trained architectures remains an important practical consideration. In this work, we present a comparative analysis of a custom-designed CNN and several widely used deep learning architectures, including VGG-16, ResNet-50, and MobileNet, for an image classification task. The custom CNN is developed and trained from scratch, while the popular architectures are employed using transfer learning under identical experimental settings. All models are evaluated using standard performance metrics such as accuracy, precision, recall, and F1-score. Experimental results show that pre-trained CNN architectures consistently outperform the custom CNN in terms of classification accuracy and convergence speed, particularly when training data is limited. However, the custom CNN demonstrates competitive performance with significantly fewer parameters and reduced computational complexity. This study highlights the trade-offs between model complexity, performance, and computational efficiency, and provides practical insights into selecting appropriate CNN architectures for image classification problems.", "AI": {"tldr": "\u9884\u8bad\u7ec3CNN\u5728\u51c6\u786e\u7387\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u81ea\u5b9a\u4e49CNN\uff0c\u4f46\u81ea\u5b9a\u4e49\u6a21\u578b\u53c2\u6570\u66f4\u5c11\u3001\u8ba1\u7b97\u66f4\u9ad8\u6548\u3002", "motivation": "\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u9009\u62e9\u4ece\u5934\u8bbe\u8ba1\u81ea\u5b9a\u4e49CNN\u8fd8\u662f\u4f7f\u7528\u9884\u8bad\u7ec3\u67b6\u6784\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u5b9e\u9645\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u6bd4\u8f83\u4e24\u8005\u4f18\u52a3\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u81ea\u5b9a\u4e49CNN\u5e76\u4ece\u5934\u8bad\u7ec3\uff0c\u540c\u65f6\u5728\u76f8\u540c\u5b9e\u9a8c\u6761\u4ef6\u4e0b\u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u5bf9VGG-16\u3001ResNet-50\u548cMobileNet\u7b49\u4e3b\u6d41\u67b6\u6784\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u7528\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u6307\u6807\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u5206\u7c7b\u51c6\u786e\u7387\u548c\u6536\u655b\u901f\u5ea6\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u81ea\u5b9a\u4e49CNN\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u65f6\uff1b\u4f46\u81ea\u5b9a\u4e49CNN\u4ee5\u66f4\u5c11\u53c2\u6570\u548c\u66f4\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u3001\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4e3a\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2dCNN\u67b6\u6784\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002", "summary_cn": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6210\u529f\uff1b\u7136\u800c\uff0c\u5728\u4ece\u5934\u8bbe\u8ba1\u81ea\u5b9a\u4e49CNN\u4e0e\u91c7\u7528\u6210\u719f\u7684\u9884\u8bad\u7ec3\u67b6\u6784\u4e4b\u95f4\u505a\u51fa\u9009\u62e9\u4ecd\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u5b9e\u9645\u8003\u91cf\u3002\u672c\u6587\u5bf9\u4e00\u79cd\u81ea\u5b9a\u4e49\u8bbe\u8ba1\u7684CNN\u4e0e\u82e5\u5e72\u5e7f\u6cdb\u4f7f\u7528\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff08\u5305\u62ecVGG-16\u3001ResNet-50\u548cMobileNet\uff09\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\u3002\u81ea\u5b9a\u4e49CNN\u4ece\u96f6\u5f00\u59cb\u5f00\u53d1\u548c\u8bad\u7ec3\uff0c\u800c\u4e3b\u6d41\u67b6\u6784\u5219\u5728\u76f8\u540c\u7684\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\u65b9\u5f0f\u8fdb\u884c\u5e94\u7528\u3002\u6240\u6709\u6a21\u578b\u5747\u4f7f\u7528\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u7b49\u6807\u51c6\u6027\u80fd\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u9884\u8bad\u7ec3CNN\u67b6\u6784\u5728\u5206\u7c7b\u51c6\u786e\u7387\u548c\u6536\u655b\u901f\u5ea6\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u81ea\u5b9a\u4e49CNN\uff0c\u5c24\u5176\u662f\u5728\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u7136\u800c\uff0c\u81ea\u5b9a\u4e49CNN\u5728\u53c2\u6570\u6570\u91cf\u663e\u8457\u66f4\u5c11\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\u7684\u524d\u63d0\u4e0b\uff0c\u4ecd\u5c55\u73b0\u51fa\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002\u672c\u7814\u7a76\u7a81\u663e\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u3001\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u4e3a\u56fe\u50cf\u5206\u7c7b\u95ee\u9898\u4e2d\u9009\u62e9\u5408\u9002\u7684CNN\u67b6\u6784\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
