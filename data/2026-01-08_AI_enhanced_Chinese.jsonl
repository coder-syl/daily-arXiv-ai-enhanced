{"id": "2601.03286", "pdf": "https://arxiv.org/pdf/2601.03286", "abs": "https://arxiv.org/abs/2601.03286", "authors": ["NAVER Cloud HyperCLOVA X Team"], "title": "HyperCLOVA X 32B Think", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "Technical Report", "summary": "In this report, we present HyperCLOVA X 32B Think, a vision-language model designed with particular emphasis on reasoning within the Korean linguistic and cultural context, as well as agentic ability. HyperCLOVA X 32B Think is pre-trained with a strong focus on reasoning capabilities and subsequently post-trained to support multimodal understanding, enhanced reasoning, agentic behaviors, and alignment with human preferences. Experimental evaluations against comparably sized models demonstrate that our model achieves strong performance on Korean text-to-text and vision-to-text benchmarks, as well as on agent-oriented evaluation tasks. By open-sourcing HyperCLOVA X 32B Think, we aim to support broader adoption and facilitate further research and innovation across both academic and industrial communities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 HyperCLOVA X 32B Think\uff0c\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u97e9\u8bed\u8bed\u5883\u63a8\u7406\u4e0e\u667a\u80fd\u4f53\u80fd\u529b\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u591a\u9879\u97e9\u8bed\u53ca\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u7814\u7a76\u4e0e\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u9488\u5bf9\u97e9\u8bed\u8bed\u8a00\u6587\u5316\u80cc\u666f\u4f18\u5316\u3001\u540c\u65f6\u5177\u5907\u5f3a\u5927\u591a\u6a21\u6001\u7406\u89e3\u4e0e\u667a\u80fd\u4f53\u884c\u4e3a\u80fd\u529b\u7684\u5927\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u5728\u97e9\u8bed\u63a8\u7406\u3001\u89c6\u89c9-\u8bed\u8a00\u7406\u89e3\u548c\u667a\u80fd\u4f53\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u7684\u5f00\u6e90\u6a21\u578b\u3002", "method": "\u6a21\u578b\u9996\u5148\u8fdb\u884c\u4ee5\u63a8\u7406\u80fd\u529b\u4e3a\u91cd\u70b9\u7684\u9884\u8bad\u7ec3\uff0c\u968f\u540e\u901a\u8fc7\u540e\u8bad\u7ec3\u589e\u5f3a\u5176\u591a\u6a21\u6001\u7406\u89e3\u3001\u9ad8\u7ea7\u63a8\u7406\u3001\u667a\u80fd\u4f53\u884c\u4e3a\u4ee5\u53ca\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u3002", "result": "\u5728\u4e0e\u540c\u7c7b\u89c4\u6a21\u6a21\u578b\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\uff0cHyperCLOVA X 32B Think \u5728\u97e9\u8bed\u6587\u672c\u5230\u6587\u672c\u3001\u89c6\u89c9\u5230\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u9762\u5411\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\u3002", "conclusion": "HyperCLOVA X 32B Think \u662f\u4e00\u4e2a\u5728\u97e9\u8bed\u548c\u591a\u6a21\u6001\u63a8\u7406\u65b9\u9762\u5177\u6709\u7ade\u4e89\u529b\u7684\u5f00\u6e90\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u53d1\u5e03\u6709\u52a9\u4e8e\u63a8\u52a8\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5728\u76f8\u5173\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u4e0e\u521b\u65b0\u3002", "summary_cn": "\u5728\u672c\u62a5\u544a\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 HyperCLOVA X 32B Think\uff0c\u8fd9\u662f\u4e00\u79cd\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u6ce8\u91cd\u5728\u97e9\u8bed\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u4ee5\u53ca\u667a\u80fd\u4f53\u884c\u4e3a\u3002\u8be5\u6a21\u578b\u9996\u5148\u7ecf\u8fc7\u4ee5\u63a8\u7406\u80fd\u529b\u4e3a\u91cd\u70b9\u7684\u9884\u8bad\u7ec3\uff0c\u968f\u540e\u901a\u8fc7\u540e\u8bad\u7ec3\u652f\u6301\u591a\u6a21\u6001\u7406\u89e3\u3001\u589e\u5f3a\u63a8\u7406\u3001\u667a\u80fd\u4f53\u884c\u4e3a\u4ee5\u53ca\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u5bf9\u9f50\u3002\u5728\u4e0e\u89c4\u6a21\u76f8\u5f53\u7684\u6a21\u578b\u8fdb\u884c\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5728\u97e9\u8bed\u6587\u672c\u5230\u6587\u672c\u3001\u89c6\u89c9\u5230\u6587\u672c\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u9762\u5411\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002\u901a\u8fc7\u5f00\u6e90 HyperCLOVA X 32B Think\uff0c\u6211\u4eec\u65e8\u5728\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u5e76\u4fc3\u8fdb\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5728\u76f8\u5173\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u4e0e\u521b\u65b0\u3002"}}
{"id": "2601.03302", "pdf": "https://arxiv.org/pdf/2601.03302", "abs": "https://arxiv.org/abs/2601.03302", "authors": ["Mohammad Rostami", "Atik Faysal", "Hongtao Xia", "Hadi Kasasbeh", "Ziang Gao", "Huaxia Wang"], "title": "CageDroneRF: A Large-Scale RF Benchmark and Toolkit for Drone Perception", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "We present CageDroneRF (CDRF), a large-scale benchmark for Radio-Frequency (RF) drone detection and identification built from real-world captures and systematically generated synthetic variants. CDRF addresses the scarcity and limited diversity of existing RF datasets by coupling extensive raw recordings with a principled augmentation pipeline that (i) precisely controls Signal-to-Noise Ratio (SNR), (ii) injects interfering emitters, and (iii) applies frequency shifts with label-consistent bounding-box transformations for detection. This dataset spans a wide range of contemporary drone models, many unavailable in current public datasets, and acquisition conditions, derived from data collected at the Rowan University campus and within a controlled RF-cage facility. CDRF is released with interoperable open-source tools for data generation, preprocessing, augmentation, and evaluation that also operate on existing public benchmarks. CDRF enables standardized benchmarking for classification, open-set recognition, and object detection, supporting rigorous comparisons and reproducible pipelines. By releasing this comprehensive benchmark and tooling, CDRF aims to accelerate progress toward robust, generalizable RF perception models.", "AI": {"tldr": "CageDroneRF (CDRF) is a large-scale, real-world and synthetically augmented RF drone detection benchmark that addresses dataset scarcity and diversity issues, offering standardized tools for classification, open-set recognition, and object detection.", "motivation": "Existing RF datasets for drone detection suffer from limited scale and diversity, hindering the development of robust and generalizable perception models.", "method": "CDRF combines extensive real-world RF recordings with a principled synthetic augmentation pipeline that controls SNR, injects interference, and applies frequency shifts with consistent label transformations; it also provides open-source tools for data handling and evaluation.", "result": "The dataset covers diverse contemporary drone models and acquisition conditions not found in current public datasets, enabling standardized and reproducible benchmarking across multiple RF perception tasks.", "conclusion": "By releasing CDRF and its associated tooling, the authors aim to foster progress in developing robust and generalizable RF-based drone detection and identification systems.", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86CageDroneRF\uff08CDRF\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u5c04\u9891\uff08RF\uff09\u65e0\u4eba\u673a\u68c0\u6d4b\u4e0e\u8bc6\u522b\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u91c7\u96c6\u7684\u6570\u636e\u4ee5\u53ca\u7cfb\u7edf\u751f\u6210\u7684\u5408\u6210\u53d8\u4f53\u6784\u5efa\u800c\u6210\u3002CDRF\u901a\u8fc7\u5c06\u5927\u91cf\u539f\u59cb\u5f55\u97f3\u4e0e\u4e00\u5957\u539f\u5219\u6027\u7684\u589e\u5f3a\u6d41\u7a0b\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u73b0\u6709RF\u6570\u636e\u96c6\u7a00\u7f3a\u4e14\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u8be5\u589e\u5f3a\u6d41\u7a0b\uff08i\uff09\u7cbe\u786e\u63a7\u5236\u4fe1\u566a\u6bd4\uff08SNR\uff09\uff0c\uff08ii\uff09\u6ce8\u5165\u5e72\u6270\u4fe1\u53f7\u6e90\uff0c\uff08iii\uff09\u5728\u4fdd\u6301\u6807\u7b7e\u4e00\u81f4\u6027\u7684\u524d\u63d0\u4e0b\u8fdb\u884c\u9891\u7387\u504f\u79fb\u5e76\u76f8\u5e94\u8c03\u6574\u68c0\u6d4b\u7528\u7684\u8fb9\u754c\u6846\u3002\u8be5\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u5f53\u524d\u591a\u79cd\u4e3b\u6d41\u65e0\u4eba\u673a\u578b\u53f7\uff08\u5176\u4e2d\u8bb8\u591a\u5728\u73b0\u6709\u516c\u5f00\u6570\u636e\u96c6\u4e2d\u4e0d\u53ef\u83b7\u53d6\uff09\u4ee5\u53ca\u591a\u6837\u5316\u7684\u91c7\u96c6\u6761\u4ef6\uff0c\u6570\u636e\u6765\u6e90\u4e8e\u7f57\u6587\u5927\u5b66\u6821\u56ed\u53ca\u53d7\u63a7\u7684\u5c04\u9891\u5c4f\u853d\u7b3c\u8bbe\u65bd\u3002CDRF\u540c\u65f6\u53d1\u5e03\u4e86\u53ef\u4e92\u64cd\u4f5c\u7684\u5f00\u6e90\u5de5\u5177\uff0c\u652f\u6301\u6570\u636e\u751f\u6210\u3001\u9884\u5904\u7406\u3001\u589e\u5f3a\u548c\u8bc4\u4f30\uff0c\u5e76\u517c\u5bb9\u73b0\u6709\u516c\u5f00\u57fa\u51c6\u3002CDRF\u4e3a\u5206\u7c7b\u3001\u5f00\u96c6\u8bc6\u522b\u548c\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u8bc4\u6d4b\u57fa\u51c6\uff0c\u652f\u6301\u4e25\u8c28\u7684\u6a21\u578b\u6bd4\u8f83\u548c\u53ef\u590d\u73b0\u7684\u5904\u7406\u6d41\u7a0b\u3002\u901a\u8fc7\u53d1\u5e03\u8fd9\u4e00\u5168\u9762\u7684\u57fa\u51c6\u6570\u636e\u96c6\u53ca\u76f8\u5173\u5de5\u5177\uff0cCDRF\u65e8\u5728\u52a0\u901f\u9c81\u68d2\u4e14\u53ef\u6cdb\u5316\u7684\u5c04\u9891\u611f\u77e5\u6a21\u578b\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2601.03305", "pdf": "https://arxiv.org/pdf/2601.03305", "abs": "https://arxiv.org/abs/2601.03305", "authors": ["Jiahang Tu", "Ye Li", "Yiming Wu", "Hanbin Zhao", "Chao Zhang", "Hui Qian"], "title": "Mass Concept Erasure in Diffusion Models with Concept Hierarchy", "categories": ["cs.CV", "cs.AI", "cs.CY"], "comment": "This paper has been accepted by AAAI 2026", "summary": "The success of diffusion models has raised concerns about the generation of unsafe or harmful content, prompting concept erasure approaches that fine-tune modules to suppress specific concepts while preserving general generative capabilities. However, as the number of erased concepts grows, these methods often become inefficient and ineffective, since each concept requires a separate set of fine-tuned parameters and may degrade the overall generation quality. In this work, we propose a supertype-subtype concept hierarchy that organizes erased concepts into a parent-child structure. Each erased concept is treated as a child node, and semantically related concepts (e.g., macaw, and bald eagle) are grouped under a shared parent node, referred to as a supertype concept (e.g., bird). Rather than erasing concepts individually, we introduce an effective and efficient group-wise suppression method, where semantically similar concepts are grouped and erased jointly by sharing a single set of learnable parameters. During the erasure phase, standard diffusion regularization is applied to preserve denoising process in unmasked regions. To mitigate the degradation of supertype generation caused by excessive erasure of semantically related subtypes, we propose a novel method called Supertype-Preserving Low-Rank Adaptation (SuPLoRA), which encodes the supertype concept information in the frozen down-projection matrix and updates only the up-projection matrix during erasure. Theoretical analysis demonstrates the effectiveness of SuPLoRA in mitigating generation performance degradation. We construct a more challenging benchmark that requires simultaneous erasure of concepts across diverse domains, including celebrities, objects, and pornographic content.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8d85\u7c7b\u578b-\u5b50\u7c7b\u578b\u5c42\u7ea7\u7ed3\u6784\u7684\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u8bed\u4e49\u76f8\u8fd1\u7684\u5b50\u6982\u5ff5\uff08\u5982\u4e0d\u540c\u9e1f\u7c7b\uff09\u5f52\u5165\u540c\u4e00\u8d85\u7c7b\u578b\uff08\u5982\u201c\u9e1f\u201d\uff09\uff0c\u5171\u4eab\u4e00\u7ec4\u53ef\u5b66\u4e60\u53c2\u6570\u8fdb\u884c\u8054\u5408\u64e6\u9664\uff0c\u4ece\u800c\u63d0\u5347\u6548\u7387\u4e0e\u6548\u679c\uff1b\u540c\u65f6\u5f15\u5165 SuPLoRA \u65b9\u6cd5\uff0c\u5728\u51bb\u7ed3\u4e0b\u6295\u5f71\u77e9\u9635\u4e2d\u7f16\u7801\u8d85\u7c7b\u578b\u4fe1\u606f\uff0c\u4ec5\u66f4\u65b0\u4e0a\u6295\u5f71\u77e9\u9635\uff0c\u4ee5\u7f13\u89e3\u56e0\u8fc7\u5ea6\u64e6\u9664\u5bfc\u81f4\u7684\u751f\u6210\u8d28\u91cf\u4e0b\u964d\uff0c\u5e76\u5728\u591a\u9886\u57df\u6df7\u5408\u6982\u5ff5\u64e6\u9664\u7684\u65b0\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\u5728\u9762\u5bf9\u591a\u4e2a\u9700\u64e6\u9664\u6982\u5ff5\u65f6\u6548\u7387\u4f4e\u4e0b\u4e14\u6613\u635f\u5bb3\u6574\u4f53\u751f\u6210\u8d28\u91cf\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6982\u5ff5\u9700\u5355\u72ec\u5fae\u8c03\u53c2\u6570\uff0c\u7f3a\u4e4f\u5bf9\u8bed\u4e49\u76f8\u5173\u6027\u7684\u5229\u7528\u3002", "method": "\u6784\u5efa\u8d85\u7c7b\u578b-\u5b50\u7c7b\u578b\u6982\u5ff5\u5c42\u7ea7\u7ed3\u6784\uff0c\u5c06\u8bed\u4e49\u76f8\u8fd1\u7684\u5b50\u6982\u5ff5\u5f52\u5165\u540c\u4e00\u8d85\u7c7b\u578b\uff0c\u5e76\u901a\u8fc7\u5171\u4eab\u53c2\u6570\u5b9e\u73b0\u7ec4\u7ea7\u8054\u5408\u64e6\u9664\uff1b\u63d0\u51fa SuPLoRA \u65b9\u6cd5\uff0c\u5728\u4f4e\u79e9\u9002\u914d\u4e2d\u51bb\u7ed3\u4e0b\u6295\u5f71\u77e9\u9635\u4ee5\u4fdd\u7559\u8d85\u7c7b\u578b\u4fe1\u606f\uff0c\u4ec5\u66f4\u65b0\u4e0a\u6295\u5f71\u77e9\u9635\uff1b\u5728\u64e6\u9664\u9636\u6bb5\u5bf9\u672a\u906e\u853d\u533a\u57df\u65bd\u52a0\u6807\u51c6\u6269\u6563\u6b63\u5219\u5316\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u5305\u542b\u540d\u4eba\u3001\u7269\u4f53\u548c\u8272\u60c5\u5185\u5bb9\u7b49\u591a\u9886\u57df\u6df7\u5408\u6982\u5ff5\u7684\u540c\u65f6\u64e6\u9664\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u751f\u6210\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u6982\u5ff5\u5c42\u7ea7\u7ed3\u6784\u548c SuPLoRA \u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u9ad8\u8d28\u91cf\u7684\u591a\u6982\u5ff5\u8054\u5408\u64e6\u9664\uff0c\u4e3a\u5927\u89c4\u6a21\u5b89\u5168\u5185\u5bb9\u63a7\u5236\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u6269\u6563\u6a21\u578b\u7684\u6210\u529f\u5f15\u53d1\u4e86\u5bf9\u5176\u751f\u6210\u4e0d\u5b89\u5168\u6216\u6709\u5bb3\u5185\u5bb9\u7684\u62c5\u5fe7\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u63d0\u51fa\u6982\u5ff5\u64e6\u9664\u65b9\u6cd5\uff0c\u901a\u8fc7\u5fae\u8c03\u6a21\u5757\u6765\u6291\u5236\u7279\u5b9a\u6982\u5ff5\uff0c\u540c\u65f6\u4fdd\u7559\u6a21\u578b\u7684\u4e00\u822c\u751f\u6210\u80fd\u529b\u3002\u7136\u800c\uff0c\u968f\u7740\u9700\u64e6\u9664\u6982\u5ff5\u6570\u91cf\u7684\u589e\u52a0\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u53d8\u5f97\u4f4e\u6548\u4e14\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u6982\u5ff5\u90fd\u9700\u8981\u5355\u72ec\u7684\u4e00\u7ec4\u5fae\u8c03\u53c2\u6570\uff0c\u5e76\u53ef\u80fd\u635f\u5bb3\u6574\u4f53\u751f\u6210\u8d28\u91cf\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u8d85\u7c7b\u578b-\u5b50\u7c7b\u578b\u6982\u5ff5\u5c42\u7ea7\u7ed3\u6784\uff0c\u5c06\u88ab\u64e6\u9664\u7684\u6982\u5ff5\u7ec4\u7ec7\u4e3a\u7236\u5b50\u7ed3\u6784\uff1a\u6bcf\u4e2a\u88ab\u64e6\u9664\u7684\u6982\u5ff5\u4f5c\u4e3a\u5b50\u8282\u70b9\uff0c\u8bed\u4e49\u76f8\u5173\u7684\u6982\u5ff5\uff08\u4f8b\u5982\u91d1\u521a\u9e66\u9e49\u548c\u767d\u5934\u9e70\uff09\u88ab\u5f52\u5165\u4e00\u4e2a\u5171\u4eab\u7684\u7236\u8282\u70b9\uff0c\u5373\u8d85\u7c7b\u578b\u6982\u5ff5\uff08\u4f8b\u5982\u201c\u9e1f\u201d\uff09\u3002\u6211\u4eec\u4e0d\u518d\u9010\u4e2a\u64e6\u9664\u6982\u5ff5\uff0c\u800c\u662f\u5f15\u5165\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u7ec4\u7ea7\u6291\u5236\u65b9\u6cd5\uff0c\u5c06\u8bed\u4e49\u76f8\u4f3c\u7684\u6982\u5ff5\u5206\u7ec4\u5e76\u5171\u4eab\u4e00\u7ec4\u53ef\u5b66\u4e60\u53c2\u6570\u8fdb\u884c\u8054\u5408\u64e6\u9664\u3002\u5728\u64e6\u9664\u9636\u6bb5\uff0c\u5bf9\u672a\u906e\u853d\u533a\u57df\u5e94\u7528\u6807\u51c6\u6269\u6563\u6b63\u5219\u5316\u4ee5\u4fdd\u6301\u53bb\u566a\u8fc7\u7a0b\u3002\u4e3a\u7f13\u89e3\u56e0\u8fc7\u5ea6\u64e6\u9664\u8bed\u4e49\u76f8\u5173\u5b50\u7c7b\u578b\u800c\u5bfc\u81f4\u7684\u8d85\u7c7b\u578b\u751f\u6210\u80fd\u529b\u4e0b\u964d\uff0c\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\u2014\u2014\u8d85\u7c7b\u578b\u4fdd\u7559\u4f4e\u79e9\u9002\u914d\uff08SuPLoRA\uff09\uff0c\u8be5\u65b9\u6cd5\u5728\u51bb\u7ed3\u7684\u4e0b\u6295\u5f71\u77e9\u9635\u4e2d\u7f16\u7801\u8d85\u7c7b\u578b\u6982\u5ff5\u4fe1\u606f\uff0c\u5e76\u4ec5\u5728\u64e6\u9664\u8fc7\u7a0b\u4e2d\u66f4\u65b0\u4e0a\u6295\u5f71\u77e9\u9635\u3002\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86 SuPLoRA \u5728\u51cf\u8f7b\u751f\u6210\u6027\u80fd\u9000\u5316\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u8981\u6c42\u540c\u65f6\u64e6\u9664\u6765\u81ea\u591a\u4e2a\u9886\u57df\u7684\u6982\u5ff5\uff0c\u5305\u62ec\u540d\u4eba\u3001\u7269\u4f53\u548c\u8272\u60c5\u5185\u5bb9\u3002"}}
{"id": "2601.03309", "pdf": "https://arxiv.org/pdf/2601.03309", "abs": "https://arxiv.org/abs/2601.03309", "authors": ["Jianke Zhang", "Xiaoyu Chen", "Qiuyue Wang", "Mingsheng Li", "Yanjiang Guo", "Yucheng Hu", "Jiajun Zhang", "Shuai Bai", "Junyang Lin", "Jianyu Chen"], "title": "VLM4VLA: Revisiting Vision-Language-Models in Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-Language-Action (VLA) models, which integrate pretrained large Vision-Language Models (VLM) into their policy backbone, are gaining significant attention for their promising generalization capabilities. This paper revisits a fundamental yet seldom systematically studied question: how VLM choice and competence translate to downstream VLA policies performance? We introduce VLM4VLA, a minimal adaptation pipeline that converts general-purpose VLMs into VLA policies using only a small set of new learnable parameters for fair and efficient comparison. Despite its simplicity, VLM4VLA proves surprisingly competitive with more sophisticated network designs. Through extensive empirical studies on various downstream tasks across three benchmarks, we find that while VLM initialization offers a consistent benefit over training from scratch, a VLM's general capabilities are poor predictors of its downstream task performance. This challenges common assumptions, indicating that standard VLM competence is necessary but insufficient for effective embodied control. We further investigate the impact of specific embodied capabilities by fine-tuning VLMs on seven auxiliary embodied tasks (e.g., embodied QA, visual pointing, depth estimation). Contrary to intuition, improving a VLM's performance on specific embodied skills does not guarantee better downstream control performance. Finally, modality-level ablations identify the visual module in VLM, rather than the language component, as the primary performance bottleneck. We demonstrate that injecting control-relevant supervision into the vision encoder of the VLM yields consistent gains, even when the encoder remains frozen during downstream fine-tuning. This isolates a persistent domain gap between current VLM pretraining objectives and the requirements of embodied action-planning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u63d0\u51faVLM4VLA\u8fd9\u4e00\u8f7b\u91cf\u7ea7\u9002\u914d\u6846\u67b6\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u9009\u62e9\u4e0e\u80fd\u529b\u5982\u4f55\u5f71\u54cd\u5176\u5728\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u7b56\u7565\u4e2d\u7684\u4e0b\u6e38\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff1a1\uff09VLM\u521d\u59cb\u5316\u867d\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\uff0c\u4f46\u5176\u901a\u7528\u80fd\u529b\u5e76\u4e0d\u80fd\u53ef\u9760\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff1b2\uff09\u5728\u7279\u5b9a\u5177\u8eab\u4efb\u52a1\u4e0a\u5fae\u8c03VLM\u672a\u5fc5\u63d0\u5347\u63a7\u5236\u6027\u80fd\uff1b3\uff09VLM\u4e2d\u7684\u89c6\u89c9\u6a21\u5757\u662f\u6027\u80fd\u74f6\u9888\uff0c\u5411\u5176\u6ce8\u5165\u63a7\u5236\u76f8\u5173\u76d1\u7763\u4fe1\u53f7\u53ef\u663e\u8457\u63d0\u5347\u6548\u679c\uff0c\u5373\u4f7f\u8be5\u6a21\u5757\u5728\u4e0b\u6e38\u5fae\u8c03\u4e2d\u88ab\u51bb\u7ed3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9VLM\u9009\u62e9\u53ca\u5176\u80fd\u529b\u5982\u4f55\u5f71\u54cd\u4e0b\u6e38VLA\u7b56\u7565\u6027\u80fd\u7684\u7cfb\u7edf\u6027\u5206\u6790\u3002\u5c3d\u7ba1VLA\u6a21\u578b\u5e7f\u6cdb\u91c7\u7528\u9884\u8bad\u7ec3VLM\u4f5c\u4e3a\u7b56\u7565\u4e3b\u5e72\uff0c\u4f46VLM\u7684\u901a\u7528\u80fd\u529b\u662f\u5426\u8db3\u4ee5\u652f\u6491\u5177\u8eab\u63a7\u5236\u4efb\u52a1\u4ecd\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51faVLM4VLA\u2014\u2014\u4e00\u79cd\u6781\u7b80\u9002\u914d\u6d41\u7a0b\uff0c\u4ec5\u5f15\u5165\u5c11\u91cf\u53ef\u5b66\u4e60\u53c2\u6570\u5c06\u901a\u7528VLM\u8f6c\u6362\u4e3aVLA\u7b56\u7565\uff0c\u4ece\u800c\u5b9e\u73b0\u516c\u5e73\u9ad8\u6548\u7684\u6bd4\u8f83\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u5f00\u5c55\u4e09\u7c7b\u57fa\u51c6\u3001\u591a\u9879\u4efb\u52a1\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u5305\u62ecVLM\u521d\u59cb\u5316\u6548\u679c\u8bc4\u4f30\u3001\u4e03\u79cd\u5177\u8eab\u8f85\u52a9\u4efb\u52a1\u5fae\u8c03\u3001\u4ee5\u53ca\u6a21\u6001\u7ea7\u6d88\u878d\u5206\u6790\u3002", "result": "1\uff09VLM\u521d\u59cb\u5316\u59cb\u7ec8\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\uff0c\u4f46\u5176\u901a\u7528\u80fd\u529b\u4e0e\u4e0b\u6e38\u6027\u80fd\u76f8\u5173\u6027\u5f31\uff1b2\uff09\u9488\u5bf9\u7279\u5b9a\u5177\u8eab\u6280\u80fd\uff08\u5982\u5177\u8eab\u95ee\u7b54\u3001\u89c6\u89c9\u6307\u5411\u7b49\uff09\u5fae\u8c03VLM\uff0c\u5e76\u672a\u5e26\u6765\u4e00\u81f4\u7684\u63a7\u5236\u6027\u80fd\u63d0\u5347\uff1b3\uff09\u89c6\u89c9\u6a21\u5757\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u5411\u5176\u6ce8\u5165\u63a7\u5236\u76f8\u5173\u76d1\u7763\uff08\u5373\u4f7f\u51bb\u7ed3\uff09\u53ef\u7a33\u5b9a\u63d0\u5347\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u6807\u51c6VLM\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u4e0e\u5177\u8eab\u52a8\u4f5c\u89c4\u5212\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u6301\u7eed\u7684\u9886\u57df\u5dee\u8ddd\u3002\u4ec5\u9760VLM\u7684\u901a\u7528\u89c6\u89c9-\u8bed\u8a00\u80fd\u529b\u4e0d\u8db3\u4ee5\u652f\u6491\u9ad8\u6548\u63a7\u5236\uff0c\u9700\u5728\u89c6\u89c9\u7f16\u7801\u5668\u4e2d\u5f15\u5165\u9762\u5411\u63a7\u5236\u7684\u76d1\u7763\u4fe1\u53f7\u4ee5\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "summary_cn": "\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u901a\u8fc7\u5c06\u9884\u8bad\u7ec3\u7684\u5927\u89c4\u6a21\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u6574\u5408\u5230\u5176\u7b56\u7565\u4e3b\u5e72\u4e2d\uff0c\u56e0\u5176\u51fa\u8272\u7684\u6cdb\u5316\u80fd\u529b\u800c\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u3002\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u4e00\u4e2a\u57fa\u7840\u4f46\u9c9c\u6709\u7cfb\u7edf\u7814\u7a76\u7684\u95ee\u9898\uff1aVLM\u7684\u9009\u62e9\u53ca\u5176\u80fd\u529b\u5982\u4f55\u8f6c\u5316\u4e3a\u4e0b\u6e38VLA\u7b56\u7565\u7684\u6027\u80fd\uff1f\u6211\u4eec\u63d0\u51fa\u4e86VLM4VLA\uff0c\u8fd9\u662f\u4e00\u79cd\u6781\u7b80\u7684\u9002\u914d\u6d41\u7a0b\uff0c\u4ec5\u4f7f\u7528\u5c11\u91cf\u65b0\u589e\u7684\u53ef\u5b66\u4e60\u53c2\u6570\u5373\u53ef\u5c06\u901a\u7528VLM\u8f6c\u6362\u4e3aVLA\u7b56\u7565\uff0c\u4ece\u800c\u5b9e\u73b0\u516c\u5e73\u4e14\u9ad8\u6548\u7684\u6bd4\u8f83\u3002\u5c3d\u7ba1\u7ed3\u6784\u7b80\u5355\uff0cVLM4VLA\u7684\u8868\u73b0\u5374\u51fa\u4eba\u610f\u6599\u5730\u4e0e\u66f4\u590d\u6742\u7684\u7f51\u7edc\u8bbe\u8ba1\u76f8\u5f53\u3002\u901a\u8fc7\u5bf9\u4e09\u4e2a\u57fa\u51c6\u4e0a\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u7684\u5927\u91cf\u5b9e\u8bc1\u7814\u7a76\uff0c\u6211\u4eec\u53d1\u73b0\uff1a\u867d\u7136VLM\u521d\u59cb\u5316\u76f8\u6bd4\u4ece\u5934\u8bad\u7ec3\u59cb\u7ec8\u5e26\u6765\u4e00\u81f4\u6536\u76ca\uff0c\u4f46VLM\u7684\u901a\u7528\u80fd\u529b\u5374\u96be\u4ee5\u6709\u6548\u9884\u6d4b\u5176\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002\u8fd9\u4e00\u53d1\u73b0\u6311\u6218\u4e86\u666e\u904d\u5047\u8bbe\uff0c\u8868\u660e\u6807\u51c6VLM\u80fd\u529b\u5bf9\u4e8e\u6709\u6548\u7684\u5177\u8eab\u63a7\u5236\u800c\u8a00\u662f\u5fc5\u8981\u4f46\u4e0d\u5145\u5206\u7684\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u901a\u8fc7\u5728\u4e03\u9879\u8f85\u52a9\u5177\u8eab\u4efb\u52a1\uff08\u5982\u5177\u8eab\u95ee\u7b54\u3001\u89c6\u89c9\u6307\u5411\u3001\u6df1\u5ea6\u4f30\u8ba1\u7b49\uff09\u4e0a\u5fae\u8c03VLM\uff0c\u63a2\u7a76\u7279\u5b9a\u5177\u8eab\u80fd\u529b\u7684\u5f71\u54cd\u3002\u4e0e\u76f4\u89c9\u76f8\u53cd\uff0c\u63d0\u5347VLM\u5728\u7279\u5b9a\u5177\u8eab\u6280\u80fd\u4e0a\u7684\u8868\u73b0\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u4e0b\u6e38\u63a7\u5236\u6027\u80fd\u7684\u63d0\u5347\u3002\u6700\u540e\uff0c\u6a21\u6001\u7ea7\u6d88\u878d\u5b9e\u9a8c\u6307\u51fa\uff0cVLM\u4e2d\u7684\u89c6\u89c9\u6a21\u5757\u800c\u975e\u8bed\u8a00\u7ec4\u4ef6\u662f\u4e3b\u8981\u7684\u6027\u80fd\u74f6\u9888\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u5411VLM\u7684\u89c6\u89c9\u7f16\u7801\u5668\u6ce8\u5165\u63a7\u5236\u76f8\u5173\u7684\u76d1\u7763\u4fe1\u53f7\u80fd\u591f\u5e26\u6765\u7a33\u5b9a\u7684\u6027\u80fd\u589e\u76ca\uff0c\u5373\u4f7f\u8be5\u7f16\u7801\u5668\u5728\u4e0b\u6e38\u5fae\u8c03\u9636\u6bb5\u4fdd\u6301\u51bb\u7ed3\u3002\u8fd9\u63ed\u793a\u4e86\u5f53\u524dVLM\u9884\u8bad\u7ec3\u76ee\u6807\u4e0e\u5177\u8eab\u52a8\u4f5c\u89c4\u5212\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u7684\u6301\u7eed\u6027\u9886\u57df\u5dee\u8ddd\u3002"}}
{"id": "2601.03317", "pdf": "https://arxiv.org/pdf/2601.03317", "abs": "https://arxiv.org/abs/2601.03317", "authors": ["Yun-Hao Zhang", "I-Hsien Ting", "Dario Liberona", "Yun-Hsiu Liu", "Kazunori Minetaki"], "title": "Deep Learning-Based Image Recognition for Soft-Shell Shrimp Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the integration of information technology into aquaculture, production has become more stable and continues to grow annually. As consumer demand for high-quality aquatic products rises, freshness and appearance integrity are key concerns. In shrimp-based processed foods, freshness declines rapidly post-harvest, and soft-shell shrimp often suffer from head-body separation after cooking or freezing, affecting product appearance and consumer perception. To address these issues, this study leverages deep learning-based image recognition for automated classification of white shrimp immediately after harvest. A convolutional neural network (CNN) model replaces manual sorting, enhancing classification accuracy, efficiency, and consistency. By reducing processing time, this technology helps maintain freshness and ensures that shrimp transportation businesses meet customer demands more effectively.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u56fe\u50cf\u8bc6\u522b\u6280\u672f\uff0c\u901a\u8fc7CNN\u6a21\u578b\u5bf9\u521a\u6355\u635e\u7684\u767d\u867e\u8fdb\u884c\u81ea\u52a8\u5206\u7c7b\uff0c\u4ee5\u63d0\u5347\u5206\u9009\u6548\u7387\u4e0e\u51c6\u786e\u6027\uff0c\u4ece\u800c\u4fdd\u6301\u867e\u7684\u65b0\u9c9c\u5ea6\u5e76\u6ee1\u8db3\u6d88\u8d39\u8005\u5bf9\u4ea7\u54c1\u5916\u89c2\u548c\u54c1\u8d28\u7684\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u6d88\u8d39\u8005\u5bf9\u9ad8\u54c1\u8d28\u6c34\u4ea7\u54c1\u9700\u6c42\u7684\u589e\u52a0\uff0c\u867e\u7c7b\u4ea7\u54c1\u5728\u6536\u83b7\u540e\u65b0\u9c9c\u5ea6\u8fc5\u901f\u4e0b\u964d\uff0c\u4e14\u8f6f\u58f3\u867e\u5728\u70f9\u996a\u6216\u51b7\u51bb\u540e\u6613\u51fa\u73b0\u5934\u8eab\u5206\u79bb\u95ee\u9898\uff0c\u5f71\u54cd\u5916\u89c2\u548c\u6d88\u8d39\u8005\u63a5\u53d7\u5ea6\uff0c\u4e9f\u9700\u9ad8\u6548\u51c6\u786e\u7684\u5206\u9009\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u7684\u6df1\u5ea6\u5b66\u4e60\u56fe\u50cf\u8bc6\u522b\u6280\u672f\uff0c\u5bf9\u521a\u6355\u635e\u7684\u767d\u867e\u8fdb\u884c\u81ea\u52a8\u5316\u5206\u7c7b\uff0c\u66ff\u4ee3\u4f20\u7edf\u4eba\u5de5\u5206\u9009\u3002", "result": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u767d\u867e\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u4e00\u81f4\u6027\uff0c\u7f29\u77ed\u4e86\u5904\u7406\u65f6\u95f4\uff0c\u6709\u52a9\u4e8e\u7ef4\u6301\u867e\u7684\u65b0\u9c9c\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u56fe\u50cf\u8bc6\u522b\u6280\u672f\u53ef\u6709\u6548\u5e94\u7528\u4e8e\u6c34\u4ea7\u52a0\u5de5\u73af\u8282\uff0c\u63d0\u5347\u4ea7\u54c1\u8d28\u91cf\u4e0e\u5ba2\u6237\u6ee1\u610f\u5ea6\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002", "summary_cn": "\u968f\u7740\u4fe1\u606f\u6280\u672f\u878d\u5165\u6c34\u4ea7\u517b\u6b96\u4e1a\uff0c\u751f\u4ea7\u53d8\u5f97\u66f4\u52a0\u7a33\u5b9a\u5e76\u9010\u5e74\u589e\u957f\u3002\u968f\u7740\u6d88\u8d39\u8005\u5bf9\u9ad8\u54c1\u8d28\u6c34\u4ea7\u54c1\u9700\u6c42\u7684\u63d0\u5347\uff0c\u4ea7\u54c1\u7684\u65b0\u9c9c\u5ea6\u548c\u5916\u89c2\u5b8c\u6574\u6027\u6210\u4e3a\u5173\u952e\u5173\u6ce8\u70b9\u3002\u5728\u867e\u7c7b\u52a0\u5de5\u98df\u54c1\u4e2d\uff0c\u867e\u5728\u6536\u83b7\u540e\u65b0\u9c9c\u5ea6\u8fc5\u901f\u4e0b\u964d\uff0c\u800c\u8f6f\u58f3\u867e\u5728\u70f9\u996a\u6216\u51b7\u51bb\u540e\u5e38\u51fa\u73b0\u5934\u8eab\u5206\u79bb\u73b0\u8c61\uff0c\u5f71\u54cd\u4ea7\u54c1\u5916\u89c2\u53ca\u6d88\u8d39\u8005\u611f\u77e5\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u7814\u7a76\u5229\u7528\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u56fe\u50cf\u8bc6\u522b\u6280\u672f\uff0c\u5728\u767d\u867e\u521a\u6355\u635e\u540e\u5373\u8fdb\u884c\u81ea\u52a8\u5206\u7c7b\u3002\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6a21\u578b\u66ff\u4ee3\u4eba\u5de5\u5206\u9009\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u4e00\u81f4\u6027\u3002\u8be5\u6280\u672f\u901a\u8fc7\u7f29\u77ed\u5904\u7406\u65f6\u95f4\uff0c\u6709\u52a9\u4e8e\u4fdd\u6301\u867e\u7684\u65b0\u9c9c\u5ea6\uff0c\u5e76\u4f7f\u867e\u7c7b\u8fd0\u8f93\u4f01\u4e1a\u66f4\u6709\u6548\u5730\u6ee1\u8db3\u5ba2\u6237\u9700\u6c42\u3002"}}
{"id": "2601.03326", "pdf": "https://arxiv.org/pdf/2601.03326", "abs": "https://arxiv.org/abs/2601.03326", "authors": ["Jarek Duda"], "title": "Higher order PCA-like rotation-invariant features for detailed shape descriptors modulo rotation", "categories": ["cs.CV", "cs.LG"], "comment": "4 pages, 4 figures", "summary": "PCA can be used for rotation invariant features, describing a shape with its $p_{ab}=E[(x_i-E[x_a])(x_b-E[x_b])]$ covariance matrix approximating shape by ellipsoid, allowing for rotation invariants like its traces of powers. However, real shapes are usually much more complicated, hence there is proposed its extension to e.g. $p_{abc}=E[(x_a-E[x_a])(x_b-E[x_b])(x_c-E[x_c])]$ order-3 or higher tensors describing central moments, or polynomial times Gaussian allowing decodable shape descriptors of arbitrarily high accuracy, and their analogous rotation invariants. Its practical applications could be rotation-invariant features to include shape modulo rotation e.g. for molecular shape descriptors, or for up to rotation object recognition in 2D images/3D scans, or shape similarity metric allowing their inexpensive comparison (modulo rotation) without costly optimization over rotations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u63a8\u5e7f\u5230\u9ad8\u9636\u4e2d\u5fc3\u77e9\u5f20\u91cf\u6216\u591a\u9879\u5f0f\u4e58\u4ee5\u9ad8\u65af\u51fd\u6570\u7684\u5f62\u5f0f\uff0c\u4ee5\u6784\u5efa\u4efb\u610f\u7cbe\u5ea6\u7684\u65cb\u8f6c\u4e0d\u53d8\u5f62\u72b6\u63cf\u8ff0\u7b26\uff0c\u5e76\u5e94\u7528\u4e8e\u5206\u5b50\u5f62\u72b6\u63cf\u8ff0\u3001\u65cb\u8f6c\u4e0d\u53d8\u76ee\u6807\u8bc6\u522b\u548c\u9ad8\u6548\u5f62\u72b6\u76f8\u4f3c\u6027\u5ea6\u91cf\u3002", "motivation": "\u4f20\u7edfPCA\u4ec5\u5229\u7528\u4e8c\u9636\u534f\u65b9\u5dee\u77e9\u9635\u8fd1\u4f3c\u5f62\u72b6\u4e3a\u692d\u7403\u4f53\uff0c\u96be\u4ee5\u51c6\u786e\u523b\u753b\u590d\u6742\u771f\u5b9e\u5f62\u72b6\uff1b\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u9ad8\u9636\u5f20\u91cf\u6216\u66f4\u590d\u6742\u7684\u51fd\u6570\u5f62\u5f0f\u63d0\u5347\u5f62\u72b6\u63cf\u8ff0\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u65cb\u8f6c\u4e0d\u53d8\u6027\u3002", "method": "\u5c06PCA\u6269\u5c55\u81f3\u4e09\u9636\u53ca\u4ee5\u4e0a\u4e2d\u5fc3\u77e9\u5f20\u91cf\uff08\u5982 $p_{abc}=E[(x_a-E[x_a])(x_b-E[x_b])(x_c-E[x_c])]$\uff09\uff0c\u6216\u91c7\u7528\u591a\u9879\u5f0f\u4e58\u4ee5\u9ad8\u65af\u51fd\u6570\u7684\u5f62\u5f0f\uff0c\u6784\u9020\u53ef\u89e3\u7801\u4e14\u4efb\u610f\u7cbe\u5ea6\u7684\u5f62\u72b6\u63cf\u8ff0\u7b26\uff0c\u5e76\u63a8\u5bfc\u5176\u5bf9\u5e94\u7684\u65cb\u8f6c\u4e0d\u53d8\u91cf\uff08\u5982\u5e42\u8ff9\u7b49\uff09\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u9ad8\u7cbe\u5ea6\u7684\u65cb\u8f6c\u4e0d\u53d8\u7279\u5f81\uff0c\u9002\u7528\u4e8e\u5206\u5b50\u5f62\u72b6\u63cf\u8ff0\u30012D/3D\u56fe\u50cf\u4e2d\u65cb\u8f6c\u4e0d\u53d8\u76ee\u6807\u8bc6\u522b\uff0c\u4ee5\u53ca\u65e0\u9700\u6602\u8d35\u65cb\u8f6c\u4f18\u5316\u5373\u53ef\u5feb\u901f\u6bd4\u8f83\u5f62\u72b6\u76f8\u4f3c\u6027\u7684\u5ea6\u91cf\u3002", "conclusion": "\u901a\u8fc7\u9ad8\u9636\u77e9\u6216\u591a\u9879\u5f0f-\u9ad8\u65af\u7ec4\u5408\u65b9\u5f0f\uff0c\u53ef\u4ee5\u6709\u6548\u6784\u5efa\u517c\u5177\u9ad8\u7cbe\u5ea6\u4e0e\u65cb\u8f6c\u4e0d\u53d8\u6027\u7684\u5f62\u72b6\u63cf\u8ff0\u7b26\uff0c\u5728\u591a\u4e2a\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "summary_cn": "\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u53ef\u7528\u4e8e\u6784\u5efa\u65cb\u8f6c\u4e0d\u53d8\u7279\u5f81\uff0c\u901a\u8fc7\u5176\u534f\u65b9\u5dee\u77e9\u9635 $p_{ab}=E[(x_i-E[x_a])(x_b-E[x_b])]$ \u5c06\u5f62\u72b6\u8fd1\u4f3c\u4e3a\u692d\u7403\u4f53\uff0c\u5e76\u5229\u7528\u5176\u5e42\u8ff9\u7b49\u6784\u9020\u65cb\u8f6c\u4e0d\u53d8\u91cf\u3002\u7136\u800c\uff0c\u771f\u5b9e\u5f62\u72b6\u901a\u5e38\u66f4\u4e3a\u590d\u6742\uff0c\u56e0\u6b64\u672c\u6587\u63d0\u51fa\u5c06\u5176\u6269\u5c55\u81f3\u4e09\u9636\u6216\u66f4\u9ad8\u9636\u5f20\u91cf\uff08\u4f8b\u5982 $p_{abc}=E[(x_a-E[x_a])(x_b-E[x_b])(x_c-E[x_c])]$\uff09\u4ee5\u63cf\u8ff0\u4e2d\u5fc3\u77e9\uff0c\u6216\u91c7\u7528\u591a\u9879\u5f0f\u4e58\u4ee5\u9ad8\u65af\u51fd\u6570\u7684\u5f62\u5f0f\uff0c\u4ece\u800c\u83b7\u5f97\u53ef\u89e3\u7801\u4e14\u4efb\u610f\u9ad8\u7cbe\u5ea6\u7684\u5f62\u72b6\u63cf\u8ff0\u7b26\u53ca\u5176\u76f8\u5e94\u7684\u65cb\u8f6c\u4e0d\u53d8\u91cf\u3002\u8be5\u65b9\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u5305\u62ec\u7528\u4e8e\u5206\u5b50\u5f62\u72b6\u63cf\u8ff0\u7684\u65cb\u8f6c\u4e0d\u53d8\u7279\u5f81\u30012D\u56fe\u50cf\u62163D\u626b\u63cf\u4e2d\u5bf9\u65cb\u8f6c\u4e0d\u654f\u611f\u7684\u76ee\u6807\u8bc6\u522b\uff0c\u4ee5\u53ca\u4e00\u79cd\u53ef\u5728\u65e0\u9700\u6602\u8d35\u65cb\u8f6c\u4f18\u5316\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u6bd4\u8f83\u5f62\u72b6\u76f8\u4f3c\u6027\u7684\u5ea6\u91cf\u65b9\u6cd5\u3002"}}
{"id": "2601.03331", "pdf": "https://arxiv.org/pdf/2601.03331", "abs": "https://arxiv.org/abs/2601.03331", "authors": ["Yang Shi", "Yifeng Xie", "Minzhe Guo", "Liangsi Lu", "Mingxuan Huang", "Jingchao Wang", "Zhihong Zhu", "Boyan Xu", "Zhiqi Huang"], "title": "MMErroR: A Benchmark for Erroneous Reasoning in Vision-Language Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in Vision-Language Models (VLMs) have improved performance in multi-modal learning, raising the question of whether these models truly understand the content they process. Crucially, can VLMs detect when a reasoning process is wrong and identify its error type? To answer this, we present MMErroR, a multi-modal benchmark of 2,013 samples, each embedding a single coherent reasoning error. These samples span 24 subdomains across six top-level domains, ensuring broad coverage and taxonomic richness. Unlike existing benchmarks that focus on answer correctness, MMErroR targets a process-level, error-centric evaluation that requires models to detect incorrect reasoning and classify the error type within both visual and linguistic contexts. We evaluate 20 advanced VLMs, even the best model (Gemini-3.0-Pro) classifies the error in only 66.47\\% of cases, underscoring the challenge of identifying erroneous reasoning. Furthermore, the ability to accurately identify errors offers valuable insights into the capabilities of multi-modal reasoning models. Project Page: https://mmerror-benchmark.github.io", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MMErroR\uff0c\u4e00\u4e2a\u5305\u542b2013\u4e2a\u6837\u672c\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u662f\u5426\u80fd\u68c0\u6d4b\u5e76\u5206\u7c7b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u7c7b\u578b\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff08\u5982Gemini-3.0-Pro\uff09\u4e5f\u4ec5\u572866.47%\u7684\u60c5\u51b5\u4e0b\u6b63\u786e\u8bc6\u522b\u9519\u8bef\uff0c\u8868\u660e\u8be5\u4efb\u52a1\u6781\u5177\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u867d\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u5176\u662f\u5426\u771f\u6b63\u7406\u89e3\u6240\u5904\u7406\u5185\u5bb9\uff0c\u5c24\u5176\u662f\u80fd\u5426\u8bc6\u522b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u53ca\u5176\u7c7b\u578b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u63a8\u7406\u9519\u8bef\u68c0\u6d4b\u4e0e\u5206\u7c7b\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u6784\u5efaMMErroR\u57fa\u51c6\uff0c\u5305\u542b2013\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u5d4c\u5165\u4e00\u79cd\u8fde\u8d2f\u7684\u63a8\u7406\u9519\u8bef\uff0c\u8986\u76d6\u516d\u5927\u9886\u57df\u4e0b\u768424\u4e2a\u5b50\u9886\u57df\u3002\u8be5\u57fa\u51c6\u8981\u6c42\u6a21\u578b\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4e0a\u4e0b\u6587\u4e2d\u68c0\u6d4b\u9519\u8bef\u63a8\u7406\u5e76\u5206\u7c7b\u9519\u8bef\u7c7b\u578b\uff0c\u5f3a\u8c03\u8fc7\u7a0b\u7ea7\u800c\u975e\u7b54\u6848\u6b63\u786e\u6027\u7684\u8bc4\u4f30\u3002", "result": "\u5bf920\u4e2a\u5148\u8fdbVLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u8868\u73b0\u6700\u597d\u7684Gemini-3.0-Pro\u6a21\u578b\u4ec5\u572866.47%\u7684\u6837\u672c\u4e2d\u6b63\u786e\u8bc6\u522b\u9519\u8bef\u7c7b\u578b\uff0c\u8868\u660e\u5f53\u524d\u6a21\u578b\u5728\u63a8\u7406\u9519\u8bef\u8bc6\u522b\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "conclusion": "\u51c6\u786e\u8bc6\u522b\u63a8\u7406\u9519\u8bef\u7684\u80fd\u529b\u662f\u8861\u91cf\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u7406\u89e3\u6df1\u5ea6\u7684\u91cd\u8981\u6307\u6807\uff1bMMErroR\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u5411\u548c\u6311\u6218\u3002", "summary_cn": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u6700\u65b0\u8fdb\u5c55\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u7684\u6027\u80fd\uff0c\u4f46\u968f\u4e4b\u800c\u6765\u7684\u95ee\u9898\u662f\uff1a\u8fd9\u4e9b\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u5176\u6240\u5904\u7406\u7684\u5185\u5bb9\uff1f\u5c24\u5176\u5173\u952e\u7684\u662f\uff0cVLMs\u80fd\u5426\u68c0\u6d4b\u5230\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u5e76\u8bc6\u522b\u5176\u9519\u8bef\u7c7b\u578b\uff1f\u4e3a\u56de\u7b54\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86MMErroR\u2014\u2014\u4e00\u4e2a\u5305\u542b2,013\u4e2a\u6837\u672c\u7684\u591a\u6a21\u6001\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6bcf\u4e2a\u6837\u672c\u5747\u5d4c\u5165\u4e00\u79cd\u8fde\u8d2f\u7684\u63a8\u7406\u9519\u8bef\u3002\u8fd9\u4e9b\u6837\u672c\u6db5\u76d6\u516d\u5927\u9876\u7ea7\u9886\u57df\u4e0b\u768424\u4e2a\u5b50\u9886\u57df\uff0c\u786e\u4fdd\u4e86\u5e7f\u6cdb\u7684\u8986\u76d6\u8303\u56f4\u548c\u4e30\u5bcc\u7684\u5206\u7c7b\u7ed3\u6784\u3002\u4e0e\u73b0\u6709\u4fa7\u91cd\u4e8e\u7b54\u6848\u6b63\u786e\u6027\u7684\u57fa\u51c6\u4e0d\u540c\uff0cMMErroR\u805a\u7126\u4e8e\u8fc7\u7a0b\u5c42\u9762\u3001\u4ee5\u9519\u8bef\u4e3a\u4e2d\u5fc3\u7684\u8bc4\u4f30\uff0c\u8981\u6c42\u6a21\u578b\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4e0a\u4e0b\u6587\u4e2d\u68c0\u6d4b\u9519\u8bef\u63a8\u7406\u5e76\u5bf9\u5176\u9519\u8bef\u7c7b\u578b\u8fdb\u884c\u5206\u7c7b\u3002\u6211\u4eec\u8bc4\u4f30\u4e8620\u4e2a\u5148\u8fdb\u7684VLM\uff0c\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4fbf\u662f\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\uff08Gemini-3.0-Pro\uff09\u4e5f\u4ec5\u572866.47%\u7684\u60c5\u51b5\u4e0b\u6b63\u786e\u5206\u7c7b\u9519\u8bef\u7c7b\u578b\uff0c\u51f8\u663e\u4e86\u8bc6\u522b\u9519\u8bef\u63a8\u7406\u7684\u96be\u5ea6\u3002\u6b64\u5916\uff0c\u51c6\u786e\u8bc6\u522b\u9519\u8bef\u7684\u80fd\u529b\u4e3a\u6df1\u5165\u7406\u89e3\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u6d1e\u89c1\u3002"}}
{"id": "2601.03357", "pdf": "https://arxiv.org/pdf/2601.03357", "abs": "https://arxiv.org/abs/2601.03357", "authors": ["Yingyan Xu", "Pramod Rao", "Sebastian Weiss", "Gaspard Zoss", "Markus Gross", "Christian Theobalt", "Marc Habermann", "Derek Bradley"], "title": "RelightAnyone: A Generalized Relightable 3D Gaussian Head Model", "categories": ["cs.CV", "cs.GR"], "comment": null, "summary": "3D Gaussian Splatting (3DGS) has become a standard approach to reconstruct and render photorealistic 3D head avatars. A major challenge is to relight the avatars to match any scene illumination. For high quality relighting, existing methods require subjects to be captured under complex time-multiplexed illumination, such as one-light-at-a-time (OLAT). We propose a new generalized relightable 3D Gaussian head model that can relight any subject observed in a single- or multi-view images without requiring OLAT data for that subject. Our core idea is to learn a mapping from flat-lit 3DGS avatars to corresponding relightable Gaussian parameters for that avatar. Our model consists of two stages: a first stage that models flat-lit 3DGS avatars without OLAT lighting, and a second stage that learns the mapping to physically-based reflectance parameters for high-quality relighting. This two-stage design allows us to train the first stage across diverse existing multi-view datasets without OLAT lighting ensuring cross-subject generalization, where we learn a dataset-specific lighting code for self-supervised lighting alignment. Subsequently, the second stage can be trained on a significantly smaller dataset of subjects captured under OLAT illumination. Together, this allows our method to generalize well and relight any subject from the first stage as if we had captured them under OLAT lighting. Furthermore, we can fit our model to unseen subjects from as little as a single image, allowing several applications in novel view synthesis and relighting for digital avatars.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u53ef\u91cd\u5149\u71673D\u9ad8\u65af\u5934\u90e8\u6a21\u578b\uff0c\u4ec5\u9700\u5355\u89c6\u56fe\u6216\u591a\u89c6\u56fe\u56fe\u50cf\uff08\u65e0\u9700OLAT\u5149\u7167\u6570\u636e\uff09\u5373\u53ef\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5149\u7167\uff0c\u5e76\u652f\u6301\u4ece\u5355\u5f20\u56fe\u50cf\u62df\u5408\u65b0\u5bf9\u8c61\u3002", "motivation": "\u73b0\u67093D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u65b9\u6cd5\u5728\u5bf9\u6570\u5b57\u4eba\u5934\u50cf\u8fdb\u884c\u91cd\u5149\u7167\u65f6\uff0c\u901a\u5e38\u9700\u8981\u590d\u6742\u7684\u65f6\u5206\u590d\u7528\u7167\u660e\uff08\u5982OLAT\uff09\u91c7\u96c6\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u901a\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u65e0\u9700OLAT\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5149\u7167\u7684\u901a\u7528\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6a21\u578b\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u65e0OLAT\u7167\u660e\u7684\u591a\u89c6\u56fe\u6570\u636e\u4e0a\u5efa\u6a21\u5e73\u51493DGS\u5934\u50cf\uff0c\u5e76\u5b66\u4e60\u6570\u636e\u96c6\u7279\u5b9a\u7684\u5149\u7167\u7f16\u7801\u4ee5\u5b9e\u73b0\u81ea\u76d1\u7763\u5149\u7167\u5bf9\u9f50\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5728\u8f83\u5c0f\u89c4\u6a21\u7684OLAT\u6570\u636e\u96c6\u4e0a\u5b66\u4e60\u4ece\u5e73\u51493DGS\u53c2\u6570\u5230\u57fa\u4e8e\u7269\u7406\u53cd\u5c04\u7387\u53c2\u6570\u7684\u6620\u5c04\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5149\u7167\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6cdb\u5316\u5230\u4efb\u610f\u672a\u89c1\u8fc7\u7684\u5bf9\u8c61\uff0c\u5373\u4f7f\u53ea\u63d0\u4f9b\u5355\u5f20\u56fe\u50cf\u4e5f\u80fd\u5b8c\u6210\u62df\u5408\u5e76\u5b9e\u73b0\u903c\u771f\u7684\u65b0\u89c6\u89d2\u5408\u6210\u4e0e\u91cd\u5149\u7167\u6548\u679c\uff0c\u8868\u73b0\u5982\u540c\u8be5\u5bf9\u8c61\u66fe\u4f7f\u7528OLAT\u91c7\u96c6\u8fc7\u4e00\u6837\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u901a\u7528\u53ef\u91cd\u5149\u71673D\u9ad8\u65af\u5934\u50cf\u6a21\u578b\u663e\u8457\u964d\u4f4e\u4e86\u5bf9\u590d\u6742\u5149\u7167\u91c7\u96c6\u7684\u4f9d\u8d56\uff0c\u63d0\u5347\u4e863D\u6570\u5b57\u4eba\u5934\u50cf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "summary_cn": "3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5df2\u6210\u4e3a\u91cd\u5efa\u548c\u6e32\u67d3\u903c\u771f3D\u5934\u90e8\u5316\u8eab\u7684\u6807\u51c6\u65b9\u6cd5\u3002\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u662f\u5982\u4f55\u5bf9\u8fd9\u4e9b\u5316\u8eab\u8fdb\u884c\u91cd\u5149\u7167\uff0c\u4f7f\u5176\u5339\u914d\u4efb\u610f\u573a\u666f\u7167\u660e\u3002\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u91cd\u5149\u7167\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u8981\u6c42\u5728\u590d\u6742\u7684\u65f6\u5206\u590d\u7528\u7167\u660e\uff08\u4f8b\u5982\u4e00\u6b21\u4e00\u706f\uff0cOLAT\uff09\u4e0b\u91c7\u96c6\u5bf9\u8c61\u6570\u636e\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u901a\u7528\u53ef\u91cd\u5149\u71673D\u9ad8\u65af\u5934\u90e8\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u5bf9\u4ec5\u901a\u8fc7\u5355\u89c6\u56fe\u6216\u591a\u89c6\u56fe\u56fe\u50cf\u89c2\u5bdf\u5230\u7684\u4efb\u610f\u5bf9\u8c61\u8fdb\u884c\u91cd\u5149\u7167\uff0c\u800c\u65e0\u9700\u8be5\u5bf9\u8c61\u7684OLAT\u6570\u636e\u3002\u6211\u4eec\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5b66\u4e60\u4e00\u4e2a\u4ece\u5e73\u51493DGS\u5316\u8eab\u5230\u5bf9\u5e94\u53ef\u91cd\u5149\u7167\u9ad8\u65af\u53c2\u6570\u7684\u6620\u5c04\u3002\u8be5\u6a21\u578b\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u6ca1\u6709OLAT\u7167\u660e\u7684\u60c5\u51b5\u4e0b\u5efa\u6a21\u5e73\u51493DGS\u5316\u8eab\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5219\u5b66\u4e60\u6620\u5c04\u5230\u57fa\u4e8e\u7269\u7406\u7684\u53cd\u5c04\u53c2\u6570\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5149\u7167\u3002\u8fd9\u79cd\u4e24\u9636\u6bb5\u8bbe\u8ba1\u4f7f\u6211\u4eec\u80fd\u591f\u5728\u5927\u91cf\u4e0d\u542bOLAT\u7167\u660e\u7684\u73b0\u6709\u591a\u89c6\u56fe\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7b2c\u4e00\u9636\u6bb5\uff0c\u786e\u4fdd\u8de8\u5bf9\u8c61\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b66\u4e60\u6570\u636e\u96c6\u7279\u5b9a\u7684\u5149\u7167\u7f16\u7801\u5b9e\u73b0\u81ea\u76d1\u7763\u5149\u7167\u5bf9\u9f50\u3002\u968f\u540e\uff0c\u7b2c\u4e8c\u9636\u6bb5\u53ef\u5728\u89c4\u6a21\u5c0f\u5f97\u591a\u7684OLAT\u91c7\u96c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u7ed3\u5408\u4e24\u8005\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\uff0c\u5e76\u5bf9\u7b2c\u4e00\u9636\u6bb5\u4e2d\u7684\u4efb\u610f\u5bf9\u8c61\u8fdb\u884c\u91cd\u5149\u7167\uff0c\u6548\u679c\u5982\u540c\u8be5\u5bf9\u8c61\u66fe\u4f7f\u7528OLAT\u91c7\u96c6\u8fc7\u4e00\u6837\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u6a21\u578b\u751a\u81f3\u53ef\u4ee5\u4ece\u5355\u5f20\u56fe\u50cf\u62df\u5408\u672a\u89c1\u8fc7\u7684\u5bf9\u8c61\uff0c\u4e3a\u6570\u5b57\u5316\u8eab\u7684\u65b0\u89c6\u89d2\u5408\u6210\u4e0e\u91cd\u5149\u7167\u63d0\u4f9b\u4e86\u591a\u79cd\u5e94\u7528\u53ef\u80fd\u3002"}}
{"id": "2601.03362", "pdf": "https://arxiv.org/pdf/2601.03362", "abs": "https://arxiv.org/abs/2601.03362", "authors": ["Xiang Zhang", "Yang Zhang", "Lukas Mehl", "Markus Gross", "Christopher Schroers"], "title": "Guardians of the Hair: Rescuing Soft Boundaries in Depth, Stereo, and Novel Views", "categories": ["cs.CV"], "comment": null, "summary": "Soft boundaries, like thin hairs, are commonly observed in natural and computer-generated imagery, but they remain challenging for 3D vision due to the ambiguous mixing of foreground and background cues. This paper introduces Guardians of the Hair (HairGuard), a framework designed to recover fine-grained soft boundary details in 3D vision tasks. Specifically, we first propose a novel data curation pipeline that leverages image matting datasets for training and design a depth fixer network to automatically identify soft boundary regions. With a gated residual module, the depth fixer refines depth precisely around soft boundaries while maintaining global depth quality, allowing plug-and-play integration with state-of-the-art depth models. For view synthesis, we perform depth-based forward warping to retain high-fidelity textures, followed by a generative scene painter that fills disoccluded regions and eliminates redundant background artifacts within soft boundaries. Finally, a color fuser adaptively combines warped and inpainted results to produce novel views with consistent geometry and fine-grained details. Extensive experiments demonstrate that HairGuard achieves state-of-the-art performance across monocular depth estimation, stereo image/video conversion, and novel view synthesis, with significant improvements in soft boundary regions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHairGuard\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u6570\u636e\u5904\u7406\u6d41\u7a0b\u548c\u6df1\u5ea6\u4fee\u590d\u7f51\u7edc\uff0c\u6709\u6548\u63d0\u53473D\u89c6\u89c9\u4efb\u52a1\u4e2d\u8f6f\u8fb9\u754c\uff08\u5982\u7ec6\u53d1\uff09\u533a\u57df\u7684\u7ec6\u8282\u6062\u590d\u80fd\u529b\uff0c\u5728\u6df1\u5ea6\u4f30\u8ba1\u3001\u7acb\u4f53\u8f6c\u6362\u548c\u65b0\u89c6\u89d2\u5408\u6210\u65b9\u9762\u8fbe\u5230SOTA\u3002", "motivation": "\u8f6f\u8fb9\u754c\uff08\u5982\u7ec6\u53d1\uff09\u5728\u81ea\u7136\u4e0e\u5408\u6210\u56fe\u50cf\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u7531\u4e8e\u524d\u666f\u4e0e\u80cc\u666f\u4fe1\u606f\u6df7\u6742\uff0c\u7ed93D\u89c6\u89c9\u4efb\u52a1\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u7cbe\u786e\u6062\u590d\u5176\u7ec6\u8282\u3002", "method": "\u63d0\u51fa\u540d\u4e3aHairGuard\u7684\u6846\u67b6\uff1a1\uff09\u5229\u7528\u56fe\u50cf\u62a0\u56fe\u6570\u636e\u96c6\u6784\u5efa\u8bad\u7ec3\u6570\u636e\uff1b2\uff09\u8bbe\u8ba1\u5e26\u95e8\u63a7\u6b8b\u5dee\u6a21\u5757\u7684\u6df1\u5ea6\u4fee\u590d\u7f51\u7edc\uff0c\u7cbe\u51c6\u4f18\u5316\u8f6f\u8fb9\u754c\u533a\u57df\u6df1\u5ea6\uff1b3\uff09\u5728\u89c6\u56fe\u5408\u6210\u4e2d\u91c7\u7528\u57fa\u4e8e\u6df1\u5ea6\u7684\u524d\u5411\u626d\u66f2\u4fdd\u7559\u7eb9\u7406\uff0c\u5e76\u7528\u751f\u6210\u5f0f\u573a\u666f\u7ed8\u5236\u5668\u586b\u8865\u906e\u6321\u533a\u57df\uff1b4\uff09\u901a\u8fc7\u989c\u8272\u878d\u5408\u6a21\u5757\u81ea\u9002\u5e94\u6574\u5408\u7ed3\u679c\u3002", "result": "\u5728\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u3001\u7acb\u4f53\u56fe\u50cf/\u89c6\u9891\u8f6c\u6362\u548c\u65b0\u89c6\u89d2\u5408\u6210\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97SOTA\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8f6f\u8fb9\u754c\u533a\u57df\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "HairGuard\u80fd\u6709\u6548\u89e3\u51b33D\u89c6\u89c9\u4e2d\u8f6f\u8fb9\u754c\u7ec6\u8282\u6062\u590d\u96be\u9898\uff0c\u5177\u5907\u5373\u63d2\u5373\u7528\u7279\u6027\uff0c\u53ef\u5e7f\u6cdb\u96c6\u6210\u4e8e\u73b0\u6709\u6df1\u5ea6\u6a21\u578b\uff0c\u63d0\u5347\u6574\u4f53\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u7ec6\u8282\u4fdd\u771f\u5ea6\u3002", "summary_cn": "\u8f6f\u8fb9\u754c\uff08\u5982\u7ec6\u53d1\uff09\u5728\u81ea\u7136\u56fe\u50cf\u548c\u8ba1\u7b97\u673a\u751f\u6210\u56fe\u50cf\u4e2d\u5341\u5206\u5e38\u89c1\uff0c\u4f46\u7531\u4e8e\u524d\u666f\u4e0e\u80cc\u666f\u7ebf\u7d22\u7684\u6a21\u7cca\u6df7\u5408\uff0c\u5b83\u4eec\u57283D\u89c6\u89c9\u4efb\u52a1\u4e2d\u4ecd\u5177\u6311\u6218\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u201c\u53d1\u4e1d\u5b88\u62a4\u8005\u201d\uff08HairGuard\uff09\u6846\u67b6\uff0c\u65e8\u5728\u6062\u590d3D\u89c6\u89c9\u4efb\u52a1\u4e2d\u7ec6\u7c92\u5ea6\u7684\u8f6f\u8fb9\u754c\u7ec6\u8282\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u9996\u5148\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u6574\u7406\u6d41\u7a0b\uff0c\u5229\u7528\u56fe\u50cf\u62a0\u56fe\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df1\u5ea6\u4fee\u590d\u7f51\u7edc\u4ee5\u81ea\u52a8\u8bc6\u522b\u8f6f\u8fb9\u754c\u533a\u57df\u3002\u8be5\u7f51\u7edc\u901a\u8fc7\u95e8\u63a7\u6b8b\u5dee\u6a21\u5757\uff0c\u5728\u4fdd\u6301\u5168\u5c40\u6df1\u5ea6\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u7cbe\u51c6\u4f18\u5316\u8f6f\u8fb9\u754c\u5468\u56f4\u7684\u6df1\u5ea6\uff0c\u4ece\u800c\u5b9e\u73b0\u4e0e\u5f53\u524d\u5148\u8fdb\u6df1\u5ea6\u6a21\u578b\u7684\u5373\u63d2\u5373\u7528\u96c6\u6210\u3002\u5728\u89c6\u56fe\u5408\u6210\u65b9\u9762\uff0c\u6211\u4eec\u91c7\u7528\u57fa\u4e8e\u6df1\u5ea6\u7684\u524d\u5411\u626d\u66f2\u4ee5\u4fdd\u7559\u9ad8\u4fdd\u771f\u7eb9\u7406\uff0c\u968f\u540e\u4f7f\u7528\u4e00\u4e2a\u751f\u6210\u5f0f\u573a\u666f\u7ed8\u5236\u5668\u586b\u5145\u56e0\u89c6\u89d2\u53d8\u5316\u800c\u4ea7\u751f\u7684\u7a7a\u6d1e\u533a\u57df\uff0c\u5e76\u6d88\u9664\u8f6f\u8fb9\u754c\u5185\u90e8\u7684\u5197\u4f59\u80cc\u666f\u4f2a\u5f71\u3002\u6700\u540e\uff0c\u989c\u8272\u878d\u5408\u6a21\u5757\u81ea\u9002\u5e94\u5730\u7ed3\u5408\u626d\u66f2\u4e0e\u4fee\u590d\u7ed3\u679c\uff0c\u751f\u6210\u5177\u6709\u51e0\u4f55\u4e00\u81f4\u6027\u4e0e\u7ec6\u7c92\u5ea6\u7ec6\u8282\u7684\u65b0\u89c6\u89d2\u56fe\u50cf\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHairGuard\u5728\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u3001\u7acb\u4f53\u56fe\u50cf/\u89c6\u9891\u8f6c\u6362\u4ee5\u53ca\u65b0\u89c6\u89d2\u5408\u6210\u7b49\u591a\u4e2a\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u9886\u5148\u6c34\u5e73\uff0c\u5c24\u5176\u5728\u8f6f\u8fb9\u754c\u533a\u57df\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.03369", "pdf": "https://arxiv.org/pdf/2601.03369", "abs": "https://arxiv.org/abs/2601.03369", "authors": ["Sha Luo", "Yogesh Prabhu", "Tim Ossowski", "Kaiping Chen", "Junjie Hu"], "title": "RiskCueBench: Benchmarking Anticipatory Reasoning from Early Risk Cues in Video-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "With the rapid growth of video centered social media, the ability to anticipate risky events from visual data is a promising direction for ensuring public safety and preventing real world accidents. Prior work has extensively studied supervised video risk assessment across domains such as driving, protests, and natural disasters. However, many existing datasets provide models with access to the full video sequence, including the accident itself, which substantially reduces the difficulty of the task. To better reflect real world conditions, we introduce a new video understanding benchmark RiskCueBench in which videos are carefully annotated to identify a risk signal clip, defined as the earliest moment that indicates a potential safety concern. Experimental results reveal a significant gap in current systems ability to interpret evolving situations and anticipate future risky events from early visual signals, highlighting important challenges for deploying video risk prediction models in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u57fa\u51c6RiskCueBench\uff0c\u805a\u7126\u4e8e\u4ece\u89c6\u9891\u4e2d\u6700\u65e9\u7684\u98ce\u9669\u4fe1\u53f7\u9884\u6d4b\u672a\u6765\u5371\u9669\u4e8b\u4ef6\uff0c\u63ed\u793a\u73b0\u6709\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u98ce\u9669\u8bc4\u4f30\u6570\u636e\u96c6\u901a\u5e38\u5305\u542b\u5b8c\u6574\u89c6\u9891\uff08\u542b\u4e8b\u6545\u672c\u8eab\uff09\uff0c\u96be\u4ee5\u53cd\u6620\u73b0\u5b9e\u573a\u666f\u4e2d\u4ec5\u51ed\u65e9\u671f\u89c6\u89c9\u7ebf\u7d22\u9884\u6d4b\u98ce\u9669\u7684\u6311\u6218\u3002", "method": "\u6784\u5efa\u65b0\u89c6\u9891\u7406\u89e3\u57fa\u51c6RiskCueBench\uff0c\u5bf9\u89c6\u9891\u8fdb\u884c\u7cbe\u7ec6\u6807\u6ce8\uff0c\u6807\u8bc6\u51fa\u6700\u65e9\u9884\u793a\u6f5c\u5728\u5b89\u5168\u95ee\u9898\u7684\u201c\u98ce\u9669\u4fe1\u53f7\u7247\u6bb5\u201d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u7cfb\u7edf\u5728\u57fa\u4e8e\u65e9\u671f\u89c6\u89c9\u4fe1\u53f7\u89e3\u8bfb\u52a8\u6001\u60c5\u5883\u5e76\u9884\u6d4b\u672a\u6765\u98ce\u9669\u4e8b\u4ef6\u65b9\u9762\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u51f8\u663e\u4e86\u5728\u5b9e\u9645\u90e8\u7f72\u89c6\u9891\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u65f6\u6240\u9762\u4e34\u7684\u91cd\u8981\u6311\u6218\uff0c\u5f3a\u8c03\u9700\u63d0\u5347\u6a21\u578b\u5bf9\u65e9\u671f\u98ce\u9669\u7ebf\u7d22\u7684\u7406\u89e3\u80fd\u529b\u3002", "summary_cn": "\u968f\u7740\u4ee5\u89c6\u9891\u4e3a\u4e2d\u5fc3\u7684\u793e\u4ea4\u5a92\u4f53\u8fc5\u901f\u53d1\u5c55\uff0c\u4ece\u89c6\u89c9\u6570\u636e\u4e2d\u9884\u6d4b\u98ce\u9669\u4e8b\u4ef6\u6210\u4e3a\u4fdd\u969c\u516c\u5171\u5b89\u5168\u548c\u9884\u9632\u73b0\u5b9e\u4e8b\u6545\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u4ee5\u5f80\u7684\u7814\u7a76\u5df2\u5728\u9a7e\u9a76\u3001\u6297\u8bae\u6d3b\u52a8\u548c\u81ea\u7136\u707e\u5bb3\u7b49\u591a\u4e2a\u9886\u57df\u5e7f\u6cdb\u63a2\u8ba8\u4e86\u76d1\u7763\u5f0f\u89c6\u9891\u98ce\u9669\u8bc4\u4f30\u3002\u7136\u800c\uff0c\u8bb8\u591a\u73b0\u6709\u6570\u636e\u96c6\u5411\u6a21\u578b\u63d0\u4f9b\u4e86\u5305\u542b\u4e8b\u6545\u672c\u8eab\u7684\u5b8c\u6574\u89c6\u9891\u5e8f\u5217\uff0c\u8fd9\u5927\u5927\u964d\u4f4e\u4e86\u4efb\u52a1\u96be\u5ea6\u3002\u4e3a\u66f4\u597d\u5730\u53cd\u6620\u73b0\u5b9e\u6761\u4ef6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u9891\u7406\u89e3\u57fa\u51c6RiskCueBench\uff0c\u5176\u4e2d\u89c6\u9891\u7ecf\u8fc7\u4ed4\u7ec6\u6807\u6ce8\uff0c\u4ee5\u8bc6\u522b\u51fa\u201c\u98ce\u9669\u4fe1\u53f7\u7247\u6bb5\u201d\u2014\u2014\u5373\u6700\u65e9\u8868\u660e\u6f5c\u5728\u5b89\u5168\u9690\u60a3\u7684\u65f6\u95f4\u70b9\u3002\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524d\u7cfb\u7edf\u5728\u89e3\u8bfb\u52a8\u6001\u60c5\u5883\u5e76\u4ece\u65e9\u671f\u89c6\u89c9\u4fe1\u53f7\u4e2d\u9884\u6d4b\u672a\u6765\u98ce\u9669\u4e8b\u4ef6\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7a81\u663e\u4e86\u5728\u5b9e\u8df5\u4e2d\u90e8\u7f72\u89c6\u9891\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u6240\u9762\u4e34\u7684\u91cd\u8981\u6311\u6218\u3002"}}
