<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Neuromorphic Eye Tracking for Low-Latency Pupil Detection](https://arxiv.org/abs/2512.09969)
*Paul Hueber,Luca Peres,Florian Pitters,Alejandro Gloriani,Oliver Rhodes*

Main category: cs.CV

TL;DR: 本文提出一种基于脉冲神经网络（SNN）的高效事件驱动眼动追踪模型，通过轻量级LIF层和深度可分离卷积替代传统循环与注意力模块，在保持接近现有最优精度的同时，大幅降低模型大小与计算开销，适用于低功耗可穿戴AR/VR设备。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的眼动追踪方法在可穿戴系统中面临运动模糊、高计算成本和时间分辨率不足的问题；而现有SNN方法要么过于专用，要么性能不及现代ANN。因此需要一种兼顾高精度与能效的新型神经形态眼动追踪方案。

Method: 将当前最优的事件驱动眼动追踪模型转换为神经形态版本，使用轻量级LIF（Leaky Integrate-and-Fire）层替代原有的循环和注意力模块，并引入深度可分离卷积以降低模型复杂度。

Result: 所提模型平均误差为3.7–4.1像素，接近专用神经形态系统Retina（3.24像素），模型体积缩小20倍，理论计算量减少850倍；预计可在1kHz下以3.9–4.9毫瓦功耗和3毫秒延迟运行。

Conclusion: 高性能的事件驱动眼动追踪架构可以成功重构为SNN，在显著提升能效的同时保持适用于实时可穿戴部署的精度。

Abstract: Eye tracking for wearable systems demands low latency and milliwatt-level power, but conventional frame-based pipelines struggle with motion blur, high compute cost, and limited temporal resolution. Such capabilities are vital for enabling seamless and responsive interaction in emerging technologies like augmented reality (AR) and virtual reality (VR), where understanding user gaze is key to immersion and interface design. Neuromorphic sensors and spiking neural networks (SNNs) offer a promising alternative, yet existing SNN approaches are either too specialized or fall short of the performance of modern ANN architectures. This paper presents a neuromorphic version of top-performing event-based eye-tracking models, replacing their recurrent and attention modules with lightweight LIF layers and exploiting depth-wise separable convolutions to reduce model complexity. Our models obtain 3.7-4.1px mean error, approaching the accuracy of the application-specific neuromorphic system, Retina (3.24px), while reducing model size by 20x and theoretical compute by 850x, compared to the closest ANN variant of the proposed model. These efficient variants are projected to operate at an estimated 3.9-4.9 mW with 3 ms latency at 1 kHz. The present results indicate that high-performing event-based eye-tracking architectures can be redesigned as SNNs with substantial efficiency gains, while retaining accuracy suitable for real-time wearable deployment.

Abstract (中文翻译): 面向可穿戴系统的眼动追踪需要低延迟和毫瓦级功耗，但传统的基于帧的处理流程在运动模糊、高计算开销和有限的时间分辨率方面存在困难。这种能力对于增强现实（AR）和虚拟现实（VR）等新兴技术中的无缝、响应式交互至关重要，其中用户注视点的理解是沉浸感和界面设计的关键。神经形态传感器和脉冲神经网络（SNN）提供了一种有前景的替代方案，然而现有的SNN方法要么过于专用，要么性能无法达到现代人工神经网络（ANN）架构的水平。本文提出了当前最优事件驱动眼动追踪模型的神经形态版本，用轻量级LIF层取代其循环和注意力模块，并利用深度可分离卷积来降低模型复杂度。我们的模型取得了3.7–4.1像素的平均误差，接近专用神经形态系统Retina（3.24像素）的精度，同时相比最接近的ANN变体，模型大小减少了20倍，理论计算量减少了850倍。这些高效变体预计可在1kHz频率下以3.9–4.9毫瓦的功耗和3毫秒的延迟运行。结果表明，高性能的事件驱动眼动追踪架构可以被重新设计为SNN，在显著提升能效的同时，仍保持适合实时可穿戴部署的精度。

</details>


### [2] [ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects](https://arxiv.org/abs/2512.10031)
*Woojin Lee,Hyugjae Chang,Jaeho Moon,Jaehyup Lee,Munchurl Kim*

Main category: cs.CV

TL;DR: 本文提出ABBSPO框架，通过自适应边界框缩放和对称先验角度损失，提升弱监督方向目标检测（WS-OOD）的性能，尤其在仅使用水平边界框标注的情况下达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有基于水平边界框（HBox）监督的方向目标检测方法在尺度估计上存在不准确问题，且在多视角增强下易出现学习崩溃，限制了其性能。

Method: 提出ABBSPO框架，包含：(i) 自适应边界框缩放（ABBS），根据预测旋转框动态调整真实HBox尺度；(ii) 对称先验角度（SPA）损失，利用航拍目标的对称性进行自监督学习，防止学习崩溃。

Result: 大量实验表明，ABBSPO在HBox弱监督设定下显著优于现有方法，达到当前最优性能。

Conclusion: ABBSPO有效解决了HBox监督下方向目标检测中的尺度不准与学习不稳定问题，为弱监督方向目标检测提供了高效且高精度的新方案。

Abstract: Weakly supervised oriented object detection (WS-OOD) has gained attention as a cost-effective alternative to fully supervised methods, providing both efficiency and high accuracy. Among weakly supervised approaches, horizontal bounding box (HBox)-supervised OOD stands out for its ability to directly leverage existing HBox annotations while achieving the highest accuracy under weak supervision settings. This paper introduces adaptive bounding box scaling and symmetry-prior-based orientation prediction, called ABBSPO, a framework for WS-OOD. Our ABBSPO addresses limitations of previous HBox-supervised OOD methods, which compare ground truth (GT) HBoxes directly with the minimum circumscribed rectangles of predicted RBoxes, often leading to inaccurate scale estimation. To overcome this, we propose: (i) Adaptive Bounding Box Scaling (ABBS), which appropriately scales GT HBoxes to optimize for the size of each predicted RBox, ensuring more accurate scale prediction; and (ii) a Symmetric Prior Angle (SPA) loss that exploits inherent symmetry of aerial objects for self-supervised learning, resolving issues in previous methods where learning collapses when predictions for all three augmented views (original, rotated, and flipped) are consistently incorrect. Extensive experimental results demonstrate that ABBSPO achieves state-of-the-art performance, outperforming existing methods.

Abstract (中文翻译): 弱监督方向目标检测（WS-OOD）作为一种兼顾效率与精度、成本较低的替代方案，近年来受到广泛关注。在各类弱监督方法中，基于水平边界框（HBox）监督的OOS因其能直接利用现有的HBox标注，并在弱监督设定下实现最高精度而尤为突出。本文提出一种名为ABBSPO的WS-OOD框架，结合自适应边界框缩放与基于对称先验的方向预测。ABBSPO针对以往HBox监督OOS方法的局限性进行了改进——这些方法通常将真实HBox与预测旋转框（RBox）的最小外接矩形直接比较，导致尺度估计不准确。为此，我们提出：(i) 自适应边界框缩放（ABBS），根据每个预测RBox的尺寸动态调整真实HBox的尺度，从而提升尺度预测准确性；(ii) 对称先验角度（SPA）损失，利用航拍目标固有的对称性进行自监督学习，解决以往方法在原始、旋转和翻转三种增强视图预测均错误时出现的学习崩溃问题。大量实验结果表明，ABBSPO实现了最先进的性能，显著优于现有方法。

</details>


### [3] [Diffusion Is Your Friend in Show, Suggest and Tell](https://arxiv.org/abs/2512.10038)
*Jia Cheng Hu,Roberto Cavicchioli,Alessandro Capotondi*

Main category: cs.CV

TL;DR: 本文提出将扩散模型作为自回归模型的“建议模块”，而非替代方案，在图像描述生成任务中实现SOTA性能，COCO上达到125.1 CIDEr-D，优于现有自回归和扩散模型。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散去噪模型在生成式计算机视觉任务中表现优异，但在离散域（如文本生成）中仍无法超越标准自回归方法。作者旨在结合两者优势，探索一种新的范式。

Method: 提出Show, Suggest and Tell (SST)框架，利用扩散模型为自回归生成过程提供双向、可优化的建议，同时保留自回归模型强大的语言结构建模能力。

Result: SST在COCO数据集上取得125.1 CIDEr-D分数（未使用强化学习），比当前最优的自回归模型和扩散模型分别高出1.5和2.5分；实验还验证了建议模块与生成质量呈正相关。

Conclusion: 将扩散模型作为自回归生成的辅助建议机制是一种有效且有前景的新方向，值得进一步探索。

Abstract: Diffusion Denoising models demonstrated impressive results across generative Computer Vision tasks, but they still fail to outperform standard autoregressive solutions in the discrete domain, and only match them at best. In this work, we propose a different paradigm by adopting diffusion models to provide suggestions to the autoregressive generation rather than replacing them. By doing so, we combine the bidirectional and refining capabilities of the former with the strong linguistic structure provided by the latter. To showcase its effectiveness, we present Show, Suggest and Tell (SST), which achieves State-of-the-Art results on COCO, among models in a similar setting. In particular, SST achieves 125.1 CIDEr-D on the COCO dataset without Reinforcement Learning, outperforming both autoregressive and diffusion model State-of-the-Art results by 1.5 and 2.5 points. On top of the strong results, we performed extensive experiments to validate the proposal and analyze the impact of the suggestion module. Results demonstrate a positive correlation between suggestion and caption quality, overall indicating a currently underexplored but promising research direction. Code will be available at: https://github.com/jchenghu/show\_suggest\_tell.

Abstract (中文翻译): 扩散去噪模型在各类生成式计算机视觉任务中展现了令人印象深刻的效果，但在离散域（如文本生成）中仍未能超越标准的自回归方法，最多仅能达到相当水平。本文提出了一种新范式：采用扩散模型为自回归生成过程提供建议，而非取代它。通过这种方式，我们结合了扩散模型的双向性和优化能力，以及自回归模型所提供的强大语言结构。为验证该方法的有效性，我们提出了Show, Suggest and Tell（SST）模型，在相似设定下于COCO数据集上取得了当前最优结果。具体而言，SST在未使用强化学习的情况下，在COCO上达到了125.1的CIDEr-D分数，分别比当前最优的自回归模型和扩散模型高出1.5分和2.5分。除取得优异结果外，我们还进行了大量实验以验证所提方法，并分析建议模块的影响。结果表明，建议质量与生成文本质量之间存在正相关关系，整体显示出一个目前尚未被充分探索但极具前景的研究方向。代码将公开于：https://github.com/jchenghu/show_suggest_tell。

</details>


### [4] [MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata](https://arxiv.org/abs/2512.10041)
*Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman*

Main category: cs.CV

TL;DR: MetaVoxel 是一个基于联合扩散模型的框架，通过学习图像与临床元数据的联合分布，实现多任务统一建模和零样本灵活推理，在多个医学任务上达到与专用模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多数深度学习方法针对特定预测方向和输入变量训练条件模型，难以在不同任务间通用，且需要为每个任务单独训练模型。作者希望构建一个统一框架，能够灵活处理任意输入子集，并支持多种医学任务，从而提升模型的通用性和临床适用性。

Method: 提出 MetaVoxel 框架，利用单一扩散过程对医学影像（如 T1 加权 MRI）和临床元数据的联合分布进行建模，从而在一个模型中统一多种任务，并支持无需重新训练的零样本推理。

Result: 在包含超过 10,000 例 MRI 扫描和临床元数据的九个数据集上，MetaVoxel 在图像生成、年龄估计和性别预测等任务中表现与专门设计的基线模型相当，并展示了灵活推理能力。

Conclusion: 联合多模态扩散模型为统一医学 AI 模型提供了一条有前景的路径，有助于提升模型在临床中的广泛适用性。

Abstract: Modern deep learning methods have achieved impressive results across tasks from disease classification, estimating continuous biomarkers, to generating realistic medical images. Most of these approaches are trained to model conditional distributions defined by a specific predictive direction with a specific set of input variables. We introduce MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata by learning a single diffusion process spanning all variables. By capturing the joint distribution, MetaVoxel unifies tasks that traditionally require separate conditional models and supports flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining. Using more than 10,000 T1-weighted MRI scans paired with clinical metadata from nine datasets, we show that a single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines. Additional experiments highlight its capabilities for flexible inference.Together, these findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.

Abstract (中文翻译): 现代深度学习方法在疾病分类、连续生物标志物估计到生成逼真医学图像等任务中取得了令人瞩目的成果。然而，这些方法大多被训练用于建模由特定预测方向和特定输入变量定义的条件分布。我们提出了 MetaVoxel——一种生成式联合扩散建模框架，通过学习覆盖所有变量的单一扩散过程，对影像数据与临床元数据的联合分布进行建模。通过捕捉联合分布，MetaVoxel 统一了传统上需要独立条件模型的任务，并支持使用任意输入子集进行灵活的零样本推理，而无需针对具体任务重新训练。我们在来自九个数据集的超过 10,000 例 T1 加权 MRI 扫描及其配对临床元数据上验证了该方法，结果表明单个 MetaVoxel 模型即可执行图像生成、年龄估计和性别预测，并在性能上与成熟的任务专用基线模型相当。进一步实验突显了其灵活推理的能力。这些发现共同表明，联合多模态扩散模型为统一医学人工智能模型并拓展其临床应用提供了有前景的方向。

</details>


### [5] [Independent Density Estimation](https://arxiv.org/abs/2512.10067)
*Jiahao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为独立密度估计（IDE）的新方法，通过学习句子中每个词与图像特征之间的对应关系，提升视觉-语言模型在组合泛化方面的能力，并在多个数据集上展现出优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视觉-语言模型虽在图像描述和条件图像生成等任务上表现优异，但在实现类人的组合泛化能力方面仍存在困难。

Method: 提出独立密度估计（IDE）方法，构建两个基于IDE理念的模型：一个使用完全解耦的视觉表征作为输入，另一个利用变分自编码器从原始图像中提取部分解耦特征；同时提出一种基于熵的组合推理方法，融合句子中每个词的预测结果。

Result: 所提模型在多个数据集上对未见过的组合具有更强的泛化能力，优于当前主流模型。

Conclusion: IDE方法有效提升了视觉-语言模型的组合泛化能力，为解决该领域关键挑战提供了新思路。

Abstract: Large-scale Vision-Language models have achieved remarkable results in various domains, such as image captioning and conditioned image generation. Neverthe- less, these models still encounter difficulties in achieving human-like composi- tional generalization. In this study, we propose a new method called Independent Density Estimation (IDE) to tackle this challenge. IDE aims to learn the connec- tion between individual words in a sentence and the corresponding features in an image, enabling compositional generalization. We build two models based on the philosophy of IDE. The first one utilizes fully disentangled visual representations as input, and the second leverages a Variational Auto-Encoder to obtain partially disentangled features from raw images. Additionally, we propose an entropy- based compositional inference method to combine predictions of each word in the sentence. Our models exhibit superior generalization to unseen compositions compared to current models when evaluated on various datasets.

Abstract (中文翻译): 大规模视觉-语言模型在图像描述和条件图像生成等多个领域取得了显著成果。然而，这些模型在实现类人的组合泛化能力方面仍然面临困难。本研究提出了一种名为独立密度估计（Independent Density Estimation, IDE）的新方法来应对这一挑战。IDE旨在学习句子中各个词语与图像中对应特征之间的关联，从而实现组合泛化。我们基于IDE的理念构建了两个模型：第一个模型采用完全解耦的视觉表征作为输入，第二个模型则利用变分自编码器从原始图像中获取部分解耦的特征。此外，我们还提出了一种基于熵的组合推理方法，用于融合句子中每个词语的预测结果。在多个数据集上的评估表明，与现有模型相比，我们的模型在对未见过的组合进行泛化时表现更优。

</details>


### [6] [TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing](https://arxiv.org/abs/2512.10095)
*Jiachen Tao,Junyi Wu,Haoxuan Wang,Zongxin Yang,Dawen Cai,Yan Yan*

Main category: cs.CV

TL;DR: TraceFlow 是一种用于高保真渲染动态镜面场景的新框架，通过精确估计反射方向和物理准确的反射建模，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态镜面场景渲染中难以同时实现精确的反射方向估计和物理上准确的反射建模，限制了真实感表现。

Method: 提出 Residual Material-Augmented 2D Gaussian Splatting 表示以建模动态几何与材质；引入 Dynamic Environment Gaussian 和混合渲染管线，将渲染分解为漫反射与镜面反射成分，并结合光栅化与光线追踪进行物理合理的镜面合成；采用由粗到精的训练策略提升优化稳定性与物理分解合理性。

Result: 在多个动态场景基准上的实验表明，TraceFlow 在定量和定性指标上均优于先前方法，能生成更清晰、逼真的镜面反射效果。

Conclusion: TraceFlow 成功解决了动态镜面场景渲染中的关键挑战，实现了高保真、物理合理的镜面反射重建。

Abstract: We present TraceFlow, a novel framework for high-fidelity rendering of dynamic specular scenes by addressing two key challenges: precise reflection direction estimation and physically accurate reflection modeling. To achieve this, we propose a Residual Material-Augmented 2D Gaussian Splatting representation that models dynamic geometry and material properties, allowing accurate reflection ray computation. Furthermore, we introduce a Dynamic Environment Gaussian and a hybrid rendering pipeline that decomposes rendering into diffuse and specular components, enabling physically grounded specular synthesis via rasterization and ray tracing. Finally, we devise a coarse-to-fine training strategy to improve optimization stability and promote physically meaningful decomposition. Extensive experiments on dynamic scene benchmarks demonstrate that TraceFlow outperforms prior methods both quantitatively and qualitatively, producing sharper and more realistic specular reflections in complex dynamic environments.

Abstract (中文翻译): 我们提出了 TraceFlow，这是一种用于高保真渲染动态镜面场景的新颖框架，旨在解决两个关键挑战：精确的反射方向估计和物理上准确的反射建模。为此，我们提出了一种残差材质增强的二维高斯泼溅（Residual Material-Augmented 2D Gaussian Splatting）表示方法，用于建模动态几何结构和材质属性，从而实现精确的反射光线计算。此外，我们引入了动态环境高斯（Dynamic Environment Gaussian）和一种混合渲染管线，将渲染过程分解为漫反射和镜面反射两个部分，通过光栅化与光线追踪相结合的方式实现基于物理的镜面反射合成。最后，我们设计了一种由粗到精的训练策略，以提升优化稳定性并促进具有物理意义的反射成分分解。在多个动态场景基准上的大量实验表明，TraceFlow 在定量和定性评估中均优于现有方法，在复杂动态环境中生成了更清晰、更逼真的镜面反射效果。

</details>


### [7] [Hierarchical Instance Tracking to Balance Privacy Preservation with Accessible Information](https://arxiv.org/abs/2512.10102)
*Neelima Prasad,Jarek Reynolds,Neel Karsanbhai,Tanusree Sharma,Lotus Zhang,Abigale Stangl,Yang Wang,Leah Findlater,Danna Gurari*

Main category: cs.CV

TL;DR: 提出了一个新任务“层次化实例跟踪”，并发布了首个支持该任务的基准数据集，包含552个视频中的2765个实体，涵盖40个类别。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对对象及其组成部分之间层次关系的联合跟踪能力，因此需要定义一个能同时跟踪对象与部件并保持其层次结构的新任务。

Method: 提出“层次化实例跟踪”任务，并构建首个包含对象与部件层次关系的基准数据集，涵盖552段视频、2765个实体和40个类别；同时评估了四种模型的七个变体在该任务上的表现。

Result: 在所提数据集上对多个模型变体的评估表明，该任务具有挑战性，现有方法尚难以完全解决。

Conclusion: 该研究成功定义并实现了层次化实例跟踪任务，提供了公开可用的基准数据集，为未来相关研究奠定了基础。

Abstract: We propose a novel task, hierarchical instance tracking, which entails tracking all instances of predefined categories of objects and parts, while maintaining their hierarchical relationships. We introduce the first benchmark dataset supporting this task, consisting of 2,765 unique entities that are tracked in 552 videos and belong to 40 categories (across objects and parts). Evaluation of seven variants of four models tailored to our novel task reveals the new dataset is challenging. Our dataset is available at https://vizwiz.org/tasks-and-datasets/hierarchical-instance-tracking/

Abstract (中文翻译): 我们提出了一项新任务——层次化实例跟踪，该任务要求跟踪预定义类别中的所有对象及其组成部分的实例，同时保持它们之间的层次关系。我们发布了首个支持该任务的基准数据集，包含552段视频中被跟踪的2765个唯一实体，涵盖40个类别（包括对象和部件）。通过对四种模型的七个变体在该任务上的评估，结果表明新数据集具有挑战性。我们的数据集可在 https://vizwiz.org/tasks-and-datasets/hierarchical-instance-tracking/ 获取。

</details>


### [8] [Topological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization](https://arxiv.org/abs/2512.10151)
*Charles Fanning,Mehmet Emin Aktas*

Main category: cs.CV

TL;DR: 本文提出一种基于小波持久同调的条件信号，用于提升乳腺癌筛查模型在不同数据集上的泛化性能。该方法利用拓扑数据分析提取图像中跨强度阈值稳定的结构信息，并将其转化为多尺度空间图，整合进两阶段检测流程。在CBIS-DDSM数据集上训练，在INbreast和CMMD数据集上验证，结果表明加入该信号可显著提升AUC。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是女性中最常见的癌症，也是全球癌症死亡的主要原因。尽管筛查性乳腺X线摄影可降低死亡率，但其解读仍存在较高的假阴性和假阳性率，且模型在不同扫描设备、成像模态和人群中的性能常显著下降。因此，亟需提升模型的外部泛化能力。

Method: 作者提出一种基于小波的持久同调向量化方法，利用拓扑数据分析（TDA）提取图像中在不同强度阈值下保持稳定的结构特征，并将其转换为对小强度扰动具有理论稳定性的多尺度空间图。这些图通过输入层通道拼接的方式，整合到一个两阶段检测流程中。

Result: 模型在美国CBIS-DDSM胶片数字化乳腺X线数据集上训练和验证，并在葡萄牙（INbreast）和中国（CMMD）两个独立的全视野数字乳腺X线数据集上评估。在有限训练预算下，将ConvNeXt Tiny与小波持久性通道结合，使INbreast数据集上的患者级别AUC从0.55提升至0.75。

Conclusion: 所提出的基于小波持久同调的条件信号能有效提升乳腺癌检测模型在跨数据集场景下的性能，证明了拓扑特征在医学图像分析中增强模型鲁棒性和泛化能力的潜力。

Abstract: Breast cancer is the most commonly diagnosed cancer in women and a leading cause of cancer death worldwide. Screening mammography reduces mortality, yet interpretation still suffers from substantial false negatives and false positives, and model accuracy often degrades when deployed across scanners, modalities, and patient populations. We propose a simple conditioning signal aimed at improving external performance based on a wavelet based vectorization of persistent homology. Using topological data analysis, we summarize image structure that persists across intensity thresholds and convert this information into spatial, multi scale maps that are provably stable to small intensity perturbations. These maps are integrated into a two stage detection pipeline through input level channel concatenation. The model is trained and validated on the CBIS DDSM digitized film mammography cohort from the United States and evaluated on two independent full field digital mammography cohorts from Portugal (INbreast) and China (CMMD), with performance reported at the patient level. On INbreast, augmenting ConvNeXt Tiny with wavelet persistence channels increases patient level AUC from 0.55 to 0.75 under a limited training budget.

Abstract (中文翻译): 乳腺癌是女性中最常被诊断出的癌症，也是全球癌症死亡的主要原因。筛查性乳腺X线摄影可降低死亡率，但其解读仍存在大量假阴性和假阳性问题，且模型在不同扫描仪、成像模态和患者群体中部署时，准确性常常下降。我们提出一种简单的条件信号，旨在通过基于小波的持久同调向量化来提升模型的外部性能。利用拓扑数据分析，我们总结了在不同强度阈值下持续存在的图像结构，并将该信息转化为对微小强度扰动具有理论稳定性的空间多尺度图。这些图通过输入层通道拼接的方式整合到一个两阶段检测流程中。该模型在美国CBIS-DDSM胶片数字化乳腺X线数据集上进行训练和验证，并在来自葡萄牙（INbreast）和中国（CMMD）的两个独立全视野数字乳腺X线数据集上进行评估，性能以患者级别报告。在INbreast数据集上，在有限训练预算下，将ConvNeXt Tiny与小波持久性通道结合，使患者级别的AUC从0.55提升至0.75。

</details>


### [9] [Feature Coding for Scalable Machine Vision](https://arxiv.org/abs/2512.10209)
*Md Eimran Hossain Eimon,Juan Merlos,Ashan Perera,Hari Kalva,Velibor Adzic,Borko Furht*

Main category: cs.CV

TL;DR: 本文介绍了MPEG的Feature Coding for Machines (FCM)标准及其测试模型FCTM，通过压缩DNN中间特征，在保持精度的同时平均减少85.14%的比特率，为边缘-云协同推理提供高效、可互操作的解决方案。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署深度神经网络面临计算、带宽、延迟和隐私的挑战；传统全本地或全云端方案存在局限，而边缘-云分割推理虽有优势，却因传输中间特征带来新的带宽压力，亟需高效的中间特征压缩方法。

Method: 采用MPEG制定的Feature Coding for Machines（FCM）标准，设计并实现Feature Coding Test Model（FCTM），对深度神经网络的中间特征进行专门优化的压缩编码。

Result: 在多个视觉任务中，FCTM在保持模型精度的前提下，平均实现了85.14%的比特率降低。

Conclusion: FCM标准为带宽受限和注重隐私的消费级应用提供了可扩展、高效且可互操作的智能特征部署路径。

Abstract: Deep neural networks (DNNs) drive modern machine vision but are challenging to deploy on edge devices due to high compute demands. Traditional approaches-running the full model on-device or offloading to the cloud face trade-offs in latency, bandwidth, and privacy. Splitting the inference workload between the edge and the cloud offers a balanced solution, but transmitting intermediate features to enable such splitting introduces new bandwidth challenges. To address this, the Moving Picture Experts Group (MPEG) initiated the Feature Coding for Machines (FCM) standard, establishing a bitstream syntax and codec pipeline tailored for compressing intermediate features. This paper presents the design and performance of the Feature Coding Test Model (FCTM), showing significant bitrate reductions-averaging 85.14%-across multiple vision tasks while preserving accuracy. FCM offers a scalable path for efficient and interoperable deployment of intelligent features in bandwidth-limited and privacy-sensitive consumer applications.

Abstract (中文翻译): 深度神经网络（DNN）推动了现代机器视觉的发展，但由于其高计算需求，在边缘设备上的部署颇具挑战。传统方法——在设备端运行完整模型或将计算卸载至云端——在延迟、带宽和隐私方面存在权衡。将推理任务在边缘与云端之间拆分提供了一种平衡的解决方案，但为了实现这种拆分而传输中间特征又带来了新的带宽挑战。为此，动态图像专家组（MPEG）启动了“面向机器的特征编码”（Feature Coding for Machines, FCM）标准，制定了专门用于压缩中间特征的比特流语法和编解码器流程。本文介绍了特征编码测试模型（Feature Coding Test Model, FCTM）的设计与性能，在多个视觉任务中平均实现了85.14%的比特率降低，同时保持了模型精度。FCM为在带宽受限且注重隐私的消费级应用中高效、可互操作地部署智能特征提供了一条可扩展的路径。

</details>


### [10] [Latent Chain-of-Thought World Modeling for End-to-End Driving](https://arxiv.org/abs/2512.10226)
*Shuhan Tan,Kashyap Chitta,Yuxiao Chen,Ran Tian,Yurong You,Yan Wang,Wenjie Luo,Yulong Cao,Philipp Krahenbuhl,Marco Pavone,Boris Ivanovic*

Main category: cs.CV

TL;DR: 本文提出LCDrive，一种在隐空间中进行推理的视觉-语言-动作模型，通过动作对齐的隐式语言替代自然语言进行链式推理，从而提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型多使用自然语言进行链式推理（CoT），但文本可能不是最高效的推理表示方式；作者旨在探索更高效、与动作对齐的隐式推理机制以提升自动驾驶的安全性和性能。

Method: 提出Latent-CoT-Drive（LCDrive）模型，用动作提案token和世界模型token在隐空间中交替进行推理，二者共享动作词汇并基于学习到的隐式世界模型表达未来结果；先通过真实未来轨迹冷启动训练，再通过闭环强化学习进行后训练。

Result: 在大规模端到端驾驶基准上，LCDrive相比无推理和基于文本推理的基线模型，实现了更快的推理速度、更优的轨迹质量，以及在交互式强化学习中更大的性能提升。

Conclusion: 将链式推理与决策统一于动作对齐的隐空间中，比使用自然语言更高效，能显著提升自动驾驶系统的推理能力和驾驶表现。

Abstract: Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model's output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model's action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.

Abstract (中文翻译): 近期用于自动驾驶的视觉-语言-动作（VLA）模型探索了推理时推理机制，以在具有挑战性的场景中提升驾驶性能与安全性。以往大多数工作使用自然语言在生成驾驶动作前表达思维链（CoT）推理。然而，文本可能并非最高效的推理表示方式。本文提出了Latent-CoT-Drive（LCDrive）：一种在隐式语言中表达CoT的模型，该隐式语言能够捕捉所考虑驾驶动作的可能结果。我们的方法通过在与动作对齐的隐空间中统一表示CoT推理与决策过程来实现这一目标。模型不再使用自然语言，而是交替使用（1）动作提案token（与模型输出动作共享同一词汇表）和（2）世界模型token（基于学习到的隐式世界模型，表达这些动作的未来结果）进行推理。我们通过监督模型的动作提案和世界模型token（基于场景的真实未来轨迹）来冷启动隐式CoT，然后通过闭环强化学习进行后训练以增强推理能力。在大规模端到端驾驶基准测试中，LCDrive相比无推理和基于文本推理的基线模型，实现了更快的推理速度、更高质量的轨迹，以及在交互式强化学习中更大的性能提升。

</details>
