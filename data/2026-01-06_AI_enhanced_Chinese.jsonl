{"id": "2601.00812", "pdf": "https://arxiv.org/pdf/2601.00812", "abs": "https://arxiv.org/abs/2601.00812", "authors": ["Takashi Ushio", "Kazuhiro Onishi", "Hideyoshi Yanagisawa"], "title": "Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements", "categories": ["cs.CV", "cs.AI"], "comment": "This article has been accepted for publication in IEEE Access and will be published shortly", "summary": "Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified \"pleasantness,\" \"surprise,\" and \"habituation\" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected \"pleasantness\" associated with brand presentation, BS has captured \"surprise\" arising from informational complexity, and UN has reflected \"surprise\" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.", "AI": {"tldr": "\u8be5\u7814\u7a76\u57fa\u4e8e\u81ea\u7531\u80fd\u539f\u7406\uff0c\u4ec5\u5229\u7528\u5e7f\u544a\u89c6\u9891\u7684\u573a\u666f\u7ea7\u8868\u8fbe\u7279\u5f81\uff08\u65e0\u9700\u751f\u7406\u4fe1\u53f7\u6216\u4e3b\u89c2\u8bc4\u5206\uff09\u91cf\u5316\u4e86\u201c\u6109\u60a6\u5ea6\u201d\u3001\u201c\u60ca\u8bb6\u201d\u548c\u201c\u4e60\u60ef\u5316\u201d\u4e09\u79cd\u60c5\u7eea\uff0c\u5e76\u8bc6\u522b\u51fa\u4e09\u79cd\u5178\u578b\u60c5\u7eea\u6a21\u5f0f\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u7a33\u5065\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u60c5\u7eea\u4f30\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u4fe1\u606f\uff08\u5982\u751f\u7406\u4fe1\u53f7\u6216\u4e3b\u89c2\u8bc4\u5206\uff09\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff1b\u672c\u7814\u7a76\u65e8\u5728\u5efa\u7acb\u4e00\u79cd\u4e0d\u4f9d\u8d56\u6b64\u7c7b\u4fe1\u606f\u3001\u57fa\u4e8e\u81ea\u7531\u80fd\u539f\u7406\u7684\u60c5\u7eea\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u5e7f\u544a\u89c6\u9891\u5bf9\u89c2\u4f17\u60c5\u7eea\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u81ea\u7531\u80fd\uff08FE\uff09\u539f\u7406\uff0c\u5229\u7528Kullback-Leibler\u6563\u5ea6\uff08KLD\uff09\u3001\u8d1d\u53f6\u65af\u60ca\u8bb6\uff08BS\uff09\u548c\u4e0d\u786e\u5b9a\u6027\uff08UN\uff09\u4e09\u4e2a\u6307\u6807\uff0c\u4ece1,059\u4e2a15\u79d2\u98df\u54c1\u5e7f\u544a\u89c6\u9891\u7684\u573a\u666f\u7ea7\u8868\u8fbe\u7279\u5f81\u4e2d\u91cf\u5316\u201c\u6109\u60a6\u5ea6\u201d\u3001\u201c\u60ca\u8bb6\u201d\u548c\u201c\u4e60\u60ef\u5316\u201d\u60c5\u7eea\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1aKLD\u53cd\u6620\u4e0e\u54c1\u724c\u5448\u73b0\u76f8\u5173\u7684\u201c\u6109\u60a6\u5ea6\u201d\uff0cBS\u6355\u6349\u7531\u4fe1\u606f\u590d\u6742\u6027\u5f15\u8d77\u7684\u201c\u60ca\u8bb6\u201d\uff0cUN\u53cd\u6620\u7531\u5143\u7d20\u7c7b\u578b\u3001\u7a7a\u95f4\u5e03\u5c40\u4e0d\u786e\u5b9a\u6027\u53ca\u5143\u7d20\u6570\u91cf/\u53d8\u5f02\u6027\u5f15\u53d1\u7684\u201c\u60ca\u8bb6\u201d\uff1b\u7814\u7a76\u8fd8\u8bc6\u522b\u51fa\u4e09\u79cd\u5178\u578b\u60c5\u7eea\u6a21\u5f0f\uff0c\u5e76\u5728\u4e0d\u540c\u8d85\u53c2\u6570\u548c\u516d\u7c7b\u65e5\u672c\u5e7f\u544a\u89c6\u9891\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u7a33\u5065\u6027\u548c\u6cdb\u5316\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u89e3\u91ca\u7684\u60c5\u7eea\u4f30\u8ba1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u672a\u6765\u53ef\u901a\u8fc7\u6574\u5408\u66f4\u591a\u8868\u8fbe\u5143\u7d20\u5e76\u7ed3\u5408\u4e3b\u89c2\u8bc4\u5206\u8fdb\u4e00\u6b65\u9a8c\u8bc1\uff0c\u6709\u671b\u652f\u6301\u66f4\u5177\u5438\u5f15\u529b\u7684\u5e7f\u544a\u89c6\u9891\u521b\u4f5c\u6280\u672f\u7684\u53d1\u5c55\u3002", "summary_cn": "\u5728\u89c2\u770b\u5e7f\u544a\u89c6\u9891\u8fc7\u7a0b\u4e2d\u7684\u60c5\u7eea\u53cd\u5e94\u88ab\u8ba4\u4e3a\u662f\u7406\u89e3\u5a92\u4f53\u6548\u679c\u7684\u5173\u952e\u56e0\u7d20\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f1a\u5f71\u54cd\u6ce8\u610f\u529b\u3001\u8bb0\u5fc6\u548c\u8d2d\u4e70\u610f\u613f\u3002\u4e3a\u4e86\u5efa\u7acb\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u751f\u7406\u4fe1\u53f7\u6216\u4e3b\u89c2\u8bc4\u5206\u7b49\u5916\u90e8\u4fe1\u606f\u7684\u53ef\u89e3\u91ca\u60c5\u7eea\u4f30\u8ba1\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u672c\u7814\u7a76\u57fa\u4e8e\u81ea\u7531\u80fd\uff08FE\uff09\u539f\u7406\uff0c\u4ec5\u4ece\u5e7f\u544a\u89c6\u9891\u7684\u573a\u666f\u7ea7\u8868\u8fbe\u7279\u5f81\u51fa\u53d1\uff0c\u5bf9\u201c\u6109\u60a6\u5ea6\u201d\u3001\u201c\u60ca\u8bb6\u201d\u548c\u201c\u4e60\u60ef\u5316\u201d\u8fdb\u884c\u4e86\u91cf\u5316\u3002\u81ea\u7531\u80fd\u539f\u7406\u4e3a\u611f\u77e5\u3001\u5b66\u4e60\u548c\u884c\u4e3a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u89e3\u91ca\u6846\u67b6\uff0c\u5176\u4e2dKullback-Leibler\u6563\u5ea6\uff08KLD\uff09\u7528\u4e8e\u6355\u6349\u9884\u6d4b\u8bef\u5dee\uff0c\u8d1d\u53f6\u65af\u60ca\u8bb6\uff08BS\uff09\u7528\u4e8e\u6355\u6349\u4fe1\u5ff5\u66f4\u65b0\uff0c\u4e0d\u786e\u5b9a\u6027\uff08UN\uff09\u5219\u53cd\u6620\u5148\u9a8c\u6a21\u7cca\u6027\uff0c\u4e09\u8005\u5171\u540c\u6784\u6210\u4e86\u81ea\u7531\u80fd\u7684\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\u3002\u901a\u8fc7\u5bf91,059\u4e2a15\u79d2\u98df\u54c1\u5e7f\u544a\u89c6\u9891\u7684\u5b9e\u9a8c\u5206\u6790\uff0c\u7ed3\u679c\u8868\u660e\uff1aKLD\u53cd\u6620\u4e86\u4e0e\u54c1\u724c\u5448\u73b0\u76f8\u5173\u7684\u201c\u6109\u60a6\u5ea6\u201d\uff0cBS\u6355\u6349\u4e86\u7531\u4fe1\u606f\u590d\u6742\u6027\u5f15\u53d1\u7684\u201c\u60ca\u8bb6\u201d\uff0c\u800cUN\u5219\u53cd\u6620\u4e86\u7531\u5143\u7d20\u7c7b\u578b\u548c\u7a7a\u95f4\u5e03\u5c40\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u53ca\u6240\u5448\u73b0\u5143\u7d20\u7684\u591a\u6837\u6027\u548c\u6570\u91cf\u6240\u9a71\u52a8\u7684\u201c\u60ca\u8bb6\u201d\u3002\u672c\u7814\u7a76\u8fd8\u8bc6\u522b\u51fa\u4e09\u79cd\u5178\u578b\u7684\u60c5\u7eea\u6a21\u5f0f\uff0c\u5373\u4e0d\u786e\u5b9a\u523a\u6fc0\u578b\u3001\u6301\u7eed\u9ad8\u60c5\u7eea\u578b\u548c\u77ac\u65f6\u5cf0\u503c\u8870\u51cf\u578b\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5728\u4e5d\u79cd\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7684\u7a33\u5065\u6027\u6d4b\u8bd5\u4ee5\u53ca\u516d\u7c7b\u65e5\u672c\u5e7f\u544a\u89c6\u9891\uff08\u6db5\u76d6\u4e09\u79cd\u7c7b\u578b\u548c\u4e24\u79cd\u65f6\u957f\uff09\u7684\u6cdb\u5316\u6027\u9a8c\u8bc1\u5747\u8868\u660e\u8fd9\u4e9b\u8d8b\u52bf\u5177\u6709\u7a33\u5b9a\u6027\u3002\u672a\u6765\u53ef\u901a\u8fc7\u6574\u5408\u66f4\u5e7f\u6cdb\u7684\u8868\u8fbe\u5143\u7d20\uff0c\u5e76\u901a\u8fc7\u4e3b\u89c2\u8bc4\u5206\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u8be5\u65b9\u6cd5\uff0c\u6700\u7ec8\u4e3a\u5f00\u53d1\u652f\u6301\u521b\u4f5c\u66f4\u5177\u5438\u5f15\u529b\u5e7f\u544a\u89c6\u9891\u7684\u6280\u672f\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2601.00829", "pdf": "https://arxiv.org/pdf/2601.00829", "abs": "https://arxiv.org/abs/2601.00829", "authors": ["Alexander Vinogradov"], "title": "Can Generative Models Actually Forge Realistic Identity Documents?", "categories": ["cs.CV"], "comment": "11 pages, 16 figures", "summary": "Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.", "AI": {"tldr": "\u5f53\u524d\u5f00\u6e90\u6269\u6563\u6a21\u578b\u867d\u80fd\u6a21\u4eff\u8bc1\u4ef6\u5916\u89c2\uff0c\u4f46\u65e0\u6cd5\u8fbe\u5230\u6cd5\u8bc1\u7ea7\u522b\u7684\u771f\u5b9e\u6027\uff0c\u96be\u4ee5\u7ed5\u8fc7\u4eba\u5de5\u6216\u81ea\u52a8\u9a8c\u8bc1\u7cfb\u7edf\u3002", "motivation": "\u516c\u4f17\u62c5\u5fe7\u751f\u6210\u5f0f\u56fe\u50cf\u6a21\u578b\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u4f2a\u9020\u8eab\u4efd\u8bc1\u4ef6\uff0c\u56e0\u6b64\u9700\u8bc4\u4f30\u5176\u5b9e\u9645\u98ce\u9669\u3002", "method": "\u8bc4\u4f30\u591a\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u6587\u672c\u5230\u56fe\u50cf\u548c\u56fe\u50cf\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff08\u5982Stable Diffusion\u3001Qwen\u3001Flux\u7b49\uff09\u5728\u4f2a\u9020\u8eab\u4efd\u8bc1\u4ef6\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u53ef\u6a21\u62df\u8bc1\u4ef6\u8868\u9762\u5916\u89c2\uff0c\u4f46\u65e0\u6cd5\u590d\u73b0\u7ed3\u6784\u4e0e\u6cd5\u8bc1\u5c42\u9762\u7684\u771f\u5b9e\u6027\u3002", "conclusion": "\u5f53\u524d\u751f\u6210\u6a21\u578b\u5728\u5236\u4f5c\u5177\u6709\u6cd5\u8bc1\u771f\u5b9e\u6027\u7684\u8eab\u4efd\u8bc1\u4ef6\u6df1\u5ea6\u4f2a\u9020\u65b9\u9762\u7684\u80fd\u529b\u88ab\u9ad8\u4f30\uff0c\u5e94\u52a0\u5f3a\u673a\u5668\u5b66\u4e60\u4ece\u4e1a\u8005\u4e0e\u8bc1\u4ef6\u9274\u4f2a\u4e13\u5bb6\u7684\u5408\u4f5c\u4ee5\u8fdb\u884c\u66f4\u73b0\u5b9e\u7684\u98ce\u9669\u8bc4\u4f30\u3002", "summary_cn": "\u751f\u6210\u5f0f\u56fe\u50cf\u6a21\u578b\u6700\u8fd1\u5728\u56fe\u50cf\u903c\u771f\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u5f15\u53d1\u4e86\u516c\u4f17\u5bf9\u5176\u53ef\u80fd\u88ab\u6ee5\u7528\u4e8e\u6587\u4ef6\u4f2a\u9020\u7684\u62c5\u5fe7\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u5f53\u524d\u5f00\u6e90\u4e14\u516c\u5f00\u53ef\u7528\u7684\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\u662f\u5426\u80fd\u591f\u751f\u6210\u8db3\u4ee5\u7ed5\u8fc7\u4eba\u5de5\u6216\u81ea\u52a8\u5316\u9a8c\u8bc1\u7cfb\u7edf\u7684\u8eab\u4efd\u8bc1\u4ef6\u4f2a\u9020\u54c1\u3002\u6211\u4eec\u4f7f\u7528\u591a\u79cd\u516c\u5f00\u53ef\u7528\u7684\u751f\u6210\u6a21\u578b\u7cfb\u5217\uff08\u5305\u62ec Stable Diffusion\u3001Qwen\u3001Flux\u3001Nano-Banana \u7b49\uff09\u8bc4\u4f30\u4e86\u6587\u672c\u5230\u56fe\u50cf\u548c\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u751f\u6210\u6d41\u7a0b\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u5f53\u524d\u7684\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u6a21\u62df\u8bc1\u4ef6\u7684\u8868\u9762\u7f8e\u5b66\u7279\u5f81\uff0c\u4f46\u65e0\u6cd5\u518d\u73b0\u5176\u7ed3\u6784\u548c\u6cd5\u8bc1\u5c42\u9762\u7684\u771f\u5b9e\u6027\u3002\u56e0\u6b64\uff0c\u751f\u6210\u5f0f\u8eab\u4efd\u8bc1\u4ef6\u6df1\u5ea6\u4f2a\u9020\u8fbe\u5230\u6cd5\u8bc1\u7ea7\u771f\u5b9e\u6027\u7684\u98ce\u9669\u53ef\u80fd\u88ab\u9ad8\u4f30\uff0c\u8fd9\u7a81\u663e\u4e86\u673a\u5668\u5b66\u4e60\u4ece\u4e1a\u8005\u4e0e\u8bc1\u4ef6\u9274\u4f2a\u4e13\u5bb6\u4e4b\u95f4\u5408\u4f5c\u5f00\u5c55\u73b0\u5b9e\u98ce\u9669\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.00837", "pdf": "https://arxiv.org/pdf/2601.00837", "abs": "https://arxiv.org/abs/2601.00837", "authors": ["Agniv Roy Choudhury"], "title": "Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.\n  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.\n  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.\n  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\\% accuracy, 99.61\\% F1-score, and 99.93\\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.\n  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.\n  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u4ece\u5934\u8bad\u7ec3\u7684CNN\u4e0e\u57fa\u4e8e\u8fc1\u79fb\u5b66\u4e60\uff08ResNet50\u3001DenseNet121\u3001EfficientNet-B0\uff09\u7684\u6a21\u578b\u5728\u513f\u7ae5\u80ba\u708eX\u5149\u8bca\u65ad\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5fae\u8c03\u540e\u7684ResNet50\u6548\u679c\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe99.43%\uff0c\u8868\u660e\u8fc1\u79fb\u5b66\u4e60\u7ed3\u5408\u5fae\u8c03\u53ef\u4f5c\u4e3a\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u6709\u6548\u7684\u7b5b\u67e5\u5de5\u5177\u3002", "motivation": "\u513f\u7ae5\u80ba\u708e\u662f\u4e94\u5c81\u4ee5\u4e0b\u513f\u7ae5\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u6bcf\u5e74\u5bfc\u81f4\u8d8570\u4e07\u4f8b\u6b7b\u4ea1\u3002\u80f8\u90e8X\u5149\u8bca\u65ad\u53d7\u9650\u4e8e\u653e\u5c04\u79d1\u533b\u751f\u6570\u91cf\u4e0d\u8db3\u548c\u5224\u8bfb\u5dee\u5f02\uff0c\u4e9f\u9700\u53ef\u9760\u7684\u81ea\u52a8\u5316\u8f85\u52a9\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u4f7f\u75285,216\u5f20\u513f\u7ae5\u80f8\u7247\u6570\u636e\u96c6\uff0880/10/10\u5212\u5206\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\uff09\uff0c\u8bad\u7ec3\u5e76\u8bc4\u4f30\u4e03\u79cd\u6a21\u578b\uff08\u5305\u62ec\u4ece\u5934\u8bad\u7ec3CNN\u548c\u4e09\u79cd\u8fc1\u79fb\u5b66\u4e60\u67b6\u6784\u7684\u51bb\u7ed3\u9aa8\u5e72\u4e0e\u5fae\u8c03\u7248\u672c\uff09\uff0c\u91c7\u7528\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548cAUC\u6307\u6807\uff0c\u5e76\u5229\u7528Grad-CAM\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u5fae\u8c03\u7248ResNet50\u8868\u73b0\u6700\u4f18\uff1a\u51c6\u786e\u738799.43%\u3001F1\u5206\u657099.61%\u3001AUC 99.93%\uff0c\u4ec53\u4f8b\u8bef\u5224\uff1b\u5fae\u8c03\u7b56\u7565\u5e73\u5747\u6bd4\u51bb\u7ed3\u9aa8\u5e72\u9ad85.5\u4e2a\u767e\u5206\u70b9\uff1bGrad-CAM\u663e\u793a\u6a21\u578b\u5173\u6ce8\u4e34\u5e8a\u76f8\u5173\u80ba\u90e8\u533a\u57df\u3002", "conclusion": "\u8fc1\u79fb\u5b66\u4e60\u7ed3\u5408\u5fae\u8c03\u663e\u8457\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684CNN\uff0c\u5728\u513f\u7ae5\u80ba\u708e\u68c0\u6d4b\u4e2d\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u51c6\u786e\u7387\uff0c\u5177\u5907\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u4f5c\u4e3a\u7b5b\u67e5\u5de5\u5177\u7684\u6f5c\u529b\uff1b\u672a\u6765\u9700\u5728\u591a\u4e2d\u5fc3\u53ca\u6210\u4eba\u6570\u636e\u96c6\u4e0a\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002", "summary_cn": "\u80ba\u708e\u662f\u4e94\u5c81\u4ee5\u4e0b\u513f\u7ae5\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u6bcf\u5e74\u9020\u6210\u8d85\u8fc770\u4e07\u4f8b\u6b7b\u4ea1\u3002\u80f8\u90e8X\u5149\u7247\u7684\u51c6\u786e\u8bca\u65ad\u53d7\u9650\u4e8e\u653e\u5c04\u79d1\u533b\u751f\u7684\u53ef\u83b7\u5f97\u6027\u53ca\u5176\u5224\u8bfb\u7684\u53d8\u5f02\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u4ece\u5934\u8bad\u7ec3\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u4e0e\u91c7\u7528\u8fc1\u79fb\u5b66\u4e60\uff08ResNet50\u3001DenseNet121\u3001EfficientNet-B0\uff09\u7684\u6a21\u578b\u5728\u513f\u7ae5\u80ba\u708e\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u8bc4\u4f30\u51bb\u7ed3\u9aa8\u5e72\u7f51\u7edc\u4e0e\u5fae\u8c03\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\u3002\u7814\u7a76\u4f7f\u7528\u5305\u542b5,216\u5f20\u513f\u7ae5\u80f8\u90e8X\u5149\u7247\u7684\u6570\u636e\u96c6\uff0c\u630980/10/10\u6bd4\u4f8b\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u3002\u5171\u8bad\u7ec3\u5e76\u8bc4\u4f30\u4e86\u4e03\u79cd\u6a21\u578b\uff0c\u8bc4\u4ef7\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548cAUC\uff0c\u5e76\u901a\u8fc7Grad-CAM\u53ef\u89c6\u5316\u63d0\u4f9b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5fae\u8c03\u540e\u7684ResNet50\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe99.43%\uff0cF1\u5206\u6570\u4e3a99.61%\uff0cAUC\u8fbe99.93%\uff0c\u4ec5\u51fa\u73b03\u4f8b\u8bef\u5206\u7c7b\uff1b\u5fae\u8c03\u7b56\u7565\u5e73\u5747\u6bd4\u51bb\u7ed3\u9aa8\u5e72\u7f51\u7edc\u9ad8\u51fa5.5\u4e2a\u767e\u5206\u70b9\uff1bGrad-CAM\u786e\u8ba4\u6a21\u578b\u9884\u6d4b\u4f9d\u636e\u7684\u662f\u4e34\u5e8a\u4e0a\u76f8\u5173\u7684\u80ba\u90e8\u533a\u57df\u3002\u7ed3\u8bba\u6307\u51fa\uff0c\u91c7\u7528\u5fae\u8c03\u7684\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u5728\u513f\u7ae5\u80ba\u708e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684CNN\uff0c\u5c55\u73b0\u51fa\u63a5\u8fd1\u5b8c\u7f8e\u7684\u51c6\u786e\u6027\uff0c\u8be5\u7cfb\u7edf\u5728\u8d44\u6e90\u6709\u9650\u5730\u533a\u5177\u6709\u4f5c\u4e3a\u7b5b\u67e5\u5de5\u5177\u7684\u5de8\u5927\u6f5c\u529b\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u5728\u591a\u4e2d\u5fc3\u53ca\u6210\u4eba\u6570\u636e\u96c6\u4e0a\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u8fd9\u4e9b\u53d1\u73b0\u3002"}}
{"id": "2601.00839", "pdf": "https://arxiv.org/pdf/2601.00839", "abs": "https://arxiv.org/abs/2601.00839", "authors": ["Zahid Ullah", "Muhammad Hilal", "Eunsoo Lee", "Dragan Pamucar", "Jihie Kim"], "title": "Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS", "categories": ["cs.CV"], "comment": null, "summary": "Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.", "AI": {"tldr": "\u672c\u6587\u5728CAMUS\u6570\u636e\u96c6\u4e0a\u5bf9U-Net\u3001Attention U-Net\u548cTransUNet\u8fdb\u884c\u4e86\u6807\u51c6\u5316\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\uff08\u5982NIfTI vs PNG\uff09\u3001\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u548cGPT\u8f85\u52a9\u4f2a\u6807\u7b7e\u5bf9\u5206\u5272\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u4e0e\u5b9e\u7528\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7efc\u8ff0\u7f3a\u4e4f\u5c06\u5fc3\u810f\u8d85\u58f0\u56fe\u50cf\u5206\u5272\u7684\u6df1\u5ea6\u5b66\u4e60\u8fdb\u5c55\u4e0e\u7edf\u4e00\u3001\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c\u57fa\u51c6\u76f8\u7ed3\u5408\u7684\u5de5\u4f5c\u3002", "method": "\u5728CAMUS\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u5212\u5206\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6807\u51c6\uff0c\u5bf9\u6bd4U-Net\u3001Attention U-Net\u548cTransUNet\u4e09\u79cd\u67b6\u6784\uff1b\u63a2\u7d22\u591a\u79cd\u9884\u5904\u7406\u65b9\u5f0f\uff08\u539f\u751fNIfTI\u300116\u4f4dPNG\u3001GPT\u8f85\u52a9\u4f2a\u6807\u7b7e\uff09\u53ca\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff08SSL\uff09\u7684\u5f71\u54cd\u3002", "result": "\u539f\u751fNIfTI\u6570\u636e\u8bad\u7ec3\u7684U-Net\u8fbe\u523094%\u5e73\u5747Dice\uff1bPNG\u6d41\u7a0b\u4e3a91%\uff1bAttention U-Net\u5728\u5c0f\u6216\u4f4e\u5bf9\u6bd4\u533a\u57df\u7565\u6709\u6539\u5584\uff1bTransUNet\u7ed3\u5408SSL\u5728\u56f0\u96be\u5e27\u4e0a\u6cdb\u5316\u80fd\u529b\u6700\u5f3a\uff1b\u7ecf\u7f6e\u4fe1\u5ea6\u8fc7\u6ee4\u7684\u4f2a\u6807\u7b7e\u63d0\u5347\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u5efa\u7acb\u4e86\u6807\u51c6\u5316\u3001\u53ef\u590d\u73b0\u7684\u5206\u5272\u57fa\u51c6\uff0c\u63d0\u4f9b\u4e86\u8d85\u58f0\u6570\u636e\u9884\u5904\u7406\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u5c55\u671b\u4e86\u81ea\u76d1\u7763\u5b66\u4e60\u4e0eGPT\u9a71\u52a8\u7684\u591a\u6a21\u6001\u6807\u6ce8\u6d41\u7a0b\u5728\u5feb\u901f\u6807\u6ce8\u4e0e\u6570\u636e\u96c6\u6784\u5efa\u4e2d\u7684\u6f5c\u529b\u3002", "summary_cn": "\u591a\u7bc7\u7efc\u8ff0\u8bba\u6587\u603b\u7ed3\u4e86\u5fc3\u810f\u5f71\u50cf\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u8fdb\u5c55\uff0c\u4f46\u5f88\u5c11\u6709\u5de5\u4f5c\u5c06\u8fd9\u4e9b\u7efc\u8ff0\u4e0e\u7edf\u4e00\u4e14\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c\u57fa\u51c6\u8054\u7cfb\u8d77\u6765\u3002\u672c\u7814\u7a76\u7ed3\u5408\u4e86\u5bf9\u5fc3\u810f\u8d85\u58f0\u5206\u5272\u6587\u732e\u7684\u805a\u7126\u7efc\u8ff0\uff0c\u5e76\u5728\u201c\u7528\u4e8e\u591a\u7ed3\u6784\u8d85\u58f0\u5206\u5272\u7684\u5fc3\u810f\u91c7\u96c6\uff08CAMUS\uff09\u201d\u8d85\u58f0\u5fc3\u52a8\u56fe\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u4e09\u79cd\u5177\u6709\u5f71\u54cd\u529b\u7684\u67b6\u6784\u2014\u2014U-Net\u3001Attention U-Net\u548cTransUNet\u2014\u2014\u8fdb\u884c\u4e86\u53d7\u63a7\u6bd4\u8f83\u3002\u6211\u4eec\u7684\u57fa\u51c6\u6d4b\u8bd5\u6db5\u76d6\u4e86\u591a\u79cd\u9884\u5904\u7406\u8def\u5f84\uff0c\u5305\u62ec\u539f\u751fNIfTI\u4f53\u6570\u636e\u300116\u4f4dPNG\u5bfc\u51fa\u3001GPT\u8f85\u52a9\u7684\u591a\u8fb9\u5f62\u4f2a\u6807\u7b7e\uff0c\u4ee5\u53ca\u5728\u6570\u5343\u5e27\u672a\u6807\u6ce8\u52a8\u6001\u56fe\u50cf\u4e0a\u7684\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff08SSL\uff09\u3002\u5728\u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u5212\u5206\u3001\u635f\u5931\u51fd\u6570\u548c\u8bc4\u4f30\u6807\u51c6\u4e0b\uff0c\u76f4\u63a5\u5728NIfTI\u6570\u636e\uff08\u4fdd\u7559\u539f\u59cb\u52a8\u6001\u8303\u56f4\uff09\u4e0a\u8bad\u7ec3\u7684\u666e\u901aU-Net\u8fbe\u5230\u4e8694%\u7684\u5e73\u5747Dice\u7cfb\u6570\uff0c\u800c16\u4f4dPNG\u6d41\u7a0b\u5728\u7c7b\u4f3c\u6761\u4ef6\u4e0b\u8fbe\u5230\u4e8691%\u3002Attention U-Net\u5728\u5c0f\u76ee\u6807\u6216\u4f4e\u5bf9\u6bd4\u5ea6\u533a\u57df\u63d0\u4f9b\u4e86\u9002\u5ea6\u6539\u8fdb\uff0c\u51cf\u5c11\u4e86\u8fb9\u754c\u6cc4\u6f0f\uff1b\u800cTransUNet\u51ed\u501f\u5176\u5efa\u6a21\u5168\u5c40\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\uff0c\u5728\u56f0\u96be\u5e27\u4e0a\u5c55\u73b0\u51fa\u6700\u5f3a\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528SSL\u521d\u59cb\u5316\u65f6\u3002\u7ecf\u8fc7\u7f6e\u4fe1\u5ea6\u8fc7\u6ee4\u7684\u4f2a\u6807\u7b7e\u6269\u5c55\u4e86\u8bad\u7ec3\u96c6\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u3002\u603b\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u7684\u8d21\u732e\u6709\u4e09\u65b9\u9762\uff1a\u4e00\u662f\u5728\u6807\u51c6\u5316\u7684CAMUS\u9884\u5904\u7406\u4e0e\u8bc4\u4f30\u6761\u4ef6\u4e0b\uff0c\u5bf9U-Net\u3001Attention U-Net\u548cTransUNet\u8fdb\u884c\u4e86\u7edf\u4e00\u3001\u516c\u5e73\u7684\u57fa\u51c6\u6d4b\u8bd5\uff1b\u4e8c\u662f\u5c31\u8d85\u58f0\u6570\u636e\u51c6\u5907\u8fc7\u7a0b\u4e2d\u5982\u4f55\u4fdd\u6301\u5f3a\u5ea6\u4fdd\u771f\u5ea6\u3001\u5206\u8fa8\u7387\u4e00\u81f4\u6027\u548c\u5bf9\u9f50\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff1b\u4e09\u662f\u5c55\u671b\u4e86\u53ef\u6269\u5c55\u7684\u81ea\u76d1\u7763\u65b9\u6cd5\u4ee5\u53ca\u65b0\u5174\u7684\u591a\u6a21\u6001GPT\u9a71\u52a8\u6807\u6ce8\u6d41\u7a0b\u5728\u5feb\u901f\u6807\u6ce8\u3001\u8d28\u91cf\u4fdd\u8bc1\u548c\u9488\u5bf9\u6027\u6570\u636e\u96c6\u6784\u5efa\u65b9\u9762\u7684\u524d\u666f\u3002"}}
{"id": "2601.00854", "pdf": "https://arxiv.org/pdf/2601.00854", "abs": "https://arxiv.org/abs/2601.00854", "authors": ["Igor Lodin", "Sergii Filatov", "Vira Filatova", "Dmytro Filatov"], "title": "Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge", "categories": ["cs.CV"], "comment": "11 pages, 5 figures", "summary": "We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.", "AI": {"tldr": "\u63d0\u51faMCLSC\u65b9\u6cd5\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u901a\u8fc7\u4e24\u4e2a\u6f5c\u5728\u8bed\u4e49\u753b\u5e03\uff08\u9759\u6001\u5c42\u548c\u52a8\u6001\u5c42\uff09\u5b9e\u73b0\u9ad8\u6548\u7684\u89c6\u89c9\u60c5\u5883\u611f\u77e5\uff0c\u5229\u7528\u8fd0\u52a8\u8865\u507f\u4e0e\u5f02\u6b65\u89e6\u53d1\u5206\u5272\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u3001\u9ad8\u6548\u7684\u89c6\u89c9\u60c5\u5883\u611f\u77e5\uff0c\u907f\u514d\u5bf9\u6bcf\u4e00\u5e27\u90fd\u6267\u884c\u9ad8\u6210\u672c\u7684\u5168\u666f\u5206\u5272\u3002", "method": "\u91c7\u7528Motion-Compensated Latent Semantic Canvases\uff08MCLSC\uff09\u6846\u67b6\uff0c\u7ef4\u62a4\u4e24\u4e2a\u6f5c\u5728\u8bed\u4e49\u753b\u5e03\uff1a\u7f13\u6162\u7d2f\u79ef\u7684\u9759\u6001\u5c42\u548c\u5feb\u901f\u66f4\u65b0\u7684\u52a8\u6001\u5c42\uff1b\u57fa\u4e8e\u89c6\u9891\u6d41\u7a33\u5b9a\u540e\u7684\u57fa\u51c6\u5750\u6807\u7cfb\uff0c\u5e76\u4ec5\u5728\u68c0\u6d4b\u5230\u8fd0\u52a8\u65f6\u5f02\u6b65\u89e6\u53d1Mask2Former\u5168\u666f\u5206\u5272\uff0c\u540c\u65f6\u901a\u8fc7\u8fd0\u52a8\u8865\u507f\u4fdd\u6301\u8bed\u4e49\u8bb0\u5fc6\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728480p\u9884\u5f55\u89c6\u9891\u4e0a\uff0c\u76f8\u6bd4\u9010\u5e27\u5206\u5272\uff0c\u539f\u578b\u7cfb\u7edf\u5c06\u5206\u5272\u8c03\u7528\u6b21\u6570\u51cf\u5c1130\u500d\u4ee5\u4e0a\uff0c\u7aef\u5230\u7aef\u5e73\u5747\u5904\u7406\u65f6\u95f4\u964d\u4f4e20\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u9759\u6001/\u52a8\u6001\u8bed\u4e49\u53e0\u52a0\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "MCLSC\u80fd\u663e\u8457\u964d\u4f4e\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u8ba1\u7b97\u8d1f\u8f7d\uff0c\u540c\u65f6\u7ef4\u6301\u9ad8\u8d28\u91cf\u7684\u8bed\u4e49\u60c5\u5883\u611f\u77e5\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86\u8fd0\u52a8\u8865\u507f\u6f5c\u5728\u8bed\u4e49\u753b\u5e03\uff08MCLSC\uff09\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u89c6\u89c9\u60c5\u5883\u611f\u77e5\u3002\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5728\u4e00\u4e2a\u7531\u89c6\u9891\u6d41\u7a33\u5b9a\u5f97\u5230\u7684\u57fa\u51c6\u5750\u6807\u7cfb\u4e2d\uff0c\u7ef4\u62a4\u4e24\u4e2a\u6f5c\u5728\u8bed\u4e49\u753b\u5e03\u2014\u2014\u4e00\u4e2a\u7f13\u6162\u7d2f\u79ef\u7684\u9759\u6001\u5c42\u548c\u4e00\u4e2a\u5feb\u901f\u66f4\u65b0\u7684\u52a8\u6001\u5c42\u3002\u9ad8\u5f00\u9500\u7684\u5168\u666f\u5206\u5272\u6a21\u578b\uff08Mask2Former\uff09\u4ee5\u5f02\u6b65\u65b9\u5f0f\u8fd0\u884c\uff0c\u5e76\u53d7\u8fd0\u52a8\u89e6\u53d1\uff1a\u4ec5\u5f53\u68c0\u6d4b\u5230\u8fd0\u52a8\u8868\u660e\u6709\u65b0\u4fe1\u606f\u51fa\u73b0\u65f6\u624d\u6267\u884c\u63a8\u7406\uff0c\u800c\u901a\u8fc7\u7a33\u5b9a\u5316\u548c\u8fd0\u52a8\u8865\u507f\u673a\u5236\u7ef4\u6301\u6f5c\u5728\u8bed\u4e49\u8bb0\u5fc6\u7684\u4e00\u81f4\u5750\u6807\u7cfb\u7edf\u3002\u5728480p\u9884\u5f55\u89c6\u9891\u7247\u6bb5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6734\u7d20\u7684\u9010\u5e27\u5206\u5272\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u4eec\u7684\u539f\u578b\u7cfb\u7edf\u5c06\u5206\u5272\u8c03\u7528\u6b21\u6570\u51cf\u5c11\u4e8630\u500d\u4ee5\u4e0a\uff0c\u7aef\u5230\u7aef\u5e73\u5747\u5904\u7406\u65f6\u95f4\u964d\u4f4e\u4e8620\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4ecd\u80fd\u4fdd\u6301\u8fde\u8d2f\u7684\u9759\u6001/\u52a8\u6001\u8bed\u4e49\u53e0\u52a0\u6548\u679c\u3002"}}
{"id": "2601.00879", "pdf": "https://arxiv.org/pdf/2601.00879", "abs": "https://arxiv.org/abs/2601.00879", "authors": ["Zahid Ullah", "Jihie Kim"], "title": "VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading", "categories": ["cs.CV"], "comment": null, "summary": "Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.", "AI": {"tldr": "\u63d0\u51faVLOrdinalFormer\uff0c\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u4e0e\u8bed\u8a00\u7684\u5e8f\u6570\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u819d\u9aa8\u5173\u8282\u708e\uff08KOA\uff09\u81ea\u52a8\u5206\u7ea7\uff0c\u5728KL1\u548cKL2\u7b49\u65e9\u671f\u9636\u6bb5\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u5177\u5907\u826f\u597d\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u819d\u9aa8\u5173\u8282\u708e\uff08KOA\uff09\u662f\u5168\u7403\u81f4\u6b8b\u4e3b\u56e0\u4e4b\u4e00\uff0c\u5176\u4e25\u91cd\u7a0b\u5ea6\u5e38\u4f9d\u636eKellgren-Lawrence\uff08KL\uff09\u5206\u7ea7\u7cfb\u7edf\u8bc4\u4f30\u3002\u7136\u800c\uff0cKL1\u4e0eKL2\u7b49\u65e9\u671f\u9636\u6bb5\u5728X\u5149\u7247\u4e0a\u5dee\u5f02\u7ec6\u5fae\uff0c\u653e\u5c04\u79d1\u533b\u751f\u95f4\u5224\u8bfb\u4e00\u81f4\u6027\u5dee\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u5206\u7ea7\u65b9\u6cd5\u3002", "method": "\u63d0\u51faVLOrdinalFormer\u6846\u67b6\uff1a\u4ee5ViT-L/16\u4e3a\u4e3b\u5e72\u7f51\u7edc\uff0c\u7ed3\u5408CORAL\u5e8f\u6570\u56de\u5f52\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165CLIP\u9a71\u52a8\u7684\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\uff0c\u5c06\u5173\u8282\u95f4\u9699\u72ed\u7a84\u3001\u9aa8\u8d58\u5f62\u6210\u548c\u8f6f\u9aa8\u4e0b\u786c\u5316\u7b49\u4e34\u5e8a\u6587\u672c\u6982\u5ff5\u878d\u5165\u6a21\u578b\uff1b\u91c7\u7528\u5206\u5c42\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u3001\u7c7b\u522b\u611f\u77e5\u91cd\u52a0\u6743\u53ca\u6d4b\u8bd5\u65f6\u589e\u5f3a\u914d\u5408\u5168\u5c40\u9608\u503c\u4f18\u5316\u4ee5\u63d0\u5347\u9c81\u68d2\u6027\u3002", "result": "\u5728OAI kneeKL224\u6570\u636e\u96c6\u4e0a\uff0cVLOrdinalFormer\u5728\u5b8fF1\u5206\u6570\u548c\u603b\u4f53\u51c6\u786e\u7387\u4e0a\u4f18\u4e8eCNN\u548cViT\u57fa\u7ebf\u6a21\u578b\uff0c\u5c24\u5176\u5728KL1\u548cKL2\u5206\u7ea7\u4e0a\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u672a\u727a\u7272\u8f7b\u5ea6\u6216\u91cd\u5ea6\u75c5\u4f8b\u7684\u5206\u7c7b\u7cbe\u5ea6\uff1bGrad-CAM\u4e0eCLIP\u76f8\u4f3c\u56fe\u663e\u793a\u6a21\u578b\u5173\u6ce8\u533a\u57df\u5177\u6709\u4e34\u5e8a\u76f8\u5173\u6027\u3002", "conclusion": "VLOrdinalFormer\u5c55\u793a\u4e86\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u7684\u5e8f\u6570Transformer\u5728KOA\u81ea\u52a8\u5206\u7ea7\u548c\u75be\u75c5\u8fdb\u5c55\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\uff0c\u53ef\u4f5c\u4e3a\u5e38\u89c4\u653e\u5c04\u5b9e\u8df5\u4e2d\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u8f85\u52a9\u5de5\u5177\u3002", "summary_cn": "\u819d\u9aa8\u5173\u8282\u708e\uff08KOA\uff09\u662f\u5168\u7403\u81f4\u6b8b\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\uff0c\u4f7f\u7528Kellgren-Lawrence\uff08KL\uff09\u5206\u7ea7\u7cfb\u7edf\u8fdb\u884c\u51c6\u786e\u7684\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u4f30\u5bf9\u4e8e\u4e34\u5e8a\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u65e9\u671f\u75c5\u53d8\u9636\u6bb5\uff08\u5c24\u5176\u662fKL1\u548cKL2\uff09\u5728X\u5149\u7247\u4e0a\u7684\u5f71\u50cf\u5b66\u5dee\u5f02\u975e\u5e38\u7ec6\u5fae\uff0c\u5e38\u5e38\u5bfc\u81f4\u653e\u5c04\u79d1\u533b\u751f\u4e4b\u95f4\u5b58\u5728\u8f83\u5927\u7684\u5224\u8bfb\u5dee\u5f02\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86VLOrdinalFormer\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u5f15\u5bfc\u7684\u5e8f\u6570\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u819d\u5173\u8282X\u5149\u7247\u4e2d\u5b9e\u73b0\u5168\u81ea\u52a8KOA\u5206\u7ea7\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86ViT-L/16\u9aa8\u5e72\u7f51\u7edc\u3001\u57fa\u4e8eCORAL\u7684\u5e8f\u6570\u56de\u5f52\u4ee5\u53ca\u7531\u5bf9\u6bd4\u8bed\u8a00-\u56fe\u50cf\u9884\u8bad\u7ec3\uff08CLIP\uff09\u9a71\u52a8\u7684\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6574\u5408\u4e0e\u5173\u8282\u95f4\u9699\u72ed\u7a84\u3001\u9aa8\u8d58\u5f62\u6210\u548c\u8f6f\u9aa8\u4e0b\u786c\u5316\u76f8\u5173\u7684\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u6587\u672c\u6982\u5ff5\u3002\u4e3a\u63d0\u9ad8\u6a21\u578b\u9c81\u68d2\u6027\u5e76\u7f13\u89e3\u8fc7\u62df\u5408\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u5206\u5c42\u4e94\u6298\u4ea4\u53c9\u9a8c\u8bc1\u3001\u9488\u5bf9\u56f0\u96be\u4e2d\u95f4\u7b49\u7ea7\u7684\u7c7b\u522b\u611f\u77e5\u91cd\u52a0\u6743\u7b56\u7565\uff0c\u4ee5\u53ca\u7ed3\u5408\u5168\u5c40\u9608\u503c\u4f18\u5316\u7684\u6d4b\u8bd5\u65f6\u589e\u5f3a\u6280\u672f\u3002\u5728\u516c\u5f00\u53ef\u7528\u7684OAI kneeKL224\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVLOrdinalFormer\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u4f18\u6027\u80fd\uff0c\u5728\u5b8fF1\u5206\u6570\u548c\u6574\u4f53\u51c6\u786e\u7387\u65b9\u9762\u5747\u4f18\u4e8eCNN\u548cViT\u57fa\u7ebf\u6a21\u578b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6240\u63d0\u6846\u67b6\u5728KL1\u548cKL2\u5206\u7ea7\u4e0a\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u5e76\u672a\u964d\u4f4e\u5bf9\u8f7b\u5ea6\u6216\u91cd\u5ea6\u75c5\u4f8b\u7684\u5206\u7c7b\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5229\u7528Grad-CAM\u548cCLIP\u76f8\u4f3c\u6027\u56fe\u8fdb\u884c\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u8bc1\u5b9e\uff0c\u6a21\u578b\u59cb\u7ec8\u805a\u7126\u4e8e\u5177\u6709\u4e34\u5e8a\u76f8\u5173\u6027\u7684\u89e3\u5256\u533a\u57df\u3002\u8fd9\u4e9b\u7ed3\u679c\u51f8\u663e\u4e86\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u7684\u5e8f\u6570Transformer\u4f5c\u4e3a\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u5de5\u5177\u5728\u5e38\u89c4\u653e\u5c04\u5b9e\u8df5\u4e2d\u7528\u4e8eKOA\u5206\u7ea7\u548c\u75be\u75c5\u8fdb\u5c55\u8bc4\u4f30\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2601.00887", "pdf": "https://arxiv.org/pdf/2601.00887", "abs": "https://arxiv.org/abs/2601.00887", "authors": ["Hongbo Jin", "Kuanwei Lin", "Wenhao Zhang", "Yichen Jin", "Ge Li"], "title": "VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition", "categories": ["cs.CV"], "comment": null, "summary": "Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVideoCuRL\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u89c6\u9891\u7406\u89e3\u4efb\u52a1\u7684\u96be\u5ea6\u5206\u89e3\u4e3a\u89c6\u89c9\u65f6\u95f4\u611f\u77e5\u8d1f\u8377\u548c\u8ba4\u77e5\u63a8\u7406\u6df1\u5ea6\u4e24\u4e2a\u6b63\u4ea4\u7ef4\u5ea6\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e2D\u8bfe\u7a0b\u5b66\u4e60\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u52a8\u6001\u7a00\u758fKL\u6563\u5ea6\u4e0e\u7ed3\u6784\u5316\u56de\u8bbf\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86VideoLLM\u5728\u63a8\u7406\u4e0e\u611f\u77e5\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u907f\u514d\u4e86\u751f\u6210\u5f0f\u8bfe\u7a0b\u5e26\u6765\u7684\u9ad8\u63a8\u7406\u5f00\u9500\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u5728\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\uff08VideoLLMs\uff09\u8bad\u7ec3\u4e2d\u591a\u91c7\u7528\u968f\u673a\u6253\u4e71\u6216\u57fa\u4e8e\u6807\u91cf\u96be\u5ea6\u6307\u6807\u7684\u7b80\u5355\u8bfe\u7a0b\u7b56\u7565\uff0c\u96be\u4ee5\u6709\u6548\u533a\u5206\u89c6\u9891\u7406\u89e3\u4e2d\u7684\u4e24\u7c7b\u6b63\u4ea4\u6311\u6218\uff1a\u89c6\u89c9\u65f6\u95f4\u611f\u77e5\u8d1f\u8377\u4e0e\u8ba4\u77e5\u63a8\u7406\u6df1\u5ea6\u3002", "method": "\u63d0\u51faVideoCuRL\u6846\u67b6\uff0c\u5229\u7528\u65e0\u9700\u8bad\u7ec3\u7684\u4ee3\u7406\u6307\u6807\uff08\u5149\u6d41\u4e0e\u5173\u952e\u5e27\u71b5\u8861\u91cf\u89c6\u89c9\u590d\u6742\u5ea6\uff0c\u6821\u51c6\u60ca\u5947\u5ea6\u8861\u91cf\u8ba4\u77e5\u590d\u6742\u5ea6\uff09\u5c06\u6570\u636e\u6620\u5c04\u5230\u4e8c\u7ef4\u8bfe\u7a0b\u7f51\u683c\uff0c\u5e76\u91c7\u7528\u80fd\u529b\u611f\u77e5\u7684\u5bf9\u89d2\u6ce2\u524d\u7b56\u7565\u8c03\u5ea6\u8bad\u7ec3\uff1b\u540c\u65f6\u5f15\u5165\u52a8\u6001\u7a00\u758fKL\u6563\u5ea6\u548c\u7ed3\u6784\u5316\u56de\u8bbf\u673a\u5236\u4ee5\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728VSI-Bench\u4e0a\u63a8\u7406\u4efb\u52a1\u63d0\u5347+2.5\uff0c\u5728VideoMME\u4e0a\u611f\u77e5\u4efb\u52a1\u63d0\u5347+2.9\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709RL\u57fa\u7ebf\uff1b\u4e14\u6d88\u9664\u4e86\u751f\u6210\u5f0f\u8bfe\u7a0b\u5e26\u6765\u7684\u9ad8\u6602\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "VideoCuRL\u901a\u8fc7\u89e3\u8026\u89c6\u9891\u7406\u89e3\u4e2d\u7684\u4e24\u7c7b\u96be\u5ea6\u7ef4\u5ea6\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u4e3a\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u7684\u540e\u8bad\u7ec3\u65b9\u6848\u3002", "summary_cn": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5bf9\u4e8e\u8d4b\u4e88\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\uff08VideoLLMs\uff09\u590d\u6742\u7684\u65f6\u7a7a\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684RL\u8303\u5f0f\u4e3b\u8981\u4f9d\u8d56\u4e8e\u968f\u673a\u6570\u636e\u6253\u4e71\u6216\u57fa\u4e8e\u6807\u91cf\u96be\u5ea6\u6307\u6807\u7684\u7b80\u5355\u8bfe\u7a0b\u7b56\u7565\u3002\u6211\u4eec\u8ba4\u4e3a\uff0c\u6807\u91cf\u6307\u6807\u65e0\u6cd5\u89e3\u8026\u89c6\u9891\u7406\u89e3\u4e2d\u7684\u4e24\u7c7b\u6b63\u4ea4\u6311\u6218\uff1a\u89c6\u89c9\u65f6\u95f4\u611f\u77e5\u8d1f\u8377\u4e0e\u8ba4\u77e5\u63a8\u7406\u6df1\u5ea6\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86VideoCuRL\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5c06\u96be\u5ea6\u5206\u89e3\u4e3a\u8fd9\u4e24\u4e2a\u7ef4\u5ea6\u3002\u6211\u4eec\u91c7\u7528\u9ad8\u6548\u4e14\u65e0\u9700\u8bad\u7ec3\u7684\u4ee3\u7406\u6307\u6807\u2014\u2014\u5149\u6d41\u548c\u5173\u952e\u5e27\u71b5\u7528\u4e8e\u8861\u91cf\u89c6\u89c9\u590d\u6742\u5ea6\uff0c\u6821\u51c6\u60ca\u5947\u5ea6\uff08Calibrated Surprisal\uff09\u7528\u4e8e\u8861\u91cf\u8ba4\u77e5\u590d\u6742\u5ea6\uff0c\u4ece\u800c\u5c06\u6570\u636e\u6620\u5c04\u5230\u4e00\u4e2a\u4e8c\u7ef4\u8bfe\u7a0b\u7f51\u683c\u4e0a\u3002\u968f\u540e\uff0c\u4e00\u79cd\u80fd\u529b\u611f\u77e5\u7684\u5bf9\u89d2\u6ce2\u524d\uff08Diagonal Wavefront\uff09\u7b56\u7565\u4ece\u57fa\u7840\u5bf9\u9f50\u9010\u6b65\u8c03\u5ea6\u81f3\u590d\u6742\u63a8\u7406\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u52a8\u6001\u7a00\u758fKL\u6563\u5ea6\uff08Dynamic Sparse KL\uff09\u548c\u7ed3\u6784\u5316\u56de\u8bbf\uff08Structured Revisiting\uff09\u673a\u5236\uff0c\u4ee5\u9632\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u5956\u52b1\u5d29\u6e83\u548c\u707e\u96be\u6027\u9057\u5fd8\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cVideoCuRL\u5728\u63a8\u7406\u4efb\u52a1\uff08VSI-Bench\u4e0a+2.5\uff09\u548c\u611f\u77e5\u4efb\u52a1\uff08VideoMME\u4e0a+2.9\uff09\u4e0a\u5747\u663e\u8457\u8d85\u8d8a\u4e86\u5f3a\u5927\u7684RL\u57fa\u7ebf\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cVideoCuRL\u6d88\u9664\u4e86\u57fa\u4e8e\u751f\u6210\u5f0f\u8bfe\u7a0b\u6240\u5e26\u6765\u7684\u9ad8\u6602\u63a8\u7406\u5f00\u9500\uff0c\u4e3a\u9c81\u68d2\u7684\u89c6\u9891\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00888", "pdf": "https://arxiv.org/pdf/2601.00888", "abs": "https://arxiv.org/abs/2601.00888", "authors": ["Happy Gery Pangestu", "Andi Prademon Yunus", "Siti Khomsah"], "title": "Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study", "categories": ["cs.CV"], "comment": "29 pages, 9 figures, submitted in VCIBA", "summary": "Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e94\u79cdCNN\u4e3b\u5e72\u7f51\u7edc\u5728\u5370\u5c3c\u8721\u67d3\u98ce\u683c\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0ResNet\u5728\u4fdd\u6301\u7ed3\u6784\u76f8\u4f3c\u6027\u7684\u540c\u65f6\u663e\u8457\u4f18\u4e8eVGG\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5b9e\u9645\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eVGG\u7684\u795e\u7ecf\u98ce\u683c\u8fc1\u79fb\u65b9\u6cd5\u867d\u5177\u5f3a\u98ce\u683c\u8868\u73b0\u529b\uff0c\u4f46\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u5927\uff0c\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\uff0c\u56e0\u6b64\u9700\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u67b6\u6784\u3002", "method": "\u5bf9VGG16\u3001VGG19\u3001Inception V3\u3001ResNet50\u548cResNet101\u4e94\u79cdCNN\u4e3b\u5e72\u8fdb\u884c\u7cfb\u7edf\u6027\u5bf9\u6bd4\uff0c\u57fa\u4e8e245\u7ec4\u53d7\u63a7\u5b9e\u9a8c\uff0c\u7ed3\u5408\u5b9a\u91cf\u6307\u6807\uff08\u5982SSIM\u3001LPIPS\u3001FLOPs\uff09\u3001\u5b9a\u6027\u8bc4\u4f30\u4e0e\u7edf\u8ba1\u5206\u6790\uff08ANOVA\uff09\uff0c\u8003\u5bdf\u7ed3\u6784\u4fdd\u7559\u3001\u98ce\u683c\u8868\u73b0\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u4e3b\u5e72\u7f51\u7edc\u9009\u62e9\u5728\u7ed3\u6784\u76f8\u4f3c\u6027\u4e0a\u65e0\u663e\u8457\u5dee\u5f02\uff08SSIM ANOVA p=0.83\uff09\uff1bResNet\u6bd4VGG\u5feb5-6\u500d\u6536\u655b\uff0c\u611f\u77e5\u76f8\u4f3c\u6027\u76f8\u5f53\uff08LPIPS\u22480.53\uff09\uff0c\u4e14FLOPs\u51cf\u5c11\u8d8516\u500d\uff080.63 vs 10.12 GFLOPs\uff09\uff1b\u5b9a\u6027\u4e0a\uff0cVGG\u751f\u6210\u66f4\u5bc6\u96c6\u7684\u7ed8\u753b\u7eb9\u7406\uff0cResNet\u66f4\u7a33\u5b9a\u4fdd\u7559\u51e0\u4f55\u7ed3\u6784\u4e0e\u8721\u67d3\u7b14\u89e6\uff0cInception V3\u8868\u73b0\u5c45\u4e2d\u4f46\u566a\u58f0\u8f83\u591a\u3002", "conclusion": "\u5728\u795e\u7ecf\u98ce\u683c\u8fc1\u79fb\u4e2d\uff0c\u5e94\u5c06\u67b6\u6784\u9009\u62e9\u91cd\u70b9\u4ece\u8ffd\u6c42\u6700\u5927\u98ce\u683c\u5f3a\u5ea6\u8f6c\u5411\u517c\u987e\u6548\u7387\u4e0e\u7ed3\u6784\u4fdd\u7559\uff0cResNet\u4e3b\u5e72\u662f\u9762\u5411\u5de5\u4e1a\u7ea7\u53ef\u6269\u5c55\u8721\u67d3\u751f\u6210\u7684\u5b9e\u7528\u57fa\u7840\u3002", "summary_cn": "\u795e\u7ecf\u98ce\u683c\u8fc1\u79fb\uff08NST\uff09\u4e3a\u5370\u5c3c\u8721\u67d3\u56fe\u6848\u7684\u6570\u5b57\u4fdd\u5b58\u4e0e\u751f\u6210\u5f0f\u63a2\u7d22\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6846\u67b6\uff1b\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56VGG\u67b6\u6784\uff0c\u5176\u5f3a\u5927\u7684\u98ce\u683c\u8868\u73b0\u529b\u4ee5\u9ad8\u6602\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u4e3a\u4ee3\u4ef7\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u3002\u672c\u7814\u7a76\u5bf9\u4e94\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684CNN\u4e3b\u5e72\u7f51\u7edc\uff08VGG16\u3001VGG19\u3001Inception V3\u3001ResNet50\u548cResNet101\uff09\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u5bf9\u6bd4\u5206\u6790\uff0c\u57fa\u4e8e245\u7ec4\u53d7\u63a7\u5b9e\u9a8c\uff0c\u7ed3\u5408\u5b9a\u91cf\u6307\u6807\u3001\u5b9a\u6027\u8bc4\u4f30\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u8003\u5bdf\u7ed3\u6784\u4fdd\u7559\u3001\u98ce\u683c\u8868\u73b0\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e3b\u5e72\u7f51\u7edc\u7684\u9009\u62e9\u5728\u7ed3\u6784\u76f8\u4f3c\u6027\u65b9\u9762\u672a\u4ea7\u751f\u7edf\u8ba1\u663e\u8457\u5dee\u5f02\uff08SSIM\u7684ANOVA\u68c0\u9a8cp=0.83\uff09\uff0c\u8bf4\u660e\u5404\u6a21\u578b\u5728\u7ed3\u6784\u4fdd\u7559\u80fd\u529b\u4e0a\u76f8\u5f53\uff0c\u4f46\u98ce\u683c\u8d28\u91cf\u5e76\u4e0d\u7b49\u540c\u3002\u5728\u6b64\u80cc\u666f\u4e0b\uff0c\u57fa\u4e8eResNet\u7684\u67b6\u6784\u6bd4VGG\u6a21\u578b\u6536\u655b\u901f\u5ea6\u5feb\u7ea65\u20136\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u8fd1\u7684\u611f\u77e5\u76f8\u4f3c\u6027\uff08LPIPS = 0.53\uff09\uff0c\u4e14\u6240\u9700FLOPs\u51cf\u5c11\u8d85\u8fc716\u500d\uff080.63 vs 10.12 GFLOPs\uff09\u3002\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u7a33\u5b9a\u7684\u98ce\u683c\u6743\u8861\uff1aVGG\u751f\u6210\u66f4\u5bc6\u96c6\u7684\u7ed8\u753b\u5f0f\u7eb9\u7406\uff0cResNet\u503e\u5411\u4e8e\u51e0\u4f55\u7a33\u5b9a\u6027\u5e76\u66f4\u597d\u5730\u4fdd\u7559\u8721\u67d3\u7b14\u89e6\uff0c\u98ce\u683c\u5316\u7a0b\u5ea6\u8f83\u6e29\u548c\uff0c\u800cInception V3\u5219\u8868\u73b0\u51fa\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\u4f46\u566a\u58f0\u66f4\u591a\u7684\u884c\u4e3a\u3002\u8fd9\u4e9b\u53d1\u73b0\u5c06NST\u4e2d\u7684\u67b6\u6784\u9009\u62e9\u91cd\u5fc3\u4ece\u6700\u5927\u5316\u98ce\u683c\u5f3a\u5ea6\u8f6c\u5411\u6ce8\u91cd\u6548\u7387\u4e0e\u7ed3\u6784\u4fdd\u7559\u7684\u5b9e\u9645\u90e8\u7f72\uff0c\u51f8\u663e\u4e86\u57fa\u4e8eResNet\u7684\u4e3b\u5e72\u7f51\u7edc\u4f5c\u4e3a\u53ef\u6269\u5c55\u3001\u9762\u5411\u5de5\u4e1a\u5e94\u7528\u7684\u8721\u67d3\u751f\u6210\u5b9e\u7528\u57fa\u7840\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.00897", "pdf": "https://arxiv.org/pdf/2601.00897", "abs": "https://arxiv.org/abs/2601.00897", "authors": ["Sai Teja Erukude", "Jane Mascarenhas", "Lior Shamir"], "title": "CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "23 pages", "summary": "Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCornViT\uff0c\u4e00\u79cd\u4e09\u9636\u6bb5\u5377\u79ef\u89c6\u89c9Transformer\uff08CvT\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u7389\u7c73\u7c7d\u7c92\u5206\u7ea7\u3002\u8be5\u65b9\u6cd5\u5728\u7eaf\u5ea6\u3001\u5f62\u6001\u548c\u80da\u671d\u5411\u4e09\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8eResNet\u548cDenseNet\uff0c\u5e76\u914d\u5957\u53d1\u5e03\u6570\u636e\u96c6\u4e0eWeb\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u7389\u7c73\u7c7d\u7c92\u5206\u7ea7\u4ecd\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\uff0c\u7f3a\u4e4f\u9ad8\u6548\u3001\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4e3a\u63d0\u5347\u79cd\u5b50\u8ba4\u8bc1\u3001\u5b9a\u5411\u64ad\u79cd\u548c\u80b2\u79cd\u4e2d\u7684\u5206\u7ea7\u51c6\u786e\u6027\uff0c\u4e9f\u9700\u5f15\u5165\u80fd\u6a21\u62df\u4eba\u7c7b\u5206\u6790\u5e08\u5206\u5c42\u63a8\u7406\u80fd\u529b\u7684\u667a\u80fd\u89c6\u89c9\u7cfb\u7edf\u3002", "method": "\u63d0\u51faCornViT\u4e09\u9636\u6bb5CvT-13\u5206\u7c7b\u5668\uff1a\u7b2c\u4e00\u9636\u6bb5\u533a\u5206\u7eaf\u4e0e\u975e\u7eaf\u7c7d\u7c92\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5bf9\u7eaf\u7c7d\u7c92\u5206\u4e3a\u6241\u5e73\u4e0e\u5706\u5f62\uff1b\u7b2c\u4e09\u9636\u6bb5\u5224\u65ad\u7eaf\u6241\u5e73\u7c7d\u7c92\u7684\u80da\u671d\u5411\uff08\u4e0a/\u4e0b\uff09\u3002\u57fa\u4e8e\u516c\u5f00\u56fe\u50cf\u96c6\u6784\u5efa\u5e76\u53d1\u5e03\u4e09\u4e2a\u9636\u6bb5\u4e13\u7528\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528ImageNet-22k\u9884\u8bad\u7ec3CvT-13\u6a21\u578b\u8fdb\u884c\u5934\u90e8\u5fae\u8c03\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e0a\uff0cCornViT\u5728\u7eaf\u5ea6\u3001\u5f62\u6001\u548c\u80da\u671d\u5411\u4efb\u52a1\u5206\u522b\u8fbe\u523093.76%\u300194.11%\u548c91.12%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8eResNet-50\uff0876.56\u201381.02%\uff09\u548cDenseNet-121\uff0886.56\u201389.38%\uff09\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u57fa\u4e8eFlask\u7684Web\u5e94\u7528\u4ee5\u652f\u6301\u9636\u6bb5\u5316\u63a8\u7406\u548c\u53ef\u89c6\u5316\u8f93\u51fa\u3002", "conclusion": "CornViT\u7ed3\u5408\u5377\u79ef\u589e\u5f3a\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u7389\u7c73\u7c7d\u7c92\u8d28\u91cf\u8bc4\u4f30\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5176\u6846\u67b6\u3001\u6570\u636e\u96c6\u548cWeb\u5de5\u5177\u5171\u540c\u6784\u6210\u4e86\u4e00\u5957\u53ef\u90e8\u7f72\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u79cd\u5b50\u8d28\u91cf\u5de5\u4f5c\u6d41\u7a0b\u7684\u667a\u80fd\u5316\u3002", "summary_cn": "\u51c6\u786e\u7684\u7389\u7c73\u7c7d\u7c92\u5206\u7ea7\u5bf9\u4e8e\u79cd\u5b50\u8ba4\u8bc1\u3001\u5b9a\u5411\u64ad\u79cd\u548c\u80b2\u79cd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u4ecd\u4e3b\u8981\u4f9d\u9760\u4eba\u5de5\u68c0\u67e5\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86CornViT\u2014\u2014\u4e00\u79cd\u4e09\u9636\u6bb5\u5377\u79ef\u89c6\u89c9Transformer\uff08CvT\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u4eba\u7c7b\u79cd\u5b50\u5206\u6790\u5e08\u7684\u5206\u5c42\u63a8\u7406\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u5355\u7c92\u7c7d\u7c92\u8bc4\u4f30\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u4f9d\u6b21\u8fd0\u884c\u7684CvT-13\u5206\u7c7b\u5668\uff0c\u5904\u7406384\u00d7384\u7684RGB\u56fe\u50cf\uff1a\u7b2c\u4e00\u9636\u6bb5\u533a\u5206\u7eaf\u7c7d\u7c92\u4e0e\u975e\u7eaf\u7c7d\u7c92\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5c06\u7eaf\u7c7d\u7c92\u5206\u4e3a\u6241\u5e73\u578b\u548c\u5706\u578b\uff1b\u7b2c\u4e09\u9636\u6bb5\u5224\u65ad\u7eaf\u6241\u5e73\u7c7d\u7c92\u7684\u80da\u671d\u5411\uff08\u5411\u4e0a\u6216\u5411\u4e0b\uff09\u3002\u7814\u7a76\u56e2\u961f\u4ece\u4e00\u4e2a\u516c\u5f00\u7684\u7389\u7c73\u79cd\u5b50\u56fe\u50cf\u96c6\u4e2d\u624b\u52a8\u91cd\u65b0\u6807\u6ce8\u5e76\u7b5b\u9009\u56fe\u50cf\uff0c\u6784\u5efa\u4e86\u4e09\u4e2a\u9636\u6bb5\u4e13\u7528\u7684\u6570\u636e\u96c6\uff1a\u7eaf\u5ea6\u6570\u636e\u96c6\u542b7265\u7c92\uff0c\u5f62\u6001\u6570\u636e\u96c6\u542b3859\u7c92\u7eaf\u7c7d\u7c92\uff0c\u80da\u671d\u5411\u6570\u636e\u96c6\u542b1960\u7c92\u7eaf\u6241\u5e73\u7c7d\u7c92\uff0c\u6240\u6709\u6570\u636e\u5747\u5df2\u4f5c\u4e3a\u57fa\u51c6\u53d1\u5e03\u3002\u901a\u8fc7\u5bf9ImageNet-22k\u9884\u8bad\u7ec3\u7684CvT-13\u4e3b\u5e72\u7f51\u7edc\u4ec5\u5fae\u8c03\u5206\u7c7b\u5934\uff0c\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e8693.76%\uff08\u7eaf\u5ea6\uff09\u300194.11%\uff08\u5f62\u6001\uff09\u548c91.12%\uff08\u80da\u671d\u5411\uff09\u7684\u51c6\u786e\u7387\u3002\u5728\u76f8\u540c\u8bad\u7ec3\u6761\u4ef6\u4e0b\uff0cResNet-50\u7684\u51c6\u786e\u7387\u4ec5\u4e3a76.56%\u81f381.02%\uff0cDenseNet-121\u4e3a86.56%\u81f389.38%\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5377\u79ef\u589e\u5f3a\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5728\u7c7d\u7c92\u5206\u6790\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002\u4e3a\u4fbf\u4e8e\u5e94\u7528\uff0c\u4f5c\u8005\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eFlask\u7684Web\u5e94\u7528\u7a0b\u5e8f\uff0c\u652f\u6301\u5206\u9636\u6bb5\u63a8\u7406\u5e76\u901a\u8fc7\u6d4f\u89c8\u5668\u754c\u9762\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8f93\u51fa\u3002CornViT\u6846\u67b6\u3001\u7cbe\u9009\u6570\u636e\u96c6\u548cWeb\u5e94\u7528\u5171\u540c\u6784\u6210\u4e86\u4e00\u4e2a\u53ef\u5728\u79cd\u5b50\u8d28\u91cf\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u90e8\u7f72\u7684\u81ea\u52a8\u5316\u7389\u7c73\u7c7d\u7c92\u8d28\u91cf\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u3002\u6e90\u4ee3\u7801\u548c\u6570\u636e\u5747\u5df2\u516c\u5f00\u3002"}}
{"id": "2601.00905", "pdf": "https://arxiv.org/pdf/2601.00905", "abs": "https://arxiv.org/abs/2601.00905", "authors": ["Eliot Park", "Abhi Kumar", "Pranav Rajpurkar"], "title": "Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems", "categories": ["cs.CV", "cs.AI"], "comment": "x", "summary": "While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6700\u65b0\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u3001GPT-4o-mini \u548c Claude 3.5\uff09\u5728\u5224\u65ad\u65e5\u5e38\u7269\u54c1\u53ef\u56de\u6536\u6027\u65b9\u9762\u7684\u5e94\u7528\uff0c\u8bc4\u4f30\u5176\u5728\u5339\u914d\u7269\u54c1\u4e0e\u6b63\u786e\u56de\u6536\u7bb1\u3001\u8003\u8651\u5730\u57df\u89c4\u5219\u3001\u6c61\u67d3/\u635f\u574f\u53ca\u591a\u6750\u6599\u7ec4\u6210\u7b49\u590d\u6742\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u867d\u6709\u663e\u8457\u8fdb\u6b65\u4f46\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002", "motivation": "\u516c\u4f17\u666e\u904d\u96be\u4ee5\u51c6\u786e\u5224\u65ad\u7269\u54c1\u7684\u53ef\u56de\u6536\u6027\u53ca\u5176\u6b63\u786e\u5904\u7f6e\u65b9\u5f0f\uff0c\u4e9f\u9700\u667a\u80fd\u5de5\u5177\u8f85\u52a9\u63d0\u5347\u56de\u6536\u6548\u7387\u548c\u73af\u4fdd\u5b9e\u8df5\u3002", "method": "\u5229\u7528\u7cbe\u9009\u7684\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u8bc4\u4f30GPT-4o\u3001GPT-4o-mini\u548cClaude 3.5\u7b49\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u5c06\u7269\u54c1\u5339\u914d\u5230\u5408\u9002\u56de\u6536\u7bb1\u7684\u80fd\u529b\uff0c\u5305\u62ec\u5224\u65ad\u7269\u54c1\u662f\u5426\u80fd\u653e\u5165\u56de\u6536\u7bb1\uff0c\u5e76\u6d4b\u8bd5\u6a21\u578b\u5728\u4e09\u79cd\u6311\u6218\u6027\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff1a(i) \u6839\u636e\u5730\u533a\u56de\u6536\u6307\u5357\u8c03\u6574\u9884\u6d4b\uff1b(ii) \u8003\u8651\u6c61\u67d3\u6216\u7ed3\u6784\u635f\u574f\uff1b(iii) \u5904\u7406\u591a\u6750\u6599\u7269\u54c1\u3002", "result": "\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u76f8\u6bd4\u4ee5\u5f80\u7248\u672c\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u5904\u7406\u590d\u6742\u56de\u6536\u60c5\u5883\u65f6\u8868\u73b0\u66f4\u4f73\uff0c\u4f46\u5728\u67d0\u4e9b\u5177\u4f53\u4efb\u52a1\u4e0a\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u6301\u7eed\u4f18\u5316\u5177\u5907\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u7684\u6a21\u578b\u5bf9\u4e8e\u6539\u5584\u516c\u4f17\u56de\u6536\u884c\u4e3a\u548c\u63a8\u52a8\u73af\u5883\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "summary_cn": "\u5c3d\u7ba1\u9ad8\u6548\u56de\u6536\u7684\u91cd\u8981\u6027\u5e7f\u53d7\u8ba4\u53ef\uff0c\u4f46\u666e\u901a\u516c\u4f17\u5728\u51c6\u786e\u5224\u65ad\u7269\u54c1\u7684\u53ef\u56de\u6536\u6027\u53ca\u5176\u6b63\u786e\u5904\u7f6e\u65b9\u5f0f\u65b9\u9762\u4ecd\u9762\u4e34\u590d\u6742\u6311\u6218\u3002\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u524d\u6cbf\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\u3001GPT-4o-mini \u548c Claude 3.5\uff09\u5728\u9884\u6d4b\u5e38\u89c1\u5e9f\u5f03\u7269\u54c1\u53ef\u56de\u6536\u6027\u65b9\u9762\u7684\u5e94\u7528\u3002\u901a\u8fc7\u4e00\u4e2a\u7cbe\u5fc3\u6574\u7406\u7684\u56fe\u50cf\u6570\u636e\u96c6\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u8fd9\u4e9b\u6a21\u578b\u5c06\u7269\u54c1\u5339\u914d\u81f3\u9002\u5f53\u56de\u6536\u7bb1\u7684\u80fd\u529b\uff0c\u5305\u62ec\u5224\u65ad\u7269\u54c1\u662f\u5426\u80fd\u7269\u7406\u653e\u5165\u53ef\u7528\u56de\u6536\u7bb1\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u8003\u5bdf\u4e86\u6a21\u578b\u5728\u82e5\u5e72\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff1a(i) \u6839\u636e\u7279\u5b9a\u5730\u533a\u7684\u56de\u6536\u6307\u5357\u8c03\u6574\u9884\u6d4b\uff1b(ii) \u8003\u8651\u7269\u54c1\u7684\u6c61\u67d3\u6216\u7ed3\u6784\u635f\u574f\u60c5\u51b5\uff1b(iii) \u5904\u7406\u7531\u591a\u79cd\u6750\u6599\u7ec4\u6210\u7684\u7269\u54c1\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u65e9\u671f\u7248\u672c\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u5176\u5c1a\u5b58\u7684\u4e0d\u8db3\u4e4b\u5904\u3002\u6301\u7eed\u6539\u8fdb\u5177\u5907\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u7684\u6a21\u578b\uff0c\u5bf9\u4e8e\u63d0\u5347\u516c\u4f17\u56de\u6536\u5b9e\u8df5\u548c\u4fc3\u8fdb\u73af\u5883\u53ef\u6301\u7eed\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002"}}
