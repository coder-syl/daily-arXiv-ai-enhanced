{"id": "2512.19711", "pdf": "https://arxiv.org/pdf/2512.19711", "abs": "https://arxiv.org/abs/2512.19711", "authors": ["Md Nahid Hasan Shuvo", "Moinul Hossain"], "title": "PHANTOM: PHysical ANamorphic Threats Obstructing Connected Vehicle Mobility", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG"], "comment": null, "summary": "Connected autonomous vehicles (CAVs) rely on vision-based deep neural networks (DNNs) and low-latency (Vehicle-to-Everything) V2X communication to navigate safely and efficiently. Despite their advances, these systems remain vulnerable to physical adversarial attacks. In this paper, we introduce PHANTOM (PHysical ANamorphic Threats Obstructing connected vehicle Mobility), a novel framework for crafting and deploying perspective-dependent adversarial examples using \\textit{anamorphic art}. PHANTOM exploits geometric distortions that appear natural to humans but are misclassified with high confidence by state-of-the-art object detectors. Unlike conventional attacks, PHANTOM operates in black-box settings without model access and demonstrates strong transferability across four diverse detector architectures (YOLOv5, SSD, Faster R-CNN, and RetinaNet). Comprehensive evaluation in CARLA across varying speeds, weather conditions, and lighting scenarios shows that PHANTOM achieves over 90\\% attack success rate under optimal conditions and maintains 60-80\\% effectiveness even in degraded environments. The attack activates within 6-10 meters of the target, providing insufficient time for safe maneuvering. Beyond individual vehicle deception, PHANTOM triggers network-wide disruption in CAV systems: SUMO-OMNeT++ co-simulation demonstrates that false emergency messages propagate through V2X links, increasing Peak Age of Information by 68-89\\% and degrading safety-critical communication. These findings expose critical vulnerabilities in both perception and communication layers of CAV ecosystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPHANTOM\uff0c\u4e00\u79cd\u5229\u7528\u53d8\u5f62\u827a\u672f\u751f\u6210\u89c6\u89d2\u4f9d\u8d56\u7684\u7269\u7406\u5bf9\u6297\u6837\u672c\u7684\u65b0\u65b9\u6cd5\uff0c\u53ef\u5728\u9ed1\u76d2\u6761\u4ef6\u4e0b\u6b3a\u9a97\u591a\u79cd\u4e3b\u6d41\u76ee\u6807\u68c0\u6d4b\u5668\uff0c\u5e76\u901a\u8fc7V2X\u901a\u4fe1\u5f15\u53d1\u7f51\u8054\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7cfb\u7edf\u7684\u5168\u5c40\u5b89\u5168\u98ce\u9669\u3002", "motivation": "\u7f51\u8054\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08CAVs\uff09\u4f9d\u8d56\u57fa\u4e8e\u89c6\u89c9\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u4f4e\u5ef6\u8fdfV2X\u901a\u4fe1\uff0c\u4f46\u6613\u53d7\u7269\u7406\u5bf9\u6297\u653b\u51fb\u3002\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u901a\u5e38\u9700\u767d\u76d2\u8bbf\u95ee\u6216\u7f3a\u4e4f\u8de8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u672a\u5145\u5206\u8003\u8651\u5bf9\u6574\u4e2aCAV\u901a\u4fe1\u751f\u6001\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faPHANTOM\u6846\u67b6\uff0c\u5229\u7528\u53d8\u5f62\u827a\u672f\uff08anamorphic art\uff09\u6784\u9020\u51e0\u4f55\u7578\u53d8\u56fe\u6848\uff0c\u8fd9\u4e9b\u56fe\u6848\u5bf9\u4eba\u7c7b\u770b\u4f3c\u81ea\u7136\uff0c\u5374\u80fd\u9ad8\u7f6e\u4fe1\u5ea6\u8bef\u5bfc\u76ee\u6807\u68c0\u6d4b\u5668\uff1b\u8be5\u65b9\u6cd5\u65e0\u9700\u76ee\u6807\u6a21\u578b\u4fe1\u606f\uff08\u9ed1\u76d2\uff09\uff0c\u5e76\u6d4b\u8bd5\u5176\u5728YOLOv5\u3001SSD\u3001Faster R-CNN\u548cRetinaNet\u56db\u79cd\u68c0\u6d4b\u5668\u4e0a\u7684\u8fc1\u79fb\u6027\uff1b\u5728CARLA\u4eff\u771f\u73af\u5883\u4e2d\u8bc4\u4f30\u4e0d\u540c\u901f\u5ea6\u3001\u5929\u6c14\u548c\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u653b\u51fb\u6548\u679c\uff0c\u5e76\u901a\u8fc7SUMO-OMNeT++\u8054\u5408\u4eff\u771f\u5206\u6790V2X\u901a\u4fe1\u5c42\u9762\u7684\u8fde\u9501\u5f71\u54cd\u3002", "result": "\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u653b\u51fb\u6210\u529f\u7387\u8d8590%\uff0c\u6076\u52a3\u73af\u5883\u4e0b\u4ecd\u4fdd\u630160\u201380%\u6709\u6548\u6027\uff1b\u653b\u51fb\u5728\u8ddd\u76ee\u68076\u201310\u7c73\u5185\u89e6\u53d1\uff0c\u7559\u7ed9\u8f66\u8f86\u7684\u5b89\u5168\u53cd\u5e94\u65f6\u95f4\u4e0d\u8db3\uff1b\u901a\u8fc7V2X\u4f20\u64ad\u865a\u5047\u7d27\u6025\u6d88\u606f\uff0c\u4f7f\u4fe1\u606f\u5cf0\u503c\u5e74\u9f84\u589e\u52a068\u201389%\uff0c\u4e25\u91cd\u5e72\u6270\u5b89\u5168\u5173\u952e\u901a\u4fe1\u3002", "conclusion": "PHANTOM\u63ed\u793a\u4e86CAV\u7cfb\u7edf\u5728\u611f\u77e5\u5c42\u548c\u901a\u4fe1\u5c42\u5747\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u9700\u540c\u65f6\u52a0\u5f3a\u7269\u7406\u5bf9\u6297\u9c81\u68d2\u6027\u548cV2X\u6d88\u606f\u9a8c\u8bc1\u673a\u5236\u3002", "summary_cn": "\u7f51\u8054\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\uff08CAVs\uff09\u4f9d\u8d56\u57fa\u4e8e\u89c6\u89c9\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNNs\uff09\u548c\u4f4e\u5ef6\u8fdf\u7684\u8f66\u8054\u7f51\uff08V2X\uff09\u901a\u4fe1\u6765\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u884c\u9a76\u3002\u5c3d\u7ba1\u6280\u672f\u4e0d\u65ad\u8fdb\u6b65\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u4ecd\u5bb9\u6613\u53d7\u5230\u7269\u7406\u5bf9\u6297\u653b\u51fb\u7684\u5f71\u54cd\u3002\u672c\u6587\u63d0\u51fa\u4e86PHANTOM\uff08\u5229\u7528\u53d8\u5f62\u827a\u672f\u5236\u9020\u963b\u788d\u7f51\u8054\u8f66\u8f86\u79fb\u52a8\u7684\u7269\u7406\u53d8\u5f62\u5a01\u80c1\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5229\u7528\u201c\u53d8\u5f62\u827a\u672f\u201d\uff08anamorphic art\uff09\u6784\u5efa\u548c\u90e8\u7f72\u89c6\u89d2\u4f9d\u8d56\u578b\u5bf9\u6297\u6837\u672c\u7684\u65b0\u6846\u67b6\u3002PHANTOM\u5229\u7528\u51e0\u4f55\u7578\u53d8\u56fe\u6848\uff0c\u8fd9\u4e9b\u56fe\u6848\u5bf9\u4eba\u7c7b\u800c\u8a00\u770b\u8d77\u6765\u81ea\u7136\uff0c\u5374\u80fd\u88ab\u5f53\u524d\u6700\u5148\u8fdb\u7684\u76ee\u6807\u68c0\u6d4b\u5668\u4ee5\u9ad8\u7f6e\u4fe1\u5ea6\u9519\u8bef\u8bc6\u522b\u3002\u4e0e\u4f20\u7edf\u653b\u51fb\u4e0d\u540c\uff0cPHANTOM\u53ef\u5728\u65e0\u9700\u8bbf\u95ee\u76ee\u6807\u6a21\u578b\u7684\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u8fd0\u884c\uff0c\u5e76\u5728\u56db\u79cd\u4e0d\u540c\u7684\u68c0\u6d4b\u5668\u67b6\u6784\uff08YOLOv5\u3001SSD\u3001Faster R-CNN \u548c RetinaNet\uff09\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8fc1\u79fb\u80fd\u529b\u3002\u5728CARLA\u4eff\u771f\u5e73\u53f0\u4e2d\uff0c\u9488\u5bf9\u4e0d\u540c\u8f66\u901f\u3001\u5929\u6c14\u6761\u4ef6\u548c\u5149\u7167\u573a\u666f\u7684\u5168\u9762\u8bc4\u4f30\u8868\u660e\uff0cPHANTOM\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc790%\uff0c\u5373\u4f7f\u5728\u73af\u5883\u9000\u5316\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u4fdd\u630160%\u81f380%\u7684\u6709\u6548\u6027\u3002\u8be5\u653b\u51fb\u5728\u8ddd\u79bb\u76ee\u68076\u81f310\u7c73\u8303\u56f4\u5185\u6fc0\u6d3b\uff0c\u7559\u7ed9\u8f66\u8f86\u7684\u5b89\u5168\u64cd\u63a7\u65f6\u95f4\u4e0d\u8db3\u3002\u6b64\u5916\uff0cPHANTOM\u4e0d\u4ec5\u6b3a\u9a97\u5355\u4e2a\u8f66\u8f86\uff0c\u8fd8\u4f1a\u901a\u8fc7V2X\u94fe\u8def\u89e6\u53d1\u5168\u7f51\u8303\u56f4\u7684\u5e72\u6270\uff1aSUMO-OMNeT++\u8054\u5408\u4eff\u771f\u663e\u793a\uff0c\u865a\u5047\u7684\u7d27\u6025\u6d88\u606f\u5728\u7f51\u7edc\u4e2d\u4f20\u64ad\uff0c\u5bfc\u81f4\u4fe1\u606f\u5cf0\u503c\u5e74\u9f84\uff08Peak Age of Information\uff09\u589e\u52a068%\u81f389%\uff0c\u4e25\u91cd\u635f\u5bb3\u4e86\u5b89\u5168\u5173\u952e\u901a\u4fe1\u3002\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86CAV\u751f\u6001\u7cfb\u7edf\u5728\u611f\u77e5\u5c42\u548c\u901a\u4fe1\u5c42\u5747\u5b58\u5728\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\u3002"}}
{"id": "2512.19817", "pdf": "https://arxiv.org/pdf/2512.19817", "abs": "https://arxiv.org/abs/2512.19817", "authors": ["SaiKiran Tedla", "Kelly Zhu", "Trevor Canham", "Felix Taubner", "Michael S. Brown", "Kiriakos N. Kutulakos", "David B. Lindell"], "title": "Generating the Past, Present and Future from a Motion-Blurred Image", "categories": ["cs.CV", "cs.GR"], "comment": "Code and data are available at https://blur2vid.github.io", "summary": "We seek to answer the question: what can a motion-blurred image reveal about a scene's past, present, and future? Although motion blur obscures image details and degrades visual quality, it also encodes information about scene and camera motion during an exposure. Previous techniques leverage this information to estimate a sharp image from an input blurry one, or to predict a sequence of video frames showing what might have occurred at the moment of image capture. However, they rely on handcrafted priors or network architectures to resolve ambiguities in this inverse problem, and do not incorporate image and video priors on large-scale datasets. As such, existing methods struggle to reproduce complex scene dynamics and do not attempt to recover what occurred before or after an image was taken. Here, we introduce a new technique that repurposes a pre-trained video diffusion model trained on internet-scale datasets to recover videos revealing complex scene dynamics during the moment of capture and what might have occurred immediately into the past or future. Our approach is robust and versatile; it outperforms previous methods for this task, generalizes to challenging in-the-wild images, and supports downstream tasks such as recovering camera trajectories, object motion, and dynamic 3D scene structure. Code and data are available at https://blur2vid.github.io", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u9891\u6269\u6563\u6a21\u578b\u4ece\u5355\u5f20\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u4e2d\u6062\u590d\u51fa\u5305\u542b\u590d\u6742\u52a8\u6001\u4fe1\u606f\u7684\u89c6\u9891\uff0c\u63ed\u793a\u62cd\u6444\u65f6\u523b\u53ca\u524d\u540e\u53ef\u80fd\u53d1\u751f\u7684\u573a\u666f\u53d8\u5316\uff0c\u5e76\u5728\u591a\u9879\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u4ece\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u4e2d\u6062\u590d\u6e05\u6670\u5185\u5bb9\u6216\u9884\u6d4b\u89c6\u9891\u5e8f\u5217\u65f6\uff0c\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u5148\u9a8c\u6216\u7279\u5b9a\u7f51\u7edc\u7ed3\u6784\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u52a8\u6001\u573a\u666f\uff0c\u4e5f\u65e0\u6cd5\u91cd\u5efa\u56fe\u50cf\u62cd\u6444\u524d\u540e\u7684\u4e8b\u4ef6\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u5927\u89c4\u6a21\u56fe\u50cf\u4e0e\u89c6\u9891\u6570\u636e\u4e2d\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "method": "\u8be5\u65b9\u6cd5\u91cd\u65b0\u5229\u7528\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684\u89c6\u9891\u6269\u6563\u6a21\u578b\uff0c\u4ece\u5355\u5f20\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u4e2d\u6062\u590d\u51fa\u5c55\u73b0\u62cd\u6444\u77ac\u95f4\u53ca\u524d\u540e\u77ed\u65f6\u95f4\u5185\u7684\u590d\u6742\u573a\u666f\u52a8\u6001\u89c6\u9891\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6062\u590d\u89c6\u9891\u8d28\u91cf\u4e0a\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\uff0c\u80fd\u6cdb\u5316\u5230\u771f\u5b9e\u590d\u6742\u573a\u666f\uff0c\u5e76\u652f\u6301\u76f8\u673a\u8f68\u8ff9\u3001\u7269\u4f53\u8fd0\u52a8\u548c\u52a8\u60013D\u573a\u666f\u7ed3\u6784\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "conclusion": "\u5229\u7528\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u89c6\u9891\u6269\u6563\u6a21\u578b\u53ef\u6709\u6548\u4ece\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u4e2d\u6316\u6398\u4e30\u5bcc\u7684\u65f6\u7a7a\u4fe1\u606f\uff0c\u4e3a\u7406\u89e3\u573a\u666f\u8fc7\u53bb\u3001\u73b0\u5728\u4e0e\u672a\u6765\u63d0\u4f9b\u5f3a\u5927\u5de5\u5177\u3002", "summary_cn": "\u6211\u4eec\u8bd5\u56fe\u56de\u7b54\u8fd9\u6837\u4e00\u4e2a\u95ee\u9898\uff1a\u4e00\u5f20\u8fd0\u52a8\u6a21\u7cca\u7684\u56fe\u50cf\u80fd\u63ed\u793a\u573a\u666f\u7684\u8fc7\u53bb\u3001\u73b0\u5728\u548c\u672a\u6765\u54ea\u4e9b\u4fe1\u606f\uff1f\u5c3d\u7ba1\u8fd0\u52a8\u6a21\u7cca\u4f1a\u63a9\u76d6\u56fe\u50cf\u7ec6\u8282\u5e76\u964d\u4f4e\u89c6\u89c9\u8d28\u91cf\uff0c\u4f46\u5b83\u4e5f\u7f16\u7801\u4e86\u66dd\u5149\u671f\u95f4\u573a\u666f\u4e0e\u76f8\u673a\u8fd0\u52a8\u7684\u4fe1\u606f\u3002\u4ee5\u5f80\u7684\u6280\u672f\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u4ece\u8f93\u5165\u7684\u6a21\u7cca\u56fe\u50cf\u4e2d\u4f30\u8ba1\u51fa\u6e05\u6670\u56fe\u50cf\uff0c\u6216\u9884\u6d4b\u4e00\u6bb5\u89c6\u9891\u5e27\u5e8f\u5217\u4ee5\u5c55\u793a\u56fe\u50cf\u6355\u83b7\u65f6\u523b\u53ef\u80fd\u53d1\u751f\u7684\u60c5\u51b5\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684\u5148\u9a8c\u6216\u7279\u5b9a\u7f51\u7edc\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e00\u9006\u95ee\u9898\u4e2d\u7684\u6b67\u4e49\uff0c\u4e14\u672a\u7ed3\u5408\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u56fe\u50cf\u4e0e\u89c6\u9891\u5148\u9a8c\u3002\u56e0\u6b64\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u518d\u73b0\u590d\u6742\u7684\u573a\u666f\u52a8\u6001\uff0c\u4e5f\u65e0\u6cd5\u6062\u590d\u56fe\u50cf\u62cd\u6444\u4e4b\u524d\u6216\u4e4b\u540e\u53d1\u751f\u7684\u5185\u5bb9\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6280\u672f\uff0c\u901a\u8fc7\u91cd\u65b0\u5229\u7528\u5728\u4e92\u8054\u7f51\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684\u89c6\u9891\u6269\u6563\u6a21\u578b\uff0c\u4ece\u5355\u5f20\u6a21\u7cca\u56fe\u50cf\u4e2d\u6062\u590d\u51fa\u80fd\u63ed\u793a\u62cd\u6444\u65f6\u523b\u590d\u6742\u52a8\u6001\u4ee5\u53ca\u7d27\u90bb\u8fc7\u53bb\u6216\u672a\u6765\u53ef\u80fd\u4e8b\u4ef6\u7684\u89c6\u9891\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u548c\u901a\u7528\u6027\uff1a\u5728\u8be5\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\uff0c\u80fd\u6cdb\u5316\u81f3\u5177\u6709\u6311\u6218\u6027\u7684\u91ce\u5916\u56fe\u50cf\uff0c\u5e76\u652f\u6301\u6062\u590d\u76f8\u673a\u8f68\u8ff9\u3001\u7269\u4f53\u8fd0\u52a8\u548c\u52a8\u60013D\u573a\u666f\u7ed3\u6784\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002\u4ee3\u7801\u548c\u6570\u636e\u53ef\u5728 https://blur2vid.github.io \u83b7\u53d6\u3002"}}
{"id": "2512.19823", "pdf": "https://arxiv.org/pdf/2512.19823", "abs": "https://arxiv.org/abs/2512.19823", "authors": ["SaiKiran Tedla", "Zhoutong Zhang", "Xuaner Zhang", "Shumian Xin"], "title": "Learning to Refocus with Video Diffusion Models", "categories": ["cs.CV"], "comment": "Code and data are available at https://www.learn2refocus.github.io . SIGGRAPH Asia 2025, Dec. 2025", "summary": "Focus is a cornerstone of photography, yet autofocus systems often fail to capture the intended subject, and users frequently wish to adjust focus after capture. We introduce a novel method for realistic post-capture refocusing using video diffusion models. From a single defocused image, our approach generates a perceptually accurate focal stack, represented as a video sequence, enabling interactive refocusing and unlocking a range of downstream applications. We release a large-scale focal stack dataset acquired under diverse real-world smartphone conditions to support this work and future research. Our method consistently outperforms existing approaches in both perceptual quality and robustness across challenging scenarios, paving the way for more advanced focus-editing capabilities in everyday photography. Code and data are available at www.learn2refocus.github.io", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u9891\u6269\u6563\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\uff0c\u53ef\u4ece\u5355\u5f20\u5931\u7126\u56fe\u50cf\u751f\u6210\u903c\u771f\u7684\u7126\u8ddd\u5806\u6808\u89c6\u9891\uff0c\u5b9e\u73b0\u62cd\u6444\u540e\u7684\u4ea4\u4e92\u5f0f\u91cd\u5bf9\u7126\uff0c\u5e76\u53d1\u5e03\u4e86\u5927\u89c4\u6a21\u771f\u5b9e\u573a\u666f\u624b\u673a\u62cd\u6444\u7684\u7126\u8ddd\u5806\u6808\u6570\u636e\u96c6\u3002", "motivation": "\u81ea\u52a8\u5bf9\u7126\u7cfb\u7edf\u5e38\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u7528\u6237\u610f\u56fe\u7684\u4e3b\u4f53\uff0c\u4e14\u7528\u6237\u5e0c\u671b\u5728\u62cd\u6444\u540e\u80fd\u8c03\u6574\u7126\u70b9\u3002", "method": "\u5229\u7528\u89c6\u9891\u6269\u6563\u6a21\u578b\uff0c\u4ece\u5355\u5f20\u5931\u7126\u56fe\u50cf\u751f\u6210\u611f\u77e5\u4e0a\u51c6\u786e\u7684\u7126\u8ddd\u5806\u6808\uff08\u4ee5\u89c6\u9891\u5e8f\u5217\u8868\u793a\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u611f\u77e5\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65e5\u5e38\u6444\u5f71\u4e2d\u66f4\u9ad8\u7ea7\u7684\u7126\u70b9\u7f16\u8f91\u80fd\u529b\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "summary_cn": "\u5bf9\u7126\u662f\u6444\u5f71\u7684\u6838\u5fc3\u8981\u7d20\uff0c\u7136\u800c\u81ea\u52a8\u5bf9\u7126\u7cfb\u7edf\u5e38\u5e38\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u7528\u6237\u9884\u671f\u7684\u4e3b\u4f53\uff0c\u800c\u4e14\u7528\u6237\u7ecf\u5e38\u5e0c\u671b\u5728\u62cd\u6444\u540e\u8c03\u6574\u7126\u70b9\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u89c6\u9891\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u903c\u771f\u62cd\u6444\u540e\u91cd\u5bf9\u7126\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700\u4e00\u5f20\u5931\u7126\u56fe\u50cf\uff0c\u5373\u53ef\u751f\u6210\u5728\u611f\u77e5\u4e0a\u51c6\u786e\u7684\u7126\u8ddd\u5806\u6808\uff0c\u5e76\u4ee5\u89c6\u9891\u5e8f\u5217\u8868\u793a\uff0c\u4ece\u800c\u652f\u6301\u4ea4\u4e92\u5f0f\u91cd\u5bf9\u7126\u5e76\u62d3\u5c55\u591a\u79cd\u4e0b\u6e38\u5e94\u7528\u3002\u4e3a\u652f\u6301\u672c\u7814\u7a76\u53ca\u672a\u6765\u76f8\u5173\u5de5\u4f5c\uff0c\u6211\u4eec\u53d1\u5e03\u4e86\u4e00\u4e2a\u5728\u591a\u6837\u5316\u771f\u5b9e\u4e16\u754c\u667a\u80fd\u624b\u673a\u6761\u4ef6\u4e0b\u91c7\u96c6\u7684\u5927\u89c4\u6a21\u7126\u8ddd\u5806\u6808\u6570\u636e\u96c6\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u611f\u77e5\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u4e5f\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u65e5\u5e38\u6444\u5f71\u4e2d\u66f4\u5148\u8fdb\u7684\u7126\u70b9\u7f16\u8f91\u529f\u80fd\u94fa\u5e73\u4e86\u9053\u8def\u3002\u4ee3\u7801\u548c\u6570\u636e\u53ef\u5728 www.learn2refocus.github.io \u83b7\u53d6\u3002"}}
{"id": "2512.19850", "pdf": "https://arxiv.org/pdf/2512.19850", "abs": "https://arxiv.org/abs/2512.19850", "authors": ["A. Shekhovtsov"], "title": "RANSAC Scoring Functions: Analysis and Reality Check", "categories": ["cs.CV", "stat.AP"], "comment": null, "summary": "We revisit the problem of assigning a score (a quality of fit) to candidate geometric models -- one of the key components of RANSAC for robust geometric fitting. In a non-robust setting, the ``gold standard'' scoring function, known as the geometric error, follows from a probabilistic model with Gaussian noises. We extend it to spherical noises. In a robust setting, we consider a mixture with uniformly distributed outliers and show that a threshold-based parameterization leads to a unified view of likelihood-based and robust M-estimators and associated local optimization schemes.\n  Next we analyze MAGSAC++ which stands out for two reasons. First, it achieves the best results according to existing benchmarks. Second, it makes quite different modeling assumptions and derivation steps. We discovered, however that the derivation does not correspond to sound principles and the resulting score function is in fact numerically equivalent to a simple Gaussian-uniform likelihood, a basic model within the proposed framework.\n  Finally, we propose an experimental methodology for evaluating scoring functions: assuming either a large validation set, or a small random validation set in expectation. We find that all scoring functions, including using a learned inlier distribution, perform identically. In particular, MAGSAC++ score is found to be neither better performing than simple contenders nor less sensitive to the choice of the threshold hyperparameter.\n  Our theoretical and experimental analysis thus comprehensively revisit the state-of-the-art, which is critical for any future research seeking to improve the methods or apply them to other robust fitting problems.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86RANSAC\u4e2d\u7528\u4e8e\u8bc4\u4f30\u5019\u9009\u51e0\u4f55\u6a21\u578b\u62df\u5408\u8d28\u91cf\u7684\u8bc4\u5206\u51fd\u6570\u3002\u4f5c\u8005\u5c06\u7ecf\u5178\u7684\u9ad8\u65af\u566a\u58f0\u4e0b\u7684\u51e0\u4f55\u8bef\u5dee\u63a8\u5e7f\u81f3\u7403\u5f62\u566a\u58f0\uff0c\u5e76\u5728\u9c81\u68d2\u8bbe\u5b9a\u4e0b\u901a\u8fc7\u9ad8\u65af-\u5747\u5300\u6df7\u5408\u6a21\u578b\u7edf\u4e00\u4e86\u57fa\u4e8e\u4f3c\u7136\u548cM\u4f30\u8ba1\u5668\u7684\u65b9\u6cd5\u3002\u6587\u7ae0\u6307\u51fa\u5f53\u524dSOTA\u65b9\u6cd5MAGSAC++\u5b9e\u9645\u4e0a\u7b49\u4ef7\u4e8e\u4e00\u4e2a\u7b80\u5355\u7684\u9ad8\u65af-\u5747\u5300\u4f3c\u7136\u6a21\u578b\uff0c\u4e14\u5b9e\u9a8c\u8868\u660e\u5305\u62ec\u5b66\u4e60\u578b\u5185\u70b9\u5206\u5e03\u5728\u5185\u7684\u5404\u79cd\u8bc4\u5206\u51fd\u6570\u6027\u80fd\u5e76\u65e0\u663e\u8457\u5dee\u5f02\uff0cMAGSAC++\u5e76\u4e0d\u4f18\u4e8e\u7b80\u5355\u65b9\u6cd5\uff0c\u4e5f\u672a\u5bf9\u9608\u503c\u8d85\u53c2\u6570\u66f4\u9c81\u68d2\u3002", "motivation": "RANSAC\u4e2d\u8bc4\u5206\u51fd\u6570\u7684\u8bbe\u8ba1\u5bf9\u9c81\u68d2\u51e0\u4f55\u62df\u5408\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\uff08\u5982MAGSAC++\uff09\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u4f18\u52bf\u5c1a\u4e0d\u6e05\u6670\uff0c\u9700\u7cfb\u7edf\u6027\u91cd\u5ba1\u4ee5\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002", "method": "\u4ece\u6982\u7387\u5efa\u6a21\u51fa\u53d1\uff0c\u5c06\u51e0\u4f55\u8bef\u5dee\u6269\u5c55\u5230\u7403\u5f62\u566a\u58f0\uff1b\u5f15\u5165\u9ad8\u65af-\u5747\u5300\u6df7\u5408\u6a21\u578b\uff0c\u5728\u9c81\u68d2\u8bbe\u5b9a\u4e0b\u7edf\u4e00\u4f3c\u7136\u4e0eM\u4f30\u8ba1\u6846\u67b6\uff1b\u5e76\u901a\u8fc7\u5927\u9a8c\u8bc1\u96c6\u6216\u5c0f\u968f\u673a\u9a8c\u8bc1\u96c6\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u8bc4\u4f30\u4e0d\u540c\u8bc4\u5206\u51fd\u6570\u3002", "result": "MAGSAC++\u7684\u8bc4\u5206\u51fd\u6570\u5728\u6570\u503c\u4e0a\u7b49\u4ef7\u4e8e\u7b80\u5355\u7684\u9ad8\u65af-\u5747\u5300\u4f3c\u7136\u6a21\u578b\uff1b\u6240\u6709\u8bc4\u5206\u51fd\u6570\uff08\u542b\u5b66\u4e60\u578b\uff09\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4e00\u81f4\uff0cMAGSAC++\u65e2\u4e0d\u4f18\u4e8e\u7b80\u5355\u65b9\u6cd5\uff0c\u4e5f\u672a\u5bf9\u9608\u503c\u66f4\u9c81\u68d2\u3002", "conclusion": "\u5f53\u524dSOTA\u8bc4\u5206\u51fd\u6570\u5e76\u65e0\u5b9e\u8d28\u6027\u4f18\u52bf\uff0c\u5176\u7406\u8bba\u4e0e\u5b9e\u9a8c\u9700\u88ab\u5168\u9762\u91cd\u5ba1\uff0c\u8fd9\u5bf9\u540e\u7eed\u6539\u8fdb\u6216\u62d3\u5c55\u9c81\u68d2\u62df\u5408\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "summary_cn": "\u6211\u4eec\u91cd\u65b0\u5ba1\u89c6\u4e86\u4e3a\u5019\u9009\u51e0\u4f55\u6a21\u578b\u5206\u914d\u8bc4\u5206\uff08\u5373\u62df\u5408\u8d28\u91cf\uff09\u7684\u95ee\u9898\u2014\u2014\u8fd9\u662fRANSAC\u9c81\u68d2\u51e0\u4f55\u62df\u5408\u4e2d\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\u3002\u5728\u975e\u9c81\u68d2\u8bbe\u5b9a\u4e0b\uff0c\u88ab\u79f0\u4e3a\u201c\u9ec4\u91d1\u6807\u51c6\u201d\u7684\u8bc4\u5206\u51fd\u6570\u5373\u51e0\u4f55\u8bef\u5dee\uff0c\u5b83\u6e90\u4e8e\u5e26\u6709\u9ad8\u65af\u566a\u58f0\u7684\u6982\u7387\u6a21\u578b\u3002\u6211\u4eec\u5c06\u8be5\u6a21\u578b\u63a8\u5e7f\u81f3\u7403\u5f62\u566a\u58f0\u60c5\u5f62\u3002\u5728\u9c81\u68d2\u8bbe\u5b9a\u4e0b\uff0c\u6211\u4eec\u8003\u8651\u4e86\u5305\u542b\u5747\u5300\u5206\u5e03\u79bb\u7fa4\u70b9\u7684\u6df7\u5408\u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u57fa\u4e8e\u9608\u503c\u7684\u53c2\u6570\u5316\u65b9\u6cd5\u80fd\u591f\u7edf\u4e00\u57fa\u4e8e\u4f3c\u7136\u548c\u9c81\u68d2M\u4f30\u8ba1\u5668\u53ca\u5176\u76f8\u5e94\u7684\u5c40\u90e8\u4f18\u5316\u65b9\u6848\u3002  \n\u63a5\u7740\uff0c\u6211\u4eec\u5206\u6790\u4e86MAGSAC++\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u56e0\u4e24\u70b9\u800c\u7a81\u51fa\uff1a\u4e00\u662f\u6839\u636e\u73b0\u6709\u57fa\u51c6\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff1b\u4e8c\u662f\u5176\u5efa\u6a21\u5047\u8bbe\u548c\u63a8\u5bfc\u6b65\u9aa4\u4e0e\u5176\u4ed6\u65b9\u6cd5\u663e\u8457\u4e0d\u540c\u3002\u7136\u800c\u6211\u4eec\u53d1\u73b0\uff0c\u5176\u63a8\u5bfc\u5e76\u4e0d\u7b26\u5408\u4e25\u8c28\u7684\u6982\u7387\u539f\u5219\uff0c\u6240\u5f97\u8bc4\u5206\u51fd\u6570\u5728\u6570\u503c\u4e0a\u5b9e\u9645\u4e0a\u7b49\u4ef7\u4e8e\u6240\u63d0\u6846\u67b6\u5185\u4e00\u4e2a\u7b80\u5355\u7684\u9ad8\u65af-\u5747\u5300\u4f3c\u7136\u6a21\u578b\u3002  \n\u6700\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u8bc4\u5206\u51fd\u6570\u7684\u5b9e\u9a8c\u65b9\u6cd5\uff1a\u5047\u8bbe\u6709\u5927\u578b\u9a8c\u8bc1\u96c6\uff0c\u6216\u5728\u671f\u671b\u610f\u4e49\u4e0b\u4f7f\u7528\u5c0f\u578b\u968f\u673a\u9a8c\u8bc1\u96c6\u3002\u6211\u4eec\u53d1\u73b0\u6240\u6709\u8bc4\u5206\u51fd\u6570\uff08\u5305\u62ec\u4f7f\u7528\u5b66\u4e60\u5f97\u5230\u7684\u5185\u70b9\u5206\u5e03\u7684\u65b9\u6cd5\uff09\u8868\u73b0\u5b8c\u5168\u76f8\u540c\u3002\u7279\u522b\u662f\uff0cMAGSAC++\u7684\u8bc4\u5206\u51fd\u6570\u65e2\u4e0d\u6bd4\u7b80\u5355\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\uff0c\u4e5f\u5e76\u672a\u5bf9\u9608\u503c\u8d85\u53c2\u6570\u7684\u9009\u62e9\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u654f\u611f\u6027\u3002  \n\u56e0\u6b64\uff0c\u6211\u4eec\u7684\u7406\u8bba\u4e0e\u5b9e\u9a8c\u5206\u6790\u5168\u9762\u91cd\u5ba1\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u8fd9\u5bf9\u4e8e\u672a\u6765\u65e8\u5728\u6539\u8fdb\u8fd9\u4e9b\u65b9\u6cd5\u6216\u5c06\u5176\u5e94\u7528\u4e8e\u5176\u4ed6\u9c81\u68d2\u62df\u5408\u95ee\u9898\u7684\u7814\u7a76\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2512.19871", "pdf": "https://arxiv.org/pdf/2512.19871", "abs": "https://arxiv.org/abs/2512.19871", "authors": ["Jong Wook Kim", "Wonseok Roh", "Ha Dam Baek", "Pilhyeon Lee", "Jonghyun Choi", "Sangpil Kim"], "title": "HyGE-Occ: Hybrid View-Transformation with 3D Gaussian and Edge Priors for 3D Panoptic Occupancy Prediction", "categories": ["cs.CV"], "comment": "11 pages, 6 figures", "summary": "3D Panoptic Occupancy Prediction aims to reconstruct a dense volumetric scene map by predicting the semantic class and instance identity of every occupied region in 3D space. Achieving such fine-grained 3D understanding requires precise geometric reasoning and spatially consistent scene representation across complex environments. However, existing approaches often struggle to maintain precise geometry and capture the precise spatial range of 3D instances critical for robust panoptic separation. To overcome these limitations, we introduce HyGE-Occ, a novel framework that leverages a hybrid view-transformation branch with 3D Gaussian and edge priors to enhance both geometric consistency and boundary awareness in 3D panoptic occupancy prediction. HyGE-Occ employs a hybrid view-transformation branch that fuses a continuous Gaussian-based depth representation with a discretized depth-bin formulation, producing BEV features with improved geometric consistency and structural coherence. In parallel, we extract edge maps from BEV features and use them as auxiliary information to learn edge cues. In our extensive experiments on the Occ3D-nuScenes dataset, HyGE-Occ outperforms existing work, demonstrating superior 3D geometric reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyGE-Occ\uff0c\u4e00\u79cd\u7ed3\u54083D\u9ad8\u65af\u4e0e\u8fb9\u7f18\u5148\u9a8c\u7684\u6df7\u5408\u89c6\u56fe\u53d8\u6362\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53473D\u5168\u666f\u5360\u636e\u9884\u6d4b\u4e2d\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u8fb9\u754c\u611f\u77e5\u80fd\u529b\uff0c\u5728Occ3D-nuScenes\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u57283D\u5168\u666f\u5360\u636e\u9884\u6d4b\u4e2d\u96be\u4ee5\u4fdd\u6301\u7cbe\u786e\u51e0\u4f55\u7ed3\u6784\u5e76\u51c6\u786e\u6355\u6349\u5b9e\u4f8b\u7684\u7a7a\u95f4\u8303\u56f4\uff0c\u5f71\u54cd\u4e86\u5168\u666f\u5206\u5272\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51faHyGE-Occ\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u89c6\u56fe\u53d8\u6362\u5206\u652f\u878d\u5408\u8fde\u7eed\u9ad8\u65af\u6df1\u5ea6\u8868\u793a\u4e0e\u79bb\u6563\u6df1\u5ea6\u533a\u95f4\u8868\u793a\u4ee5\u589e\u5f3aBEV\u7279\u5f81\u7684\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u5e76\u5229\u7528\u4eceBEV\u7279\u5f81\u4e2d\u63d0\u53d6\u7684\u8fb9\u7f18\u56fe\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u606f\u63d0\u5347\u8fb9\u754c\u611f\u77e5\u3002", "result": "\u5728Occ3D-nuScenes\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHyGE-Occ\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u66f4\u5f3a\u76843D\u51e0\u4f55\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "HyGE-Occ\u6709\u6548\u63d0\u5347\u4e863D\u5168\u666f\u5360\u636e\u9884\u6d4b\u4e2d\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u5b9e\u4f8b\u8fb9\u754c\u51c6\u786e\u6027\uff0c\u4e3a\u590d\u6742\u573a\u666f\u4e0b\u7684\u5bc6\u96c63D\u8bed\u4e49\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "3D\u5168\u666f\u5360\u636e\u9884\u6d4b\u65e8\u5728\u901a\u8fc7\u9884\u6d4b\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u6bcf\u4e2a\u88ab\u5360\u636e\u533a\u57df\u7684\u8bed\u4e49\u7c7b\u522b\u548c\u5b9e\u4f8b\u8eab\u4efd\uff0c\u91cd\u5efa\u5bc6\u96c6\u7684\u4f53\u7d20\u5316\u573a\u666f\u5730\u56fe\u3002\u5b9e\u73b0\u8fd9\u79cd\u7ec6\u7c92\u5ea6\u76843D\u7406\u89e3\u9700\u8981\u5728\u590d\u6742\u73af\u5883\u4e2d\u8fdb\u884c\u7cbe\u786e\u7684\u51e0\u4f55\u63a8\u7406\u5e76\u4fdd\u6301\u7a7a\u95f4\u4e00\u81f4\u7684\u573a\u666f\u8868\u793a\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u96be\u4ee5\u7ef4\u6301\u7cbe\u786e\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u5e76\u4e14\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u5bf9\u9c81\u68d2\u5168\u666f\u5206\u79bb\u81f3\u5173\u91cd\u8981\u76843D\u5b9e\u4f8b\u7a7a\u95f4\u8303\u56f4\u3002\u4e3a\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\uff0c\u6211\u4eec\u63d0\u51fa\u4e86HyGE-Occ\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5b83\u5229\u7528\u7ed3\u54083D\u9ad8\u65af\u4e0e\u8fb9\u7f18\u5148\u9a8c\u7684\u6df7\u5408\u89c6\u56fe\u53d8\u6362\u5206\u652f\uff0c\u4ee5\u589e\u5f3a3D\u5168\u666f\u5360\u636e\u9884\u6d4b\u4e2d\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u8fb9\u754c\u611f\u77e5\u80fd\u529b\u3002HyGE-Occ\u91c7\u7528\u6df7\u5408\u89c6\u56fe\u53d8\u6362\u5206\u652f\uff0c\u5c06\u57fa\u4e8e\u8fde\u7eed\u9ad8\u65af\u7684\u6df1\u5ea6\u8868\u793a\u4e0e\u79bb\u6563\u5316\u7684\u6df1\u5ea6\u533a\u95f4\u8868\u793a\u76f8\u878d\u5408\uff0c\u751f\u6210\u5177\u6709\u66f4\u9ad8\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u7ed3\u6784\u8fde\u8d2f\u6027\u7684\u9e1f\u77b0\u56fe\uff08BEV\uff09\u7279\u5f81\u3002\u540c\u65f6\uff0c\u6211\u4eec\u4eceBEV\u7279\u5f81\u4e2d\u63d0\u53d6\u8fb9\u7f18\u56fe\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u606f\u7528\u4e8e\u5b66\u4e60\u8fb9\u7f18\u7ebf\u7d22\u3002\u5728Occ3D-nuScenes\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHyGE-Occ\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u5353\u8d8a\u76843D\u51e0\u4f55\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2512.19918", "pdf": "https://arxiv.org/pdf/2512.19918", "abs": "https://arxiv.org/abs/2512.19918", "authors": ["Houston H. Zhang", "Tao Zhang", "Baoze Lin", "Yuanqi Xue", "Yincheng Zhu", "Huan Liu", "Li Gu", "Linfeng Ye", "Ziqiang Wang", "Xinxin Zuo", "Yang Wang", "Yuanhao Yu", "Zhixiang Chi"], "title": "Widget2Code: From Visual Widgets to UI Code via Multimodal LLMs", "categories": ["cs.CV"], "comment": "Code: https://github.com/Djanghao/widget2code", "summary": "User interface to code (UI2Code) aims to generate executable code that can faithfully reconstruct a given input UI. Prior work focuses largely on web pages and mobile screens, leaving app widgets underexplored. Unlike web or mobile UIs with rich hierarchical context, widgets are compact, context-free micro-interfaces that summarize key information through dense layouts and iconography under strict spatial constraints. Moreover, while (image, code) pairs are widely available for web or mobile UIs, widget designs are proprietary and lack accessible markup. We formalize this setting as the Widget-to-Code (Widget2Code) and introduce an image-only widget benchmark with fine-grained, multi-dimensional evaluation metrics. Benchmarking shows that although generalized multimodal large language models (MLLMs) outperform specialized UI2Code methods, they still produce unreliable and visually inconsistent code. To address these limitations, we develop a baseline that jointly advances perceptual understanding and structured code generation. At the perceptual level, we follow widget design principles to assemble atomic components into complete layouts, equipped with icon retrieval and reusable visualization modules. At the system level, we design an end-to-end infrastructure, WidgetFactory, which includes a framework-agnostic widget-tailored domain-specific language (WidgetDSL) and a compiler that translates it into multiple front-end implementations (e.g., React, HTML/CSS). An adaptive rendering module further refines spatial dimensions to satisfy compactness constraints. Together, these contributions substantially enhance visual fidelity, establishing a strong baseline and unified infrastructure for future Widget2Code research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faWidget2Code\u4efb\u52a1\uff0c\u9488\u5bf9\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u3001\u5e03\u5c40\u7d27\u51d1\u7684App\u5c0f\u90e8\u4ef6\uff08widgets\uff09\u4ece\u56fe\u50cf\u751f\u6210\u4ee3\u7801\u7684\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u4ec5\u57fa\u4e8e\u56fe\u50cf\u7684\u5c0f\u90e8\u4ef6\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u4e86\u5305\u542b\u611f\u77e5\u7406\u89e3\u4e0e\u7ed3\u6784\u5316\u4ee3\u7801\u751f\u6210\u7684\u57fa\u7ebf\u65b9\u6cd5WidgetFactory\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709UI2Code\u7814\u7a76\u4e3b\u8981\u805a\u7126\u4e8e\u7f51\u9875\u548c\u79fb\u52a8\u754c\u9762\uff0c\u800cApp\u5c0f\u90e8\u4ef6\u56e0\u7ed3\u6784\u7d27\u51d1\u3001\u4e0a\u4e0b\u6587\u7f3a\u5931\u3001\u8bbe\u8ba1\u4e13\u6709\u4e14\u7f3a\u4e4f\u53ef\u8bbf\u95ee\u7684\u6807\u8bb0\u6570\u636e\uff0c\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u540c\u65f6\uff0c\u901a\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u751f\u6210\u7684\u4ee3\u7801\u4e0d\u53ef\u9760\u4e14\u89c6\u89c9\u4e0d\u4e00\u81f4\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u4ec5\u57fa\u4e8e\u56fe\u50cf\u7684\u5c0f\u90e8\u4ef6\u57fa\u51c6\uff0c\u5e76\u63d0\u51faWidgetFactory\u57fa\u7ebf\u7cfb\u7edf\uff1a\u5728\u611f\u77e5\u5c42\u9762\uff0c\u4f9d\u636e\u5c0f\u90e8\u4ef6\u8bbe\u8ba1\u539f\u5219\u7ec4\u5408\u539f\u5b50\u7ec4\u4ef6\uff0c\u5f15\u5165\u56fe\u6807\u68c0\u7d22\u4e0e\u53ef\u590d\u7528\u53ef\u89c6\u5316\u6a21\u5757\uff1b\u5728\u7cfb\u7edf\u5c42\u9762\uff0c\u8bbe\u8ba1\u4e86\u4e0e\u6846\u67b6\u65e0\u5173\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00WidgetDSL\u53ca\u5176\u7f16\u8bd1\u5668\uff0c\u652f\u6301\u751f\u6210\u591a\u79cd\u524d\u7aef\u5b9e\u73b0\uff08\u5982React\u3001HTML/CSS\uff09\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u6e32\u67d3\u6a21\u5757\u4f18\u5316\u7a7a\u95f4\u7d27\u51d1\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5c3d\u7ba1\u901a\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\u4f18\u4e8e\u4e13\u7528UI2Code\u65b9\u6cd5\uff0c\u4f46\u4ecd\u5b58\u5728\u53ef\u9760\u6027\u4e0e\u89c6\u89c9\u4e00\u81f4\u6027\u95ee\u9898\uff1b\u6240\u63d0\u51fa\u7684WidgetFactory\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u4ee3\u7801\u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u672c\u6587\u6b63\u5f0f\u5b9a\u4e49\u4e86Widget2Code\u4efb\u52a1\uff0c\u63d0\u4f9b\u4e86\u8bc4\u4f30\u57fa\u51c6\u4e0e\u7edf\u4e00\u57fa\u7840\u8bbe\u65bd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "summary_cn": "\u7528\u6237\u754c\u9762\u5230\u4ee3\u7801\uff08UI2Code\uff09\u65e8\u5728\u751f\u6210\u53ef\u5fe0\u5b9e\u91cd\u5efa\u7ed9\u5b9a\u8f93\u5165\u7528\u6237\u754c\u9762\u7684\u53ef\u6267\u884c\u4ee3\u7801\u3002\u4ee5\u5f80\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u7f51\u9875\u548c\u79fb\u52a8\u5c4f\u5e55\uff0c\u800c\u5e94\u7528\u7a0b\u5e8f\u5c0f\u90e8\u4ef6\uff08app widgets\uff09\u5219\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u4e0e\u5177\u6709\u4e30\u5bcc\u5c42\u6b21\u4e0a\u4e0b\u6587\u7684\u7f51\u9875\u6216\u79fb\u52a8UI\u4e0d\u540c\uff0c\u5c0f\u90e8\u4ef6\u662f\u7d27\u51d1\u3001\u65e0\u4e0a\u4e0b\u6587\u7684\u5fae\u578b\u754c\u9762\uff0c\u5728\u4e25\u683c\u7684\u7a7a\u95f4\u9650\u5236\u4e0b\u901a\u8fc7\u5bc6\u96c6\u5e03\u5c40\u548c\u56fe\u6807\u6765\u6982\u62ec\u5173\u952e\u4fe1\u606f\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u7f51\u9875\u6216\u79fb\u52a8UI\u5b58\u5728\u5927\u91cf\uff08\u56fe\u50cf\uff0c\u4ee3\u7801\uff09\u914d\u5bf9\u6570\u636e\uff0c\u4f46\u5c0f\u90e8\u4ef6\u8bbe\u8ba1\u5c5e\u4e8e\u4e13\u6709\u5185\u5bb9\uff0c\u7f3a\u4e4f\u53ef\u8bbf\u95ee\u7684\u6807\u8bb0\u8bed\u8a00\u3002\u672c\u6587\u5c06\u8fd9\u4e00\u573a\u666f\u5f62\u5f0f\u5316\u4e3a\u201c\u5c0f\u90e8\u4ef6\u5230\u4ee3\u7801\u201d\uff08Widget2Code\uff09\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u4ec5\u57fa\u4e8e\u56fe\u50cf\u7684\u5c0f\u90e8\u4ef6\u57fa\u51c6\uff0c\u914d\u5907\u7ec6\u7c92\u5ea6\u3001\u591a\u7ef4\u5ea6\u7684\u8bc4\u4f30\u6307\u6807\u3002\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u5c3d\u7ba1\u901a\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4f18\u4e8e\u4e13\u95e8\u7684UI2Code\u65b9\u6cd5\uff0c\u5176\u751f\u6210\u7684\u4ee3\u7801\u4ecd\u4e0d\u53ef\u9760\u4e14\u89c6\u89c9\u4e0d\u4e00\u81f4\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u6b65\u63a8\u8fdb\u611f\u77e5\u7406\u89e3\u4e0e\u7ed3\u6784\u5316\u4ee3\u7801\u751f\u6210\u3002\u5728\u611f\u77e5\u5c42\u9762\uff0c\u6211\u4eec\u9075\u5faa\u5c0f\u90e8\u4ef6\u8bbe\u8ba1\u539f\u5219\uff0c\u5c06\u539f\u5b50\u7ec4\u4ef6\u7ec4\u88c5\u4e3a\u5b8c\u6574\u5e03\u5c40\uff0c\u5e76\u914d\u5907\u56fe\u6807\u68c0\u7d22\u4e0e\u53ef\u590d\u7528\u7684\u53ef\u89c6\u5316\u6a21\u5757\u3002\u5728\u7cfb\u7edf\u5c42\u9762\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u57fa\u7840\u8bbe\u65bdWidgetFactory\uff0c\u5176\u4e2d\u5305\u62ec\u4e00\u4e2a\u4e0e\u6846\u67b6\u65e0\u5173\u3001\u9762\u5411\u5c0f\u90e8\u4ef6\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08WidgetDSL\uff09\u53ca\u5176\u7f16\u8bd1\u5668\uff0c\u53ef\u5c06\u5176\u7ffb\u8bd1\u4e3a\u591a\u79cd\u524d\u7aef\u5b9e\u73b0\uff08\u5982React\u3001HTML/CSS\uff09\u3002\u4e00\u4e2a\u81ea\u9002\u5e94\u6e32\u67d3\u6a21\u5757\u8fdb\u4e00\u6b65\u4f18\u5316\u7a7a\u95f4\u5c3a\u5bf8\u4ee5\u6ee1\u8db3\u7d27\u51d1\u6027\u7ea6\u675f\u3002\u8fd9\u4e9b\u8d21\u732e\u5171\u540c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u4fdd\u771f\u5ea6\uff0c\u4e3a\u672a\u6765\u7684Widget2Code\u7814\u7a76\u5efa\u7acb\u4e86\u5f3a\u6709\u529b\u7684\u57fa\u7ebf\u548c\u7edf\u4e00\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2512.19928", "pdf": "https://arxiv.org/pdf/2512.19928", "abs": "https://arxiv.org/abs/2512.19928", "authors": ["S. Mazdak Abulnaga", "Andrew Hoopes", "Malte Hoffmann", "Robin Magnet", "Maks Ovsjanikov", "Lilla Z\u00f6llei", "John Guttag", "Bruce Fischl", "Adrian Dalca"], "title": "Unified Brain Surface and Volume Registration", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate registration of brain MRI scans is fundamental for cross-subject analysis in neuroscientific studies. This involves aligning both the cortical surface of the brain and the interior volume. Traditional methods treat volumetric and surface-based registration separately, which often leads to inconsistencies that limit downstream analyses. We propose a deep learning framework, NeurAlign, that registers $3$D brain MRI images by jointly aligning both cortical and subcortical regions through a unified volume-and-surface-based representation. Our approach leverages an intermediate spherical coordinate space to bridge anatomical surface topology with volumetric anatomy, enabling consistent and anatomically accurate alignment. By integrating spherical registration into the learning, our method ensures geometric coherence between volume and surface domains. In a series of experiments on both in-domain and out-of-domain datasets, our method consistently outperforms both classical and machine learning-based registration methods -- improving the Dice score by up to 7 points while maintaining regular deformation fields. Additionally, it is orders of magnitude faster than the standard method for this task, and is simpler to use because it requires no additional inputs beyond an MRI scan. With its superior accuracy, fast inference, and ease of use, NeurAlign sets a new standard for joint cortical and subcortical registration.", "AI": {"tldr": "NeurAlign \u662f\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u4f53\u79ef-\u8868\u9762\u8868\u793a\uff0c\u5728\u7403\u9762\u5750\u6807\u7a7a\u95f4\u4e2d\u540c\u65f6\u5bf9\u5927\u8111\u76ae\u5c42\u548c\u76ae\u4e0b\u7ed3\u6784\u8fdb\u884c\u914d\u51c6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u7387\u3001\u901f\u5ea6\u548c\u6613\u7528\u6027\u65b9\u9762\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u8111MRI\u914d\u51c6\u65b9\u6cd5\u5c06\u4f53\u7d20\u548c\u8868\u9762\u914d\u51c6\u5206\u5f00\u5904\u7406\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u4e00\u81f4\uff0c\u9650\u5236\u4e86\u540e\u7eed\u5206\u6790\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u8054\u5408\u5bf9\u9f50\u76ae\u5c42\u4e0e\u76ae\u4e0b\u7ed3\u6784\u3001\u4fdd\u6301\u89e3\u5256\u4e00\u81f4\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa NeurAlign \u6846\u67b6\uff0c\u5229\u7528\u4e2d\u95f4\u7403\u9762\u5750\u6807\u7a7a\u95f4\uff0c\u5c06\u89e3\u5256\u8868\u9762\u62d3\u6251\u4e0e\u4f53\u79ef\u89e3\u5256\u7ed3\u6784\u7ed3\u5408\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u6df1\u5ea6\u5b66\u4e60\u5b9e\u73b0\u4f53\u79ef\u4e0e\u8868\u9762\u7684\u4e00\u81f4\u914d\u51c6\uff0c\u5e76\u5728\u8bad\u7ec3\u4e2d\u6574\u5408\u7403\u9762\u914d\u51c6\u4ee5\u4fdd\u8bc1\u51e0\u4f55\u4e00\u81f4\u6027\u3002", "result": "\u5728\u57df\u5185\u548c\u57df\u5916\u6570\u636e\u96c6\u4e0a\uff0cNeurAlign \u5747\u4f18\u4e8e\u4f20\u7edf\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0cDice \u5206\u6570\u6700\u9ad8\u63d0\u53477\u4e2a\u70b9\uff0c\u53d8\u5f62\u573a\u66f4\u89c4\u5219\uff0c\u63a8\u7406\u901f\u5ea6\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e14\u4ec5\u9700\u8f93\u5165MRI\u56fe\u50cf\u5373\u53ef\u4f7f\u7528\u3002", "conclusion": "NeurAlign \u5728\u8054\u5408\u76ae\u5c42\u4e0e\u76ae\u4e0b\u7ed3\u6784\u914d\u51c6\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3001\u66f4\u5feb\u7684\u901f\u5ea6\u548c\u66f4\u7b80\u4fbf\u7684\u4f7f\u7528\u6d41\u7a0b\uff0c\u4e3a\u8111\u5f71\u50cf\u5206\u6790\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002", "summary_cn": "\u51c6\u786e\u914d\u51c6\u8111\u90e8MRI\u626b\u63cf\u662f\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u4e2d\u8de8\u88ab\u8bd5\u5206\u6790\u7684\u57fa\u7840\uff0c\u8fd9\u9700\u8981\u540c\u65f6\u5bf9\u9f50\u5927\u8111\u7684\u76ae\u5c42\u8868\u9762\u548c\u5185\u90e8\u4f53\u79ef\u3002\u4f20\u7edf\u65b9\u6cd5\u5c06\u4f53\u7d20\u914d\u51c6\u548c\u57fa\u4e8e\u8868\u9762\u7684\u914d\u51c6\u5206\u5f00\u5904\u7406\uff0c\u5e38\u5e38\u5bfc\u81f4\u4e0d\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u9650\u5236\u4e86\u540e\u7eed\u5206\u6790\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6 NeurAlign\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u4f53\u79ef-\u8868\u9762\u8868\u793a\uff0c\u5728\u4e09\u7ef4\u8111MRI\u56fe\u50cf\u4e2d\u8054\u5408\u5bf9\u9f50\u76ae\u5c42\u548c\u76ae\u4e0b\u533a\u57df\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e2d\u95f4\u7403\u9762\u5750\u6807\u7a7a\u95f4\uff0c\u5c06\u89e3\u5256\u8868\u9762\u62d3\u6251\u7ed3\u6784\u4e0e\u4f53\u79ef\u89e3\u5256\u4fe1\u606f\u76f8\u8fde\u63a5\uff0c\u4ece\u800c\u5b9e\u73b0\u4e00\u81f4\u4e14\u89e3\u5256\u5b66\u4e0a\u51c6\u786e\u7684\u5bf9\u9f50\u3002\u901a\u8fc7\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6574\u5408\u7403\u9762\u914d\u51c6\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u786e\u4fdd\u4e86\u4f53\u79ef\u57df\u4e0e\u8868\u9762\u57df\u4e4b\u95f4\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u5728\u4e00\u7cfb\u5217\u9488\u5bf9\u57df\u5185\u548c\u57df\u5916\u6570\u636e\u96c6\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u7ecf\u5178\u65b9\u6cd5\u548c\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u914d\u51c6\u65b9\u6cd5\u2014\u2014Dice\u5206\u6570\u6700\u591a\u63d0\u9ad8\u4e867\u4e2a\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u89c4\u5219\u7684\u5f62\u53d8\u573a\u3002\u6b64\u5916\uff0c\u5176\u63a8\u7406\u901f\u5ea6\u6bd4\u5f53\u524d\u6807\u51c6\u65b9\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\uff0c\u5e76\u4e14\u4f7f\u7528\u66f4\u7b80\u4fbf\uff0c\u4ec5\u9700\u8f93\u5165MRI\u626b\u63cf\u56fe\u50cf\u5373\u53ef\u3002\u51ed\u501f\u5176\u5353\u8d8a\u7684\u51c6\u786e\u6027\u3001\u5feb\u901f\u7684\u63a8\u7406\u80fd\u529b\u548c\u6613\u7528\u6027\uff0cNeurAlign \u4e3a\u76ae\u5c42\u4e0e\u76ae\u4e0b\u7ed3\u6784\u8054\u5408\u914d\u51c6\u8bbe\u7acb\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2512.19934", "pdf": "https://arxiv.org/pdf/2512.19934", "abs": "https://arxiv.org/abs/2512.19934", "authors": ["Wentao Wu", "Xiao Wang", "Chenglong Li", "Jin Tang", "Bin Luo"], "title": "Vehicle-centric Perception via Multimodal Structured Pre-training", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Journal extension of VehicleMAE (AAAI 2024)", "summary": "Vehicle-centric perception plays a crucial role in many intelligent systems, including large-scale surveillance systems, intelligent transportation, and autonomous driving. Existing approaches lack effective learning of vehicle-related knowledge during pre-training, resulting in poor capability for modeling general vehicle perception representations. To handle this problem, we propose VehicleMAE-V2, a novel vehicle-centric pre-trained large model. By exploring and exploiting vehicle-related multimodal structured priors to guide the masked token reconstruction process, our approach can significantly enhance the model's capability to learn generalizable representations for vehicle-centric perception. Specifically, we design the Symmetry-guided Mask Module (SMM), Contour-guided Representation Module (CRM) and Semantics-guided Representation Module (SRM) to incorporate three kinds of structured priors into token reconstruction including symmetry, contour and semantics of vehicles respectively. SMM utilizes the vehicle symmetry constraints to avoid retaining symmetric patches and can thus select high-quality masked image patches and reduce information redundancy. CRM minimizes the probability distribution divergence between contour features and reconstructed features and can thus preserve holistic vehicle structure information during pixel-level reconstruction. SRM aligns image-text features through contrastive learning and cross-modal distillation to address the feature confusion caused by insufficient semantic understanding during masked reconstruction. To support the pre-training of VehicleMAE-V2, we construct Autobot4M, a large-scale dataset comprising approximately 4 million vehicle images and 12,693 text descriptions. Extensive experiments on five downstream tasks demonstrate the superior performance of VehicleMAE-V2.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVehicleMAE-V2\uff0c\u4e00\u79cd\u9762\u5411\u8f66\u8f86\u611f\u77e5\u7684\u9884\u8bad\u7ec3\u5927\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u5bf9\u79f0\u6027\u3001\u8f6e\u5ed3\u548c\u8bed\u4e49\u4e09\u79cd\u7ed3\u6784\u5316\u5148\u9a8c\u77e5\u8bc6\u6307\u5bfc\u63a9\u7801\u91cd\u5efa\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u8f66\u8f86\u8868\u5f81\u5b66\u4e60\u80fd\u529b\uff0c\u5e76\u5728\u4e94\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u7f3a\u4e4f\u5bf9\u8f66\u8f86\u76f8\u5173\u77e5\u8bc6\u7684\u6709\u6548\u5b66\u4e60\uff0c\u5bfc\u81f4\u96be\u4ee5\u5efa\u6a21\u901a\u7528\u7684\u8f66\u8f86\u611f\u77e5\u8868\u5f81\u3002", "method": "\u63d0\u51faVehicleMAE-V2\u6a21\u578b\uff0c\u8bbe\u8ba1\u4e09\u4e2a\u6a21\u5757\uff1a\u5bf9\u79f0\u5f15\u5bfc\u63a9\u7801\u6a21\u5757\uff08SMM\uff09\u3001\u8f6e\u5ed3\u5f15\u5bfc\u8868\u5f81\u6a21\u5757\uff08CRM\uff09\u548c\u8bed\u4e49\u5f15\u5bfc\u8868\u5f81\u6a21\u5757\uff08SRM\uff09\uff0c\u5206\u522b\u5229\u7528\u8f66\u8f86\u7684\u5bf9\u79f0\u6027\u3001\u8f6e\u5ed3\u548c\u8bed\u4e49\u7ed3\u6784\u5316\u5148\u9a8c\u6307\u5bfc\u63a9\u7801\u91cd\u5efa\uff1b\u540c\u65f6\u6784\u5efa\u5305\u542b400\u4e07\u8f66\u8f86\u56fe\u50cf\u548c12,693\u6761\u6587\u672c\u63cf\u8ff0\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6Autobot4M\u7528\u4e8e\u9884\u8bad\u7ec3\u3002", "result": "\u5728\u4e94\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660eVehicleMAE-V2\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u878d\u5408\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5148\u9a8c\u77e5\u8bc6\uff0cVehicleMAE-V2\u80fd\u6709\u6548\u63d0\u5347\u8f66\u8f86\u4e2d\u5fc3\u611f\u77e5\u7684\u901a\u7528\u8868\u5f81\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u4e0e\u81ea\u52a8\u9a7e\u9a76\u7b49\u5e94\u7528\u63d0\u4f9b\u6709\u529b\u652f\u6301\u3002", "summary_cn": "\u4ee5\u8f66\u8f86\u4e3a\u4e2d\u5fc3\u7684\u611f\u77e5\u5728\u8bb8\u591a\u667a\u80fd\u7cfb\u7edf\u4e2d\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\uff0c\u5305\u62ec\u5927\u89c4\u6a21\u76d1\u63a7\u7cfb\u7edf\u3001\u667a\u80fd\u4ea4\u901a\u548c\u81ea\u52a8\u9a7e\u9a76\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7f3a\u4e4f\u5bf9\u8f66\u8f86\u76f8\u5173\u77e5\u8bc6\u7684\u6709\u6548\u5b66\u4e60\uff0c\u5bfc\u81f4\u5176\u5efa\u6a21\u901a\u7528\u8f66\u8f86\u611f\u77e5\u8868\u5f81\u7684\u80fd\u529b\u8f83\u5dee\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86VehicleMAE-V2\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u4ee5\u8f66\u8f86\u4e3a\u4e2d\u5fc3\u7684\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u3002\u901a\u8fc7\u63a2\u7d22\u5e76\u5229\u7528\u4e0e\u8f66\u8f86\u76f8\u5173\u7684\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5148\u9a8c\u77e5\u8bc6\u6765\u6307\u5bfc\u63a9\u7801\u6807\u8bb0\u91cd\u5efa\u8fc7\u7a0b\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u589e\u5f3a\u6a21\u578b\u5b66\u4e60\u901a\u7528\u8f66\u8f86\u611f\u77e5\u8868\u5f81\u7684\u80fd\u529b\u3002\u5177\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u5bf9\u79f0\u5f15\u5bfc\u63a9\u7801\u6a21\u5757\uff08SMM\uff09\u3001\u8f6e\u5ed3\u5f15\u5bfc\u8868\u5f81\u6a21\u5757\uff08CRM\uff09\u548c\u8bed\u4e49\u5f15\u5bfc\u8868\u5f81\u6a21\u5757\uff08SRM\uff09\uff0c\u5206\u522b\u5c06\u8f66\u8f86\u7684\u5bf9\u79f0\u6027\u3001\u8f6e\u5ed3\u548c\u8bed\u4e49\u4e09\u7c7b\u7ed3\u6784\u5316\u5148\u9a8c\u878d\u5165\u5230\u6807\u8bb0\u91cd\u5efa\u4e2d\u3002SMM\u5229\u7528\u8f66\u8f86\u5bf9\u79f0\u6027\u7ea6\u675f\u907f\u514d\u4fdd\u7559\u5bf9\u79f0\u56fe\u50cf\u5757\uff0c\u4ece\u800c\u9009\u62e9\u9ad8\u8d28\u91cf\u7684\u63a9\u7801\u56fe\u50cf\u5757\u5e76\u51cf\u5c11\u4fe1\u606f\u5197\u4f59\uff1bCRM\u901a\u8fc7\u6700\u5c0f\u5316\u8f6e\u5ed3\u7279\u5f81\u4e0e\u91cd\u5efa\u7279\u5f81\u4e4b\u95f4\u7684\u6982\u7387\u5206\u5e03\u5dee\u5f02\uff0c\u5728\u50cf\u7d20\u7ea7\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u4fdd\u7559\u5b8c\u6574\u7684\u8f66\u8f86\u7ed3\u6784\u4fe1\u606f\uff1bSRM\u5219\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u8de8\u6a21\u6001\u84b8\u998f\u5bf9\u9f50\u56fe\u6587\u7279\u5f81\uff0c\u4ee5\u7f13\u89e3\u63a9\u7801\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u56e0\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\u5bfc\u81f4\u7684\u7279\u5f81\u6df7\u6dc6\u95ee\u9898\u3002\u4e3a\u652f\u6301VehicleMAE-V2\u7684\u9884\u8bad\u7ec3\uff0c\u6211\u4eec\u6784\u5efa\u4e86Autobot4M\u2014\u2014\u4e00\u4e2a\u5305\u542b\u7ea6400\u4e07\u5f20\u8f66\u8f86\u56fe\u50cf\u548c12,693\u6761\u6587\u672c\u63cf\u8ff0\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002\u5728\u4e94\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86VehicleMAE-V2\u7684\u5353\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.19941", "pdf": "https://arxiv.org/pdf/2512.19941", "abs": "https://arxiv.org/abs/2512.19941", "authors": ["Mozes Jacobs", "Thomas Fel", "Richard Hakim", "Alessandra Brondetta", "Demba Ba", "T. Andy Keller"], "title": "Block-Recurrent Dynamics in Vision Transformers", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "25 pages, 15 figures", "summary": "As Vision Transformers (ViTs) become standard vision backbones, a mechanistic account of their computational phenomenology is essential. Despite architectural cues that hint at dynamical structure, there is no settled framework that interprets Transformer depth as a well-characterized flow. In this work, we introduce the Block-Recurrent Hypothesis (BRH), arguing that trained ViTs admit a block-recurrent depth structure such that the computation of the original $L$ blocks can be accurately rewritten using only $k \\ll L$ distinct blocks applied recurrently. Across diverse ViTs, between-layer representational similarity matrices suggest few contiguous phases. To determine whether these phases reflect genuinely reusable computation, we train block-recurrent surrogates of pretrained ViTs: Recurrent Approximations to Phase-structured TransfORmers (Raptor). In small-scale, we demonstrate that stochastic depth and training promote recurrent structure and subsequently correlate with our ability to accurately fit Raptor. We then provide an empirical existence proof for BRH by training a Raptor model to recover $96\\%$ of DINOv2 ImageNet-1k linear probe accuracy in only 2 blocks at equivalent computational cost. Finally, we leverage our hypothesis to develop a program of Dynamical Interpretability. We find i) directional convergence into class-dependent angular basins with self-correcting trajectories under small perturbations, ii) token-specific dynamics, where cls executes sharp late reorientations while patch tokens exhibit strong late-stage coherence toward their mean direction, and iii) a collapse to low rank updates in late depth, consistent with convergence to low-dimensional attractors. Altogether, we find a compact recurrent program emerges along ViT depth, pointing to a low-complexity normative solution that enables these models to be studied through principled dynamical systems analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u5757\u5faa\u73af\u5047\u8bbe\u201d\uff08BRH\uff09\uff0c\u8ba4\u4e3a\u89c6\u89c9Transformer\uff08ViT\uff09\u7684\u6df1\u5c42\u7ed3\u6784\u53ef\u88ab\u538b\u7f29\u4e3a\u5c11\u91cf\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u6a21\u5757\uff0c\u5e76\u901a\u8fc7\u8bad\u7ec3\u9012\u5f52\u4ee3\u7406\u6a21\u578bRaptor\u9a8c\u8bc1\u8be5\u5047\u8bbe\uff1b\u5b9e\u9a8c\u8868\u660eViT\u5185\u90e8\u5b58\u5728\u4f4e\u590d\u6742\u5ea6\u7684\u52a8\u6001\u7ed3\u6784\uff0c\u652f\u6301\u7528\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u8fdb\u884c\u89e3\u91ca\u3002", "motivation": "\u5f53\u524d\u5bf9Vision Transformer\uff08ViT\uff09\u5185\u90e8\u8ba1\u7b97\u673a\u5236\u7684\u7406\u89e3\u4ecd\u4e0d\u5145\u5206\uff0c\u5c3d\u7ba1\u5176\u67b6\u6784\u6697\u793a\u4e86\u67d0\u79cd\u52a8\u6001\u7ed3\u6784\uff0c\u4f46\u7f3a\u4e4f\u5c06\u6a21\u578b\u6df1\u5ea6\u89e3\u91ca\u4e3a\u660e\u786e\u52a8\u529b\u5b66\u6d41\u7a0b\u7684\u7edf\u4e00\u6846\u67b6\u3002\u4f5c\u8005\u65e8\u5728\u5efa\u7acb\u4e00\u79cd\u53ef\u89e3\u91caViT\u6df1\u5ea6\u8ba1\u7b97\u672c\u8d28\u7684\u65b0\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u201c\u5757\u5faa\u73af\u5047\u8bbe\u201d\uff08BRH\uff09\uff0c\u5373ViT\u4e2dL\u4e2a\u5757\u7684\u8ba1\u7b97\u53ef\u7531k\u226aL\u4e2a\u4e0d\u540c\u5757\u9012\u5f52\u5b9e\u73b0\uff1b\u901a\u8fc7\u5206\u6790\u5c42\u95f4\u8868\u5f81\u76f8\u4f3c\u6027\u8bc6\u522b\u76f8\u4f4d\u7ed3\u6784\uff0c\u5e76\u8bad\u7ec3\u9012\u5f52\u4ee3\u7406\u6a21\u578bRaptor\u6765\u62df\u5408\u9884\u8bad\u7ec3ViT\uff1b\u8fdb\u4e00\u6b65\u5f00\u5c55\u52a8\u529b\u5b66\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u7814\u7a76\u8868\u5f81\u8f68\u8ff9\u3001token\u52a8\u6001\u53ca\u66f4\u65b0\u79e9\u53d8\u5316\u3002", "result": "\u5728\u5c0f\u89c4\u6a21\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u968f\u673a\u6df1\u5ea6\u548c\u8bad\u7ec3\u4fc3\u8fdb\u5faa\u73af\u7ed3\u6784\u5f62\u6210\uff1b\u6210\u529f\u8bad\u7ec3\u4ec5\u542b2\u4e2a\u5757\u7684Raptor\u6a21\u578b\uff0c\u5728\u540c\u7b49\u8ba1\u7b97\u6210\u672c\u4e0b\u6062\u590dDINOv2\u5728ImageNet-1k\u4e0a\u7ebf\u6027\u63a2\u948896%\u7684\u51c6\u786e\u7387\uff1b\u89c2\u5bdf\u5230\u7c7b\u4f9d\u8d56\u7684\u89d2\u76c6\u5730\u6536\u655b\u3001token\u7279\u5f02\u6027\u52a8\u6001\u53ca\u665a\u671f\u4f4e\u79e9\u66f4\u65b0\u7b49\u52a8\u529b\u5b66\u7279\u6027\u3002", "conclusion": "ViT\u7684\u6df1\u5ea6\u8ba1\u7b97\u53ef\u88ab\u7406\u89e3\u4e3a\u4e00\u4e2a\u7d27\u51d1\u7684\u9012\u5f52\u7a0b\u5e8f\uff0c\u4f53\u73b0\u51fa\u4f4e\u590d\u6742\u5ea6\u7684\u89c4\u8303\u89e3\uff0c\u8fd9\u4f7f\u5176\u9002\u5408\u901a\u8fc7\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u8fdb\u884c\u539f\u5219\u6027\u5206\u6790\uff0c\u4e3aTransformer\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002", "summary_cn": "\u968f\u7740\u89c6\u89c9Transformer\uff08ViTs\uff09\u6210\u4e3a\u6807\u51c6\u7684\u89c6\u89c9\u9aa8\u5e72\u7f51\u7edc\uff0c\u5bf9\u5176\u8ba1\u7b97\u73b0\u8c61\u8fdb\u884c\u673a\u5236\u6027\u89e3\u91ca\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u5c3d\u7ba1\u5176\u67b6\u6784\u7ebf\u7d22\u6697\u793a\u4e86\u67d0\u79cd\u52a8\u6001\u7ed3\u6784\uff0c\u4f46\u76ee\u524d\u5c1a\u65e0\u516c\u8ba4\u7684\u6846\u67b6\u80fd\u5c06Transformer\u7684\u6df1\u5ea6\u89e3\u91ca\u4e3a\u4e00\u79cd\u5177\u6709\u826f\u597d\u7279\u5f81\u7684\u52a8\u529b\u5b66\u6d41\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u5757\u5faa\u73af\u5047\u8bbe\u201d\uff08Block-Recurrent Hypothesis, BRH\uff09\uff0c\u8ba4\u4e3a\u7ecf\u8fc7\u8bad\u7ec3\u7684ViT\u5177\u6709\u5757\u5faa\u73af\u7684\u6df1\u5ea6\u7ed3\u6784\uff0c\u5373\u539f\u59cbL\u4e2a\u5757\u7684\u8ba1\u7b97\u53ef\u4ee5\u88ab\u7cbe\u786e\u5730\u91cd\u5199\u4e3a\u4ec5\u4f7f\u7528k\u226aL\u4e2a\u4e0d\u540c\u5757\u7684\u9012\u5f52\u5e94\u7528\u3002\u5728\u591a\u79cdViT\u6a21\u578b\u4e2d\uff0c\u5c42\u95f4\u8868\u5f81\u76f8\u4f3c\u6027\u77e9\u9635\u663e\u793a\u51fa\u5c11\u6570\u8fde\u7eed\u7684\u9636\u6bb5\u3002\u4e3a\u4e86\u5224\u65ad\u8fd9\u4e9b\u9636\u6bb5\u662f\u5426\u53cd\u6620\u4e86\u771f\u6b63\u53ef\u590d\u7528\u7684\u8ba1\u7b97\uff0c\u6211\u4eec\u8bad\u7ec3\u4e86\u9884\u8bad\u7ec3ViT\u7684\u5757\u5faa\u73af\u4ee3\u7406\u6a21\u578b\uff1aRaptor\uff08Recurrent Approximations to Phase-structured TransfORmers\uff09\u3002\u5728\u5c0f\u89c4\u6a21\u5b9e\u9a8c\u4e2d\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u968f\u673a\u6df1\u5ea6\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4fc3\u8fdb\u4e86\u5faa\u73af\u7ed3\u6784\u7684\u5f62\u6210\uff0c\u5e76\u4e0e\u6211\u4eec\u51c6\u786e\u62df\u5408Raptor\u7684\u80fd\u529b\u76f8\u5173\u3002\u968f\u540e\uff0c\u6211\u4eec\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u4ec5\u542b2\u4e2a\u5757\u7684Raptor\u6a21\u578b\uff0c\u5728\u540c\u7b49\u8ba1\u7b97\u6210\u672c\u4e0b\u6062\u590d\u4e86DINOv2\u5728ImageNet-1k\u4e0a\u7ebf\u6027\u63a2\u948896%\u7684\u51c6\u786e\u7387\uff0c\u4ece\u800c\u4e3aBRH\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u6027\u7684\u5b58\u5728\u6027\u8bc1\u660e\u3002\u6700\u540e\uff0c\u6211\u4eec\u5229\u7528\u8be5\u5047\u8bbe\u5f00\u5c55\u4e86\u4e00\u9879\u201c\u52a8\u529b\u5b66\u53ef\u89e3\u91ca\u6027\u201d\u7814\u7a76\u8ba1\u5212\uff0c\u53d1\u73b0\uff1a(i) \u8868\u5f81\u6cbf\u65b9\u5411\u6536\u655b\u81f3\u7c7b\u522b\u4f9d\u8d56\u7684\u89d2\u76c6\u5730\uff0c\u4e14\u5728\u5fae\u5c0f\u6270\u52a8\u4e0b\u5177\u6709\u81ea\u6821\u6b63\u8f68\u8ff9\uff1b(ii) token\u7279\u5f02\u6027\u52a8\u6001\uff0c\u5176\u4e2dcls token\u5728\u540e\u671f\u6267\u884c\u6025\u5267\u7684\u65b9\u5411\u91cd\u5b9a\u5411\uff0c\u800cpatch tokens\u5728\u540e\u671f\u8868\u73b0\u51fa\u671d\u5411\u5176\u5747\u503c\u65b9\u5411\u7684\u5f3a\u4e00\u81f4\u6027\uff1b(iii) \u5728\u6df1\u5ea6\u540e\u671f\uff0c\u66f4\u65b0\u574d\u7f29\u4e3a\u4f4e\u79e9\uff0c\u7b26\u5408\u5411\u4f4e\u7ef4\u5438\u5f15\u5b50\u6536\u655b\u7684\u7279\u5f81\u3002\u603b\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u53d1\u73b0ViT\u6df1\u5ea6\u4e2d\u6d8c\u73b0\u51fa\u4e00\u4e2a\u7d27\u51d1\u7684\u9012\u5f52\u7a0b\u5e8f\uff0c\u6307\u5411\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u89c4\u8303\u89e3\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u57fa\u4e8e\u539f\u7406\u7684\u52a8\u529b\u7cfb\u7edf\u5206\u6790\u65b9\u6cd5\u52a0\u4ee5\u7814\u7a76\u3002"}}
{"id": "2512.19943", "pdf": "https://arxiv.org/pdf/2512.19943", "abs": "https://arxiv.org/abs/2512.19943", "authors": ["Haoyi Zhong", "Fang-Lue Zhang", "Andrew Chalmers", "Taehyun Rhee"], "title": "SE360: Semantic Edit in 360$^\\circ$ Panoramas via Hierarchical Data Construction", "categories": ["cs.CV"], "comment": null, "summary": "While instruction-based image editing is emerging, extending it to 360$^\\circ$ panoramas introduces additional challenges. Existing methods often produce implausible results in both equirectangular projections (ERP) and perspective views. To address these limitations, we propose SE360, a novel framework for multi-condition guided object editing in 360$^\\circ$ panoramas. At its core is a novel coarse-to-fine autonomous data generation pipeline without manual intervention. This pipeline leverages a Vision-Language Model (VLM) and adaptive projection adjustment for hierarchical analysis, ensuring the holistic segmentation of objects and their physical context. The resulting data pairs are both semantically meaningful and geometrically consistent, even when sourced from unlabeled panoramas. Furthermore, we introduce a cost-effective, two-stage data refinement strategy to improve data realism and mitigate model overfitting to erase artifacts. Based on the constructed dataset, we train a Transformer-based diffusion model to allow flexible object editing guided by text, mask, or reference image in 360$^\\circ$ panoramas. Our experiments demonstrate that our method outperforms existing methods in both visual quality and semantic accuracy.", "AI": {"tldr": "\u63d0\u51faSE360\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u6570\u636e\u751f\u6210\u548c\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u3001\u8bed\u4e49\u51c6\u786e\u7684360\u5ea6\u5168\u666f\u56fe\u50cf\u591a\u6761\u4ef6\u5f15\u5bfc\u5bf9\u8c61\u7f16\u8f91\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6307\u4ee4\u7684360\u5ea6\u5168\u666f\u56fe\u50cf\u7f16\u8f91\u65b9\u6cd5\u5728\u7b49\u8ddd\u67f1\u72b6\u6295\u5f71\uff08ERP\uff09\u548c\u900f\u89c6\u89c6\u56fe\u4e2d\u5e38\u4ea7\u751f\u4e0d\u5408\u7406\u7ed3\u679c\uff0c\u7f3a\u4e4f\u8bed\u4e49\u610f\u4e49\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u3002", "method": "\u6784\u5efa\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u7c97\u5230\u7cbe\u81ea\u4e3b\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u4e0e\u81ea\u9002\u5e94\u6295\u5f71\u8c03\u6574\u8fdb\u884c\u5206\u5c42\u5206\u6790\uff1b\u91c7\u7528\u4f4e\u6210\u672c\u4e24\u9636\u6bb5\u6570\u636e\u4f18\u5316\u7b56\u7565\u63d0\u5347\u771f\u5b9e\u611f\u5e76\u51cf\u5c11\u64e6\u9664\u4f2a\u5f71\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u8bad\u7ec3\u57fa\u4e8eTransformer\u7684\u6269\u6563\u6a21\u578b\uff0c\u652f\u6301\u6587\u672c\u3001\u63a9\u7801\u6216\u53c2\u8003\u56fe\u50cf\u5f15\u5bfc\u7684\u7f16\u8f91\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u8bed\u4e49\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SE360\u6709\u6548\u89e3\u51b3\u4e86360\u5ea6\u5168\u666f\u56fe\u50cf\u7f16\u8f91\u4e2d\u7684\u8bed\u4e49\u4e0e\u51e0\u4f55\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u4e3a\u591a\u6761\u4ef6\u5f15\u5bfc\u7f16\u8f91\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\u3002", "summary_cn": "\u5c3d\u7ba1\u57fa\u4e8e\u6307\u4ee4\u7684\u56fe\u50cf\u7f16\u8f91\u6b63\u5728\u5174\u8d77\uff0c\u4f46\u5c06\u5176\u6269\u5c55\u5230360\u5ea6\u5168\u666f\u56fe\u50cf\u4f1a\u5e26\u6765\u989d\u5916\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u7b49\u8ddd\u67f1\u72b6\u6295\u5f71\uff08ERP\uff09\u548c\u900f\u89c6\u89c6\u56fe\u4e2d\u5e38\u5e38\u4ea7\u751f\u4e0d\u5408\u7406\u7684\u7ed3\u679c\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e86SE360\u2014\u2014\u4e00\u79cd\u7528\u4e8e360\u5ea6\u5168\u666f\u56fe\u50cf\u4e2d\u591a\u6761\u4ef6\u5f15\u5bfc\u5bf9\u8c61\u7f16\u8f91\u7684\u65b0\u6846\u67b6\u3002\u5176\u6838\u5fc3\u662f\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u7531\u7c97\u5230\u7cbe\u7684\u81ea\u4e3b\u6570\u636e\u751f\u6210\u6d41\u7a0b\u3002\u8be5\u6d41\u7a0b\u5229\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u548c\u81ea\u9002\u5e94\u6295\u5f71\u8c03\u6574\u8fdb\u884c\u5206\u5c42\u5206\u6790\uff0c\u786e\u4fdd\u5bf9\u8c61\u53ca\u5176\u7269\u7406\u4e0a\u4e0b\u6587\u7684\u6574\u4f53\u5206\u5272\u3002\u6240\u751f\u6210\u7684\u6570\u636e\u5bf9\u5373\u4f7f\u6765\u81ea\u672a\u6807\u6ce8\u7684\u5168\u666f\u56fe\u50cf\uff0c\u4e5f\u517c\u5177\u8bed\u4e49\u610f\u4e49\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u4e24\u9636\u6bb5\u6570\u636e\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u6570\u636e\u771f\u5b9e\u611f\u5e76\u51cf\u8f7b\u6a21\u578b\u5bf9\u64e6\u9664\u4f2a\u5f71\u7684\u8fc7\u62df\u5408\u3002\u57fa\u4e8e\u6240\u6784\u5efa\u7684\u6570\u636e\u96c6\uff0c\u6211\u4eec\u8bad\u7ec3\u4e86\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u6269\u6563\u6a21\u578b\uff0c\u652f\u6301\u5728360\u5ea6\u5168\u666f\u56fe\u50cf\u4e2d\u901a\u8fc7\u6587\u672c\u3001\u63a9\u7801\u6216\u53c2\u8003\u56fe\u50cf\u8fdb\u884c\u7075\u6d3b\u7684\u5bf9\u8c61\u7f16\u8f91\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u8bed\u4e49\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
