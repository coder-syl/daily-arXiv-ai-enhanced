{"id": "2601.22164", "pdf": "https://arxiv.org/pdf/2601.22164", "abs": "https://arxiv.org/abs/2601.22164", "authors": ["Christos Tsourveloudis"], "title": "Do Open-Vocabulary Detectors Transfer to Aerial Imagery? A Comparative Evaluation", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Open-vocabulary object detection (OVD) enables zero-shot recognition of novel categories through vision-language models, achieving strong performance on natural images. However, transferability to aerial imagery remains unexplored. We present the first systematic benchmark evaluating five state-of-the-art OVD models on the LAE-80C aerial dataset (3,592 images, 80 categories) under strict zero-shot conditions. Our experimental protocol isolates semantic confusion from visual localization through Global, Oracle, and Single-Category inference modes. Results reveal severe domain transfer failure: the best model (OWLv2) achieves only 27.6% F1-score with 69% false positive rate. Critically, reducing vocabulary size from 80 to 3.2 classes yields 15x improvement, demonstrating that semantic confusion is the primary bottleneck. Prompt engineering strategies such as domain-specific prefixing and synonym expansion, fail to provide meaningful performance gains. Performance varies dramatically across datasets (F1: 0.53 on DIOR, 0.12 on FAIR1M), exposing brittleness to imaging conditions. These findings establish baseline expectations and highlight the need for domain-adaptive approaches in aerial OVD.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u68c0\u6d4b\uff08OVD\uff09\u6a21\u578b\u5728\u822a\u62cd\u56fe\u50cf\u4e0a\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5728\u822a\u62cd\u573a\u666f\u4e2d\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\uff0c\u4e3b\u8981\u74f6\u9888\u662f\u8bed\u4e49\u6df7\u6dc6\u800c\u975e\u89c6\u89c9\u5b9a\u4f4d\u3002", "motivation": "\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u68c0\u6d4b\uff08OVD\uff09\u5728\u81ea\u7136\u56fe\u50cf\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u5728\u822a\u62cd\u56fe\u50cf\u4e2d\u7684\u53ef\u8fc1\u79fb\u6027\u5c1a\u672a\u88ab\u7814\u7a76\u3002\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5f53\u524d\u5148\u8fdbOVD\u6a21\u578b\u5728\u822a\u62cd\u6570\u636e\u4e0a\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5e76\u8bc6\u522b\u5176\u5931\u8d25\u539f\u56e0\u3002", "method": "\u4f5c\u8005\u5728LAE-80C\u822a\u62cd\u6570\u636e\u96c6\uff083,592\u5f20\u56fe\u50cf\uff0c80\u4e2a\u7c7b\u522b\uff09\u4e0a\uff0c\u5bf9\u4e94\u4e2a\u6700\u5148\u8fdb\u7684OVD\u6a21\u578b\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u3002\u901a\u8fc7Global\u3001Oracle\u548cSingle-Category\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\uff0c\u5c06\u8bed\u4e49\u6df7\u6dc6\u4e0e\u89c6\u89c9\u5b9a\u4f4d\u95ee\u9898\u89e3\u8026\u3002\u6b64\u5916\uff0c\u8fd8\u6d4b\u8bd5\u4e86\u63d0\u793a\u5de5\u7a0b\uff08\u5982\u9886\u57df\u524d\u7f00\u3001\u540c\u4e49\u8bcd\u6269\u5c55\uff09\u7b49\u7b56\u7565\uff0c\u5e76\u5728DIOR\u548cFAIR1M\u7b49\u4e0d\u540c\u822a\u62cd\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cOVD\u6a21\u578b\u5728\u822a\u62cd\u56fe\u50cf\u4e0a\u5b58\u5728\u4e25\u91cd\u7684\u9886\u57df\u8fc1\u79fb\u5931\u8d25\uff1a\u6700\u4f73\u6a21\u578bOWLv2\u7684F1\u5206\u6570\u4ec5\u4e3a27.6%\uff0c\u4e14\u5047\u9633\u6027\u7387\u9ad8\u8fbe69%\u3002\u5c06\u8bcd\u6c47\u91cf\u4ece80\u7c7b\u51cf\u5c11\u52303.2\u7c7b\u53ef\u4f7f\u6027\u80fd\u63d0\u534715\u500d\uff0c\u8bc1\u660e\u8bed\u4e49\u6df7\u6dc6\u662f\u4e3b\u8981\u74f6\u9888\u3002\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u672a\u80fd\u5e26\u6765\u663e\u8457\u6539\u8fdb\uff0c\u4e14\u6a21\u578b\u5728\u4e0d\u540c\u822a\u62cd\u6570\u636e\u96c6\uff08DIOR F1: 0.53 vs FAIR1M F1: 0.12\uff09\u4e0a\u8868\u73b0\u5dee\u5f02\u5de8\u5927\uff0c\u663e\u793a\u51fa\u5bf9\u6210\u50cf\u6761\u4ef6\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u822a\u62cd\u56fe\u50cf\u4e2d\u7684\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u68c0\u6d4b\u5efa\u7acb\u4e86\u9996\u4e2a\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u4e25\u91cd\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u5f00\u53d1\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002", "summary_cn": "\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u68c0\u6d4b\uff08OVD\uff09\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4e86\u5bf9\u65b0\u7c7b\u522b\u7684\u96f6\u6837\u672c\u8bc6\u522b\uff0c\u5728\u81ea\u7136\u56fe\u50cf\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\u3002\u7136\u800c\uff0c\u5176\u5728\u822a\u62cd\u56fe\u50cf\u4e0a\u7684\u53ef\u8fc1\u79fb\u6027\u4ecd\u672a\u88ab\u63a2\u7d22\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u9996\u4e2a\u7cfb\u7edf\u6027\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cd\u6700\u5148\u8fdb\u7684OVD\u6a21\u578b\u5728LAE-80C\u822a\u62cd\u6570\u636e\u96c6\uff083,592\u5f20\u56fe\u50cf\uff0c80\u4e2a\u7c7b\u522b\uff09\u4e0a\u7684\u4e25\u683c\u96f6\u6837\u672c\u6027\u80fd\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u65b9\u6848\u901a\u8fc7\u5168\u5c40\uff08Global\uff09\u3001\u795e\u8c15\uff08Oracle\uff09\u548c\u5355\u7c7b\u522b\uff08Single-Category\uff09\u4e09\u79cd\u63a8\u7406\u6a21\u5f0f\uff0c\u5c06\u8bed\u4e49\u6df7\u6dc6\u4e0e\u89c6\u89c9\u5b9a\u4f4d\u95ee\u9898\u5206\u79bb\u5f00\u6765\u3002\u7ed3\u679c\u63ed\u793a\u4e86\u4e25\u91cd\u7684\u9886\u57df\u8fc1\u79fb\u5931\u8d25\uff1a\u6700\u4f73\u6a21\u578b\uff08OWLv2\uff09\u4ec5\u8fbe\u523027.6%\u7684F1\u5206\u6570\uff0c\u4e14\u5047\u9633\u6027\u7387\u9ad8\u8fbe69%\u3002\u5173\u952e\u7684\u662f\uff0c\u5c06\u8bcd\u6c47\u91cf\u4ece80\u7c7b\u51cf\u5c11\u52303.2\u7c7b\u53ef\u5e26\u676515\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8868\u660e\u8bed\u4e49\u6df7\u6dc6\u662f\u4e3b\u8981\u74f6\u9888\u3002\u8bf8\u5982\u9886\u57df\u7279\u5b9a\u524d\u7f00\u548c\u540c\u4e49\u8bcd\u6269\u5c55\u7b49\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u672a\u80fd\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u6027\u80fd\u589e\u76ca\u3002\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u5de8\u5927\uff08DIOR\u4e0aF1\u4e3a0.53\uff0cFAIR1M\u4e0a\u4e3a0.12\uff09\uff0c\u66b4\u9732\u4e86\u5176\u5bf9\u6210\u50cf\u6761\u4ef6\u7684\u8106\u5f31\u6027\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u822a\u62cdOVD\u8bbe\u5b9a\u4e86\u57fa\u7ebf\u9884\u671f\uff0c\u5e76\u7a81\u663e\u4e86\u5f00\u53d1\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.22218", "pdf": "https://arxiv.org/pdf/2601.22218", "abs": "https://arxiv.org/abs/2601.22218", "authors": ["Jill P. Naiman", "Daniel J. Evans", "JooYoung Seo"], "title": "What Lies Beneath: A Call for Distribution-based Visual Question & Answer Datasets", "categories": ["cs.CV", "cs.DL"], "comment": "Accepted to ACM/IEEE Joint Conference on Digital Libraries JCDL 2025, 4 pages, 2 figures", "summary": "Visual Question Answering (VQA) has become an important benchmark for assessing how large multimodal models (LMMs) interpret images. However, most VQA datasets focus on real-world images or simple diagrammatic analysis, with few focused on interpreting complex scientific charts. Indeed, many VQA datasets that analyze charts do not contain the underlying data behind those charts or assume a 1-to-1 correspondence between chart marks and underlying data. In reality, charts are transformations (i.e. analysis, simplification, modification) of data. This distinction introduces a reasoning challenge in VQA that the current datasets do not capture. In this paper, we argue for a dedicated VQA benchmark for scientific charts where there is no 1-to-1 correspondence between chart marks and underlying data. To do so, we survey existing VQA datasets and highlight limitations of the current field. We then generate synthetic histogram charts based on ground truth data, and ask both humans and a large reasoning model questions where precise answers depend on access to the underlying data. We release the open-source dataset, including figures, underlying data, distribution parameters used to generate the data, and bounding boxes for all figure marks and text for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u79d1\u5b66\u56fe\u8868\u7684\u65b0\u578bVQA\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5f3a\u8c03\u56fe\u8868\u4e0e\u5176\u5e95\u5c42\u6570\u636e\u4e4b\u95f4\u5e76\u975e\u4e00\u4e00\u5bf9\u5e94\uff0c\u8981\u6c42\u6a21\u578b\u5177\u5907\u66f4\u6df1\u5c42\u6b21\u7684\u6570\u636e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709VQA\u6570\u636e\u96c6\u591a\u5173\u6ce8\u771f\u5b9e\u56fe\u50cf\u6216\u7b80\u5355\u56fe\u8868\uff0c\u7f3a\u4e4f\u9488\u5bf9\u590d\u6742\u79d1\u5b66\u56fe\u8868\u7684\u7406\u89e3\uff0c\u4e14\u901a\u5e38\u5047\u8bbe\u56fe\u8868\u6807\u8bb0\u4e0e\u5e95\u5c42\u6570\u636e\u4e00\u4e00\u5bf9\u5e94\uff0c\u5ffd\u7565\u4e86\u56fe\u8868\u662f\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u6790\u3001\u7b80\u5316\u6216\u53d8\u6362\u540e\u7684\u4ea7\u7269\uff0c\u65e0\u6cd5\u8bc4\u4f30\u6a21\u578b\u5bf9\u8fd9\u79cd\u975e\u76f4\u63a5\u6620\u5c04\u5173\u7cfb\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u9996\u5148\u8c03\u7814\u73b0\u6709VQA\u6570\u636e\u96c6\u5e76\u6307\u51fa\u5176\u5c40\u9650\u6027\uff1b\u7136\u540e\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u751f\u6210\u5408\u6210\u7684\u76f4\u65b9\u56fe\uff0c\u5e76\u8bbe\u8ba1\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u7684\u7cbe\u786e\u7b54\u6848\u4f9d\u8d56\u4e8e\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u8bbf\u95ee\uff1b\u6700\u540e\u53d1\u5e03\u4e00\u4e2a\u5305\u542b\u56fe\u8868\u3001\u5e95\u5c42\u6570\u636e\u3001\u751f\u6210\u6570\u636e\u7684\u5206\u5e03\u53c2\u6570\u4ee5\u53ca\u6240\u6709\u56fe\u8868\u6807\u8bb0\u548c\u6587\u672c\u7684\u8fb9\u754c\u6846\u7684\u5f00\u6e90\u6570\u636e\u96c6\u3002", "result": "\u6210\u529f\u6784\u5efa\u5e76\u5f00\u6e90\u4e86\u4e00\u4e2a\u65b0\u7684VQA\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u5904\u7406\u56fe\u8868\u4e0e\u5e95\u5c42\u6570\u636e\u975e\u4e00\u4e00\u5bf9\u5e94\u60c5\u51b5\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u4e3a\u79d1\u5b66\u56fe\u8868\u7406\u89e3\u5efa\u7acb\u4e13\u95e8\u7684VQA\u57fa\u51c6\u662f\u5fc5\u8981\u7684\uff0c\u65b0\u6570\u636e\u96c6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u4ee5\u63a8\u52a8\u5927\u6a21\u578b\u5728\u590d\u6742\u6570\u636e\u53ef\u89c6\u5316\u63a8\u7406\u65b9\u9762\u7684\u53d1\u5c55\u3002", "summary_cn": "\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u5df2\u6210\u4e3a\u8bc4\u4f30\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5982\u4f55\u89e3\u8bfb\u56fe\u50cf\u7684\u91cd\u8981\u57fa\u51c6\u3002\u7136\u800c\uff0c\u5927\u591a\u6570VQA\u6570\u636e\u96c6\u805a\u7126\u4e8e\u73b0\u5b9e\u4e16\u754c\u56fe\u50cf\u6216\u7b80\u5355\u7684\u56fe\u8868\u5206\u6790\uff0c\u5f88\u5c11\u6709\u7814\u7a76\u4e13\u6ce8\u4e8e\u89e3\u8bfb\u590d\u6742\u7684\u79d1\u5b66\u56fe\u8868\u3002\u4e8b\u5b9e\u4e0a\uff0c\u8bb8\u591a\u7528\u4e8e\u5206\u6790\u56fe\u8868\u7684VQA\u6570\u636e\u96c6\u8981\u4e48\u4e0d\u5305\u542b\u8fd9\u4e9b\u56fe\u8868\u80cc\u540e\u7684\u5e95\u5c42\u6570\u636e\uff0c\u8981\u4e48\u5047\u8bbe\u56fe\u8868\u6807\u8bb0\u4e0e\u5e95\u5c42\u6570\u636e\u4e4b\u95f4\u5b58\u5728\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\u3002\u800c\u5b9e\u9645\u4e0a\uff0c\u56fe\u8868\u662f\u5bf9\u6570\u636e\u8fdb\u884c\u53d8\u6362\uff08\u5373\u5206\u6790\u3001\u7b80\u5316\u3001\u4fee\u6539\uff09\u540e\u7684\u4ea7\u7269\u3002\u8fd9\u79cd\u533a\u522b\u5728VQA\u4e2d\u5f15\u5165\u4e86\u4e00\u79cd\u5f53\u524d\u6570\u636e\u96c6\u672a\u80fd\u6355\u6349\u5230\u7684\u63a8\u7406\u6311\u6218\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4e3b\u5f20\u4e3a\u79d1\u5b66\u56fe\u8868\u5efa\u7acb\u4e00\u4e2a\u4e13\u95e8\u7684VQA\u57fa\u51c6\uff0c\u5176\u4e2d\u56fe\u8868\u6807\u8bb0\u4e0e\u5e95\u5c42\u6570\u636e\u4e4b\u95f4\u4e0d\u5b58\u5728\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u8c03\u7814\u4e86\u73b0\u6709\u7684VQA\u6570\u636e\u96c6\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u9886\u57df\u7684\u5c40\u9650\u6027\u3002\u63a5\u7740\uff0c\u6211\u4eec\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u751f\u6210\u5408\u6210\u7684\u76f4\u65b9\u56fe\uff0c\u5e76\u5411\u4eba\u7c7b\u548c\u4e00\u4e2a\u5927\u578b\u63a8\u7406\u6a21\u578b\u63d0\u51fa\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u7684\u7cbe\u786e\u7b54\u6848\u4f9d\u8d56\u4e8e\u5bf9\u5e95\u5c42\u6570\u636e\u7684\u8bbf\u95ee\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u8be5\u5f00\u6e90\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u62ec\u56fe\u8868\u3001\u5e95\u5c42\u6570\u636e\u3001\u7528\u4e8e\u751f\u6210\u6570\u636e\u7684\u5206\u5e03\u53c2\u6570\uff0c\u4ee5\u53ca\u6240\u6709\u56fe\u8868\u6807\u8bb0\u548c\u6587\u672c\u7684\u8fb9\u754c\u6846\uff0c\u4ee5\u4f9b\u672a\u6765\u7814\u7a76\u4f7f\u7528\u3002"}}
{"id": "2601.22228", "pdf": "https://arxiv.org/pdf/2601.22228", "abs": "https://arxiv.org/abs/2601.22228", "authors": ["Ken Deng", "Yifu Qiu", "Yoni Kasten", "Shay B. Cohen", "Yftah Ziser"], "title": "Lost in Space? Vision-Language Models Struggle with Relative Camera Pose Estimation", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Vision-Language Models (VLMs) perform well in 2D perception and semantic reasoning compared to their limited understanding of 3D spatial structure. We investigate this gap using relative camera pose estimation (RCPE), a fundamental vision task that requires inferring relative camera translation and rotation from a pair of images. We introduce VRRPI-Bench, a benchmark derived from unlabeled egocentric videos with verbalized annotations of relative camera motion, reflecting realistic scenarios with simultaneous translation and rotation around a shared object. We further propose VRRPI-Diag, a diagnostic benchmark that isolates individual motion degrees of freedom. Despite the simplicity of RCPE, most VLMs fail to generalize beyond shallow 2D heuristics, particularly for depth changes and roll transformations along the optical axis. Even state-of-the-art models such as GPT-5 ($0.64$) fall short of classic geometric baselines ($0.97$) and human performance ($0.92$). Moreover, VLMs exhibit difficulty in multi-image reasoning, with inconsistent performance (best $59.7\\%$) when integrating spatial cues across frames. Our findings reveal limitations in grounding VLMs in 3D and multi-view spatial reasoning.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u57283D\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u901a\u8fc7\u76f8\u5bf9\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\uff08RCPE\uff09\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u5148\u8fdb\u6a21\u578b\u4e5f\u8fdc\u900a\u4e8e\u7ecf\u5178\u51e0\u4f55\u65b9\u6cd5\u548c\u4eba\u7c7b\u8868\u73b0\u3002", "motivation": "\u63a2\u7d22VLMs\u57282D\u611f\u77e5\u548c\u8bed\u4e49\u63a8\u7406\u4e0a\u7684\u4f18\u52bf\u4e0e\u5176\u57283D\u7a7a\u95f4\u7ed3\u6784\u7406\u89e3\u4e0a\u7684\u5c40\u9650\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u6784\u5efa\u4e24\u4e2a\u57fa\u51c6\uff1aVRRPI-Bench\uff08\u57fa\u4e8e\u771f\u5b9e\u573a\u666f\u7684\u65e0\u6807\u7b7e\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u4e0e\u53e3\u5934\u63cf\u8ff0\uff09\u548cVRRPI-Diag\uff08\u9694\u79bb\u5355\u4e00\u8fd0\u52a8\u81ea\u7531\u5ea6\u7684\u8bca\u65ad\u6027\u57fa\u51c6\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30VLMs\u5728\u76f8\u5bf9\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5927\u591a\u6570VLMs\u65e0\u6cd5\u8d85\u8d8a\u6d45\u5c422D\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6df1\u5ea6\u53d8\u5316\u548c\u7ed5\u5149\u8f74\u65cb\u8f6c\uff08roll\uff09\u65b9\u9762\u8868\u73b0\u5dee\uff1bGPT-5\u5f97\u5206\u4ec50.64\uff0c\u8fdc\u4f4e\u4e8e\u7ecf\u5178\u51e0\u4f55\u57fa\u7ebf\uff080.97\uff09\u548c\u4eba\u7c7b\uff080.92\uff09\uff1b\u591a\u56fe\u50cf\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u5f31\uff0c\u8de8\u5e27\u6574\u5408\u7ebf\u7d22\u65f6\u8868\u73b0\u4e0d\u4e00\u81f4\uff08\u6700\u9ad8\u4ec559.7%\uff09\u3002", "conclusion": "\u5f53\u524dVLMs\u57283D\u7a7a\u95f4\u7406\u89e3\u548c\u591a\u89c6\u89d2\u63a8\u7406\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u4e09\u7ef4\u51e0\u4f55\u5173\u7cfb\u3002", "summary_cn": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u57282D\u611f\u77e5\u548c\u8bed\u4e49\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u7406\u89e33D\u7a7a\u95f4\u7ed3\u6784\u65b9\u9762\u4ecd\u663e\u4e0d\u8db3\u3002\u672c\u6587\u901a\u8fc7\u76f8\u5bf9\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\uff08RCPE\uff09\u8fd9\u4e00\u57fa\u7840\u89c6\u89c9\u4efb\u52a1\u6765\u63a2\u7a76\u8fd9\u4e00\u5dee\u8ddd\uff0c\u8be5\u4efb\u52a1\u8981\u6c42\u4ece\u4e00\u5bf9\u56fe\u50cf\u4e2d\u63a8\u65ad\u76f8\u5bf9\u76f8\u673a\u7684\u5e73\u79fb\u548c\u65cb\u8f6c\u3002\u6211\u4eec\u63d0\u51fa\u4e86VRRPI-Bench\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u6e90\u81ea\u5e26\u6709\u76f8\u5bf9\u76f8\u673a\u8fd0\u52a8\u53e3\u5934\u6807\u6ce8\u7684\u65e0\u6807\u7b7e\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\uff0c\u53cd\u6620\u4e86\u56f4\u7ed5\u5171\u4eab\u7269\u4f53\u540c\u65f6\u53d1\u751f\u5e73\u79fb\u548c\u65cb\u8f6c\u7684\u771f\u5b9e\u573a\u666f\u3002\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86VRRPI-Diag\u8bca\u65ad\u6027\u57fa\u51c6\uff0c\u7528\u4e8e\u9694\u79bb\u5404\u4e2a\u8fd0\u52a8\u81ea\u7531\u5ea6\u3002\u5c3d\u7ba1RCPE\u4efb\u52a1\u770b\u4f3c\u7b80\u5355\uff0c\u4f46\u5927\u591a\u6570VLMs\u4ecd\u65e0\u6cd5\u8d85\u8d8a\u6d45\u5c42\u76842D\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6df1\u5ea6\u53d8\u5316\u548c\u7ed5\u5149\u8f74\u7684\u6eda\u8f6c\uff08roll\uff09\u53d8\u6362\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u5373\u4fbf\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5982GPT-5\uff08\u5f97\u52060.64\uff09\u4e5f\u8fdc\u900a\u4e8e\u7ecf\u5178\u51e0\u4f55\u57fa\u7ebf\uff080.97\uff09\u548c\u4eba\u7c7b\u8868\u73b0\uff080.92\uff09\u3002\u6b64\u5916\uff0cVLMs\u5728\u591a\u56fe\u50cf\u63a8\u7406\u65b9\u9762\u4e5f\u5b58\u5728\u56f0\u96be\uff0c\u5728\u8de8\u5e27\u6574\u5408\u7a7a\u95f4\u7ebf\u7d22\u65f6\u8868\u73b0\u4e0d\u4e00\u81f4\uff08\u6700\u4f73\u4ec5\u4e3a59.7%\uff09\u3002\u6211\u4eec\u7684\u7814\u7a76\u63ed\u793a\u4e86VLMs\u57283D\u7a7a\u95f4\u548c\u591a\u89c6\u89d2\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.22231", "pdf": "https://arxiv.org/pdf/2601.22231", "abs": "https://arxiv.org/abs/2601.22231", "authors": ["Jian Shi", "Michael Birsak", "Wenqing Cui", "Zhenyu Li", "Peter Wonka"], "title": "Geometry without Position? When Positional Embeddings Help and Hurt Spatial Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "This paper revisits the role of positional embeddings (PEs) within vision transformers (ViTs) from a geometric perspective. We show that PEs are not mere token indices but effectively function as geometric priors that shape the spatial structure of the representation. We introduce token-level diagnostics that measure how multi-view geometric consistency in ViT representation depends on consitent PEs. Through extensive experiments on 14 foundation ViT models, we reveal how PEs influence multi-view geometry and spatial reasoning. Our findings clarify the role of PEs as a causal mechanism that governs spatial structure in ViT representations. Our code is provided in https://github.com/shijianjian/vit-geometry-probes", "AI": {"tldr": "\u672c\u6587\u4ece\u51e0\u4f55\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u4e86\u89c6\u89c9Transformer\uff08ViT\uff09\u4e2d\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\u7684\u4f5c\u7528\uff0c\u53d1\u73b0PE\u4e0d\u4ec5\u662f\u6807\u8bb0\u7d22\u5f15\uff0c\u66f4\u662f\u5851\u9020\u8868\u5f81\u7a7a\u95f4\u7ed3\u6784\u7684\u51e0\u4f55\u5148\u9a8c\uff0c\u5e76\u901a\u8fc7\u591a\u89c6\u56fe\u4e00\u81f4\u6027\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5bf9\u7a7a\u95f4\u63a8\u7406\u7684\u5173\u952e\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9ViT\u4e2d\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\u7684\u4f5c\u7528\u7406\u89e3\u4e0d\u8db3\uff0c\u901a\u5e38\u5c06\u5176\u89c6\u4e3a\u7b80\u5355\u7684\u6807\u8bb0\u7d22\u5f15\u3002\u672c\u6587\u65e8\u5728\u4ece\u51e0\u4f55\u89d2\u5ea6\u6df1\u5165\u63a2\u7a76PE\u5728\u6784\u5efaViT\u8868\u5f81\u7a7a\u95f4\u7ed3\u6784\u4e2d\u7684\u771f\u5b9e\u4f5c\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdtoken-level\u7684\u8bca\u65ad\u65b9\u6cd5\uff0c\u7528\u4e8e\u8861\u91cfViT\u8868\u5f81\u4e2d\u7684\u591a\u89c6\u56fe\u51e0\u4f55\u4e00\u81f4\u6027\u5982\u4f55\u4f9d\u8d56\u4e8e\u4e00\u81f4\u7684\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\uff0c\u5e76\u572814\u4e2a\u57fa\u7840ViT\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\u5bf9ViT\u8868\u5f81\u4e2d\u591a\u89c6\u56fe\u51e0\u4f55\u548c\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u5177\u6709\u663e\u8457\u5f71\u54cd\uff0c\u8bc1\u660ePE\u662f\u63a7\u5236\u7a7a\u95f4\u7ed3\u6784\u7684\u56e0\u679c\u673a\u5236\u3002", "conclusion": "\u4f4d\u7f6e\u7f16\u7801\uff08PE\uff09\u5728ViT\u4e2d\u626e\u6f14\u7740\u51e0\u4f55\u5148\u9a8c\u7684\u89d2\u8272\uff0c\u662f\u51b3\u5b9a\u8868\u5f81\u7a7a\u95f4\u7ed3\u6784\u7684\u5173\u952e\u56e0\u679c\u56e0\u7d20\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u6807\u8bb0\u7684\u7d22\u5f15\u3002", "summary_cn": "\u672c\u6587\u4ece\u51e0\u4f55\u89c6\u89d2\u91cd\u65b0\u5ba1\u89c6\u4e86\u89c6\u89c9Transformer\uff08ViTs\uff09\u4e2d\u4f4d\u7f6e\u7f16\u7801\uff08PEs\uff09\u7684\u4f5c\u7528\u3002\u6211\u4eec\u8868\u660e\uff0cPEs\u5e76\u975e\u4ec5\u4ec5\u662f\u6807\u8bb0\u7d22\u5f15\uff0c\u800c\u662f\u6709\u6548\u5730\u4f5c\u4e3a\u7a7a\u95f4\u7ed3\u6784\u7684\u51e0\u4f55\u5148\u9a8c\uff0c\u5851\u9020\u4e86\u8868\u5f81\u7684\u7a7a\u95f4\u7ed3\u6784\u3002\u6211\u4eec\u5f15\u5165\u4e86token\u7ea7\u522b\u7684\u8bca\u65ad\u65b9\u6cd5\uff0c\u7528\u4e8e\u8861\u91cfViT\u8868\u5f81\u4e2d\u7684\u591a\u89c6\u56fe\u51e0\u4f55\u4e00\u81f4\u6027\u5982\u4f55\u4f9d\u8d56\u4e8e\u4e00\u81f4\u7684PEs\u3002\u901a\u8fc7\u5bf914\u4e2a\u57fa\u7840ViT\u6a21\u578b\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u6211\u4eec\u63ed\u793a\u4e86PEs\u5982\u4f55\u5f71\u54cd\u591a\u89c6\u56fe\u51e0\u4f55\u548c\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u9610\u660e\u4e86PEs\u4f5c\u4e3a\u63a7\u5236ViT\u8868\u5f81\u4e2d\u7a7a\u95f4\u7ed3\u6784\u7684\u56e0\u679c\u673a\u5236\u6240\u626e\u6f14\u7684\u89d2\u8272\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\uff1ahttps://github.com/shijianjian/vit-geometry-probes"}}
{"id": "2601.22244", "pdf": "https://arxiv.org/pdf/2601.22244", "abs": "https://arxiv.org/abs/2601.22244", "authors": ["Shirin Reyhanian", "Laurenz Wiskott"], "title": "Is Hierarchical Quantization Essential for Optimal Reconstruction?", "categories": ["cs.CV", "cs.LG"], "comment": "To appear in the Proceedings of ICPRAM 2026. Code available at : https://github.com/wiskott-lab/single-vs-hier-recon", "summary": "Vector-quantized variational autoencoders (VQ-VAEs) are central to models that rely on high reconstruction fidelity, from neural compression to generative pipelines. Hierarchical extensions, such as VQ-VAE2, are often credited with superior reconstruction performance because they split global and local features across multiple levels. However, since higher levels derive all their information from lower levels, they should not carry additional reconstructive content beyond what the lower-level already encodes. Combined with recent advances in training objectives and quantization mechanisms, this leads us to ask whether a single-level VQ-VAE, with matched representational budget and no codebook collapse, can equal the reconstruction fidelity of its hierarchical counterpart. Although the multi-scale structure of hierarchical models may improve perceptual quality in downstream tasks, the effect of hierarchy on reconstruction accuracy, isolated from codebook utilization and overall representational capacity, remains empirically underexamined. We revisit this question by comparing a two-level VQ-VAE and a capacity-matched single-level model on high-resolution ImageNet images. Consistent with prior observations, we confirm that inadequate codebook utilization limits single-level VQ-VAEs and that overly high-dimensional embeddings destabilize quantization and increase codebook collapse. We show that lightweight interventions such as initialization from data, periodic reset of inactive codebook vectors, and systematic tuning of codebook hyperparameters significantly reduce collapse. Our results demonstrate that when representational budgets are matched, and codebook collapse is mitigated, single-level VQ-VAEs can match the reconstruction fidelity of hierarchical variants, challenging the assumption that hierarchical quantization is inherently superior for high-quality reconstructions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8868\u660e\uff0c\u5728\u5339\u914d\u8868\u5f81\u5bb9\u91cf\u5e76\u7f13\u89e3\u7801\u672c\u574d\u584c\u7684\u524d\u63d0\u4e0b\uff0c\u5355\u5c42VQ-VAE\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5206\u5c42VQ-VAE\u76f8\u5f53\u7684\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u6311\u6218\u4e86\u201c\u5206\u5c42\u7ed3\u6784\u5728\u91cd\u5efa\u8d28\u91cf\u4e0a\u5fc5\u7136\u66f4\u4f18\u201d\u7684\u666e\u904d\u5047\u8bbe\u3002", "motivation": "\u8d28\u7591\u5206\u5c42VQ-VAE\uff08\u5982VQ-VAE2\uff09\u5728\u91cd\u5efa\u4fdd\u771f\u5ea6\u4e0a\u4f18\u4e8e\u5355\u5c42\u6a21\u578b\u7684\u6839\u672c\u539f\u56e0\uff0c\u63a2\u7a76\u5176\u4f18\u52bf\u662f\u5426\u771f\u6b63\u6e90\u4e8e\u5206\u5c42\u7ed3\u6784\u672c\u8eab\uff0c\u8fd8\u662f\u7531\u7801\u672c\u5229\u7528\u4e0d\u8db3\u548c\u8868\u5f81\u5bb9\u91cf\u5dee\u5f02\u7b49\u5176\u4ed6\u56e0\u7d20\u5bfc\u81f4\u3002", "method": "\u5728\u9ad8\u5206\u8fa8\u7387ImageNet\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u6bd4\u4e00\u4e2a\u4e24\u5c42\u7684\u5206\u5c42VQ-VAE\u548c\u4e00\u4e2a\u8868\u5f81\u5bb9\u91cf\u76f8\u5339\u914d\u7684\u5355\u5c42VQ-VAE\u3002\u901a\u8fc7\u91c7\u7528\u8f7b\u91cf\u7ea7\u5e72\u9884\u63aa\u65bd\uff08\u5982\u4ece\u6570\u636e\u521d\u59cb\u5316\u3001\u5b9a\u671f\u91cd\u7f6e\u4e0d\u6d3b\u8dc3\u7801\u672c\u5411\u91cf\u3001\u7cfb\u7edf\u6027\u8c03\u6574\u8d85\u53c2\u6570\uff09\u6765\u7f13\u89e3\u5355\u5c42\u6a21\u578b\u4e2d\u7684\u7801\u672c\u574d\u584c\u95ee\u9898\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u8868\u5f81\u9884\u7b97\u5339\u914d\u4e14\u6709\u6548\u7f13\u89e3\u7801\u672c\u574d\u584c\u540e\uff0c\u5355\u5c42VQ-VAE\u7684\u91cd\u5efa\u4fdd\u771f\u5ea6\u53ef\u4ee5\u4e0e\u5206\u5c42\u53d8\u4f53\u76f8\u5ab2\u7f8e\u3002\u540c\u65f6\u9a8c\u8bc1\u4e86\u7801\u672c\u5229\u7528\u4e0d\u8db3\u548c\u5d4c\u5165\u7ef4\u5ea6\u592a\u9ad8\u662f\u5bfc\u81f4\u5355\u5c42\u6a21\u578b\u6027\u80fd\u4e0d\u4f73\u7684\u5173\u952e\u539f\u56e0\u3002", "conclusion": "\u5206\u5c42\u91cf\u5316\u7ed3\u6784\u5bf9\u4e8e\u5b9e\u73b0\u9ad8\u4fdd\u771f\u91cd\u5efa\u5e76\u975e\u4e0d\u53ef\u6216\u7f3a\u3002\u5355\u5c42VQ-VAE\u5728\u9002\u5f53\u7684\u8bbe\u8ba1\u548c\u8bad\u7ec3\u4e0b\uff0c\u8db3\u4ee5\u8fbe\u5230\u4e0e\u590d\u6742\u5206\u5c42\u6a21\u578b\u76f8\u5f53\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u8fd9\u4e3a\u7b80\u5316\u6a21\u578b\u67b6\u6784\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "summary_cn": "\u77e2\u91cf\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VQ-VAE\uff09\u662f\u4f9d\u8d56\u9ad8\u91cd\u5efa\u4fdd\u771f\u5ea6\u6a21\u578b\u7684\u6838\u5fc3\uff0c\u4ece\u795e\u7ecf\u538b\u7f29\u5230\u751f\u6210\u6d41\u6c34\u7ebf\u7686\u662f\u5982\u6b64\u3002\u5176\u5206\u5c42\u6269\u5c55\u7248\u672c\uff08\u5982VQ-VAE2\uff09\u5e38\u88ab\u8ba4\u4e3a\u5177\u6709\u66f4\u4f18\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u56e0\u4e3a\u5b83\u5c06\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u5206\u5e03\u5728\u591a\u4e2a\u5c42\u7ea7\u4e0a\u3002\u7136\u800c\uff0c\u7531\u4e8e\u9ad8\u5c42\u7ea7\u7684\u6240\u6709\u4fe1\u606f\u90fd\u6e90\u81ea\u4f4e\u5c42\u7ea7\uff0c\u56e0\u6b64\u5176\u4e0d\u5e94\u5305\u542b\u8d85\u51fa\u4f4e\u5c42\u7ea7\u5df2\u7f16\u7801\u5185\u5bb9\u7684\u989d\u5916\u91cd\u5efa\u4fe1\u606f\u3002\u7ed3\u5408\u8fd1\u671f\u5728\u8bad\u7ec3\u76ee\u6807\u548c\u91cf\u5316\u673a\u5236\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u6211\u4eec\u63d0\u51fa\u7591\u95ee\uff1a\u4e00\u4e2a\u5177\u6709\u5339\u914d\u8868\u5f81\u9884\u7b97\u4e14\u65e0\u7801\u672c\u574d\u584c\u7684\u5355\u5c42\u7ea7VQ-VAE\uff0c\u80fd\u5426\u8fbe\u5230\u4e0e\u5176\u5206\u5c42\u5bf9\u5e94\u7269\u76f8\u5f53\u7684\u91cd\u5efa\u4fdd\u771f\u5ea6\uff1f\u5c3d\u7ba1\u5206\u5c42\u6a21\u578b\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784\u53ef\u80fd\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u7684\u611f\u77e5\u8d28\u91cf\uff0c\u4f46\u5206\u5c42\u7ed3\u6784\u672c\u8eab\u5bf9\u91cd\u5efa\u7cbe\u5ea6\u7684\u5f71\u54cd\uff08\u5728\u6392\u9664\u7801\u672c\u5229\u7528\u7387\u548c\u603b\u4f53\u8868\u5f81\u5bb9\u91cf\u7b49\u56e0\u7d20\u540e\uff09\u4ecd\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\u3002\u6211\u4eec\u901a\u8fc7\u5728\u9ad8\u5206\u8fa8\u7387ImageNet\u56fe\u50cf\u4e0a\u6bd4\u8f83\u4e00\u4e2a\u4e24\u5c42\u7ea7VQ-VAE\u548c\u4e00\u4e2a\u5bb9\u91cf\u5339\u914d\u7684\u5355\u5c42\u7ea7\u6a21\u578b\u6765\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u95ee\u9898\u3002\u4e0e\u5148\u524d\u89c2\u5bdf\u4e00\u81f4\uff0c\u6211\u4eec\u786e\u8ba4\u4e86\u7801\u672c\u5229\u7528\u4e0d\u8db3\u4f1a\u9650\u5236\u5355\u5c42\u7ea7VQ-VAE\u7684\u6027\u80fd\uff0c\u800c\u8fc7\u9ad8\u7684\u5d4c\u5165\u7ef4\u5ea6\u4f1a\u4f7f\u91cf\u5316\u4e0d\u7a33\u5b9a\u5e76\u52a0\u5267\u7801\u672c\u574d\u584c\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u8bf8\u5982\u4ece\u6570\u636e\u521d\u59cb\u5316\u3001\u5b9a\u671f\u91cd\u7f6e\u4e0d\u6d3b\u8dc3\u7684\u7801\u672c\u5411\u91cf\u4ee5\u53ca\u7cfb\u7edf\u6027\u5730\u8c03\u6574\u7801\u672c\u8d85\u53c2\u6570\u7b49\u8f7b\u91cf\u7ea7\u5e72\u9884\u63aa\u65bd\u80fd\u663e\u8457\u51cf\u5c11\u574d\u584c\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u8868\u5f81\u9884\u7b97\u5339\u914d\u4e14\u7801\u672c\u574d\u584c\u5f97\u5230\u7f13\u89e3\u65f6\uff0c\u5355\u5c42\u7ea7VQ-VAE\u53ef\u4ee5\u5339\u654c\u5206\u5c42\u53d8\u4f53\u7684\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u4ece\u800c\u6311\u6218\u4e86\u201c\u5206\u5c42\u91cf\u5316\u5728\u9ad8\u8d28\u91cf\u91cd\u5efa\u4e0a\u5177\u6709\u5185\u5728\u4f18\u8d8a\u6027\u201d\u7684\u5047\u8bbe\u3002"}}
{"id": "2601.22275", "pdf": "https://arxiv.org/pdf/2601.22275", "abs": "https://arxiv.org/abs/2601.22275", "authors": ["Cheng Liang", "Haoxian Chen", "Liang Hou", "Qi Fan", "Gangshan Wu", "Xin Tao", "Limin Wang"], "title": "VMonarch: Efficient Video Diffusion Transformers with Structured Attention", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The quadratic complexity of the attention mechanism severely limits the context scalability of Video Diffusion Transformers (DiTs). We find that the highly sparse spatio-temporal attention patterns exhibited in Video DiTs can be naturally represented by the Monarch matrix. It is a class of structured matrices with flexible sparsity, enabling sub-quadratic attention via an alternating minimization algorithm. Accordingly, we propose VMonarch, a novel attention mechanism for Video DiTs that enables efficient computation over the dynamic sparse patterns with structured Monarch matrices. First, we adapt spatio-temporal Monarch factorization to explicitly capture the intra-frame and inter-frame correlations of the video data. Second, we introduce a recomputation strategy to mitigate artifacts arising from instabilities during alternating minimization of Monarch matrices. Third, we propose a novel online entropy algorithm fused into FlashAttention, enabling fast Monarch matrix updates for long sequences. Extensive experiments demonstrate that VMonarch achieves comparable or superior generation quality to full attention on VBench after minimal tuning. It overcomes the attention bottleneck in Video DiTs, reduces attention FLOPs by a factor of 17.5, and achieves a speedup of over 5x in attention computation for long videos, surpassing state-of-the-art sparse attention methods at 90% sparsity.", "AI": {"tldr": "VMonarch \u662f\u4e00\u79cd\u57fa\u4e8e Monarch \u77e9\u9635\u7684\u65b0\u578b\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7a00\u758f\u6027\u663e\u8457\u964d\u4f4e Video DiT \u4e2d\u6ce8\u610f\u529b\u8ba1\u7b97\u7684\u590d\u6742\u5ea6\uff0c\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u8d85\u8fc7 5 \u500d\u7684\u52a0\u901f\u548c 17.5 \u500d\u7684 FLOPs \u51cf\u5c11\u3002", "motivation": "\u89c6\u9891\u6269\u6563 Transformer\uff08Video DiTs\uff09\u4e2d\u7684\u6ce8\u610f\u529b\u673a\u5236\u5177\u6709\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5904\u7406\u957f\u89c6\u9891\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u3002\u4f5c\u8005\u89c2\u5bdf\u5230\u89c6\u9891 DiTs \u4e2d\u5b58\u5728\u9ad8\u5ea6\u7a00\u758f\u7684\u65f6\u7a7a\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u8fd9\u542f\u53d1\u4ed6\u4eec\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa VMonarch \u65b9\u6cd5\uff1a1\uff09\u91c7\u7528\u65f6\u7a7a Monarch \u5206\u89e3\u4ee5\u663e\u5f0f\u5efa\u6a21\u5e27\u5185\u4e0e\u5e27\u95f4\u76f8\u5173\u6027\uff1b2\uff09\u5f15\u5165\u91cd\u8ba1\u7b97\u7b56\u7565\u7f13\u89e3\u4ea4\u66ff\u6700\u5c0f\u5316\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\uff1b3\uff09\u8bbe\u8ba1\u4e00\u79cd\u878d\u5408\u5230 FlashAttention \u4e2d\u7684\u5728\u7ebf\u71b5\u7b97\u6cd5\uff0c\u7528\u4e8e\u5feb\u901f\u66f4\u65b0\u957f\u5e8f\u5217\u7684 Monarch \u77e9\u9635\u3002", "result": "\u5728 VBench \u4e0a\u4ec5\u9700\u5c11\u91cf\u8c03\u4f18\uff0cVMonarch \u5373\u53ef\u8fbe\u5230\u4e0e\u5168\u6ce8\u610f\u529b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u751f\u6210\u8d28\u91cf\uff1b\u76f8\u6bd4\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u5728 90% \u7a00\u758f\u5ea6\u4e0b\u5b9e\u73b0\u8d85\u8fc7 5 \u500d\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u52a0\u901f\u548c 17.5 \u500d\u7684 FLOPs \u964d\u4f4e\u3002", "conclusion": "VMonarch \u6210\u529f\u514b\u670d\u4e86 Video DiTs \u4e2d\u7684\u6ce8\u610f\u529b\u74f6\u9888\uff0c\u4e3a\u9ad8\u6548\u957f\u89c6\u9891\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u5e76\u5728\u6548\u7387\u4e0e\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u4f18\u5f02\u5e73\u8861\u3002", "summary_cn": "\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\u4e25\u91cd\u9650\u5236\u4e86\u89c6\u9891\u6269\u6563 Transformer\uff08Video DiTs\uff09\u7684\u4e0a\u4e0b\u6587\u53ef\u6269\u5c55\u6027\u3002\u6211\u4eec\u53d1\u73b0\uff0cVideo DiTs \u4e2d\u8868\u73b0\u51fa\u7684\u9ad8\u5ea6\u7a00\u758f\u7684\u65f6\u7a7a\u6ce8\u610f\u529b\u6a21\u5f0f\u53ef\u4ee5\u81ea\u7136\u5730\u7528 Monarch \u77e9\u9635\u8868\u793a\u3002Monarch \u77e9\u9635\u662f\u4e00\u7c7b\u5177\u6709\u7075\u6d3b\u7a00\u758f\u6027\u7684\u7ed3\u6784\u5316\u77e9\u9635\uff0c\u53ef\u901a\u8fc7\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\u5b9e\u73b0\u6b21\u4e8c\u6b21\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 VMonarch\u2014\u2014\u4e00\u79cd\u7528\u4e8e Video DiTs \u7684\u65b0\u578b\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5229\u7528\u7ed3\u6784\u5316\u7684 Monarch \u77e9\u9635\u5728\u52a8\u6001\u7a00\u758f\u6a21\u5f0f\u4e0a\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002\u9996\u5148\uff0c\u6211\u4eec\u5bf9\u65f6\u7a7a Monarch \u5206\u89e3\u8fdb\u884c\u9002\u914d\uff0c\u4ee5\u663e\u5f0f\u6355\u6349\u89c6\u9891\u6570\u636e\u7684\u5e27\u5185\u548c\u5e27\u95f4\u76f8\u5173\u6027\uff1b\u5176\u6b21\uff0c\u5f15\u5165\u4e00\u79cd\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u4ee5\u7f13\u89e3 Monarch \u77e9\u9635\u4ea4\u66ff\u6700\u5c0f\u5316\u8fc7\u7a0b\u4e2d\u56e0\u4e0d\u7a33\u5b9a\u6027\u800c\u4ea7\u751f\u7684\u4f2a\u5f71\uff1b\u7b2c\u4e09\uff0c\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5728\u7ebf\u71b5\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u878d\u5408\u5230 FlashAttention \u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u957f\u5e8f\u5217\u7684\u5feb\u901f Monarch \u77e9\u9635\u66f4\u65b0\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cVMonarch \u5728 VBench \u4e0a\u7ecf\u8fc7\u5c11\u91cf\u8c03\u4f18\u540e\uff0c\u5373\u53ef\u8fbe\u5230\u4e0e\u5168\u6ce8\u610f\u529b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u751f\u6210\u8d28\u91cf\u3002\u5b83\u514b\u670d\u4e86 Video DiTs \u4e2d\u7684\u6ce8\u610f\u529b\u74f6\u9888\uff0c\u5c06\u6ce8\u610f\u529b\u8ba1\u7b97\u7684 FLOPs \u964d\u4f4e\u4e86 17.5 \u500d\uff0c\u5e76\u5728\u957f\u89c6\u9891\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc7 5 \u500d\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u52a0\u901f\uff0c\u5728 90% \u7a00\u758f\u5ea6\u4e0b\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u3002"}}
{"id": "2601.22301", "pdf": "https://arxiv.org/pdf/2601.22301", "abs": "https://arxiv.org/abs/2601.22301", "authors": ["Gonzalo Gomez-Nogales", "Yicong Hong", "Chongjian Ge", "Marc Comino-Trinidad", "Dan Casas", "Yi Zhou"], "title": "Coarse-to-Real: Generative Rendering for Populated Dynamic Scenes", "categories": ["cs.CV"], "comment": "Project website at https://gonzalognogales.github.io/coarse2real/", "summary": "Traditional rendering pipelines rely on complex assets, accurate materials and lighting, and substantial computational resources to produce realistic imagery, yet they still face challenges in scalability and realism for populated dynamic scenes. We present C2R (Coarse-to-Real), a generative rendering framework that synthesizes real-style urban crowd videos from coarse 3D simulations. Our approach uses coarse 3D renderings to explicitly control scene layout, camera motion, and human trajectories, while a learned neural renderer generates realistic appearance, lighting, and fine-scale dynamics guided by text prompts. To overcome the lack of paired training data between coarse simulations and real videos, we adopt a two-phase mixed CG-real training strategy that learns a strong generative prior from large-scale real footage and introduces controllability through shared implicit spatio-temporal features across domains. The resulting system supports coarse-to-fine control, generalizes across diverse CG and game inputs, and produces temporally consistent, controllable, and realistic urban scene videos from minimal 3D input. We will release the model and project webpage at https://gonzalognogales.github.io/coarse2real/.", "AI": {"tldr": "C2R \u662f\u4e00\u4e2a\u4ece\u7c97\u75653D\u6a21\u62df\u751f\u6210\u903c\u771f\u57ce\u5e02\u4eba\u7fa4\u89c6\u9891\u7684\u751f\u6210\u5f0f\u6e32\u67d3\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u672c\u63d0\u793a\u4e0e\u795e\u7ecf\u6e32\u67d3\uff0c\u5728\u7f3a\u4e4f\u914d\u5bf9\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u53ef\u63a7\u3001\u4e00\u81f4\u4e14\u771f\u5b9e\u7684\u89c6\u9891\u5408\u6210\u3002", "motivation": "\u4f20\u7edf\u6e32\u67d3\u6d41\u7a0b\u5728\u751f\u6210\u5927\u89c4\u6a21\u52a8\u6001\u4eba\u7fa4\u573a\u666f\u65f6\u9762\u4e34\u53ef\u6269\u5c55\u6027\u4e0e\u771f\u5b9e\u611f\u7684\u6311\u6218\uff0c\u4e14\u4f9d\u8d56\u590d\u6742\u8d44\u4ea7\u3001\u7cbe\u786e\u6750\u8d28\u5149\u7167\u548c\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002\u4f5c\u8005\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u4ec5\u9700\u7b80\u53553D\u8f93\u5165\u5373\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u63a7\u4e14\u903c\u771f\u57ce\u5e02\u4eba\u7fa4\u89c6\u9891\u7684\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa C2R\uff08Coarse-to-Real\uff09\u6846\u67b6\uff1a\u5229\u7528\u7c97\u75653D\u6e32\u67d3\u63a7\u5236\u573a\u666f\u5e03\u5c40\u3001\u6444\u50cf\u673a\u8fd0\u52a8\u548c\u4eba\u7269\u8f68\u8ff9\uff0c\u901a\u8fc7\u6587\u672c\u5f15\u5bfc\u7684\u795e\u7ecf\u6e32\u67d3\u5668\u751f\u6210\u903c\u771f\u7684\u5916\u89c2\u3001\u5149\u7167\u548c\u7ec6\u8282\u52a8\u6001\uff1b\u91c7\u7528\u4e24\u9636\u6bb5\u6df7\u5408CG-\u771f\u5b9e\u8bad\u7ec3\u7b56\u7565\uff0c\u4ece\u5927\u89c4\u6a21\u771f\u5b9e\u89c6\u9891\u4e2d\u5b66\u4e60\u751f\u6210\u5148\u9a8c\uff0c\u5e76\u901a\u8fc7\u8de8\u57df\u5171\u4eab\u7684\u9690\u5f0f\u65f6\u7a7a\u7279\u5f81\u5f15\u5165\u53ef\u63a7\u6027\u3002", "result": "\u8be5\u7cfb\u7edf\u652f\u6301\u4ece\u6781\u7b803D\u8f93\u5165\u751f\u6210\u65f6\u95f4\u4e00\u81f4\u3001\u53ef\u63a7\u4e14\u903c\u771f\u7684\u57ce\u5e02\u573a\u666f\u89c6\u9891\uff0c\u80fd\u6cdb\u5316\u5230\u591a\u79cdCG\u548c\u6e38\u620f\u8f93\u5165\uff0c\u5e76\u5b9e\u73b0\u4ece\u7c97\u5230\u7ec6\u7684\u63a7\u5236\u3002", "conclusion": "C2R \u6709\u6548\u5f25\u5408\u4e86\u7c97\u7565\u6a21\u62df\u4e0e\u771f\u5b9e\u89c6\u9891\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u5728\u65e0\u9700\u914d\u5bf9\u6570\u636e\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u63a7\u7684\u751f\u6210\u5f0f\u6e32\u67d3\uff0c\u4e3a\u52a8\u6001\u4eba\u7fa4\u573a\u666f\u7684\u9ad8\u6548\u521b\u4f5c\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002", "summary_cn": "\u4f20\u7edf\u7684\u6e32\u67d3\u7ba1\u7ebf\u4f9d\u8d56\u590d\u6742\u7684\u8d44\u4ea7\u3001\u7cbe\u786e\u7684\u6750\u8d28\u4e0e\u5149\u7167\u4ee5\u53ca\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u6765\u751f\u6210\u903c\u771f\u56fe\u50cf\uff0c\u4f46\u5728\u5904\u7406\u5305\u542b\u5927\u91cf\u52a8\u6001\u4eba\u7269\u7684\u573a\u666f\u65f6\uff0c\u4ecd\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u771f\u5b9e\u611f\u65b9\u9762\u7684\u6311\u6218\u3002\u6211\u4eec\u63d0\u51fa\u4e86 C2R\uff08Coarse-to-Real\uff09\uff0c\u4e00\u79cd\u751f\u6210\u5f0f\u6e32\u67d3\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u7c97\u7565\u76843D\u6a21\u62df\u4e2d\u5408\u6210\u5177\u6709\u771f\u5b9e\u98ce\u683c\u7684\u57ce\u5e02\u4eba\u7fa4\u89c6\u9891\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u5229\u7528\u7c97\u7565\u76843D\u6e32\u67d3\u663e\u5f0f\u63a7\u5236\u573a\u666f\u5e03\u5c40\u3001\u6444\u50cf\u673a\u8fd0\u52a8\u548c\u4eba\u7269\u8f68\u8ff9\uff0c\u540c\u65f6\u901a\u8fc7\u4e00\u4e2a\u7531\u6587\u672c\u63d0\u793a\u5f15\u5bfc\u7684\u795e\u7ecf\u6e32\u67d3\u5668\u751f\u6210\u903c\u771f\u7684\u5916\u89c2\u3001\u5149\u7167\u548c\u7ec6\u7c92\u5ea6\u52a8\u6001\u6548\u679c\u3002\u4e3a\u514b\u670d\u7c97\u7565\u6a21\u62df\u4e0e\u771f\u5b9e\u89c6\u9891\u4e4b\u95f4\u7f3a\u4e4f\u914d\u5bf9\u8bad\u7ec3\u6570\u636e\u7684\u95ee\u9898\uff0c\u6211\u4eec\u91c7\u7528\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\u6df7\u5408CG-\u771f\u5b9e\u8bad\u7ec3\u7b56\u7565\uff1a\u9996\u5148\u4ece\u5927\u89c4\u6a21\u771f\u5b9e\u89c6\u9891\u4e2d\u5b66\u4e60\u5f3a\u5927\u7684\u751f\u6210\u5148\u9a8c\uff0c\u518d\u901a\u8fc7\u8de8\u57df\u5171\u4eab\u7684\u9690\u5f0f\u65f6\u7a7a\u7279\u5f81\u5f15\u5165\u53ef\u63a7\u6027\u3002\u6240\u6784\u5efa\u7684\u7cfb\u7edf\u652f\u6301\u4ece\u7c97\u5230\u7ec6\u7684\u63a7\u5236\uff0c\u80fd\u591f\u6cdb\u5316\u81f3\u591a\u79cdCG\u548c\u6e38\u620f\u8f93\u5165\uff0c\u5e76\u4ec5\u9700\u6781\u5c11\u76843D\u8f93\u5165\u5373\u53ef\u751f\u6210\u65f6\u95f4\u4e00\u81f4\u3001\u53ef\u63a7\u4e14\u903c\u771f\u7684\u57ce\u5e02\u573a\u666f\u89c6\u9891\u3002\u6211\u4eec\u5c06\u5728 https://gonzalognogales.github.io/coarse2real/ \u53d1\u5e03\u6a21\u578b\u548c\u9879\u76ee\u7f51\u9875\u3002"}}
{"id": "2601.22376", "pdf": "https://arxiv.org/pdf/2601.22376", "abs": "https://arxiv.org/abs/2601.22376", "authors": ["Run Wang", "Chaoyi Zhou", "Amir Salarpour", "Xi Liu", "Zhi-Qi Cheng", "Feng Luo", "Mert D. Pes\u00e9", "Siyu Huang"], "title": "FlexMap: Generalized HD Map Construction from Flexible Camera Configurations", "categories": ["cs.CV"], "comment": null, "summary": "High-definition (HD) maps provide essential semantic information of road structures for autonomous driving systems, yet current HD map construction methods require calibrated multi-camera setups and either implicit or explicit 2D-to-BEV transformations, making them fragile when sensors fail or camera configurations vary across vehicle fleets. We introduce FlexMap, unlike prior methods that are fixed to a specific N-camera rig, our approach adapts to variable camera configurations without any architectural changes or per-configuration retraining. Our key innovation eliminates explicit geometric projections by using a geometry-aware foundation model with cross-frame attention to implicitly encode 3D scene understanding in feature space. FlexMap features two core components: a spatial-temporal enhancement module that separates cross-view spatial reasoning from temporal dynamics, and a camera-aware decoder with latent camera tokens, enabling view-adaptive attention without the need for projection matrices. Experiments demonstrate that FlexMap outperforms existing methods across multiple configurations while maintaining robustness to missing views and sensor variations, enabling more practical real-world deployment.", "AI": {"tldr": "FlexMap \u662f\u4e00\u79cd\u65b0\u578b\u9ad8\u7cbe\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\uff0c\u65e0\u9700\u56fa\u5b9a\u76f8\u673a\u914d\u7f6e\u6216\u663e\u5f0f\u51e0\u4f55\u6295\u5f71\uff0c\u80fd\u9002\u5e94\u4e0d\u540c\u6444\u50cf\u5934\u8bbe\u7f6e\u5e76\u4fdd\u6301\u5bf9\u4f20\u611f\u5668\u7f3a\u5931\u548c\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u9ad8\u7cbe\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u6821\u51c6\u7684\u591a\u6444\u50cf\u5934\u7cfb\u7edf\u548c2D\u5230\u9e1f\u77b0\u56fe\uff08BEV\uff09\u7684\u8f6c\u6362\uff0c\u5728\u4f20\u611f\u5668\u5931\u6548\u6216\u8f66\u8f86\u95f4\u6444\u50cf\u5934\u914d\u7f6e\u4e0d\u4e00\u81f4\u65f6\u8868\u73b0\u8106\u5f31\uff0c\u96be\u4ee5\u5728\u5b9e\u9645\u4e2d\u90e8\u7f72\u3002", "method": "\u63d0\u51fa FlexMap \u65b9\u6cd5\uff0c\u5229\u7528\u5177\u6709\u8de8\u5e27\u6ce8\u610f\u529b\u673a\u5236\u7684\u51e0\u4f55\u611f\u77e5\u57fa\u7840\u6a21\u578b\uff0c\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u9690\u5f0f\u7f16\u7801\u4e09\u7ef4\u573a\u666f\u7406\u89e3\uff0c\u907f\u514d\u663e\u5f0f\u51e0\u4f55\u6295\u5f71\uff1b\u5305\u542b\u65f6\u7a7a\u589e\u5f3a\u6a21\u5757\u548c\u5e26\u6f5c\u5728\u76f8\u673a\u6807\u8bb0\u7684\u76f8\u673a\u611f\u77e5\u89e3\u7801\u5668\uff0c\u5b9e\u73b0\u65e0\u9700\u6295\u5f71\u77e9\u9635\u7684\u89c6\u56fe\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFlexMap \u5728\u591a\u79cd\u6444\u50cf\u5934\u914d\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5bf9\u7f3a\u5931\u89c6\u89d2\u548c\u4f20\u611f\u5668\u53d8\u5316\u5177\u6709\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "FlexMap \u4e3a\u9ad8\u7cbe\u5730\u56fe\u6784\u5efa\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u5b9e\u7528\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u4e2d\u591a\u6837\u5316\u7684\u8f66\u8f7d\u4f20\u611f\u5668\u914d\u7f6e\u3002", "summary_cn": "\u9ad8\u7cbe\uff08HD\uff09\u5730\u56fe\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9053\u8def\u7ed3\u6784\u7684\u5173\u952e\u8bed\u4e49\u4fe1\u606f\uff0c\u4f46\u5f53\u524d\u7684\u9ad8\u7cbe\u5730\u56fe\u6784\u5efa\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u7ecf\u8fc7\u6807\u5b9a\u7684\u591a\u6444\u50cf\u5934\u7cfb\u7edf\uff0c\u5e76\u91c7\u7528\u9690\u5f0f\u6216\u663e\u5f0f\u76842D\u5230\u9e1f\u77b0\u56fe\uff08BEV\uff09\u8f6c\u6362\uff0c\u5f53\u4f20\u611f\u5668\u5931\u6548\u6216\u8f66\u961f\u4e2d\u6444\u50cf\u5934\u914d\u7f6e\u4e0d\u4e00\u81f4\u65f6\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u53d8\u5f97\u8106\u5f31\u3002\u6211\u4eec\u63d0\u51fa\u4e86 FlexMap\uff0c\u4e0e\u4ee5\u5f80\u56fa\u5b9a\u4e8e\u7279\u5b9aN\u6444\u50cf\u5934\u88c5\u7f6e\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u65e0\u9700\u4efb\u4f55\u67b6\u6784\u4fee\u6539\u6216\u9488\u5bf9\u6bcf\u79cd\u914d\u7f6e\u91cd\u65b0\u8bad\u7ec3\uff0c\u5373\u53ef\u9002\u5e94\u53ef\u53d8\u7684\u6444\u50cf\u5934\u914d\u7f6e\u3002\u6211\u4eec\u7684\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u6452\u5f03\u4e86\u663e\u5f0f\u7684\u51e0\u4f55\u6295\u5f71\uff0c\u8f6c\u800c\u4f7f\u7528\u4e00\u4e2a\u5177\u5907\u8de8\u5e27\u6ce8\u610f\u529b\u673a\u5236\u7684\u51e0\u4f55\u611f\u77e5\u57fa\u7840\u6a21\u578b\uff0c\u5728\u7279\u5f81\u7a7a\u95f4\u4e2d\u9690\u5f0f\u5730\u7f16\u7801\u4e09\u7ef4\u573a\u666f\u7406\u89e3\u3002FlexMap \u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u4e00\u4e2a\u65f6\u7a7a\u589e\u5f3a\u6a21\u5757\uff0c\u5c06\u8de8\u89c6\u89d2\u7684\u7a7a\u95f4\u63a8\u7406\u4e0e\u65f6\u95f4\u52a8\u6001\u89e3\u8026\uff1b\u4ee5\u53ca\u4e00\u4e2a\u5e26\u6709\u6f5c\u5728\u76f8\u673a\u6807\u8bb0\u7684\u76f8\u673a\u611f\u77e5\u89e3\u7801\u5668\uff0c\u53ef\u5728\u65e0\u9700\u6295\u5f71\u77e9\u9635\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u89c6\u56fe\u81ea\u9002\u5e94\u6ce8\u610f\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFlexMap \u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5bf9\u7f3a\u5931\u89c6\u89d2\u548c\u4f20\u611f\u5668\u53d8\u5316\u5177\u6709\u826f\u597d\u7684\u9c81\u68d2\u6027\uff0c\u4ece\u800c\u652f\u6301\u66f4\u5b9e\u7528\u7684\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u3002"}}
{"id": "2601.22398", "pdf": "https://arxiv.org/pdf/2601.22398", "abs": "https://arxiv.org/abs/2601.22398", "authors": ["Aarush Noheria", "Yuguang Yao"], "title": "Jailbreaks on Vision Language Model via Multimodal Reasoning", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models (VLMs) have become central to tasks such as visual question answering, image captioning, and text-to-image generation. However, their outputs are highly sensitive to prompt variations, which can reveal vulnerabilities in safety alignment. In this work, we present a jailbreak framework that exploits post-training Chain-of-Thought (CoT) prompting to construct stealthy prompts capable of bypassing safety filters. To further increase attack success rates (ASR), we propose a ReAct-driven adaptive noising mechanism that iteratively perturbs input images based on model feedback. This approach leverages the ReAct paradigm to refine adversarial noise in regions most likely to activate safety defenses, thereby enhancing stealth and evasion. Experimental results demonstrate that the proposed dual-strategy significantly improves ASR while maintaining naturalness in both text and visual domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u540e\u8bad\u7ec3\u601d\u7ef4\u94fe\uff08CoT\uff09\u63d0\u793a\u548cReAct\u9a71\u52a8\u81ea\u9002\u5e94\u52a0\u566a\u673a\u5236\u7684\u8d8a\u72f1\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u53ef\u7ed5\u8fc7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u8fc7\u6ee4\u5668\u7684\u9690\u853d\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u653b\u51fb\u6210\u529f\u7387\u5e76\u4fdd\u6301\u6587\u672c\u4e0e\u56fe\u50cf\u7684\u81ea\u7136\u6027\u3002", "motivation": "\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5bf9\u63d0\u793a\u53d8\u5316\u9ad8\u5ea6\u654f\u611f\uff0c\u8fd9\u79cd\u654f\u611f\u6027\u53ef\u80fd\u66b4\u9732\u5176\u5728\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u7684\u6f0f\u6d1e\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5229\u7528\u8fd9\u79cd\u8106\u5f31\u6027\uff0c\u8bbe\u8ba1\u6709\u6548\u4e14\u9690\u853d\u7684\u653b\u51fb\u65b9\u6cd5\u4ee5\u7ed5\u8fc7\u73b0\u6709\u5b89\u5168\u673a\u5236\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7b56\u7565\uff1a1\uff09\u5229\u7528\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u601d\u7ef4\u94fe\uff08CoT\uff09\u63d0\u793a\u6784\u5efa\u9690\u853d\u8d8a\u72f1\u63d0\u793a\uff1b2\uff09\u5f15\u5165\u57fa\u4e8eReAct\u8303\u5f0f\u7684\u81ea\u9002\u5e94\u56fe\u50cf\u52a0\u566a\u673a\u5236\uff0c\u6839\u636e\u6a21\u578b\u53cd\u9988\u8fed\u4ee3\u6270\u52a8\u8f93\u5165\u56fe\u50cf\u4e2d\u6613\u89e6\u53d1\u5b89\u5168\u9632\u5fa1\u7684\u533a\u57df\uff0c\u4ee5\u589e\u5f3a\u653b\u51fb\u7684\u9690\u853d\u6027\u548c\u89c4\u907f\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u53cc\u7b56\u7565\u65b9\u6cd5\u5728\u6587\u672c\u548c\u89c6\u89c9\u9886\u57df\u5747\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f93\u51fa\u7684\u81ea\u7136\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u7684\u6f5c\u5728\u5f31\u70b9\uff0c\u5e76\u901a\u8fc7\u7ed3\u5408CoT\u63d0\u793a\u4e0eReAct\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u6270\u52a8\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9690\u853d\u7684\u8d8a\u72f1\u653b\u51fb\u6846\u67b6\uff0c\u5bf9\u6a21\u578b\u5b89\u5168\u6027\u63d0\u51fa\u4e86\u65b0\u7684\u6311\u6218\u3002", "summary_cn": "\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5df2\u6210\u4e3a\u89c6\u89c9\u95ee\u7b54\u3001\u56fe\u50cf\u63cf\u8ff0\u548c\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7b49\u4efb\u52a1\u7684\u6838\u5fc3\u5de5\u5177\u3002\u7136\u800c\uff0c\u5176\u8f93\u51fa\u5bf9\u63d0\u793a\u8bed\u7684\u53d8\u5316\u6781\u4e3a\u654f\u611f\uff0c\u8fd9\u79cd\u654f\u611f\u6027\u53ef\u80fd\u66b4\u9732\u51fa\u5176\u5728\u5b89\u5168\u5bf9\u9f50\u65b9\u9762\u7684\u6f0f\u6d1e\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8d8a\u72f1\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u601d\u7ef4\u94fe\uff08Chain-of-Thought, CoT\uff09\u63d0\u793a\u6765\u6784\u5efa\u80fd\u591f\u7ed5\u8fc7\u5b89\u5168\u8fc7\u6ee4\u5668\u7684\u9690\u853d\u63d0\u793a\u3002\u4e3a\u8fdb\u4e00\u6b65\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eReAct\u8303\u5f0f\u7684\u81ea\u9002\u5e94\u52a0\u566a\u673a\u5236\uff0c\u8be5\u673a\u5236\u6839\u636e\u6a21\u578b\u53cd\u9988\u8fed\u4ee3\u5730\u5bf9\u8f93\u5165\u56fe\u50cf\u8fdb\u884c\u6270\u52a8\u3002\u8be5\u65b9\u6cd5\u5229\u7528ReAct\u8303\u5f0f\uff0c\u5728\u6700\u53ef\u80fd\u6fc0\u6d3b\u5b89\u5168\u9632\u5fa1\u7684\u56fe\u50cf\u533a\u57df\u4e2d\u4f18\u5316\u5bf9\u6297\u6027\u566a\u58f0\uff0c\u4ece\u800c\u589e\u5f3a\u653b\u51fb\u7684\u9690\u853d\u6027\u548c\u89c4\u907f\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u53cc\u91cd\u7b56\u7565\u5728\u663e\u8457\u63d0\u5347\u653b\u51fb\u6210\u529f\u7387\u7684\u540c\u65f6\uff0c\u5728\u6587\u672c\u548c\u89c6\u89c9\u9886\u57df\u5747\u4fdd\u6301\u4e86\u826f\u597d\u7684\u81ea\u7136\u6027\u3002"}}
{"id": "2601.22412", "pdf": "https://arxiv.org/pdf/2601.22412", "abs": "https://arxiv.org/abs/2601.22412", "authors": ["Seth Donahue", "Irina Djuraskovic", "Kunal Shah", "Fabian Sinz", "Ross Chafetz", "R. James Cotton"], "title": "EMBC Special Issue: Calibrated Uncertainty for Trustworthy Clinical Gait Analysis Using Probabilistic Multiview Markerless Motion Capture", "categories": ["cs.CV"], "comment": "9 pages, 5 figures, EMBS Special Issue", "summary": "Video-based human movement analysis holds potential for movement assessment in clinical practice and research. However, the clinical implementation and trust of multi-view markerless motion capture (MMMC) require that, in addition to being accurate, these systems produce reliable confidence intervals to indicate how accurate they are for any individual. Building on our prior work utilizing variational inference to estimate joint angle posterior distributions, this study evaluates the calibration and reliability of a probabilistic MMMC method. We analyzed data from 68 participants across two institutions, validating the model against an instrumented walkway and standard marker-based motion capture. We measured the calibration of the confidence intervals using the Expected Calibration Error (ECE). The model demonstrated reliable calibration, yielding ECE values generally < 0.1 for both step and stride length and bias-corrected gait kinematics. We observed a median step and stride length error of ~16 mm and ~12 mm respectively, with median bias-corrected kinematic errors ranging from 1.5 to 3.8 degrees across lower extremity joints. Consistent with the calibrated ECE, the magnitude of the model's predicted uncertainty correlated strongly with observed error measures. These findings indicate that, as designed, the probabilistic model reconstruction quantifies epistemic uncertainty, allowing it to identify unreliable outputs without the need for concurrent ground-truth instrumentation.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u63a8\u65ad\u7684\u591a\u89c6\u89d2\u65e0\u6807\u8bb0\u8fd0\u52a8\u6355\u6349\uff08MMMC\uff09\u7cfb\u7edf\u7684\u7f6e\u4fe1\u533a\u95f4\u6821\u51c6\u4e0e\u53ef\u9760\u6027\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6982\u7387\u6a21\u578b\u80fd\u6709\u6548\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u65e0\u9700\u771f\u5b9e\u503c\u8bbe\u5907\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u4e0d\u53ef\u9760\u8f93\u51fa\u3002", "motivation": "\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u9700\u8981\u53ef\u9760\u4e14\u53ef\u4fe1\u8d56\u7684\u65e0\u6807\u8bb0\u8fd0\u52a8\u6355\u6349\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u8981\u6c42\u9ad8\u7cbe\u5ea6\uff0c\u8fd8\u9700\u63d0\u4f9b\u51c6\u786e\u53cd\u6620\u4e2a\u4f53\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4ee5\u589e\u5f3a\u4e34\u5e8a\u91c7\u7eb3\u548c\u4fe1\u4efb\u3002", "method": "\u57fa\u4e8e\u5148\u524d\u5229\u7528\u53d8\u5206\u63a8\u65ad\u4f30\u8ba1\u5173\u8282\u89d2\u5ea6\u540e\u9a8c\u5206\u5e03\u7684\u5de5\u4f5c\uff0c\u672c\u7814\u7a76\u572868\u540d\u53d7\u8bd5\u8005\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u6982\u7387\u6027MMMC\u65b9\u6cd5\uff0c\u4f7f\u7528\u9884\u671f\u6821\u51c6\u8bef\u5dee\uff08ECE\uff09\u8bc4\u4f30\u7f6e\u4fe1\u533a\u95f4\u6821\u51c6\u60c5\u51b5\uff0c\u5e76\u4e0e\u4eea\u5668\u5316\u6b65\u9053\u548c\u6807\u51c6\u6807\u8bb0\u5f0f\u8fd0\u52a8\u6355\u6349\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u6a21\u578b\u5728\u6821\u51c6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff08ECE\u901a\u5e38<0.1\uff09\uff0c\u6b65\u957f\u548c\u8de8\u6b65\u957f\u4e2d\u4f4d\u8bef\u5dee\u5206\u522b\u4e3a\u7ea616 mm\u548c12 mm\uff0c\u4e0b\u80a2\u5404\u5173\u8282\u6821\u6b63\u540e\u8fd0\u52a8\u5b66\u8bef\u5dee\u4e2d\u4f4d\u6570\u4e3a1.5\u20133.8\u5ea6\uff0c\u4e14\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u5b9e\u9645\u8bef\u5dee\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6982\u7387\u6a21\u578b\u80fd\u6709\u6548\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u5728\u6ca1\u6709\u540c\u6b65\u771f\u5b9e\u503c\u8bbe\u5907\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u4e0d\u53ef\u9760\u7684\u8f93\u51fa\uff0c\u5177\u5907\u4e34\u5e8a\u5e94\u7528\u6f5c\u529b\u3002", "summary_cn": "\u57fa\u4e8e\u89c6\u9891\u7684\u4eba\u4f53\u8fd0\u52a8\u5206\u6790\u5728\u4e34\u5e8a\u5b9e\u8df5\u548c\u7814\u7a76\u4e2d\u7684\u8fd0\u52a8\u8bc4\u4f30\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002\u7136\u800c\uff0c\u591a\u89c6\u89d2\u65e0\u6807\u8bb0\u8fd0\u52a8\u6355\u6349\uff08MMMC\uff09\u7cfb\u7edf\u7684\u4e34\u5e8a\u5e94\u7528\u548c\u53ef\u4fe1\u5ea6\u4e0d\u4ec5\u8981\u6c42\u5176\u5177\u5907\u9ad8\u51c6\u786e\u6027\uff0c\u8fd8\u9700\u8981\u80fd\u591f\u751f\u6210\u53ef\u9760\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u4ee5\u6307\u793a\u5bf9\u4efb\u4f55\u4e2a\u4f53\u9884\u6d4b\u7684\u51c6\u786e\u7a0b\u5ea6\u3002\u672c\u7814\u7a76\u5728\u6211\u4eec\u5148\u524d\u5229\u7528\u53d8\u5206\u63a8\u65ad\u4f30\u8ba1\u5173\u8282\u89d2\u5ea6\u540e\u9a8c\u5206\u5e03\u5de5\u4f5c\u7684\u57fa\u7840\u4e0a\uff0c\u8bc4\u4f30\u4e86\u4e00\u79cd\u6982\u7387\u6027MMMC\u65b9\u6cd5\u7684\u6821\u51c6\u6027\u548c\u53ef\u9760\u6027\u3002\u6211\u4eec\u5206\u6790\u4e86\u6765\u81ea\u4e24\u4e2a\u673a\u6784\u517168\u540d\u53c2\u4e0e\u8005\u7684\u6570\u636e\uff0c\u5c06\u8be5\u6a21\u578b\u4e0e\u4eea\u5668\u5316\u6b65\u9053\u548c\u6807\u51c6\u6807\u8bb0\u5f0f\u8fd0\u52a8\u6355\u6349\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6bd4\u9a8c\u8bc1\u3002\u6211\u4eec\u91c7\u7528\u9884\u671f\u6821\u51c6\u8bef\u5dee\uff08ECE\uff09\u6765\u8861\u91cf\u7f6e\u4fe1\u533a\u95f4\u7684\u6821\u51c6\u7a0b\u5ea6\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6a21\u578b\u5728\u6821\u51c6\u65b9\u9762\u8868\u73b0\u53ef\u9760\uff0c\u6b65\u957f\u548c\u8de8\u6b65\u957f\u4ee5\u53ca\u504f\u5dee\u6821\u6b63\u540e\u7684\u6b65\u6001\u8fd0\u52a8\u5b66\u53c2\u6570\u7684ECE\u503c\u666e\u904d\u5c0f\u4e8e0.1\u3002\u89c2\u5bdf\u5230\u7684\u6b65\u957f\u548c\u8de8\u6b65\u957f\u4e2d\u4f4d\u8bef\u5dee\u5206\u522b\u7ea6\u4e3a16\u6beb\u7c73\u548c12\u6beb\u7c73\uff0c\u4e0b\u80a2\u5404\u5173\u8282\u7684\u504f\u5dee\u6821\u6b63\u540e\u8fd0\u52a8\u5b66\u8bef\u5dee\u4e2d\u4f4d\u6570\u57281.5\u81f33.8\u5ea6\u4e4b\u95f4\u3002\u4e0e\u6821\u51c6\u826f\u597d\u7684ECE\u4e00\u81f4\uff0c\u6a21\u578b\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u5927\u5c0f\u4e0e\u89c2\u6d4b\u5230\u7684\u8bef\u5dee\u6307\u6807\u9ad8\u5ea6\u76f8\u5173\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6982\u7387\u6a21\u578b\u5982\u8bbe\u8ba1\u6240\u9884\u671f\uff0c\u80fd\u591f\u91cf\u5316\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u4ece\u800c\u5728\u65e0\u9700\u540c\u6b65\u771f\u5b9e\u503c\u8bbe\u5907\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u4e0d\u53ef\u9760\u7684\u8f93\u51fa\u3002"}}
