{"id": "2602.15072", "pdf": "https://arxiv.org/pdf/2602.15072", "abs": "https://arxiv.org/abs/2602.15072", "authors": ["Abdul Joseph Fofanah", "Lian Wen", "Alpha Alimamy Kamara", "Zhongyi Zhang", "David Chen", "Albert Patrick Sankoh"], "title": "GRAFNet: Multiscale Retinal Processing via Guided Cortical Attention Feedback for Enhancing Medical Image Polyp Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate polyp segmentation in colonoscopy is essential for cancer prevention but remains challenging due to: (1) high morphological variability (from flat to protruding lesions), (2) strong visual similarity to normal structures such as folds and vessels, and (3) the need for robust multi-scale detection. Existing deep learning approaches suffer from unidirectional processing, weak multi-scale fusion, and the absence of anatomical constraints, often leading to false positives (over-segmentation of normal structures) and false negatives (missed subtle flat lesions). We propose GRAFNet, a biologically inspired architecture that emulates the hierarchical organisation of the human visual system. GRAFNet integrates three key modules: (1) a Guided Asymmetric Attention Module (GAAM) that mimics orientation-tuned cortical neurones to emphasise polyp boundaries, (2) a MultiScale Retinal Module (MSRM) that replicates retinal ganglion cell pathways for parallel multi-feature analysis, and (3) a Guided Cortical Attention Feedback Module (GCAFM) that applies predictive coding for iterative refinement. These are unified in a Polyp Encoder-Decoder Module (PEDM) that enforces spatial-semantic consistency via resolution-adaptive feedback. Extensive experiments on five public benchmarks (Kvasir-SEG, CVC-300, CVC-ColonDB, CVC-Clinic, and PolypGen) demonstrate consistent state-of-the-art performance, with 3-8% Dice improvements and 10-20% higher generalisation over leading methods, while offering interpretable decision pathways. This work establishes a paradigm in which neural computation principles bridge the gap between AI accuracy and clinically trustworthy reasoning. Code is available at https://github.com/afofanah/GRAFNet.", "AI": {"tldr": "GRAFNet\u662f\u4e00\u79cd\u53d7\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u542f\u53d1\u7684\u65b0\u578b\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u6a21\u62df\u751f\u7269\u89c6\u89c9\u673a\u5236\uff0c\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u606f\u8089\u5206\u5272\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u7ed3\u80a0\u955c\u606f\u8089\u5206\u5272\u4e2d\u5b58\u5728\u5355\u5411\u5904\u7406\u3001\u591a\u5c3a\u5ea6\u878d\u5408\u5f31\u548c\u7f3a\u4e4f\u89e3\u5256\u7ea6\u675f\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u5047\u9633\u6027\u548c\u5047\u9634\u6027\u7ed3\u679c\uff0c\u5f71\u54cd\u4e34\u5e8a\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faGRAFNet\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\u5f15\u5bfc\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u6a21\u5757\uff08GAAM\uff09\u3001\u591a\u5c3a\u5ea6\u89c6\u7f51\u819c\u6a21\u5757\uff08MSRM\uff09\u548c\u5f15\u5bfc\u76ae\u5c42\u6ce8\u610f\u529b\u53cd\u9988\u6a21\u5757\uff08GCAFM\uff09\uff0c\u5e76\u6574\u5408\u4e8e\u606f\u8089\u7f16\u89e3\u7801\u6a21\u5757\uff08PEDM\uff09\u4e2d\uff0c\u5b9e\u73b0\u7a7a\u95f4-\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\uff0cDice\u6307\u6807\u63d0\u53473-8%\uff0c\u6cdb\u5316\u80fd\u529b\u63d0\u9ad810-20%\uff0c\u4e14\u5177\u5907\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u795e\u7ecf\u8ba1\u7b97\u539f\u7406\u5f15\u5165\u533b\u5b66\u56fe\u50cf\u5206\u5272\uff0c\u5f25\u5408\u4e86AI\u7cbe\u5ea6\u4e0e\u4e34\u5e8a\u53ef\u4fe1\u63a8\u7406\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u53ef\u4fe1AI\u5728\u533b\u7597\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002", "summary_cn": "\u7ed3\u80a0\u955c\u68c0\u67e5\u4e2d\u51c6\u786e\u7684\u606f\u8089\u5206\u5272\u5bf9\u4e8e\u764c\u75c7\u9884\u9632\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u4ee5\u4e0b\u539f\u56e0\u4ecd\u5177\u6311\u6218\u6027\uff1a(1) \u5f62\u6001\u9ad8\u5ea6\u53ef\u53d8\uff08\u4ece\u6241\u5e73\u5230\u9686\u8d77\u75c5\u53d8\uff09\uff0c(2) \u4e0e\u76b1\u895e\u548c\u8840\u7ba1\u7b49\u6b63\u5e38\u7ed3\u6784\u5728\u89c6\u89c9\u4e0a\u9ad8\u5ea6\u76f8\u4f3c\uff0c(3) \u9700\u8981\u9c81\u68d2\u7684\u591a\u5c3a\u5ea6\u68c0\u6d4b\u80fd\u529b\u3002\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u5355\u5411\u5904\u7406\u3001\u5f31\u591a\u5c3a\u5ea6\u878d\u5408\u4ee5\u53ca\u7f3a\u4e4f\u89e3\u5256\u7ea6\u675f\uff0c\u5e38\u5bfc\u81f4\u5047\u9633\u6027\uff08\u5c06\u6b63\u5e38\u7ed3\u6784\u8fc7\u5ea6\u5206\u5272\uff09\u548c\u5047\u9634\u6027\uff08\u6f0f\u68c0\u7ec6\u5fae\u6241\u5e73\u75c5\u53d8\uff09\u3002\u672c\u6587\u63d0\u51faGRAFNet\uff0c\u4e00\u79cd\u53d7\u751f\u7269\u542f\u53d1\u7684\u67b6\u6784\uff0c\u6a21\u62df\u4eba\u7c7b\u89c6\u89c9\u7cfb\u7edf\u7684\u5c42\u7ea7\u7ec4\u7ec7\u3002GRAFNet\u6574\u5408\u4e09\u4e2a\u5173\u952e\u6a21\u5757\uff1a(1) \u5f15\u5bfc\u975e\u5bf9\u79f0\u6ce8\u610f\u529b\u6a21\u5757\uff08GAAM\uff09\uff0c\u6a21\u62df\u65b9\u5411\u8c03\u8c10\u76ae\u5c42\u795e\u7ecf\u5143\u4ee5\u5f3a\u5316\u606f\u8089\u8fb9\u754c\uff1b(2) \u591a\u5c3a\u5ea6\u89c6\u7f51\u819c\u6a21\u5757\uff08MSRM\uff09\uff0c\u590d\u73b0\u89c6\u7f51\u819c\u795e\u7ecf\u8282\u7ec6\u80de\u901a\u8def\u4ee5\u8fdb\u884c\u5e76\u884c\u591a\u7279\u5f81\u5206\u6790\uff1b(3) \u5f15\u5bfc\u76ae\u5c42\u6ce8\u610f\u529b\u53cd\u9988\u6a21\u5757\uff08GCAFM\uff09\uff0c\u91c7\u7528\u9884\u6d4b\u7f16\u7801\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002\u8fd9\u4e9b\u6a21\u5757\u7edf\u4e00\u4e8e\u606f\u8089\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u5757\uff08PEDM\uff09\u4e2d\uff0c\u901a\u8fc7\u5206\u8fa8\u7387\u81ea\u9002\u5e94\u53cd\u9988\u786e\u4fdd\u7a7a\u95f4-\u8bed\u4e49\u4e00\u81f4\u6027\u3002\u5728\u4e94\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\uff08Kvasir-SEG\u3001CVC-300\u3001CVC-ColonDB\u3001CVC-Clinic\u548cPolypGen\uff09\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0cDice\u6307\u6807\u63d0\u53473-8%\uff0c\u6cdb\u5316\u80fd\u529b\u6bd4\u4e3b\u6d41\u65b9\u6cd5\u9ad810-20%\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u8def\u5f84\u3002\u672c\u5de5\u4f5c\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u8303\u5f0f\uff0c\u5373\u5229\u7528\u795e\u7ecf\u8ba1\u7b97\u539f\u7406\u5f25\u5408\u4eba\u5de5\u667a\u80fd\u7cbe\u5ea6\u4e0e\u4e34\u5e8a\u53ef\u4fe1\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\uff1ahttps://github.com/afofanah/GRAFNet\u3002"}}
{"id": "2602.15124", "pdf": "https://arxiv.org/pdf/2602.15124", "abs": "https://arxiv.org/abs/2602.15124", "authors": ["Shiyu Xuan", "Dongkai Wang", "Zechao Li", "Jinhui Tang"], "title": "Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition", "categories": ["cs.CV"], "comment": "ICLR 2026", "summary": "Zero-shot Human-object interaction (HOI) detection aims to locate humans and objects in images and recognize their interactions. While advances in open-vocabulary object detection provide promising solutions for object localization, interaction recognition (IR) remains challenging due to the combinatorial diversity of interactions. Existing methods, including two-stage methods, tightly couple IR with a specific detector and rely on coarse-grained vision-language model (VLM) features, which limit generalization to unseen interactions. In this work, we propose a decoupled framework that separates object detection from IR and leverages multi-modal large language models (MLLMs) for zero-shot IR. We introduce a deterministic generation method that formulates IR as a visual question answering task and enforces deterministic outputs, enabling training-free zero-shot IR. To further enhance performance and efficiency by fine-tuning the model, we design a spatial-aware pooling module that integrates appearance and pairwise spatial cues, and a one-pass deterministic matching method that predicts all candidate interactions in a single forward pass. Extensive experiments on HICO-DET and V-COCO demonstrate that our method achieves superior zero-shot performance, strong cross-dataset generalization, and the flexibility to integrate with any object detectors without retraining. The codes are publicly available at https://github.com/SY-Xuan/DA-HOI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u7684\u96f6\u6837\u672c\u4eba-\u7269\u4ea4\u4e92\uff08HOI\uff09\u68c0\u6d4b\u6846\u67b6\uff0c\u5c06\u76ee\u6807\u68c0\u6d4b\u4e0e\u4ea4\u4e92\u8bc6\u522b\u5206\u79bb\uff0c\u5e76\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8fdb\u884c\u96f6\u6837\u672c\u4ea4\u4e92\u8bc6\u522b\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u751f\u6210\u65b9\u6cd5\u548c\u7a7a\u95f4\u611f\u77e5\u6c60\u5316\u6a21\u5757\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u96f6\u6837\u672c\u4eba-\u7269\u4ea4\u4e92\uff08HOI\uff09\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u5c06\u4ea4\u4e92\u8bc6\u522b\uff08IR\uff09\u4e0e\u7279\u5b9a\u68c0\u6d4b\u5668\u7d27\u5bc6\u8026\u5408\uff0c\u5e76\u4f9d\u8d56\u7c97\u7c92\u5ea6\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7279\u5f81\uff0c\u9650\u5236\u4e86\u5bf9\u672a\u89c1\u4ea4\u4e92\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u66f4\u7075\u6d3b\u3001\u901a\u7528\u4e14\u9ad8\u6548\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u89e3\u8026\u6846\u67b6\uff0c\u5c06\u76ee\u6807\u68c0\u6d4b\u4e0e\u4ea4\u4e92\u8bc6\u522b\u5206\u79bb\uff1b\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\uff0c\u5c06\u4ea4\u4e92\u8bc6\u522b\u5efa\u6a21\u4e3a\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u5e76\u91c7\u7528\u786e\u5b9a\u6027\u751f\u6210\u65b9\u6cd5\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u7684\u96f6\u6837\u672c\u63a8\u7406\uff1b\u4e3a\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u8bbe\u8ba1\u4e86\u7a7a\u95f4\u611f\u77e5\u6c60\u5316\u6a21\u5757\u4ee5\u878d\u5408\u5916\u89c2\u4e0e\u7a7a\u95f4\u5173\u7cfb\u7279\u5f81\uff0c\u5e76\u63d0\u51fa\u5355\u6b21\u524d\u5411\u4f20\u64ad\u7684\u786e\u5b9a\u6027\u5339\u914d\u7b56\u7565\u3002", "result": "\u5728HICO-DET\u548cV-COCO\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5177\u6709\u5f3a\u5927\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u80fd\u7075\u6d3b\u9002\u914d\u4efb\u610f\u76ee\u6807\u68c0\u6d4b\u5668\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u89e3\u8026\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u96f6\u6837\u672c\u4eba-\u7269\u4ea4\u4e92\u68c0\u6d4b\u7684\u6027\u80fd\u4e0e\u7075\u6d3b\u6027\uff0c\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002", "summary_cn": "\u96f6\u6837\u672c\u4eba-\u7269\u4ea4\u4e92\uff08HOI\uff09\u68c0\u6d4b\u65e8\u5728\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u4eba\u548c\u7269\u4f53\u5e76\u8bc6\u522b\u5b83\u4eec\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb\u3002\u5c3d\u7ba1\u5f00\u653e\u8bcd\u6c47\u76ee\u6807\u68c0\u6d4b\u7684\u8fdb\u5c55\u4e3a\u76ee\u6807\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7531\u4e8e\u4ea4\u4e92\u7ec4\u5408\u7684\u591a\u6837\u6027\uff0c\u4ea4\u4e92\u8bc6\u522b\uff08IR\uff09\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u4e24\u9636\u6bb5\u65b9\u6cd5\uff09\u901a\u5e38\u5c06IR\u4e0e\u7279\u5b9a\u68c0\u6d4b\u5668\u7d27\u5bc6\u8026\u5408\uff0c\u5e76\u4f9d\u8d56\u7c97\u7c92\u5ea6\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7279\u5f81\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5bf9\u672a\u89c1\u8fc7\u4ea4\u4e92\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u6846\u67b6\uff0c\u5c06\u76ee\u6807\u68c0\u6d4b\u4e0eIR\u5206\u79bb\uff0c\u5e76\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8fdb\u884c\u96f6\u6837\u672cIR\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u751f\u6210\u65b9\u6cd5\uff0c\u5c06IR\u5efa\u6a21\u4e3a\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u5e76\u5f3a\u5236\u8f93\u51fa\u786e\u5b9a\u6027\u7ed3\u679c\uff0c\u4ece\u800c\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u7684\u96f6\u6837\u672cIR\u3002\u4e3a\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u548c\u6548\u7387\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7a7a\u95f4\u611f\u77e5\u6c60\u5316\u6a21\u5757\uff0c\u7528\u4e8e\u878d\u5408\u5916\u89c2\u7279\u5f81\u4e0e\u6210\u5bf9\u7a7a\u95f4\u7ebf\u7d22\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u6b21\u524d\u5411\u4f20\u64ad\u7684\u786e\u5b9a\u6027\u5339\u914d\u65b9\u6cd5\uff0c\u53ef\u5728\u4e00\u6b21\u63a8\u7406\u4e2d\u9884\u6d4b\u6240\u6709\u5019\u9009\u4ea4\u4e92\u3002\u5728HICO-DET\u548cV-COCO\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u96f6\u6837\u672c\u6027\u80fd\u3001\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u4e14\u80fd\u591f\u7075\u6d3b\u5730\u4e0e\u4efb\u610f\u76ee\u6807\u68c0\u6d4b\u5668\u96c6\u6210\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002\u4ee3\u7801\u5df2\u516c\u5f00\u4e8e https://github.com/SY-Xuan/DA-HOI\u3002"}}
{"id": "2602.15138", "pdf": "https://arxiv.org/pdf/2602.15138", "abs": "https://arxiv.org/abs/2602.15138", "authors": ["Marcus Jenkins", "Jasenka Mazibrada", "Bogdan Leahu", "Michal Mackiewicz"], "title": "MB-DSMIL-CL-PL: Scalable Weakly Supervised Ovarian Cancer Subtype Classification and Localisation Using Contrastive and Prototype Learning with Frozen Patch Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The study of histopathological subtypes is valuable for the personalisation of effective treatment strategies for ovarian cancer. However, increasing diagnostic workloads present a challenge for UK pathology departments, leading to the rise in AI approaches. While traditional approaches in this field have relied on pre-computed, frozen image features, recent advances have shifted towards end-to-end feature extraction, providing an improvement in accuracy but at the expense of significantly reduced scalability during training and time-consuming experimentation. In this paper, we propose a new approach for subtype classification and localisation in ovarian cancer histopathology images using contrastive and prototype learning with pre-computed, frozen features via feature-space augmentations. Compared to DSMIL, our method achieves an improvement of 70.4\\% and 15.3\\% in F1 score for instance- and slide-level classification, respectively, along with AUC gains of 16.9\\% for instance localisation and 2.3\\% for slide classification, while maintaining the use of frozen patch features.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u548c\u539f\u578b\u5b66\u4e60\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8ba1\u7b97\u7684\u51bb\u7ed3\u7279\u5f81\u5bf9\u5375\u5de2\u764c\u7ec4\u7ec7\u75c5\u7406\u56fe\u50cf\u8fdb\u884c\u4e9a\u578b\u5206\u7c7b\u4e0e\u5b9a\u4f4d\uff0c\u5728\u4fdd\u6301\u7279\u5f81\u51bb\u7ed3\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5375\u5de2\u764c\u7ec4\u7ec7\u75c5\u7406\u4e9a\u578b\u7814\u7a76\u5bf9\u4e2a\u6027\u5316\u6cbb\u7597\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u82f1\u56fd\u75c5\u7406\u90e8\u95e8\u9762\u4e34\u8bca\u65ad\u5de5\u4f5c\u91cf\u6fc0\u589e\u7684\u95ee\u9898\uff0c\u4fc3\u4f7fAI\u65b9\u6cd5\u7684\u53d1\u5c55\u3002\u73b0\u6709\u7aef\u5230\u7aef\u65b9\u6cd5\u867d\u63d0\u9ad8\u51c6\u786e\u7387\uff0c\u5374\u727a\u7272\u4e86\u8bad\u7ec3\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9a8c\u6548\u7387\u3002", "method": "\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u548c\u539f\u578b\u5b66\u4e60\uff0c\u7ed3\u5408\u7279\u5f81\u7a7a\u95f4\u589e\u5f3a\u6280\u672f\uff0c\u5229\u7528\u9884\u8ba1\u7b97\u4e14\u51bb\u7ed3\u7684\u56fe\u50cf\u5757\u7279\u5f81\u8fdb\u884c\u5375\u5de2\u764c\u4e9a\u578b\u7684\u5206\u7c7b\u4e0e\u5b9a\u4f4d\u3002", "result": "\u76f8\u6bd4DSMIL\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u4f8b\u7ea7\u548c\u5207\u7247\u7ea7\u5206\u7c7b\u7684F1\u5206\u6570\u5206\u522b\u63d0\u534770.4%\u548c15.3%\uff0c\u5728\u5b9e\u4f8b\u5b9a\u4f4d\u548c\u5207\u7247\u5206\u7c7b\u7684AUC\u5206\u522b\u63d0\u534716.9%\u548c2.3%\uff0c\u540c\u65f6\u4fdd\u6301\u4f7f\u7528\u51bb\u7ed3\u7684patch\u7279\u5f81\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u5e95\u5c42\u7279\u5f81\u63d0\u53d6\u5668\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5375\u5de2\u764c\u7ec4\u7ec7\u75c5\u7406\u4e9a\u578b\u5206\u7c7b\u4e0e\u5b9a\u4f4d\u7684\u6027\u80fd\uff0c\u517c\u987e\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "summary_cn": "\u7ec4\u7ec7\u75c5\u7406\u5b66\u4e9a\u578b\u7684\u7814\u7a76\u5bf9\u4e8e\u5375\u5de2\u764c\u4e2a\u6027\u5316\u6709\u6548\u6cbb\u7597\u7b56\u7565\u7684\u5236\u5b9a\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002\u7136\u800c\uff0c\u65e5\u76ca\u589e\u52a0\u7684\u8bca\u65ad\u5de5\u4f5c\u91cf\u7ed9\u82f1\u56fd\u75c5\u7406\u90e8\u95e8\u5e26\u6765\u4e86\u6311\u6218\uff0c\u63a8\u52a8\u4e86\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u7684\u5e94\u7528\u3002\u5c3d\u7ba1\u8be5\u9886\u57df\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9884\u8ba1\u7b97\u4e14\u51bb\u7ed3\u7684\u56fe\u50cf\u7279\u5f81\uff0c\u4f46\u8fd1\u671f\u7814\u7a76\u5df2\u8f6c\u5411\u7aef\u5230\u7aef\u7279\u5f81\u63d0\u53d6\uff0c\u867d\u7136\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u5374\u4ee5\u8bad\u7ec3\u9636\u6bb5\u53ef\u6269\u5c55\u6027\u5927\u5e45\u964d\u4f4e\u548c\u5b9e\u9a8c\u8017\u65f6\u589e\u52a0\u4e3a\u4ee3\u4ef7\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u589e\u5f3a\uff0c\u5229\u7528\u9884\u8ba1\u7b97\u4e14\u51bb\u7ed3\u7684\u7279\u5f81\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u539f\u578b\u5b66\u4e60\uff0c\u5b9e\u73b0\u5375\u5de2\u764c\u7ec4\u7ec7\u75c5\u7406\u56fe\u50cf\u7684\u4e9a\u578b\u5206\u7c7b\u4e0e\u5b9a\u4f4d\u3002\u4e0eDSMIL\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u4f8b\u7ea7\u548c\u5207\u7247\u7ea7\u5206\u7c7b\u7684F1\u5206\u6570\u5206\u522b\u63d0\u5347\u4e8670.4%\u548c15.3%\uff0c\u5728\u5b9e\u4f8b\u5b9a\u4f4d\u548c\u5207\u7247\u5206\u7c7b\u7684AUC\u5206\u522b\u63d0\u5347\u4e8616.9%\u548c2.3%\uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u4f7f\u7528\u51bb\u7ed3\u7684\u56fe\u50cf\u5757\u7279\u5f81\u3002"}}
{"id": "2602.15154", "pdf": "https://arxiv.org/pdf/2602.15154", "abs": "https://arxiv.org/abs/2602.15154", "authors": ["Praditha Alwis", "Soumyadeep Chandra", "Deepak Ravikumar", "Kaushik Roy"], "title": "Loss Knows Best: Detecting Annotation Errors in Videos via Loss Trajectories", "categories": ["cs.CV", "cs.LG"], "comment": "8 pages, 5 figures, 6 tables", "summary": "High-quality video datasets are foundational for training robust models in tasks like action recognition, phase detection, and event segmentation. However, many real-world video datasets suffer from annotation errors such as *mislabeling*, where segments are assigned incorrect class labels, and *disordering*, where the temporal sequence does not follow the correct progression. These errors are particularly harmful in phase-annotated tasks, where temporal consistency is critical. We propose a novel, model-agnostic method for detecting annotation errors by analyzing the Cumulative Sample Loss (CSL)--defined as the average loss a frame incurs when passing through model checkpoints saved across training epochs. This per-frame loss trajectory acts as a dynamic fingerprint of frame-level learnability. Mislabeled or disordered frames tend to show consistently high or irregular loss patterns, as they remain difficult for the model to learn throughout training, while correctly labeled frames typically converge to low loss early. To compute CSL, we train a video segmentation model and store its weights at each epoch. These checkpoints are then used to evaluate the loss of each frame in a test video. Frames with persistently high CSL are flagged as likely candidates for annotation errors, including mislabeling or temporal misalignment. Our method does not require ground truth on annotation errors and is generalizable across datasets. Experiments on EgoPER and Cholec80 demonstrate strong detection performance, effectively identifying subtle inconsistencies such as mislabeling and frame disordering. The proposed approach provides a powerful tool for dataset auditing and improving training reliability in video-based machine learning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7d2f\u79ef\u6837\u672c\u635f\u5931\uff08CSL\uff09\u7684\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u89c6\u9891\u6570\u636e\u96c6\u4e2d\u5e27\u7ea7\u6807\u6ce8\u9519\u8bef\uff08\u5982\u8bef\u6807\u548c\u65f6\u5e8f\u9519\u4e71\uff09\uff0c\u65e0\u9700\u771f\u5b9e\u9519\u8bef\u6807\u7b7e\uff0c\u5728EgoPER\u548cCholec80\u4e0a\u9a8c\u8bc1\u6709\u6548\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u89c6\u9891\u6570\u636e\u96c6\u5e38\u5b58\u5728\u6807\u6ce8\u9519\u8bef\uff08\u5982\u8bef\u6807\u548c\u65f6\u5e8f\u9519\u4e71\uff09\uff0c\u5c24\u5176\u5728\u5bf9\u65f6\u95f4\u4e00\u81f4\u6027\u8981\u6c42\u9ad8\u7684\u9636\u6bb5\u6807\u6ce8\u4efb\u52a1\u4e2d\u5371\u5bb3\u663e\u8457\uff0c\u4e9f\u9700\u6709\u6548\u65b9\u6cd5\u8fdb\u884c\u81ea\u52a8\u68c0\u6d4b\u4ee5\u63d0\u5347\u6a21\u578b\u8bad\u7ec3\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6bcf\u5e27\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5404\u8f6e\u6b21\u6a21\u578b\u68c0\u67e5\u70b9\u4e0a\u7684\u5e73\u5747\u635f\u5931\uff08\u5373\u7d2f\u79ef\u6837\u672c\u635f\u5931\uff0cCSL\uff09\u6765\u8bc6\u522b\u5f02\u5e38\u5e27\uff1b\u8bef\u6807\u6216\u9519\u5e8f\u5e27\u901a\u5e38\u8868\u73b0\u51fa\u6301\u7eed\u9ad8\u6216\u4e0d\u89c4\u5219\u7684\u635f\u5931\u6a21\u5f0f\uff0c\u800c\u6b63\u786e\u6807\u6ce8\u5e27\u5219\u65e9\u671f\u6536\u655b\u81f3\u4f4e\u635f\u5931\uff1b\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u771f\u5b9e\u9519\u8bef\u6807\u7b7e\uff0c\u4e14\u9002\u7528\u4e8e\u4e0d\u540c\u6570\u636e\u96c6\u3002", "result": "\u5728EgoPER\u548cCholec80\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u5305\u62ec\u8bef\u6807\u548c\u5e27\u987a\u5e8f\u9519\u4e71\u5728\u5185\u7684\u7ec6\u5fae\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5c55\u73b0\u51fa\u5f3a\u5065\u7684\u9519\u8bef\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e3a\u89c6\u9891\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u65e0\u76d1\u7763\u7684\u6807\u6ce8\u8d28\u91cf\u5ba1\u8ba1\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u89c6\u9891\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u8bad\u7ec3\u53ef\u9760\u6027\u548c\u6570\u636e\u8d28\u91cf\u3002", "summary_cn": "\u9ad8\u8d28\u91cf\u89c6\u9891\u6570\u636e\u96c6\u662f\u8bad\u7ec3\u52a8\u4f5c\u8bc6\u522b\u3001\u9636\u6bb5\u68c0\u6d4b\u548c\u4e8b\u4ef6\u5206\u5272\u7b49\u4efb\u52a1\u9c81\u68d2\u6a21\u578b\u7684\u57fa\u7840\u3002\u7136\u800c\uff0c\u8bb8\u591a\u73b0\u5b9e\u4e16\u754c\u7684\u89c6\u9891\u6570\u636e\u96c6\u5b58\u5728\u6807\u6ce8\u9519\u8bef\uff0c\u4f8b\u5982\u201c\u8bef\u6807\u201d\uff08\u5373\u7247\u6bb5\u88ab\u8d4b\u4e88\u9519\u8bef\u7684\u7c7b\u522b\u6807\u7b7e\uff09\u548c\u201c\u65f6\u5e8f\u9519\u4e71\u201d\uff08\u5373\u65f6\u95f4\u5e8f\u5217\u672a\u9075\u5faa\u6b63\u786e\u7684\u8fdb\u5c55\u987a\u5e8f\uff09\u3002\u8fd9\u4e9b\u9519\u8bef\u5728\u9636\u6bb5\u6807\u6ce8\u4efb\u52a1\u4e2d\u5c24\u5176\u6709\u5bb3\uff0c\u56e0\u4e3a\u8fd9\u7c7b\u4efb\u52a1\u5bf9\u65f6\u95f4\u4e00\u81f4\u6027\u8981\u6c42\u6781\u9ad8\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u7d2f\u79ef\u6837\u672c\u635f\u5931\uff08Cumulative Sample Loss, CSL\uff09\u6765\u68c0\u6d4b\u6807\u6ce8\u9519\u8bef\u2014\u2014CSL\u5b9a\u4e49\u4e3a\u4e00\u5e27\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5404\u8f6e\u6b21\u4fdd\u5b58\u7684\u6a21\u578b\u68c0\u67e5\u70b9\u4e0a\u6240\u4ea7\u751f\u7684\u5e73\u5747\u635f\u5931\u3002\u8fd9\u79cd\u9010\u5e27\u7684\u635f\u5931\u8f68\u8ff9\u53ef\u4f5c\u4e3a\u5e27\u7ea7\u53ef\u5b66\u4e60\u6027\u7684\u52a8\u6001\u6307\u7eb9\uff1a\u8bef\u6807\u6216\u65f6\u5e8f\u9519\u4e71\u7684\u5e27\u901a\u5e38\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u6301\u7eed\u8f83\u9ad8\u6216\u4e0d\u89c4\u5219\u7684\u635f\u5931\u6a21\u5f0f\uff0c\u800c\u6b63\u786e\u6807\u6ce8\u7684\u5e27\u5219\u5f80\u5f80\u5728\u65e9\u671f\u5c31\u6536\u655b\u5230\u8f83\u4f4e\u635f\u5931\u3002\u4e3a\u8ba1\u7b97CSL\uff0c\u6211\u4eec\u8bad\u7ec3\u4e00\u4e2a\u89c6\u9891\u5206\u5272\u6a21\u578b\uff0c\u5e76\u5728\u6bcf\u4e2a\u8bad\u7ec3\u8f6e\u6b21\u4fdd\u5b58\u5176\u6743\u91cd\uff1b\u968f\u540e\u5229\u7528\u8fd9\u4e9b\u68c0\u67e5\u70b9\u8bc4\u4f30\u6d4b\u8bd5\u89c6\u9891\u4e2d\u6bcf\u4e00\u5e27\u7684\u635f\u5931\u3002\u6301\u7eed\u9ad8CSL\u7684\u5e27\u5c06\u88ab\u6807\u8bb0\u4e3a\u53ef\u80fd\u5b58\u5728\u6807\u6ce8\u9519\u8bef\uff08\u5305\u62ec\u8bef\u6807\u6216\u65f6\u95f4\u9519\u4f4d\uff09\u7684\u5019\u9009\u5bf9\u8c61\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u6807\u6ce8\u9519\u8bef\u7684\u771f\u5b9e\u6807\u7b7e\uff0c\u4e14\u53ef\u5728\u4e0d\u540c\u6570\u636e\u96c6\u95f4\u6cdb\u5316\u3002\u5728EgoPER\u548cCholec80\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u5f3a\u5927\u7684\u68c0\u6d4b\u6027\u80fd\uff0c\u80fd\u6709\u6548\u8bc6\u522b\u8bf8\u5982\u8bef\u6807\u548c\u5e27\u987a\u5e8f\u9519\u4e71\u7b49\u7ec6\u5fae\u4e0d\u4e00\u81f4\u95ee\u9898\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u89c6\u9891\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u96c6\u5ba1\u8ba1\u548c\u63d0\u5347\u8bad\u7ec3\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2602.15167", "pdf": "https://arxiv.org/pdf/2602.15167", "abs": "https://arxiv.org/abs/2602.15167", "authors": ["Xiaoyi Wen", "Fei Jiang"], "title": "Distributional Deep Learning for Super-Resolution of 4D Flow MRI under Domain Shift", "categories": ["cs.CV", "stat.AP", "stat.ML"], "comment": null, "summary": "Super-resolution is widely used in medical imaging to enhance low-quality data, reducing scan time and improving abnormality detection. Conventional super-resolution approaches typically rely on paired datasets of downsampled and original high resolution images, training models to reconstruct high resolution images from their artificially degraded counterparts. However, in real-world clinical settings, low resolution data often arise from acquisition mechanisms that differ significantly from simple downsampling. As a result, these inputs may lie outside the domain of the training data, leading to poor model generalization due to domain shift. To address this limitation, we propose a distributional deep learning framework that improves model robustness and domain generalization. We develop this approch for enhancing the resolution of 4D Flow MRI (4DF). This is a novel imaging modality that captures hemodynamic flow velocity and clinically relevant metrics such as vessel wall stress. These metrics are critical for assessing aneurysm rupture risk. Our model is initially trained on high resolution computational fluid dynamics (CFD) simulations and their downsampled counterparts. It is then fine-tuned on a small, harmonized dataset of paired 4D Flow MRI and CFD samples. We derive the theoretical properties of our distributional estimators and demonstrate that our framework significantly outperforms traditional deep learning approaches through real data applications. This highlights the effectiveness of distributional learning in addressing domain shift and improving super-resolution performance in clinically realistic scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u6df1\u5ea6\u5b66\u4e60\u7684\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53474D Flow MRI\u56fe\u50cf\u8d28\u91cf\uff0c\u5728\u5b58\u5728\u57df\u504f\u79fb\u7684\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u901a\u8fc7\u7b80\u5355\u4e0b\u91c7\u6837\u751f\u6210\u7684\u914d\u5bf9\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f46\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\uff0c\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u5f80\u5f80\u6e90\u4e8e\u4e0e\u4e0b\u91c7\u6837\u673a\u5236\u4e0d\u540c\u7684\u91c7\u96c6\u8fc7\u7a0b\uff0c\u5bfc\u81f4\u6a21\u578b\u56e0\u57df\u504f\u79fb\u800c\u6cdb\u5316\u80fd\u529b\u5dee\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u5206\u5e03\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff1a\u9996\u5148\u5728\u9ad8\u5206\u8fa8\u7387\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\uff08CFD\uff09\u6a21\u62df\u53ca\u5176\u4e0b\u91c7\u6837\u7248\u672c\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u7136\u540e\u5728\u5c11\u91cf\u914d\u5bf9\u76844D Flow MRI\u4e0eCFD\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u63a8\u5bfc\u4e86\u8be5\u5206\u5e03\u4f30\u8ba1\u5668\u7684\u7406\u8bba\u6027\u8d28\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u3002", "conclusion": "\u5206\u5e03\u5b66\u4e60\u80fd\u6709\u6548\u5e94\u5bf9\u57df\u504f\u79fb\u95ee\u9898\uff0c\u5728\u4e34\u5e8a\u5b9e\u9645\u573a\u666f\u4e2d\u63d0\u5347\u8d85\u5206\u8fa8\u7387\u6027\u80fd\uff0c\u5c24\u5176\u9002\u7528\u4e8e4D Flow MRI\u7b49\u65b0\u578b\u533b\u5b66\u6210\u50cf\u6a21\u6001\u3002", "summary_cn": "\u8d85\u5206\u8fa8\u7387\u6280\u672f\u5e7f\u6cdb\u5e94\u7528\u4e8e\u533b\u5b66\u6210\u50cf\uff0c\u4ee5\u589e\u5f3a\u4f4e\u8d28\u91cf\u6570\u636e\uff0c\u4ece\u800c\u7f29\u77ed\u626b\u63cf\u65f6\u95f4\u5e76\u63d0\u9ad8\u5f02\u5e38\u68c0\u6d4b\u80fd\u529b\u3002\u4f20\u7edf\u7684\u8d85\u5206\u8fa8\u7387\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u7531\u4e0b\u91c7\u6837\u56fe\u50cf\u548c\u539f\u59cb\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7ec4\u6210\u7684\u914d\u5bf9\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u6a21\u578b\u4ece\u4eba\u4e3a\u9000\u5316\u7684\u56fe\u50cf\u4e2d\u91cd\u5efa\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u3002\u7136\u800c\uff0c\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\uff0c\u4f4e\u5206\u8fa8\u7387\u6570\u636e\u5f80\u5f80\u6e90\u4e8e\u4e0e\u7b80\u5355\u4e0b\u91c7\u6837\u663e\u8457\u4e0d\u540c\u7684\u91c7\u96c6\u673a\u5236\uff0c\u5bfc\u81f4\u8f93\u5165\u6570\u636e\u8d85\u51fa\u8bad\u7ec3\u6570\u636e\u7684\u5206\u5e03\u8303\u56f4\uff0c\u56e0\u57df\u504f\u79fb\u800c\u4f7f\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0b\u964d\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5206\u5e03\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u57df\u6cdb\u5316\u80fd\u529b\u3002\u6211\u4eec\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u63d0\u53474D Flow MRI\uff084DF\uff09\u7684\u5206\u8fa8\u7387\u30024D Flow MRI\u662f\u4e00\u79cd\u65b0\u578b\u6210\u50cf\u6a21\u6001\uff0c\u53ef\u6355\u6349\u8840\u6d41\u901f\u5ea6\u53ca\u8840\u7ba1\u58c1\u5e94\u529b\u7b49\u4e34\u5e8a\u76f8\u5173\u6307\u6807\uff0c\u8fd9\u4e9b\u6307\u6807\u5bf9\u4e8e\u8bc4\u4f30\u52a8\u8109\u7624\u7834\u88c2\u98ce\u9669\u81f3\u5173\u91cd\u8981\u3002\u6211\u4eec\u7684\u6a21\u578b\u9996\u5148\u5728\u9ad8\u5206\u8fa8\u7387\u8ba1\u7b97\u6d41\u4f53\u52a8\u529b\u5b66\uff08CFD\uff09\u6a21\u62df\u53ca\u5176\u4e0b\u91c7\u6837\u7248\u672c\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u968f\u540e\u5728\u4e00\u4e2a\u5c0f\u89c4\u6a21\u4f46\u7ecf\u8fc7\u534f\u8c03\u76844D Flow MRI\u4e0eCFD\u914d\u5bf9\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002\u6211\u4eec\u63a8\u5bfc\u4e86\u6240\u63d0\u5206\u5e03\u4f30\u8ba1\u5668\u7684\u7406\u8bba\u6027\u8d28\uff0c\u5e76\u901a\u8fc7\u771f\u5b9e\u6570\u636e\u5e94\u7528\u8bc1\u660e\u8be5\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002\u8fd9\u51f8\u663e\u4e86\u5206\u5e03\u5b66\u4e60\u5728\u5e94\u5bf9\u57df\u504f\u79fb\u3001\u63d0\u5347\u4e34\u5e8a\u73b0\u5b9e\u573a\u666f\u4e2d\u8d85\u5206\u8fa8\u7387\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.15181", "pdf": "https://arxiv.org/pdf/2602.15181", "abs": "https://arxiv.org/abs/2602.15181", "authors": ["Yunxiao Zhang", "William Stone", "Suryansh Kumar"], "title": "Time-Archival Camera Virtualization for Sports and Visual Performances", "categories": ["cs.CV", "cs.LG", "cs.RO"], "comment": "Project Page: https://yunxiaozhangjack.com/tacv/; Under minor revision in Journal of Computer Vision and Image Understanding (CVIU); Special Issue: Computer Vision for Sports and Winter Sports. Outcome of a master and bachelor student project completed in Visual and Spatial AI Lab at TAMU", "summary": "Camera virtualization -- an emerging solution to novel view synthesis -- holds transformative potential for visual entertainment, live performances, and sports broadcasting by enabling the generation of photorealistic images from novel viewpoints using images from a limited set of calibrated multiple static physical cameras. Despite recent advances, achieving spatially and temporally coherent and photorealistic rendering of dynamic scenes with efficient time-archival capabilities, particularly in fast-paced sports and stage performances, remains challenging for existing approaches. Recent methods based on 3D Gaussian Splatting (3DGS) for dynamic scenes could offer real-time view-synthesis results. Yet, they are hindered by their dependence on accurate 3D point clouds from the structure-from-motion method and their inability to handle large, non-rigid, rapid motions of different subjects (e.g., flips, jumps, articulations, sudden player-to-player transitions). Moreover, independent motions of multiple subjects can break the Gaussian-tracking assumptions commonly used in 4DGS, ST-GS, and other dynamic splatting variants. This paper advocates reconsidering a neural volume rendering formulation for camera virtualization and efficient time-archival capabilities, making it useful for sports broadcasting and related applications. By modeling a dynamic scene as rigid transformations across multiple synchronized camera views at a given time, our method performs neural representation learning, providing enhanced visual rendering quality at test time. A key contribution of our approach is its support for time-archival, i.e., users can revisit any past temporal instance of a dynamic scene and can perform novel view synthesis, enabling retrospective rendering for replay, analysis, and archival of live events, a functionality absent in existing neural rendering approaches and novel view synthesis...", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u4f53\u6e32\u67d3\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u52a8\u6001\u573a\u666f\u7684\u76f8\u673a\u865a\u62df\u5316\uff0c\u652f\u6301\u9ad8\u8d28\u91cf\u3001\u65f6\u7a7a\u4e00\u81f4\u7684\u65b0\u89c6\u89d2\u5408\u6210\u4e0e\u65f6\u95f4\u56de\u6eaf\u529f\u80fd\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f53\u80b2\u8d5b\u4e8b\u7b49\u5feb\u901f\u8fd0\u52a8\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u65b9\u6cd5\u5728\u5904\u7406\u591a\u4e3b\u4f53\u3001\u975e\u521a\u6027\u3001\u5feb\u901f\u8fd0\u52a8\uff08\u5982\u7ffb\u8f6c\u3001\u8df3\u8dc3\u3001\u7403\u5458\u95f4\u5feb\u901f\u5207\u6362\uff09\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u4e14\u4f9d\u8d56\u7cbe\u786e\u7684\u8fd0\u52a8\u7ed3\u6784\uff08SfM\uff09\u70b9\u4e91\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u65f6\u95f4\u5b58\u6863\u4e0e\u56de\u6eaf\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u517c\u987e\u6e32\u67d3\u8d28\u91cf\u3001\u65f6\u7a7a\u4e00\u81f4\u6027\u4e0e\u65f6\u95f4\u56de\u6eaf\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u91cd\u65b0\u91c7\u7528\u795e\u7ecf\u4f53\u6e32\u67d3\u6846\u67b6\uff0c\u5c06\u52a8\u6001\u573a\u666f\u5efa\u6a21\u4e3a\u5728\u7ed9\u5b9a\u65f6\u523b\u591a\u4e2a\u540c\u6b65\u76f8\u673a\u89c6\u89d2\u4e0b\u7684\u521a\u6027\u53d8\u6362\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u8868\u793a\u5b66\u4e60\u63d0\u5347\u6d4b\u8bd5\u65f6\u7684\u6e32\u67d3\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u652f\u6301\u65f6\u95f4\u5b58\u6863\uff0c\u5141\u8bb8\u7528\u6237\u56de\u6eaf\u4efb\u610f\u5386\u53f2\u65f6\u523b\u5e76\u8fdb\u884c\u65b0\u89c6\u89d2\u5408\u6210\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u89c6\u89c9\u6e32\u67d3\u8d28\u91cf\u4e0a\u4f18\u4e8e\u73b0\u6709\u52a8\u6001\u9ad8\u65af\u6cfc\u6e85\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u5b9e\u73b0\u4e86\u5bf9\u52a8\u6001\u573a\u666f\u7684\u9ad8\u6548\u65f6\u95f4\u5b58\u6863\u4e0e\u56de\u6eaf\u6e32\u67d3\uff0c\u9002\u7528\u4e8e\u4f53\u80b2\u76f4\u64ad\u7b49\u9700\u8981\u56de\u653e\u4e0e\u5206\u6790\u7684\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u795e\u7ecf\u4f53\u6e32\u67d3\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u52a8\u6001\u65b0\u89c6\u89d2\u5408\u6210\u6280\u672f\u5728\u5904\u7406\u590d\u6742\u8fd0\u52a8\u548c\u65f6\u95f4\u5b58\u6863\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u4f53\u80b2\u5e7f\u64ad\u7b49\u5b9e\u65f6\u89c6\u89c9\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "summary_cn": "\u76f8\u673a\u865a\u62df\u5316\u2014\u2014\u4e00\u79cd\u65b0\u5174\u7684\u65b0\u89c6\u89d2\u5408\u6210\u89e3\u51b3\u65b9\u6848\u2014\u2014\u901a\u8fc7\u4f7f\u7528\u6709\u9650\u6570\u91cf\u7684\u7ecf\u8fc7\u6807\u5b9a\u7684\u9759\u6001\u7269\u7406\u76f8\u673a\u56fe\u50cf\u751f\u6210\u903c\u771f\u7684\u65b0\u89c6\u89d2\u56fe\u50cf\uff0c\u5728\u89c6\u89c9\u5a31\u4e50\u3001\u73b0\u573a\u8868\u6f14\u548c\u4f53\u80b2\u8f6c\u64ad\u9886\u57df\u5177\u6709\u53d8\u9769\u6027\u6f5c\u529b\u3002\u5c3d\u7ba1\u8fd1\u671f\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u73b0\u5177\u6709\u9ad8\u6548\u65f6\u95f4\u5b58\u6863\u80fd\u529b\u7684\u52a8\u6001\u573a\u666f\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u4e00\u81f4\u4e14\u903c\u771f\u7684\u6e32\u67d3\u65b9\u9762\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5feb\u8282\u594f\u7684\u4f53\u80b2\u8d5b\u4e8b\u548c\u821e\u53f0\u8868\u6f14\u4e2d\u3002\u6700\u8fd1\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u52a8\u6001\u573a\u666f\u65b9\u6cd5\u867d\u80fd\u63d0\u4f9b\u5b9e\u65f6\u89c6\u56fe\u5408\u6210\u7ed3\u679c\uff0c\u4f46\u5176\u53d7\u9650\u4e8e\u5bf9\u8fd0\u52a8\u7ed3\u6784\uff08Structure-from-Motion\uff09\u65b9\u6cd5\u6240\u751f\u6210\u7684\u7cbe\u786e3D\u70b9\u4e91\u7684\u4f9d\u8d56\uff0c\u5e76\u4e14\u65e0\u6cd5\u5904\u7406\u4e0d\u540c\u4e3b\u4f53\u7684\u5927\u5c3a\u5ea6\u3001\u975e\u521a\u6027\u3001\u5feb\u901f\u8fd0\u52a8\uff08\u4f8b\u5982\u7ffb\u8f6c\u3001\u8df3\u8dc3\u3001\u5173\u8282\u8fd0\u52a8\u3001\u7403\u5458\u95f4\u7684\u7a81\u7136\u8f6c\u6362\uff09\u3002\u6b64\u5916\uff0c\u591a\u4e2a\u4e3b\u4f53\u7684\u72ec\u7acb\u8fd0\u52a8\u4f1a\u7834\u574f4DGS\u3001ST-GS\u53ca\u5176\u4ed6\u52a8\u6001\u6cfc\u6e85\u53d8\u4f53\u4e2d\u5e38\u7528\u7684\u9ad8\u65af\u8ddf\u8e2a\u5047\u8bbe\u3002\u672c\u6587\u4e3b\u5f20\u91cd\u65b0\u8003\u8651\u7528\u4e8e\u76f8\u673a\u865a\u62df\u5316\u7684\u795e\u7ecf\u4f53\u6e32\u67d3\u516c\u5f0f\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u65f6\u95f4\u5b58\u6863\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u4f53\u80b2\u8f6c\u64ad\u53ca\u76f8\u5173\u5e94\u7528\u4e2d\u66f4\u4e3a\u5b9e\u7528\u3002\u901a\u8fc7\u5c06\u52a8\u6001\u573a\u666f\u5efa\u6a21\u4e3a\u5728\u7ed9\u5b9a\u65f6\u95f4\u70b9\u8de8\u591a\u4e2a\u540c\u6b65\u76f8\u673a\u89c6\u89d2\u7684\u521a\u6027\u53d8\u6362\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6267\u884c\u795e\u7ecf\u8868\u793a\u5b66\u4e60\uff0c\u4ece\u800c\u5728\u6d4b\u8bd5\u65f6\u63d0\u4f9b\u589e\u5f3a\u7684\u89c6\u89c9\u6e32\u67d3\u8d28\u91cf\u3002\u6211\u4eec\u65b9\u6cd5\u7684\u4e00\u4e2a\u5173\u952e\u8d21\u732e\u5728\u4e8e\u5176\u652f\u6301\u65f6\u95f4\u5b58\u6863\uff0c\u5373\u7528\u6237\u53ef\u4ee5\u56de\u6eaf\u52a8\u6001\u573a\u666f\u7684\u4efb\u610f\u8fc7\u53bb\u65f6\u95f4\u70b9\u5e76\u6267\u884c\u65b0\u89c6\u89d2\u5408\u6210\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u73b0\u573a\u4e8b\u4ef6\u7684\u56de\u653e\u3001\u5206\u6790\u548c\u5b58\u6863\u7684\u56de\u6eaf\u6e32\u67d3\u529f\u80fd\uff0c\u800c\u8fd9\u4e00\u529f\u80fd\u5728\u73b0\u6709\u7684\u795e\u7ecf\u6e32\u67d3\u65b9\u6cd5\u548c\u65b0\u89c6\u89d2\u5408\u6210\u6280\u672f\u4e2d\u662f\u7f3a\u5931\u7684\u3002"}}
{"id": "2602.15257", "pdf": "https://arxiv.org/pdf/2602.15257", "abs": "https://arxiv.org/abs/2602.15257", "authors": ["Austin Veselka"], "title": "How to Train Your Long-Context Visual Document Model", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are open-weight, namely Qwen3 VL and GLM 4.5/6V, their training recipes and data pipelines are not reproducible. We systematically study continued pretraining, supervised finetuning, and preference optimization for 24B and 32B parameter models, backed by extensive LC evaluations and ablations to bridge this gap, and achieve state-of-the-art performance on MMLongBenchDoc for both parameter scales. In addition to this, our key findings include: (i) training on context lengths that match evaluation context lengths outperforms training on longer contexts, (ii) training and evaluating with page indices provides a simple, high-impact boost to long-document performance, (iii) our synthetic data pipelines enable self-improvement via continued pretraining and supervised finetuning, and (iv) we extend the known text-to-visual long context transfer to the reverse, showing that visual long context training transfers to long-context text performance. We also release MMLBD-C, a manually corrected version of MMLongBenchDoc to reduce erroneous and low quality examples in the benchmark.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u957f\u8fbe344K\u4e0a\u4e0b\u6587\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u8bad\u7ec3\u7814\u7a76\uff0c\u7cfb\u7edf\u63a2\u7d22\u4e8624B\u548c32B\u53c2\u6570\u6a21\u578b\u5728\u957f\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\u7b56\u7565\uff0c\u5728MMLongBenchDoc\u4e0a\u8fbe\u5230SOTA\uff0c\u5e76\u63ed\u793a\u4e86\u82e5\u5e72\u5173\u952e\u53d1\u73b0\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u957f\u5ea6\u5339\u914d\u3001\u9875\u7801\u7d22\u5f15\u4f7f\u7528\u3001\u5408\u6210\u6570\u636e\u81ea\u63d0\u5347\u4ee5\u53ca\u89c6\u89c9-\u6587\u672c\u957f\u4e0a\u4e0b\u6587\u8fc1\u79fb\u7b49\u3002", "motivation": "\u5f53\u524d\u867d\u6709\u5982Qwen3 VL\u548cGLM 4.5/6V\u7b49\u5f00\u6e90\u957f\u4e0a\u4e0b\u6587\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5176\u8bad\u7ec3\u65b9\u6cd5\u548c\u6570\u636e\u6d41\u7a0b\u4e0d\u53ef\u590d\u73b0\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4f5c\u8005\u5f00\u5c55\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u65e8\u5728\u5efa\u7acb\u53ef\u590d\u73b0\u7684\u957f\u4e0a\u4e0b\u6587\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u8303\u5f0f\uff0c\u5e76\u6df1\u5165\u7406\u89e3\u5f71\u54cd\u957f\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002", "method": "\u4f5c\u8005\u5bf924B\u548c32B\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6027\u5b9e\u9a8c\uff0c\u6db5\u76d6\u6301\u7eed\u9884\u8bad\u7ec3\uff08continued pretraining\uff09\u3001\u76d1\u7763\u5fae\u8c03\uff08supervised finetuning\uff09\u548c\u504f\u597d\u4f18\u5316\uff08preference optimization\uff09\uff1b\u6784\u5efa\u5408\u6210\u6570\u636e\u7ba1\u9053\uff1b\u5728\u591a\u79cd\u957f\u4e0a\u4e0b\u6587\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\uff1b\u5e76\u5f15\u5165\u9875\u7801\u7d22\u5f15\u4f5c\u4e3a\u8f93\u5165\u7279\u5f81\u3002", "result": "\u5728MMLongBenchDoc\u57fa\u51c6\u4e0a\uff0c\u4e24\u4e2a\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u5747\u53d6\u5f97\u5f53\u524d\u6700\u4f18\u6027\u80fd\uff1b\u53d1\u73b0\u5339\u914d\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u4e0a\u4e0b\u6587\u957f\u5ea6\u66f4\u6709\u6548\uff1b\u4f7f\u7528\u9875\u7801\u7d22\u5f15\u663e\u8457\u63d0\u5347\u957f\u6587\u6863\u6027\u80fd\uff1b\u5408\u6210\u6570\u636e\u652f\u6301\u6a21\u578b\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u5b9e\u73b0\u81ea\u6211\u6539\u8fdb\uff1b\u9996\u6b21\u9a8c\u8bc1\u4e86\u89c6\u89c9\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u53ef\u53cd\u5411\u8fc1\u79fb\u5230\u7eaf\u6587\u672c\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u590d\u73b0\u7684\u957f\u4e0a\u4e0b\u6587\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u63d0\u5347\u957f\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u6027\u80fd\u7684\u5173\u952e\u6280\u672f\u8def\u5f84\uff0c\u5e76\u8bc1\u5b9e\u4e86\u89c6\u89c9\u4e0e\u6587\u672c\u957f\u4e0a\u4e0b\u6587\u80fd\u529b\u4e4b\u95f4\u7684\u53cc\u5411\u8fc1\u79fb\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u591a\u6a21\u6001\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86\u9996\u4e2a\u5168\u9762\u3001\u5927\u89c4\u6a21\u7684\u957f\u4e0a\u4e0b\u6587\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7814\u7a76\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u6700\u9ad8\u8fbe344K\uff0c\u805a\u7126\u4e8e\u957f\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\uff0c\u5e76\u8003\u5bdf\u5176\u5411\u957f\u4e0a\u4e0b\u6587\u7eaf\u6587\u672c\u4efb\u52a1\u7684\u8fc1\u79fb\u80fd\u529b\u3002\u5c3d\u7ba1\u76ee\u524d\u5df2\u6709\u82e5\u5e72\u5f3a\u5927\u7684\u5f00\u6e90\u6a21\u578b\uff08\u5982Qwen3 VL\u548cGLM 4.5/6V\uff09\uff0c\u4f46\u5176\u8bad\u7ec3\u65b9\u6848\u548c\u6570\u636e\u6d41\u7a0b\u4e0d\u53ef\u590d\u73b0\u3002\u6211\u4eec\u7cfb\u7edf\u5730\u7814\u7a76\u4e8624B\u548c32B\u53c2\u6570\u89c4\u6a21\u6a21\u578b\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\u7b56\u7565\uff0c\u8f85\u4ee5\u5e7f\u6cdb\u7684\u957f\u4e0a\u4e0b\u6587\u8bc4\u4f30\u548c\u6d88\u878d\u5b9e\u9a8c\uff0c\u4ee5\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5e76\u5728MMLongBenchDoc\u57fa\u51c6\u4e0a\u5bf9\u4e24\u79cd\u53c2\u6570\u89c4\u6a21\u5747\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u5173\u952e\u53d1\u73b0\u5305\u62ec\uff1a(i) \u4f7f\u7528\u4e0e\u8bc4\u4f30\u4e0a\u4e0b\u6587\u957f\u5ea6\u76f8\u5339\u914d\u7684\u957f\u5ea6\u8fdb\u884c\u8bad\u7ec3\uff0c\u4f18\u4e8e\u4f7f\u7528\u66f4\u957f\u4e0a\u4e0b\u6587\u8fdb\u884c\u8bad\u7ec3\uff1b(ii) \u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u4e2d\u5f15\u5165\u9875\u7801\u7d22\u5f15\uff0c\u80fd\u7b80\u5355\u800c\u663e\u8457\u5730\u63d0\u5347\u957f\u6587\u6863\u6027\u80fd\uff1b(iii) \u6211\u4eec\u7684\u5408\u6210\u6570\u636e\u7ba1\u9053\u80fd\u591f\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u6a21\u578b\u7684\u81ea\u6211\u6539\u8fdb\uff1b(iv) \u6211\u4eec\u5c06\u5df2\u77e5\u7684\u6587\u672c\u5230\u89c6\u89c9\u7684\u957f\u4e0a\u4e0b\u6587\u8fc1\u79fb\u6269\u5c55\u5230\u4e86\u53cd\u5411\u60c5\u5f62\uff0c\u8bc1\u660e\u4e86\u89c6\u89c9\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u4e5f\u80fd\u8fc1\u79fb\u5230\u957f\u4e0a\u4e0b\u6587\u6587\u672c\u4efb\u52a1\u7684\u6027\u80fd\u63d0\u5347\u3002\u6211\u4eec\u8fd8\u53d1\u5e03\u4e86MMLBD-C\uff0c\u8fd9\u662fMMLongBenchDoc\u7684\u4e00\u4e2a\u624b\u52a8\u4fee\u6b63\u7248\u672c\uff0c\u65e8\u5728\u51cf\u5c11\u57fa\u51c6\u4e2d\u9519\u8bef\u548c\u4f4e\u8d28\u91cf\u7684\u6837\u672c\u3002"}}
{"id": "2602.15277", "pdf": "https://arxiv.org/pdf/2602.15277", "abs": "https://arxiv.org/abs/2602.15277", "authors": ["Muhammad J. Alahmadi", "Peng Gao", "Feiyi Wang", "Dongkuan", "Xu"], "title": "Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large-scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration-Exploitation Distillation (E^2D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E^2D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being 18x faster, and on ImageNet-21K, our method substantially improves accuracy while remaining 4.3x faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u63a2\u7d22-\u5229\u7528\u84b8\u998f\uff08E\u00b2D\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u84b8\u998f\u4e2d\u540c\u65f6\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u548c\u9ad8\u6548\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89e3\u8026\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u84b8\u998f\u65b9\u6cd5\u5728\u6548\u7387\u4e0e\u51c6\u786e\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff1a\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u51c6\u786e\u7387\u9ad8\u4f46\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u65e0\u4f18\u5316\u65b9\u6cd5\u6548\u7387\u9ad8\u4f46\u727a\u7272\u51c6\u786e\u7387\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51faE\u00b2D\u65b9\u6cd5\uff0c\u91c7\u7528\u9ad8\u6548\u6d41\u6c34\u7ebf\uff1a\u9996\u5148\u4ee5\u5168\u56fe\u50cf\u521d\u59cb\u5316\u4fdd\u7559\u8bed\u4e49\u5b8c\u6574\u6027\u548c\u7279\u5f81\u591a\u6837\u6027\uff1b\u7136\u540e\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\u2014\u2014\u63a2\u7d22\u9636\u6bb5\u8fdb\u884c\u5747\u5300\u66f4\u65b0\u5e76\u8bc6\u522b\u9ad8\u635f\u5931\u533a\u57df\uff0c\u5229\u7528\u9636\u6bb5\u805a\u7126\u4e8e\u8fd9\u4e9b\u533a\u57df\u52a0\u901f\u6536\u655b\u3002", "result": "\u5728ImageNet-1K\u4e0a\u8d85\u8d8aSOTA\u4e14\u5feb18\u500d\uff1b\u5728ImageNet-21K\u4e0a\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u4e14\u5feb4.3\u500d\u3002", "conclusion": "\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u3001\u51cf\u5c11\u5197\u4f59\u7684\u66f4\u65b0\u7b56\u7565\uff0c\u800c\u975e\u66b4\u529b\u4f18\u5316\uff0c\u53ef\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u84b8\u998f\u4e2d\u6709\u6548\u5f25\u5408\u51c6\u786e\u7387\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "summary_cn": "\u6570\u636e\u96c6\u84b8\u998f\u5c06\u539f\u59cb\u6570\u636e\u538b\u7f29\u4e3a\u7d27\u51d1\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5728\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u5b58\u50a8\u9700\u6c42\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4ece\u800c\u652f\u6301\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u90e8\u7f72\u3002\u5c3d\u7ba1\u8fd1\u671f\u57fa\u4e8e\u89e3\u8026\u7684\u84b8\u998f\u65b9\u6cd5\u5df2\u80fd\u5b9e\u73b0\u5927\u89c4\u6a21\u6570\u636e\u96c6\u84b8\u998f\uff0c\u4f46\u4ecd\u9762\u4e34\u6548\u7387\u5dee\u8ddd\uff1a\u57fa\u4e8e\u4f18\u5316\u7684\u89e3\u8026\u65b9\u6cd5\u867d\u7136\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u5de8\u5927\uff1b\u800c\u65e0\u9700\u4f18\u5316\u7684\u89e3\u8026\u65b9\u6cd5\u867d\u9ad8\u6548\uff0c\u5374\u727a\u7272\u4e86\u51c6\u786e\u7387\u3002\u4e3a\u514b\u670d\u8fd9\u4e00\u6743\u8861\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u63a2\u7d22-\u5229\u7528\u84b8\u998f\uff08Exploration-Exploitation Distillation, E\u00b2D\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u7b80\u5355\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u6d41\u6c34\u7ebf\u6765\u6700\u5c0f\u5316\u5197\u4f59\u8ba1\u7b97\uff1a\u9996\u5148\u91c7\u7528\u5168\u56fe\u50cf\u521d\u59cb\u5316\u4ee5\u4fdd\u7559\u8bed\u4e49\u5b8c\u6574\u6027\u548c\u7279\u5f81\u591a\u6837\u6027\uff0c\u968f\u540e\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\u2014\u2014\u63a2\u7d22\u9636\u6bb5\u6267\u884c\u5747\u5300\u66f4\u65b0\u5e76\u8bc6\u522b\u9ad8\u635f\u5931\u533a\u57df\uff0c\u5229\u7528\u9636\u6bb5\u5219\u805a\u7126\u4e8e\u8fd9\u4e9b\u533a\u57df\u4ee5\u52a0\u901f\u6536\u655b\u3002\u6211\u4eec\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u4e0a\u8bc4\u4f30\u4e86E\u00b2D\uff0c\u5728ImageNet-1K\u4e0a\u8d85\u8d8a\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u4e14\u901f\u5ea6\u63d0\u534718\u500d\uff1b\u5728ImageNet-21K\u4e0a\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u4fdd\u63014.3\u500d\u52a0\u901f\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u6709\u9488\u5bf9\u6027\u5730\u51cf\u5c11\u5197\u4f59\u66f4\u65b0\uff0c\u800c\u975e\u4f9d\u8d56\u66b4\u529b\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u5f25\u5408\u5927\u89c4\u6a21\u6570\u636e\u96c6\u84b8\u998f\u4e2d\u51c6\u786e\u7387\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\uff1ahttps://github.com/ncsu-dk-lab\u3002"}}
{"id": "2602.15278", "pdf": "https://arxiv.org/pdf/2602.15278", "abs": "https://arxiv.org/abs/2602.15278", "authors": ["Manuel Cherep", "Pranav M R", "Pattie Maes", "Nikhil Singh"], "title": "Visual Persuasion: What Influences Decisions of Vision-Language Models?", "categories": ["cs.CV", "cs.AI"], "comment": "45 pages, 17 figures", "summary": "The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision function as a latent visual utility that can be inferred through revealed preference: choices between systematically edited images. Starting from common images, such as product photos, we propose methods for visual prompt optimization, adapting text optimization methods to iteratively propose and apply visually plausible modifications using an image generation model (such as in composition, lighting, or background). We then evaluate which edits increase selection probability. Through large-scale experiments on frontier VLMs, we demonstrate that optimized edits significantly shift choice probabilities in head-to-head comparisons. We develop an automatic interpretability pipeline to explain these preferences, identifying consistent visual themes that drive selection. We argue that this approach offers a practical and efficient way to surface visual vulnerabilities, safety concerns that might otherwise be discovered implicitly in the wild, supporting more proactive auditing and governance of image-based AI agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u63a7\u56fe\u50cf\u9009\u62e9\u4efb\u52a1\u548c\u7cfb\u7edf\u6027\u6270\u52a8\u8f93\u5165\uff0c\u7814\u7a76\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u89c6\u89c9\u504f\u597d\u3002\u5229\u7528\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5bf9\u5e38\u89c1\u56fe\u50cf\u8fdb\u884c\u89c6\u89c9\u4e0a\u5408\u7406\u7684\u4fee\u6539\uff0c\u5e76\u8bc4\u4f30\u54ea\u4e9b\u4fee\u6539\u4f1a\u63d0\u9ad8\u88ab\u9009\u4e2d\u7684\u6982\u7387\u3002\u5b9e\u9a8c\u8868\u660e\u4f18\u5316\u540e\u7684\u7f16\u8f91\u80fd\u663e\u8457\u6539\u53d8VLM\u7684\u9009\u62e9\u503e\u5411\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\u63ed\u793a\u9a71\u52a8\u504f\u597d\u7684\u4e00\u81f4\u89c6\u89c9\u4e3b\u9898\uff0c\u4e3aAI\u4ee3\u7406\u7684\u89c6\u89c9\u5b89\u5168\u5ba1\u8ba1\u63d0\u4f9b\u9ad8\u6548\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u91cf\u7f51\u7edc\u56fe\u50cf\u6b63\u88ab\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u667a\u80fd\u4f53\u5927\u89c4\u6a21\u89e3\u8bfb\u5e76\u7528\u4e8e\u51b3\u7b56\uff08\u5982\u70b9\u51fb\u3001\u63a8\u8350\u6216\u8d2d\u4e70\uff09\uff0c\u4f46\u6211\u4eec\u5bf9\u5176\u89c6\u89c9\u504f\u597d\u7684\u7ed3\u6784\u77e5\u4e4b\u751a\u5c11\u3002\u4e3a\u4e86\u4e3b\u52a8\u53d1\u73b0\u6f5c\u5728\u7684\u89c6\u89c9\u6f0f\u6d1e\u4e0e\u5b89\u5168\u98ce\u9669\uff0c\u6709\u5fc5\u8981\u5efa\u7acb\u4e00\u79cd\u7cfb\u7edf\u6027\u65b9\u6cd5\u6765\u7814\u7a76\u548c\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\u89c6\u89c9\u51b3\u7b56\u673a\u5236\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u53d7\u63a7\u56fe\u50cf\u9009\u62e9\u4efb\u52a1\u6846\u67b6\uff0c\u5c06VLM\u7684\u51b3\u7b56\u51fd\u6570\u89c6\u4e3a\u53ef\u901a\u8fc7\u201c\u663e\u793a\u6027\u504f\u597d\u201d\u63a8\u65ad\u7684\u6f5c\u5728\u89c6\u89c9\u6548\u7528\u3002\u4ece\u5e38\u89c1\u56fe\u50cf\uff08\u5982\u4ea7\u54c1\u7167\u7247\uff09\u51fa\u53d1\uff0c\u501f\u9274\u6587\u672c\u4f18\u5316\u65b9\u6cd5\uff0c\u63d0\u51fa\u89c6\u89c9\u63d0\u793a\u4f18\u5316\u7b56\u7565\uff1a\u5229\u7528\u56fe\u50cf\u751f\u6210\u6a21\u578b\u8fed\u4ee3\u5730\u63d0\u51fa\u5e76\u5e94\u7528\u5728\u6784\u56fe\u3001\u5149\u7167\u6216\u80cc\u666f\u7b49\u65b9\u9762\u89c6\u89c9\u4e0a\u5408\u7406\u7684\u4fee\u6539\uff0c\u518d\u8bc4\u4f30\u8fd9\u4e9b\u7f16\u8f91\u5bf9\u9009\u62e9\u6982\u7387\u7684\u5f71\u54cd\u3002\u540c\u65f6\u5f00\u53d1\u81ea\u52a8\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\u4ee5\u8bc6\u522b\u9a71\u52a8\u504f\u597d\u7684\u89c6\u89c9\u4e3b\u9898\u3002", "result": "\u5728\u524d\u6cbfVLM\u4e0a\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u8868\u660e\uff0c\u7ecf\u8fc7\u4f18\u5316\u7684\u56fe\u50cf\u7f16\u8f91\u80fd\u663e\u8457\u63d0\u5347\u5176\u5728\u4e24\u4e24\u6bd4\u8f83\u4e2d\u7684\u88ab\u9009\u4e2d\u6982\u7387\u3002\u81ea\u52a8\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63ed\u793a\u4e86\u82e5\u5e72\u4e00\u81f4\u7684\u89c6\u89c9\u504f\u597d\u4e3b\u9898\uff0c\u8bf4\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63ed\u793a\u6a21\u578b\u7684\u89c6\u89c9\u51b3\u7b56\u903b\u8f91\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u624b\u6bb5\uff0c\u7528\u4e8e\u63ed\u793a\u57fa\u4e8e\u56fe\u50cf\u7684AI\u667a\u80fd\u4f53\u7684\u89c6\u89c9\u504f\u597d\u53ca\u5176\u6f5c\u5728\u5b89\u5168\u98ce\u9669\uff0c\u6709\u52a9\u4e8e\u5728\u5b9e\u9645\u90e8\u7f72\u524d\u4e3b\u52a8\u8fdb\u884c\u5ba1\u8ba1\u4e0e\u6cbb\u7406\uff0c\u907f\u514d\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9690\u5f0f\u66b4\u9732\u95ee\u9898\u3002", "summary_cn": "\u7f51\u7edc\u4e0a\u5145\u65a5\u7740\u5927\u91cf\u56fe\u50cf\uff0c\u8fd9\u4e9b\u56fe\u50cf\u6700\u521d\u662f\u4e3a\u4eba\u7c7b\u6d88\u8d39\u800c\u521b\u5efa\u7684\uff0c\u5982\u4eca\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u4f7f\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u667a\u80fd\u4f53\u6240\u89e3\u8bfb\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u5728\u5927\u89c4\u6a21\u4e0a\u505a\u51fa\u89c6\u89c9\u51b3\u7b56\uff0c\u51b3\u5b9a\u70b9\u51fb\u3001\u63a8\u8350\u6216\u8d2d\u4e70\u4ec0\u4e48\u3002\u7136\u800c\uff0c\u6211\u4eec\u5bf9\u5176\u89c6\u89c9\u504f\u597d\u7684\u7ed3\u6784\u77e5\u4e4b\u751a\u5c11\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u7814\u7a76\u6846\u67b6\uff0c\u901a\u8fc7\u5c06VLM\u7f6e\u4e8e\u53d7\u63a7\u7684\u56fe\u50cf\u9009\u62e9\u4efb\u52a1\u4e2d\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u6270\u52a8\u5176\u8f93\u5165\u6765\u63a2\u7a76\u8fd9\u4e00\u95ee\u9898\u3002\u6211\u4eec\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5c06\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u51fd\u6570\u89c6\u4e3a\u4e00\u79cd\u6f5c\u5728\u7684\u89c6\u89c9\u6548\u7528\uff0c\u53ef\u901a\u8fc7\u201c\u663e\u793a\u6027\u504f\u597d\u201d\u8fdb\u884c\u63a8\u65ad\uff1a\u5373\u5728\u7cfb\u7edf\u6027\u7f16\u8f91\u540e\u7684\u56fe\u50cf\u4e4b\u95f4\u8fdb\u884c\u9009\u62e9\u3002\u4ece\u5e38\u89c1\u56fe\u50cf\uff08\u5982\u4ea7\u54c1\u7167\u7247\uff09\u51fa\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u89c6\u89c9\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\uff0c\u501f\u9274\u6587\u672c\u4f18\u5316\u6280\u672f\uff0c\u5229\u7528\u56fe\u50cf\u751f\u6210\u6a21\u578b\u8fed\u4ee3\u5730\u63d0\u51fa\u5e76\u5e94\u7528\u5728\u6784\u56fe\u3001\u5149\u7167\u6216\u80cc\u666f\u7b49\u65b9\u9762\u89c6\u89c9\u4e0a\u5408\u7406\u7684\u4fee\u6539\u3002\u968f\u540e\uff0c\u6211\u4eec\u8bc4\u4f30\u54ea\u4e9b\u7f16\u8f91\u80fd\u63d0\u9ad8\u88ab\u9009\u4e2d\u7684\u6982\u7387\u3002\u901a\u8fc7\u5bf9\u524d\u6cbfVLM\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u4f18\u5316\u540e\u7684\u7f16\u8f91\u5728\u4e24\u4e24\u6bd4\u8f83\u4e2d\u80fd\u663e\u8457\u6539\u53d8\u9009\u62e9\u6982\u7387\u3002\u6211\u4eec\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u53ef\u89e3\u91ca\u6027\u6d41\u7a0b\uff0c\u7528\u4e8e\u89e3\u91ca\u8fd9\u4e9b\u504f\u597d\uff0c\u8bc6\u522b\u51fa\u9a71\u52a8\u9009\u62e9\u7684\u4e00\u81f4\u6027\u89c6\u89c9\u4e3b\u9898\u3002\u6211\u4eec\u8ba4\u4e3a\uff0c\u8be5\u65b9\u6cd5\u4e3a\u63ed\u793a\u89c6\u89c9\u6f0f\u6d1e\u548c\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u65b9\u5f0f\uff0c\u8fd9\u4e9b\u95ee\u9898\u82e5\u975e\u5982\u6b64\uff0c\u53ef\u80fd\u53ea\u80fd\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u88ab\u9690\u5f0f\u53d1\u73b0\uff0c\u4ece\u800c\u652f\u6301\u5bf9\u57fa\u4e8e\u56fe\u50cf\u7684AI\u667a\u80fd\u4f53\u8fdb\u884c\u66f4\u4e3b\u52a8\u7684\u5ba1\u8ba1\u4e0e\u6cbb\u7406\u3002"}}
{"id": "2602.15287", "pdf": "https://arxiv.org/pdf/2602.15287", "abs": "https://arxiv.org/abs/2602.15287", "authors": ["Xinshuang Liu", "Runfa Blark Li", "Truong Nguyen"], "title": "Consistency-Preserving Diverse Video Generation", "categories": ["cs.CV"], "comment": null, "summary": "Text-to-video generation is expensive, so only a few samples are typically produced per prompt. In this low-sample regime, maximizing the value of each batch requires high cross-video diversity. Recent methods improve diversity for image generation, but for videos they often degrade within-video temporal consistency and require costly backpropagation through a video decoder. We propose a joint-sampling framework for flow-matching video generators that improves batch diversity while preserving temporal consistency. Our approach applies diversity-driven updates and then removes only the components that would decrease a temporal-consistency objective. To avoid image-space gradients, we compute both objectives with lightweight latent-space models, avoiding video decoding and decoder backpropagation. Experiments on a state-of-the-art text-to-video flow-matching model show diversity comparable to strong joint-sampling baselines while substantially improving temporal consistency and color naturalness. Code will be released.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u89c6\u9891\u751f\u6210\u7684\u8054\u5408\u91c7\u6837\u6846\u67b6\uff0c\u5728\u63d0\u5347\u6279\u6b21\u591a\u6837\u6027\u7684\u540c\u65f6\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u907f\u514d\u6602\u8d35\u7684\u89c6\u9891\u89e3\u7801\u548c\u53cd\u5411\u4f20\u64ad\u3002", "motivation": "\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u6210\u672c\u9ad8\uff0c\u901a\u5e38\u6bcf\u4e2a\u63d0\u793a\u4ec5\u751f\u6210\u5c11\u91cf\u6837\u672c\u3002\u5728\u4f4e\u6837\u672c\u60c5\u51b5\u4e0b\uff0c\u9700\u63d0\u9ad8\u6bcf\u6279\u6837\u672c\u7684\u591a\u6837\u6027\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5e38\u727a\u7272\u89c6\u9891\u5185\u7684\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u4e14\u4f9d\u8d56\u6602\u8d35\u7684\u89e3\u7801\u5668\u53cd\u5411\u4f20\u64ad\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u91c7\u6837\u6846\u67b6\uff0c\u5148\u65bd\u52a0\u591a\u6837\u6027\u9a71\u52a8\u7684\u66f4\u65b0\uff0c\u518d\u79fb\u9664\u4f1a\u964d\u4f4e\u65f6\u95f4\u4e00\u81f4\u6027\u76ee\u6807\u7684\u6210\u5206\uff1b\u4f7f\u7528\u8f7b\u91cf\u7ea7\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\u8ba1\u7b97\u591a\u6837\u6027\u548c\u4e00\u81f4\u6027\u76ee\u6807\uff0c\u907f\u514d\u56fe\u50cf\u7a7a\u95f4\u68af\u5ea6\u3001\u89c6\u9891\u89e3\u7801\u53ca\u89e3\u7801\u5668\u53cd\u5411\u4f20\u64ad\u3002", "result": "\u5728\u6700\u5148\u8fdb\u7684\u6587\u672c\u5230\u89c6\u9891\u6d41\u5339\u914d\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u65b9\u9762\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u8272\u5f69\u81ea\u7136\u5ea6\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u4e86\u89c6\u9891\u751f\u6210\u4e2d\u7684\u591a\u6837\u6027\u4e0e\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u3002", "summary_cn": "\u6587\u672c\u5230\u89c6\u9891\u751f\u6210\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u901a\u5e38\u6bcf\u4e2a\u63d0\u793a\u4ec5\u751f\u6210\u5c11\u91cf\u6837\u672c\u3002\u5728\u8fd9\u79cd\u4f4e\u6837\u672c\u573a\u666f\u4e0b\uff0c\u6700\u5927\u5316\u6bcf\u6279\u6837\u672c\u7684\u4ef7\u503c\u9700\u8981\u8f83\u9ad8\u7684\u8de8\u89c6\u9891\u591a\u6837\u6027\u3002\u8fd1\u671f\u7684\u65b9\u6cd5\u867d\u63d0\u5347\u4e86\u56fe\u50cf\u751f\u6210\u7684\u591a\u6837\u6027\uff0c\u4f46\u5728\u89c6\u9891\u751f\u6210\u4e2d\u5f80\u5f80\u635f\u5bb3\u4e86\u89c6\u9891\u5185\u90e8\u7684\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u9700\u8981\u901a\u8fc7\u89c6\u9891\u89e3\u7801\u5668\u8fdb\u884c\u4ee3\u4ef7\u9ad8\u6602\u7684\u53cd\u5411\u4f20\u64ad\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6d41\u5339\u914d\u89c6\u9891\u751f\u6210\u5668\u7684\u8054\u5408\u91c7\u6837\u6846\u67b6\uff0c\u5728\u63d0\u5347\u6279\u6b21\u591a\u6837\u6027\u7684\u540c\u65f6\u4fdd\u7559\u65f6\u95f4\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u5e94\u7528\u7531\u591a\u6837\u6027\u9a71\u52a8\u7684\u66f4\u65b0\uff0c\u7136\u540e\u4ec5\u79fb\u9664\u90a3\u4e9b\u4f1a\u964d\u4f4e\u65f6\u95f4\u4e00\u81f4\u6027\u76ee\u6807\u7684\u6210\u5206\u3002\u4e3a\u907f\u514d\u56fe\u50cf\u7a7a\u95f4\u68af\u5ea6\uff0c\u6211\u4eec\u5728\u8f7b\u91cf\u7ea7\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\u4e2d\u8ba1\u7b97\u591a\u6837\u6027\u548c\u4e00\u81f4\u6027\u76ee\u6807\uff0c\u4ece\u800c\u907f\u514d\u89c6\u9891\u89e3\u7801\u548c\u89e3\u7801\u5668\u53cd\u5411\u4f20\u64ad\u3002\u5728\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6587\u672c\u5230\u89c6\u9891\u6d41\u5339\u914d\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u6837\u6027\u65b9\u9762\u4e0e\u5f3a\u5927\u7684\u8054\u5408\u91c7\u6837\u57fa\u7ebf\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u6539\u5584\u4e86\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u8272\u5f69\u81ea\u7136\u5ea6\u3002\u4ee3\u7801\u5c06\u88ab\u516c\u5f00\u3002"}}
