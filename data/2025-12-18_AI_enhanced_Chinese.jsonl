{"id": "2512.14755", "pdf": "https://arxiv.org/pdf/2512.14755", "abs": "https://arxiv.org/abs/2512.14755", "authors": ["Paul Weinmann", "Ferdinand Schenck", "Martin \u0160iklar"], "title": "SkyCap: Bitemporal VHR Optical-SAR Quartets for Amplitude Change Detection and Foundation-Model Evaluation", "categories": ["cs.CV"], "comment": "8 pages, 0 figures. Accepted at Advances in Representation Learning for Earth Observation (REO) at EurIPS 2025", "summary": "Change detection for linear infrastructure monitoring requires reliable high-resolution data and regular acquisition cadence. Optical very-high-resolution (VHR) imagery is interpretable and straightforward to label, but clouds break this cadence. Synthetic Aperture Radar (SAR) enables all-weather acquisitions, yet is difficult to annotate. We introduce SkyCap, a bitemporal VHR optical-SAR dataset constructed by archive matching and co-registration of (optical) SkySat and Capella Space (SAR) scenes. We utilize optical-to-SAR label transfer to obtain SAR amplitude change detection (ACD) labels without requiring SAR-expert annotations. We perform continued pretraining of SARATR-X on our SAR data and benchmark the resulting SAR-specific foundation models (FMs) together with SARATR-X against optical FMs on SkyCap under different preprocessing choices. Among evaluated models, MTP(ViT-B+RVSA), an optical FM, with dB+Z-score preprocessing attains the best result (F1$_c$ = 45.06), outperforming SAR-specific FMs further pretrained directly on Capella data. We observe strong sensitivity to preprocessing alignment with pretraining statistics, and the ranking of optical models on optical change detection does not transfer one-to-one to SAR ACD. To our knowledge, this is the first evaluation of foundation models on VHR SAR ACD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSkyCap\u6570\u636e\u96c6\uff0c\u878d\u5408\u9ad8\u5206\u8fa8\u7387\u5149\u5b66\u4e0eSAR\u5f71\u50cf\u7528\u4e8e\u7ebf\u6027\u57fa\u7840\u8bbe\u65bd\u53d8\u5316\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u5149\u5b66\u5230SAR\u7684\u6807\u7b7e\u8fc1\u79fb\u751f\u6210SAR\u53d8\u5316\u6807\u7b7e\u3002\u5b9e\u9a8c\u53d1\u73b0\uff0c\u7ecf\u9002\u5f53\u9884\u5904\u7406\u7684\u5149\u5b66\u57fa\u7840\u6a21\u578b\u5728SAR\u5e45\u5ea6\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4e13\u95e8\u9488\u5bf9SAR\u5fae\u8c03\u7684\u57fa\u7840\u6a21\u578b\u3002", "motivation": "\u5149\u5b66\u9ad8\u5206\u8fa8\u7387\u5f71\u50cf\u6613\u53d7\u4e91\u5c42\u5e72\u6270\uff0c\u800cSAR\u867d\u53ef\u5168\u5929\u5019\u6210\u50cf\u4f46\u96be\u4ee5\u6807\u6ce8\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\uff0c\u9700\u6784\u5efa\u878d\u5408\u4e24\u7c7b\u6570\u636e\u7684\u57fa\u51c6\u5e76\u63a2\u7d22\u65e0\u9700SAR\u4e13\u5bb6\u6807\u6ce8\u7684\u53d8\u5316\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u6784\u5efaSkyCap\u53cc\u65f6\u76f8VHR\u5149\u5b66-SAR\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5149\u5b66\u81f3SAR\u7684\u6807\u7b7e\u8fc1\u79fb\u83b7\u5f97SAR\u5e45\u5ea6\u53d8\u5316\u68c0\u6d4b\u6807\u7b7e\uff1b\u5bf9SARATR-X\u6a21\u578b\u5728SAR\u6570\u636e\u4e0a\u7ee7\u7eed\u9884\u8bad\u7ec3\uff0c\u5e76\u5728\u4e0d\u540c\u9884\u5904\u7406\u7b56\u7565\u4e0b\u8bc4\u4f30\u591a\u79cd\u57fa\u7840\u6a21\u578b\u5728SkyCap\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u5728\u6240\u6709\u8bc4\u4f30\u6a21\u578b\u4e2d\uff0c\u91c7\u7528dB+Z-score\u9884\u5904\u7406\u7684\u5149\u5b66\u57fa\u7840\u6a21\u578bMTP(ViT-B+RVSA)\u8868\u73b0\u6700\u4f73\uff08F1_c = 45.06\uff09\uff0c\u4f18\u4e8e\u76f4\u63a5\u5728Capella SAR\u6570\u636e\u4e0a\u5fae\u8c03\u7684SAR\u4e13\u7528\u57fa\u7840\u6a21\u578b\uff1b\u540c\u65f6\u53d1\u73b0\u6a21\u578b\u6027\u80fd\u5bf9\u9884\u5904\u7406\u4e0e\u9884\u8bad\u7ec3\u7edf\u8ba1\u7684\u4e00\u81f4\u6027\u9ad8\u5ea6\u654f\u611f\uff0c\u4e14\u5149\u5b66\u6a21\u578b\u5728\u5149\u5b66\u53d8\u5316\u68c0\u6d4b\u4e2d\u7684\u6392\u5e8f\u4e0d\u80fd\u76f4\u63a5\u8fc1\u79fb\u5230SAR\u4efb\u52a1\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5728VHR SAR\u5e45\u5ea6\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u4e0a\u5bf9\u57fa\u7840\u6a21\u578b\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u8868\u660e\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9884\u5904\u7406\u53ef\u4f7f\u901a\u7528\u5149\u5b66\u6a21\u578b\u5728SAR\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e13\u7528SAR\u6a21\u578b\uff0c\u7a81\u663e\u4e86\u6570\u636e\u9884\u5904\u7406\u4e0e\u6a21\u578b\u9002\u914d\u7684\u91cd\u8981\u6027\u3002", "summary_cn": "\u7528\u4e8e\u7ebf\u6027\u57fa\u7840\u8bbe\u65bd\u76d1\u6d4b\u7684\u53d8\u5316\u68c0\u6d4b\u9700\u8981\u53ef\u9760\u4e14\u9ad8\u5206\u8fa8\u7387\u7684\u6570\u636e\u4ee5\u53ca\u5b9a\u671f\u7684\u83b7\u53d6\u9891\u7387\u3002\u5149\u5b66\u8d85\u9ad8\u5206\u8fa8\u7387\uff08VHR\uff09\u5f71\u50cf\u5177\u6709\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u4e14\u6613\u4e8e\u6807\u6ce8\uff0c\u4f46\u4e91\u5c42\u4f1a\u7834\u574f\u5176\u83b7\u53d6\u8282\u594f\u3002\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\uff08SAR\uff09\u53ef\u5b9e\u73b0\u5168\u5929\u5019\u6210\u50cf\uff0c\u4f46\u96be\u4ee5\u8fdb\u884c\u6807\u6ce8\u3002\u6211\u4eec\u63d0\u51fa\u4e86SkyCap\uff0c\u8fd9\u662f\u4e00\u4e2a\u53cc\u65f6\u76f8VHR\u5149\u5b66-SAR\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5f52\u6863\u5339\u914d\u548c\u5171\u914d\u51c6\uff08\u5149\u5b66\uff09SkySat\u4e0eCapella Space\uff08SAR\uff09\u573a\u666f\u6784\u5efa\u800c\u6210\u3002\u6211\u4eec\u5229\u7528\u5149\u5b66\u5230SAR\u7684\u6807\u7b7e\u8fc1\u79fb\u65b9\u6cd5\uff0c\u5728\u65e0\u9700SAR\u4e13\u5bb6\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97SAR\u5e45\u5ea6\u53d8\u5316\u68c0\u6d4b\uff08ACD\uff09\u6807\u7b7e\u3002\u6211\u4eec\u5728\u81ea\u6709SAR\u6570\u636e\u4e0a\u5bf9SARATR-X\u6a21\u578b\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5e76\u5c06\u6240\u5f97\u7684SAR\u4e13\u7528\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u4e0e\u539f\u59cbSARATR-X\u4e00\u8d77\uff0c\u5728\u4e0d\u540c\u9884\u5904\u7406\u9009\u62e9\u4e0b\u4e0e\u5149\u5b66\u57fa\u7840\u6a21\u578b\u5728SkyCap\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u5728\u6240\u8bc4\u4f30\u7684\u6a21\u578b\u4e2d\uff0c\u91c7\u7528dB+Z-score\u9884\u5904\u7406\u7684\u5149\u5b66\u57fa\u7840\u6a21\u578bMTP(ViT-B+RVSA)\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff08F1_c = 45.06\uff09\uff0c\u4f18\u4e8e\u76f4\u63a5\u5728Capella\u6570\u636e\u4e0a\u8fdb\u4e00\u6b65\u9884\u8bad\u7ec3\u7684SAR\u4e13\u7528\u57fa\u7840\u6a21\u578b\u3002\u6211\u4eec\u89c2\u5bdf\u5230\u6a21\u578b\u6027\u80fd\u5bf9\u9884\u5904\u7406\u4e0e\u9884\u8bad\u7ec3\u7edf\u8ba1\u91cf\u7684\u4e00\u81f4\u6027\u9ad8\u5ea6\u654f\u611f\uff0c\u4e14\u5149\u5b66\u6a21\u578b\u5728\u5149\u5b66\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u6392\u5e8f\u5e76\u4e0d\u80fd\u4e00\u5bf9\u4e00\u5730\u8fc1\u79fb\u5230SAR\u5e45\u5ea6\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u4e2d\u3002\u636e\u6211\u4eec\u6240\u77e5\uff0c\u8fd9\u662f\u9996\u6b21\u5728VHR SAR\u5e45\u5ea6\u53d8\u5316\u68c0\u6d4b\u4efb\u52a1\u4e0a\u5bf9\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002"}}
{"id": "2512.14757", "pdf": "https://arxiv.org/pdf/2512.14757", "abs": "https://arxiv.org/abs/2512.14757", "authors": ["Tomohito Kawabata", "Xinyu Zhang", "Ling Xiao"], "title": "SocialNav-MoE: A Mixture-of-Experts Vision Language Model for Socially Compliant Navigation with Reinforcement Fine-Tuning", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "For robots navigating in human-populated environments, safety and social compliance are equally critical, yet prior work has mostly emphasized safety. Socially compliant navigation that accounts for human comfort, social norms, and contextual appropriateness remains underexplored. Vision language models (VLMs) show promise for this task; however, large-scale models incur substantial computational overhead, leading to higher inference latency and energy consumption, which makes them unsuitable for real-time deployment on resource-constrained robotic platforms. To address this issue, we investigate the effectiveness of small VLM and propose SocialNav-MoE, an efficient Mixture-of-Experts vision language model for socially compliant navigation with reinforcement fine-tuning (RFT). We further introduce a semantic similarity reward (SSR) to effectively leverage RFT for enhancing the decision-making capabilities. Additionally, we study the effectiveness of different small language model types (Phi, Qwen, and StableLM), routing strategies, and vision encoders (CLIP vs. SigLIP, frozen vs. fine-tuned). Experiments on the SNEI dataset demonstrate that SocialNav-MoE achieves an excellent balance between navigation accuracy and efficiency. The proposed SSR function is more effective than hard-level and character-level rewards. Source code will be released upon acceptance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSocialNav-MoE\uff0c\u4e00\u79cd\u57fa\u4e8e\u5c0f\u578b\u6df7\u5408\u4e13\u5bb6\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u793e\u4ea4\u5bfc\u822a\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f3a\u5316\u5fae\u8c03\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u5956\u52b1\uff0c\u5728\u4fdd\u8bc1\u5bfc\u822a\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u5bfc\u822a\u7814\u7a76\u591a\u5173\u6ce8\u5b89\u5168\u6027\uff0c\u5ffd\u89c6\u4e86\u5bf9\u4eba\u7c7b\u8212\u9002\u5ea6\u3001\u793e\u4f1a\u89c4\u8303\u548c\u60c5\u5883\u9002\u5f53\u6027\u7684\u8003\u91cf\uff1b\u540c\u65f6\uff0c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u56e0\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u96be\u4ee5\u90e8\u7f72\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u673a\u5668\u4eba\u5e73\u53f0\u3002", "method": "\u63d0\u51faSocialNav-MoE\u6a21\u578b\uff0c\u91c7\u7528\u5c0f\u578b\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u89c6\u89c9\u8bed\u8a00\u67b6\u6784\uff0c\u7ed3\u5408\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u4e0e\u65b0\u8bbe\u8ba1\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u5956\u52b1\uff08SSR\uff09\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u5c0f\u8bed\u8a00\u6a21\u578b\uff08Phi\u3001Qwen\u3001StableLM\uff09\u3001\u8def\u7531\u7b56\u7565\u53ca\u89c6\u89c9\u7f16\u7801\u5668\uff08CLIP vs. SigLIP\uff0c\u51bb\u7ed3 vs. \u5fae\u8c03\uff09\u7684\u6548\u679c\u3002", "result": "\u5728SNEI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSocialNav-MoE\u5728\u5bfc\u822a\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0c\u4e14\u6240\u63d0\u51fa\u7684SSR\u4f18\u4e8e\u786c\u7ea7\u522b\u548c\u5b57\u7b26\u7ea7\u522b\u5956\u52b1\u3002", "conclusion": "\u5c0f\u578b\u6df7\u5408\u4e13\u5bb6\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u8bed\u4e49\u76f8\u4f3c\u6027\u5956\u52b1\u80fd\u6709\u6548\u5b9e\u73b0\u9ad8\u6548\u4e14\u7b26\u5408\u793e\u4ea4\u89c4\u8303\u7684\u673a\u5668\u4eba\u5bfc\u822a\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5b9e\u65f6\u5e94\u7528\u573a\u666f\u3002", "summary_cn": "\u5bf9\u4e8e\u5728\u4eba\u7c7b\u73af\u5883\u4e2d\u5bfc\u822a\u7684\u673a\u5668\u4eba\u800c\u8a00\uff0c\u5b89\u5168\u6027\u548c\u793e\u4ea4\u5408\u89c4\u6027\u540c\u6837\u91cd\u8981\uff0c\u4f46\u4ee5\u5f80\u7684\u7814\u7a76\u4e3b\u8981\u5f3a\u8c03\u5b89\u5168\u6027\u3002\u8003\u8651\u5230\u4eba\u7c7b\u8212\u9002\u5ea6\u3001\u793e\u4f1a\u89c4\u8303\u548c\u60c5\u5883\u9002\u5f53\u6027\u7684\u793e\u4ea4\u5408\u89c4\u5bfc\u822a\u4ecd\u9c9c\u6709\u63a2\u7d22\u3002\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u6b64\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u7136\u800c\u5927\u89c4\u6a21\u6a21\u578b\u5e26\u6765\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u5bfc\u81f4\u66f4\u9ad8\u7684\u63a8\u7406\u5ef6\u8fdf\u548c\u80fd\u8017\uff0c\u4f7f\u5176\u96be\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u673a\u5668\u4eba\u5e73\u53f0\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u90e8\u7f72\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u6211\u4eec\u7814\u7a76\u4e86\u5c0f\u578bVLM\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86SocialNav-MoE\u2014\u2014\u4e00\u79cd\u7528\u4e8e\u793e\u4ea4\u5408\u89c4\u5bfc\u822a\u7684\u9ad8\u6548\u6df7\u5408\u4e13\u5bb6\uff08Mixture-of-Experts\uff09\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u5f15\u5165\u8bed\u4e49\u76f8\u4f3c\u6027\u5956\u52b1\uff08SSR\uff09\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528RFT\u63d0\u5347\u51b3\u7b56\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08Phi\u3001Qwen\u548cStableLM\uff09\u3001\u8def\u7531\u7b56\u7565\u4ee5\u53ca\u89c6\u89c9\u7f16\u7801\u5668\uff08CLIP\u4e0eSigLIP\uff0c\u51bb\u7ed3\u4e0e\u5fae\u8c03\uff09\u7684\u6548\u679c\u3002\u5728SNEI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSocialNav-MoE\u5728\u5bfc\u822a\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u51fa\u8272\u7684\u5e73\u8861\uff0c\u6240\u63d0\u51fa\u7684SSR\u51fd\u6570\u4f18\u4e8e\u786c\u7ea7\u522b\u548c\u5b57\u7b26\u7ea7\u522b\u5956\u52b1\u3002\u8bba\u6587\u88ab\u63a5\u6536\u540e\u5c06\u516c\u5f00\u6e90\u4ee3\u7801\u3002"}}
{"id": "2512.14758", "pdf": "https://arxiv.org/pdf/2512.14758", "abs": "https://arxiv.org/abs/2512.14758", "authors": ["Fan Bu", "Rongfeng Li", "Zijin Li", "Ya Li", "Linfeng Fan", "Pei Huang"], "title": "The Renaissance of Expert Systems: Optical Recognition of Printed Chinese Jianpu Musical Scores with Lyrics", "categories": ["cs.CV"], "comment": "13 pages, 12 figures", "summary": "Large-scale optical music recognition (OMR) research has focused mainly on Western staff notation, leaving Chinese Jianpu (numbered notation) and its rich lyric resources underexplored. We present a modular expert-system pipeline that converts printed Jianpu scores with lyrics into machine-readable MusicXML and MIDI, without requiring massive annotated training data. Our approach adopts a top-down expert-system design, leveraging traditional computer-vision techniques (e.g., phrase correlation, skeleton analysis) to capitalize on prior knowledge, while integrating unsupervised deep-learning modules for image feature embeddings. This hybrid strategy strikes a balance between interpretability and accuracy. Evaluated on The Anthology of Chinese Folk Songs, our system massively digitizes (i) a melody-only collection of more than 5,000 songs (> 300,000 notes) and (ii) a curated subset with lyrics comprising over 1,400 songs (> 100,000 notes). The system achieves high-precision recognition on both melody (note-wise F1 = 0.951) and aligned lyrics (character-wise F1 = 0.931).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u6a21\u5757\u5316\u4e13\u5bb6\u7cfb\u7edf\uff0c\u7528\u4e8e\u5c06\u5e26\u6b4c\u8bcd\u7684\u5370\u5237\u7248\u7b80\u8c31\u4e50\u8c31\u9ad8\u7cbe\u5ea6\u8f6c\u6362\u4e3aMusicXML\u548cMIDI\u683c\u5f0f\uff0c\u5728\u65cb\u5f8b\u548c\u6b4c\u8bcd\u8bc6\u522b\u4e0a\u5747\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u5149\u5b66\u4e50\u8c31\u8bc6\u522b\uff08OMR\uff09\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u897f\u65b9\u4e94\u7ebf\u8c31\uff0c\u800c\u4e2d\u56fd\u7b80\u8c31\u53ca\u5176\u4e30\u5bcc\u7684\u6b4c\u8bcd\u8d44\u6e90\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u4e13\u5bb6\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u7ed3\u5408\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff08\u5982\u77ed\u8bed\u76f8\u5173\u6027\u3001\u9aa8\u67b6\u5206\u6790\uff09\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\uff0c\u5e76\u96c6\u6210\u65e0\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757\u8fdb\u884c\u56fe\u50cf\u7279\u5f81\u5d4c\u5165\uff0c\u5f62\u6210\u517c\u987e\u53ef\u89e3\u91ca\u6027\u4e0e\u51c6\u786e\u6027\u7684\u6df7\u5408\u7b56\u7565\u3002", "result": "\u5728\u300a\u4e2d\u56fd\u6c11\u6b4c\u9009\u96c6\u300b\u4e0a\u8bc4\u4f30\uff0c\u7cfb\u7edf\u6210\u529f\u6570\u5b57\u5316\u4e865000\u591a\u9996\u7eaf\u65cb\u5f8b\u6b4c\u66f2\uff08\u8d8530\u4e07\u97f3\u7b26\uff09\u548c1400\u591a\u9996\u5e26\u6b4c\u8bcd\u6b4c\u66f2\uff08\u8d8510\u4e07\u97f3\u7b26\uff09\uff0c\u65cb\u5f8b\u8bc6\u522bF1\u8fbe0.951\uff0c\u6b4c\u8bcd\u5bf9\u9f50F1\u8fbe0.931\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u5757\u5316\u4e13\u5bb6\u7cfb\u7edf\u80fd\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u5730\u5b9e\u73b0\u7b80\u8c31\u4e50\u8c31\u53ca\u5176\u6b4c\u8bcd\u7684\u6570\u5b57\u5316\uff0c\u4e3a\u975e\u897f\u65b9\u4e50\u8c31\u7684OMR\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u8303\u5f0f\u3002", "summary_cn": "\u5927\u89c4\u6a21\u5149\u5b66\u4e50\u8c31\u8bc6\u522b\uff08OMR\uff09\u7814\u7a76\u4e3b\u8981\u805a\u7126\u4e8e\u897f\u65b9\u4e94\u7ebf\u8c31\uff0c\u800c\u4e2d\u56fd\u7b80\u8c31\uff08\u6570\u5b57\u8c31\uff09\u53ca\u5176\u4e30\u5bcc\u7684\u6b4c\u8bcd\u8d44\u6e90\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u4e13\u5bb6\u7cfb\u7edf\u6d41\u6c34\u7ebf\uff0c\u53ef\u5728\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5e26\u6b4c\u8bcd\u7684\u5370\u5237\u7248\u7b80\u8c31\u4e50\u8c31\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u8bfb\u7684MusicXML\u548cMIDI\u683c\u5f0f\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u4e13\u5bb6\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5229\u7528\u4f20\u7edf\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff08\u4f8b\u5982\u77ed\u8bed\u76f8\u5173\u6027\u3001\u9aa8\u67b6\u5206\u6790\uff09\u6765\u5145\u5206\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\uff0c\u540c\u65f6\u96c6\u6210\u65e0\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6a21\u5757\u4ee5\u63d0\u53d6\u56fe\u50cf\u7279\u5f81\u5d4c\u5165\u3002\u8fd9\u79cd\u6df7\u5408\u7b56\u7565\u5728\u53ef\u89e3\u91ca\u6027\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002\u5728\u300a\u4e2d\u56fd\u6c11\u6b4c\u9009\u96c6\u300b\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6211\u4eec\u7684\u7cfb\u7edf\u5927\u89c4\u6a21\u6570\u5b57\u5316\u4e86\uff08i\uff09\u5305\u542b5000\u591a\u9996\u6b4c\u66f2\uff08\u8d85\u8fc730\u4e07\u97f3\u7b26\uff09\u7684\u7eaf\u65cb\u5f8b\u96c6\u5408\uff0c\u4ee5\u53ca\uff08ii\uff09\u5305\u542b1400\u591a\u9996\u6b4c\u66f2\uff08\u8d85\u8fc710\u4e07\u97f3\u7b26\uff09\u7684\u5e26\u6b4c\u8bcd\u7cbe\u9009\u5b50\u96c6\u3002\u8be5\u7cfb\u7edf\u5728\u65cb\u5f8b\u8bc6\u522b\uff08\u97f3\u7b26\u7ea7F1 = 0.951\uff09\u548c\u5bf9\u9f50\u6b4c\u8bcd\uff08\u5b57\u7b26\u7ea7F1 = 0.931\uff09\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u8bc6\u522b\u3002"}}
{"id": "2512.14760", "pdf": "https://arxiv.org/pdf/2512.14760", "abs": "https://arxiv.org/abs/2512.14760", "authors": ["Afrah Shaahid", "Muzammil Behzad"], "title": "AquaDiff: Diffusion-Based Underwater Image Enhancement for Addressing Color Distortion", "categories": ["cs.CV"], "comment": null, "summary": "Underwater images are severely degraded by wavelength-dependent light absorption and scattering, resulting in color distortion, low contrast, and loss of fine details that hinder vision-based underwater applications. To address these challenges, we propose AquaDiff, a diffusion-based underwater image enhancement framework designed to correct chromatic distortions while preserving structural and perceptual fidelity. AquaDiff integrates a chromatic prior-guided color compensation strategy with a conditional diffusion process, where cross-attention dynamically fuses degraded inputs and noisy latent states at each denoising step. An enhanced denoising backbone with residual dense blocks and multi-resolution attention captures both global color context and local details. Furthermore, a novel cross-domain consistency loss jointly enforces pixel-level accuracy, perceptual similarity, structural integrity, and frequency-domain fidelity. Extensive experiments on multiple challenging underwater benchmarks demonstrate that AquaDiff provides good results as compared to the state-of-the-art traditional, CNN-, GAN-, and diffusion-based methods, achieving superior color correction and competitive overall image quality across diverse underwater conditions.", "AI": {"tldr": "AquaDiff \u662f\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6c34\u4e0b\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u8272\u5ea6\u5148\u9a8c\u5f15\u5bfc\u7684\u989c\u8272\u8865\u507f\u7b56\u7565\u548c\u6761\u4ef6\u6269\u6563\u8fc7\u7a0b\uff0c\u5728\u591a\u4e2a\u6c34\u4e0b\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8272\u5f69\u6821\u6b63\u4e0e\u6574\u4f53\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u6c34\u4e0b\u56fe\u50cf\u56e0\u6ce2\u957f\u4f9d\u8d56\u7684\u5149\u5438\u6536\u548c\u6563\u5c04\u800c\u4e25\u91cd\u9000\u5316\uff0c\u8868\u73b0\u4e3a\u989c\u8272\u5931\u771f\u3001\u5bf9\u6bd4\u5ea6\u4f4e\u548c\u7ec6\u8282\u4e22\u5931\uff0c\u963b\u788d\u4e86\u57fa\u4e8e\u89c6\u89c9\u7684\u6c34\u4e0b\u5e94\u7528\u3002\u56e0\u6b64\u4e9f\u9700\u6709\u6548\u65b9\u6cd5\u6765\u540c\u65f6\u6062\u590d\u8272\u5f69\u548c\u7ed3\u6784\u4fe1\u606f\u3002", "method": "\u63d0\u51fa AquaDiff \u6846\u67b6\uff0c\u7ed3\u5408\u8272\u5ea6\u5148\u9a8c\u5f15\u5bfc\u7684\u989c\u8272\u8865\u507f\u7b56\u7565\u4e0e\u6761\u4ef6\u6269\u6563\u8fc7\u7a0b\uff1b\u5728\u6bcf\u4e00\u6b65\u53bb\u566a\u4e2d\u4f7f\u7528\u4ea4\u53c9\u6ce8\u610f\u529b\u52a8\u6001\u878d\u5408\u9000\u5316\u8f93\u5165\u4e0e\u5e26\u566a\u6f5c\u5728\u72b6\u6001\uff1b\u91c7\u7528\u5e26\u6709\u6b8b\u5dee\u5bc6\u96c6\u5757\u548c\u591a\u5206\u8fa8\u7387\u6ce8\u610f\u529b\u7684\u589e\u5f3a\u53bb\u566a\u4e3b\u5e72\u7f51\u7edc\uff1b\u5e76\u8bbe\u8ba1\u4e00\u79cd\u65b0\u9896\u7684\u8de8\u57df\u4e00\u81f4\u6027\u635f\u5931\uff0c\u8054\u5408\u7ea6\u675f\u50cf\u7d20\u7ea7\u7cbe\u5ea6\u3001\u611f\u77e5\u76f8\u4f3c\u6027\u3001\u7ed3\u6784\u5b8c\u6574\u6027\u548c\u9891\u57df\u4fdd\u771f\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6c34\u4e0b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAquaDiff \u5728\u8272\u5f69\u6821\u6b63\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5728\u6574\u4f53\u56fe\u50cf\u8d28\u91cf\u4e0a\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4f20\u7edf\u65b9\u6cd5\u3001CNN\u3001GAN \u548c\u6269\u6563\u6a21\u578b\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "AquaDiff \u80fd\u6709\u6548\u89e3\u51b3\u6c34\u4e0b\u56fe\u50cf\u7684\u989c\u8272\u5931\u771f\u548c\u7ec6\u8282\u4e22\u5931\u95ee\u9898\uff0c\u5728\u591a\u79cd\u6c34\u4e0b\u73af\u5883\u4e0b\u5747\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u589e\u5f3a\u6027\u80fd\uff0c\u4e3a\u6c34\u4e0b\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002", "summary_cn": "\u6c34\u4e0b\u56fe\u50cf\u7531\u4e8e\u6ce2\u957f\u4f9d\u8d56\u7684\u5149\u5438\u6536\u548c\u6563\u5c04\u800c\u4e25\u91cd\u9000\u5316\uff0c\u5bfc\u81f4\u989c\u8272\u5931\u771f\u3001\u5bf9\u6bd4\u5ea6\u4f4e\u4ee5\u53ca\u7cbe\u7ec6\u7ec6\u8282\u7684\u4e22\u5931\uff0c\u4ece\u800c\u963b\u788d\u4e86\u57fa\u4e8e\u89c6\u89c9\u7684\u6c34\u4e0b\u5e94\u7528\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 AquaDiff\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u6c34\u4e0b\u56fe\u50cf\u589e\u5f3a\u6846\u67b6\uff0c\u65e8\u5728\u6821\u6b63\u8272\u5ea6\u5931\u771f\uff0c\u540c\u65f6\u4fdd\u6301\u7ed3\u6784\u548c\u611f\u77e5\u4fdd\u771f\u5ea6\u3002AquaDiff \u5c06\u8272\u5ea6\u5148\u9a8c\u5f15\u5bfc\u7684\u989c\u8272\u8865\u507f\u7b56\u7565\u4e0e\u6761\u4ef6\u6269\u6563\u8fc7\u7a0b\u76f8\u7ed3\u5408\uff0c\u5728\u6bcf\u4e00\u6b65\u53bb\u566a\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u52a8\u6001\u878d\u5408\u9000\u5316\u8f93\u5165\u4e0e\u5e26\u566a\u6f5c\u5728\u72b6\u6001\u3002\u5176\u589e\u5f3a\u7684\u53bb\u566a\u4e3b\u5e72\u7f51\u7edc\u91c7\u7528\u6b8b\u5dee\u5bc6\u96c6\u5757\u548c\u591a\u5206\u8fa8\u7387\u6ce8\u610f\u529b\u673a\u5236\uff0c\u80fd\u591f\u540c\u65f6\u6355\u6349\u5168\u5c40\u8272\u5f69\u4e0a\u4e0b\u6587\u548c\u5c40\u90e8\u7ec6\u8282\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8de8\u57df\u4e00\u81f4\u6027\u635f\u5931\uff0c\u8054\u5408\u7ea6\u675f\u50cf\u7d20\u7ea7\u7cbe\u5ea6\u3001\u611f\u77e5\u76f8\u4f3c\u6027\u3001\u7ed3\u6784\u5b8c\u6574\u6027\u4ee5\u53ca\u9891\u57df\u4fdd\u771f\u5ea6\u3002\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6c34\u4e0b\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAquaDiff \u76f8\u8f83\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4f20\u7edf\u65b9\u6cd5\u3001CNN\u3001GAN \u4ee5\u53ca\u6269\u6563\u6a21\u578b\u65b9\u6cd5\uff0c\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6548\u679c\uff0c\u5728\u591a\u6837\u5316\u7684\u6c34\u4e0b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u8272\u5f69\u6821\u6b63\u548c\u5177\u6709\u7ade\u4e89\u529b\u7684\u6574\u4f53\u56fe\u50cf\u8d28\u91cf\u3002"}}
{"id": "2512.14770", "pdf": "https://arxiv.org/pdf/2512.14770", "abs": "https://arxiv.org/abs/2512.14770", "authors": ["Xixian Wu", "Yang Ou", "Pengchao Tian", "Zian Yang", "Jielei Zhang", "Peiyi Li", "Longwen Gao"], "title": "Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision-language models (VLMs) have demonstrated significant potential in Visual Question Answering (VQA). However, the susceptibility of VLMs to hallucinations can lead to overconfident yet incorrect answers, severely undermining answer reliability. To address this, we propose Dual-Assessment for VLM Reliability (DAVR), a novel framework that integrates Self-Reflection and Cross-Model Verification for comprehensive uncertainty estimation. The DAVR framework features a dual-pathway architecture: one pathway leverages dual selector modules to assess response reliability by fusing VLM latent features with QA embeddings, while the other deploys external reference models for factual cross-checking to mitigate hallucinations. Evaluated in the Reliable VQA Challenge at ICCV-CLVL 2025, DAVR achieves a leading $\u03a6_{100}$ score of 39.64 and a 100-AUC of 97.22, securing first place and demonstrating its effectiveness in enhancing the trustworthiness of VLM responses.", "AI": {"tldr": "\u63d0\u51faDAVR\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u53cd\u601d\u4e0e\u8de8\u6a21\u578b\u9a8c\u8bc1\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728VQA\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u95ee\u9898\uff0c\u5728ICCV-CLVL 2025\u6311\u6218\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\u3002", "motivation": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u4e2d\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u5bfc\u81f4\u56de\u7b54\u8fc7\u4e8e\u81ea\u4fe1\u4f46\u9519\u8bef\uff0c\u4e25\u91cd\u635f\u5bb3\u7b54\u6848\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51faDAVR\u6846\u67b6\uff0c\u5305\u542b\u53cc\u8def\u5f84\u67b6\u6784\uff1a\u4e00\u8def\u4f7f\u7528\u53cc\u9009\u62e9\u5668\u6a21\u5757\u878d\u5408VLM\u6f5c\u5728\u7279\u5f81\u4e0e\u95ee\u7b54\u5d4c\u5165\u4ee5\u8bc4\u4f30\u56de\u7b54\u53ef\u9760\u6027\uff1b\u53e6\u4e00\u8def\u5f15\u5165\u5916\u90e8\u53c2\u8003\u6a21\u578b\u8fdb\u884c\u4e8b\u5b9e\u4ea4\u53c9\u9a8c\u8bc1\u4ee5\u7f13\u89e3\u5e7b\u89c9\u3002", "result": "\u5728ICCV-CLVL 2025\u7684Reliable VQA Challenge\u4e2d\uff0cDAVR\u53d6\u5f97\u03a6\u2081\u2080\u2080\u5f97\u520639.64\u548c100-AUC\u5f97\u520697.22\uff0c\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "DAVR\u6709\u6548\u63d0\u5347\u4e86VLM\u56de\u7b54\u7684\u53ef\u4fe1\u5ea6\uff0c\u4e3a\u89e3\u51b3VLM\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u7136\u800c\uff0cVLMs\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u5bfc\u81f4\u5176\u7ed9\u51fa\u8fc7\u4e8e\u81ea\u4fe1\u5374\u9519\u8bef\u7684\u7b54\u6848\uff0c\u4e25\u91cd\u524a\u5f31\u4e86\u56de\u7b54\u7684\u53ef\u9760\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u7528\u4e8eVLM\u53ef\u9760\u6027\u7684\u53cc\u91cd\u8bc4\u4f30\u201d\uff08DAVR\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u81ea\u53cd\u601d\u4e0e\u8de8\u6a21\u578b\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u5168\u9762\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002DAVR\u6846\u67b6\u91c7\u7528\u53cc\u8def\u5f84\u67b6\u6784\uff1a\u4e00\u6761\u8def\u5f84\u5229\u7528\u53cc\u9009\u62e9\u5668\u6a21\u5757\uff0c\u901a\u8fc7\u878d\u5408VLM\u7684\u6f5c\u5728\u7279\u5f81\u4e0e\u95ee\u7b54\u5d4c\u5165\u6765\u8bc4\u4f30\u56de\u7b54\u7684\u53ef\u9760\u6027\uff1b\u53e6\u4e00\u6761\u8def\u5f84\u5219\u90e8\u7f72\u5916\u90e8\u53c2\u8003\u6a21\u578b\u8fdb\u884c\u4e8b\u5b9e\u4ea4\u53c9\u6838\u67e5\uff0c\u4ee5\u51cf\u8f7b\u5e7b\u89c9\u73b0\u8c61\u3002\u5728ICCV-CLVL 2025\u4e3e\u529e\u7684Reliable VQA Challenge\u4e2d\uff0cDAVR\u53d6\u5f97\u4e86\u03a6\u2081\u2080\u2080\u5f97\u5206\u4e3a39.64\u3001100-AUC\u5f97\u5206\u4e3a97.22\u7684\u4f18\u5f02\u6210\u7ee9\uff0c\u4f4d\u5217\u7b2c\u4e00\uff0c\u5145\u5206\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347VLM\u56de\u7b54\u53ef\u4fe1\u5ea6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.14870", "pdf": "https://arxiv.org/pdf/2512.14870", "abs": "https://arxiv.org/abs/2512.14870", "authors": ["Dan Ben-Ami", "Gabriele Serussi", "Kobi Cohen", "Chaim Baskin"], "title": "HERBench: A Benchmark for Multi-Evidence Integration in Video Question Answering", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Video Large Language Models (Video-LLMs) are rapidly improving, yet current Video Question Answering (VideoQA) benchmarks often allow questions to be answered from a single salient cue, under-testing reasoning that must aggregate multiple, temporally separated visual evidence. We present HERBench, a VideoQA benchmark purpose-built to assess multi-evidence integration across time. Each question requires aggregating at least three non-overlapping evidential cues across distinct video segments, so neither language priors nor a single snapshot can suffice. HERBench comprises 26K five-way multiple-choice questions organized into twelve compositional tasks that probe identity binding, cross-entity relations, temporal ordering, co-occurrence verification, and counting. To make evidential demand measurable, we introduce the Minimum Required Frame-Set (MRFS), the smallest number of frames a model must fuse to answer correctly, and show that HERBench imposes substantially higher demand than prior datasets (mean MRFS 5.5 vs. 2.6-4.2). Evaluating 13 state-of-the-art Video-LLMs on HERBench reveals pervasive failures: accuracies of 31-42% are only slightly above the 20% random-guess baseline. We disentangle this failure into two critical bottlenecks: (1) a retrieval deficit, where frame selectors overlook key evidence, and (2) a fusion deficit, where models fail to integrate information even when all necessary evidence is provided. By making cross-time evidence both unavoidable and quantifiable, HERBench establishes a principled target for advancing robust, compositional video understanding.", "AI": {"tldr": "\u63d0\u51faHERBench\u89c6\u9891\u95ee\u7b54\u57fa\u51c6\uff0c\u4e13\u95e8\u8bc4\u4f30\u6a21\u578b\u8de8\u65f6\u95f4\u6574\u5408\u591a\u6761\u89c6\u89c9\u8bc1\u636e\u7684\u80fd\u529b\uff1b\u73b0\u670913\u4e2a\u5148\u8fdbVideo-LLM\u5728\u6b64\u57fa\u51c6\u4e0a\u8868\u73b0\u4ec5\u7565\u9ad8\u4e8e\u968f\u673a\u731c\u6d4b\uff0c\u63ed\u793a\u5176\u5728\u5173\u952e\u5e27\u68c0\u7d22\u548c\u4fe1\u606f\u878d\u5408\u4e24\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u74f6\u9888\u3002", "motivation": "\u5f53\u524d\u89c6\u9891\u95ee\u7b54\uff08VideoQA\uff09\u57fa\u51c6\u901a\u5e38\u5141\u8bb8\u4ec5\u51ed\u5355\u4e00\u663e\u8457\u7ebf\u7d22\u56de\u7b54\u95ee\u9898\uff0c\u672a\u80fd\u5145\u5206\u6d4b\u8bd5\u6a21\u578b\u6574\u5408\u591a\u4e2a\u3001\u65f6\u95f4\u4e0a\u5206\u79bb\u7684\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efaHERBench\u57fa\u51c6\uff0c\u5305\u542b26K\u4e2a\u4e94\u9009\u4e00\u591a\u9879\u9009\u62e9\u9898\uff0c\u6db5\u76d612\u79cd\u7ec4\u5408\u4efb\u52a1\uff0c\u8981\u6c42\u6bcf\u4e2a\u95ee\u9898\u5fc5\u987b\u6574\u5408\u81f3\u5c11\u4e09\u4e2a\u975e\u91cd\u53e0\u7684\u3001\u6765\u81ea\u4e0d\u540c\u89c6\u9891\u7247\u6bb5\u7684\u8bc1\u636e\u7ebf\u7d22\u3002\u5f15\u5165\u201c\u6700\u5c0f\u6240\u9700\u5e27\u96c6\u201d\uff08MRFS\uff09\u6307\u6807\u6765\u91cf\u5316\u6a21\u578b\u6b63\u786e\u56de\u7b54\u6240\u9700\u7684\u6700\u5c11\u5e27\u6570\u3002", "result": "HERBench\u7684\u5e73\u5747MRFS\u4e3a5.5\uff0c\u8fdc\u9ad8\u4e8e\u4ee5\u5f80\u6570\u636e\u96c6\uff082.6-4.2\uff09\u3002\u572813\u4e2a\u6700\u5148\u8fdb\u7684Video-LLM\u4e0a\u8bc4\u4f30\uff0c\u5176\u51c6\u786e\u7387\u4ec5\u4e3a31-42%\uff0c\u4ec5\u7565\u9ad8\u4e8e20%\u7684\u968f\u673a\u731c\u6d4b\u57fa\u7ebf\u3002\u5206\u6790\u53d1\u73b0\u5931\u8d25\u6e90\u4e8e\u4e24\u4e2a\u74f6\u9888\uff1a\u5173\u952e\u8bc1\u636e\u68c0\u7d22\u4e0d\u8db3\u548c\u4fe1\u606f\u878d\u5408\u5931\u8d25\u3002", "conclusion": "HERBench\u901a\u8fc7\u4f7f\u8de8\u65f6\u95f4\u8bc1\u636e\u6574\u5408\u53d8\u5f97\u4e0d\u53ef\u907f\u514d\u4e14\u53ef\u91cf\u5316\uff0c\u4e3a\u63a8\u52a8\u9c81\u68d2\u3001\u7ec4\u5408\u5f0f\u7684\u89c6\u9891\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u660e\u786e\u7684\u76ee\u6807\u548c\u8bc4\u4f30\u6807\u51c6\u3002", "summary_cn": "\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b\uff08Video-LLMs\uff09\u6b63\u5728\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u5f53\u524d\u7684\u89c6\u9891\u95ee\u7b54\uff08VideoQA\uff09\u57fa\u51c6\u901a\u5e38\u5141\u8bb8\u4ec5\u51ed\u5355\u4e00\u663e\u8457\u7ebf\u7d22\u56de\u7b54\u95ee\u9898\uff0c\u672a\u80fd\u5145\u5206\u6d4b\u8bd5\u6a21\u578b\u6574\u5408\u591a\u4e2a\u3001\u65f6\u95f4\u4e0a\u5206\u79bb\u7684\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002\u6211\u4eec\u63d0\u51fa\u4e86HERBench\uff0c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u8bc4\u4f30\u8de8\u65f6\u95f4\u591a\u8bc1\u636e\u6574\u5408\u80fd\u529b\u800c\u6784\u5efa\u7684VideoQA\u57fa\u51c6\u3002\u5176\u4e2d\u6bcf\u4e2a\u95ee\u9898\u90fd\u8981\u6c42\u6574\u5408\u81f3\u5c11\u4e09\u4e2a\u6765\u81ea\u4e0d\u540c\u89c6\u9891\u7247\u6bb5\u7684\u3001\u975e\u91cd\u53e0\u7684\u8bc1\u636e\u7ebf\u7d22\uff0c\u56e0\u6b64\u4ec5\u9760\u8bed\u8a00\u5148\u9a8c\u6216\u5355\u5e27\u5feb\u7167\u90fd\u65e0\u6cd5\u4f5c\u7b54\u3002HERBench\u5305\u542b2.6\u4e07\u4e2a\u4e94\u9009\u4e00\u591a\u9879\u9009\u62e9\u9898\uff0c\u7ec4\u7ec7\u6210\u5341\u4e8c\u4e2a\u7ec4\u5408\u4efb\u52a1\uff0c\u7528\u4ee5\u8003\u5bdf\u8eab\u4efd\u7ed1\u5b9a\u3001\u8de8\u5b9e\u4f53\u5173\u7cfb\u3001\u65f6\u95f4\u6392\u5e8f\u3001\u5171\u73b0\u9a8c\u8bc1\u548c\u8ba1\u6570\u7b49\u80fd\u529b\u3002\u4e3a\u4e86\u4f7f\u8bc1\u636e\u9700\u6c42\u53ef\u5ea6\u91cf\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u201c\u6700\u5c0f\u6240\u9700\u5e27\u96c6\u201d\uff08MRFS\uff09\uff0c\u5373\u6a21\u578b\u6b63\u786e\u4f5c\u7b54\u6240\u9700\u878d\u5408\u7684\u6700\u5c11\u5e27\u6570\uff0c\u5e76\u8bc1\u660eHERBench\u7684\u8981\u6c42\u8fdc\u9ad8\u4e8e\u4ee5\u5f80\u6570\u636e\u96c6\uff08\u5e73\u5747MRFS\u4e3a5.5\uff0c\u800c\u6b64\u524d\u4e3a2.6-4.2\uff09\u3002\u5728HERBench\u4e0a\u5bf913\u4e2a\u6700\u5148\u8fdb\u7684Video-LLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5176\u51c6\u786e\u7387\u4ec5\u4e3a31-42%\uff0c\u4ec5\u7565\u9ad8\u4e8e20%\u7684\u968f\u673a\u731c\u6d4b\u57fa\u7ebf\u3002\u6211\u4eec\u5c06\u6b64\u5931\u8d25\u5f52\u7ed3\u4e3a\u4e24\u4e2a\u5173\u952e\u74f6\u9888\uff1a\uff081\uff09\u68c0\u7d22\u7f3a\u9677\uff0c\u5373\u5e27\u9009\u62e9\u5668\u5ffd\u7565\u4e86\u5173\u952e\u8bc1\u636e\uff1b\uff082\uff09\u878d\u5408\u7f3a\u9677\uff0c\u5373\u5373\u4f7f\u63d0\u4f9b\u4e86\u6240\u6709\u5fc5\u8981\u8bc1\u636e\uff0c\u6a21\u578b\u4e5f\u65e0\u6cd5\u6709\u6548\u6574\u5408\u4fe1\u606f\u3002\u901a\u8fc7\u4f7f\u8de8\u65f6\u95f4\u8bc1\u636e\u6574\u5408\u53d8\u5f97\u4e0d\u53ef\u907f\u514d\u4e14\u53ef\u91cf\u5316\uff0cHERBench\u4e3a\u63a8\u8fdb\u9c81\u68d2\u3001\u7ec4\u5408\u5f0f\u7684\u89c6\u9891\u7406\u89e3\u80fd\u529b\u786e\u7acb\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u7684\u76ee\u6807\u3002"}}
{"id": "2512.14876", "pdf": "https://arxiv.org/pdf/2512.14876", "abs": "https://arxiv.org/abs/2512.14876", "authors": ["Daniel Perkins", "Davis Hunter", "Dhrumil Patel", "Galen Flanagan"], "title": "Isolated Sign Language Recognition with Segmentation and Pose Estimation", "categories": ["cs.CV"], "comment": "5 pages, 3 Figures", "summary": "The recent surge in large language models has automated translations of spoken and written languages. However, these advances remain largely inaccessible to American Sign Language (ASL) users, whose language relies on complex visual cues. Isolated sign language recognition (ISLR) - the task of classifying videos of individual signs - can help bridge this gap but is currently limited by scarce per-sign data, high signer variability, and substantial computational costs. We propose a model for ISLR that reduces computational requirements while maintaining robustness to signer variation. Our approach integrates (i) a pose estimation pipeline to extract hand and face joint coordinates, (ii) a segmentation module that isolates relevant information, and (iii) a ResNet-Transformer backbone to jointly model spatial and temporal dependencies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b64\u7acb\u624b\u8bed\u8bc6\u522b\uff08ISLR\uff09\u7684\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u59ff\u6001\u4f30\u8ba1\u3001\u4fe1\u606f\u5206\u5272\u548cResNet-Transformer\u9aa8\u5e72\u7f51\u7edc\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u5bf9\u4e0d\u540c\u624b\u8bed\u8005\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u53e3\u8bed\u548c\u4e66\u9762\u8bed\u7ffb\u8bd1\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u7f8e\u56fd\u624b\u8bed\uff08ASL\uff09\u7528\u6237\u56e0\u4f9d\u8d56\u590d\u6742\u89c6\u89c9\u7ebf\u7d22\u800c\u96be\u4ee5\u53d7\u76ca\u3002\u73b0\u6709ISLR\u65b9\u6cd5\u53d7\u9650\u4e8e\u6bcf\u7c7b\u624b\u8bed\u6837\u672c\u7a00\u5c11\u3001\u624b\u8bed\u8005\u5dee\u5f02\u5927\u4ee5\u53ca\u8ba1\u7b97\u5f00\u9500\u9ad8\u3002", "method": "\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u4e09\u4e2a\u6a21\u5757\uff1a(i) \u59ff\u6001\u4f30\u8ba1\u6d41\u7a0b\u4ee5\u63d0\u53d6\u624b\u90e8\u548c\u9762\u90e8\u5173\u8282\u5750\u6807\uff1b(ii) \u5206\u5272\u6a21\u5757\u4ee5\u9694\u79bb\u76f8\u5173\u4fe1\u606f\uff1b(iii) ResNet-Transformer\u9aa8\u5e72\u7f51\u7edc\u8054\u5408\u5efa\u6a21\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u8be5\u6a21\u578b\u5728\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u7684\u540c\u65f6\uff0c\u5bf9\u4e0d\u540c\u624b\u8bed\u8005\u7684\u5dee\u5f02\u8868\u73b0\u51fa\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684ISLR\u6a21\u578b\u6709\u6548\u7f13\u89e3\u4e86\u6570\u636e\u7a00\u7f3a\u3001\u4e2a\u4f53\u5dee\u5f02\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u6311\u6218\uff0c\u4e3a\u624b\u8bed\u8bc6\u522b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "summary_cn": "\u8fd1\u671f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fc5\u731b\u53d1\u5c55\u5df2\u5b9e\u73b0\u4e86\u5bf9\u53e3\u8bed\u548c\u4e66\u9762\u8bed\u8a00\u7ffb\u8bd1\u7684\u81ea\u52a8\u5316\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u8fdb\u5c55\u5bf9\u4e8e\u4f9d\u8d56\u590d\u6742\u89c6\u89c9\u7ebf\u7d22\u7684\u7f8e\u56fd\u624b\u8bed\uff08ASL\uff09\u7528\u6237\u800c\u8a00\u4ecd\u57fa\u672c\u65e0\u6cd5\u89e6\u53ca\u3002\u5b64\u7acb\u624b\u8bed\u8bc6\u522b\uff08ISLR\uff09\u2014\u2014\u5373\u5bf9\u5355\u4e2a\u624b\u8bed\u52a8\u4f5c\u89c6\u9891\u8fdb\u884c\u5206\u7c7b\u7684\u4efb\u52a1\u2014\u2014\u6709\u52a9\u4e8e\u5f25\u5408\u8fd9\u4e00\u9e3f\u6c9f\uff0c\u4f46\u76ee\u524d\u53d7\u9650\u4e8e\u6bcf\u7c7b\u624b\u8bed\u6837\u672c\u7a00\u7f3a\u3001\u624b\u8bed\u8005\u95f4\u5dee\u5f02\u663e\u8457\u4ee5\u53ca\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eISLR\u7684\u6a21\u578b\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u9700\u6c42\u7684\u540c\u65f6\u4fdd\u6301\u5bf9\u624b\u8bed\u8005\u5dee\u5f02\u7684\u9c81\u68d2\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u6574\u5408\u4e86\u4ee5\u4e0b\u4e09\u4e2a\u90e8\u5206\uff1a(i) \u4e00\u4e2a\u59ff\u6001\u4f30\u8ba1\u6d41\u7a0b\uff0c\u7528\u4e8e\u63d0\u53d6\u624b\u90e8\u548c\u9762\u90e8\u5173\u8282\u5750\u6807\uff1b(ii) \u4e00\u4e2a\u5206\u5272\u6a21\u5757\uff0c\u7528\u4e8e\u9694\u79bb\u76f8\u5173\u4fe1\u606f\uff1b(iii) \u4e00\u4e2aResNet-Transformer\u9aa8\u5e72\u7f51\u7edc\uff0c\u7528\u4e8e\u8054\u5408\u5efa\u6a21\u7a7a\u95f4\u548c\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002"}}
{"id": "2512.14878", "pdf": "https://arxiv.org/pdf/2512.14878", "abs": "https://arxiv.org/abs/2512.14878", "authors": ["Wenshuo Li", "Majid Mirmehdi", "Tilo Burghardt"], "title": "Visual-textual Dermatoglyphic Animal Biometrics: A First Case Study on Panthera tigris", "categories": ["cs.CV"], "comment": null, "summary": "Biologists have long combined visuals with textual field notes to re-identify (Re-ID) animals. Contemporary AI tools automate this for species with distinctive morphological features but remain largely image-based. Here, we extend Re-ID methodologies by incorporating precise dermatoglyphic textual descriptors-an approach used in forensics but new to ecology. We demonstrate that these specialist semantics abstract and encode animal coat topology using human-interpretable language tags. Drawing on 84,264 manually labelled minutiae across 3,355 images of 185 tigers (Panthera tigris), we evaluate this visual-textual methodology, revealing novel capabilities for cross-modal identity retrieval. To optimise performance, we developed a text-image co-synthesis pipeline to generate 'virtual individuals', each comprising dozens of life-like visuals paired with dermatoglyphic text. Benchmarking against real-world scenarios shows this augmentation significantly boosts AI accuracy in cross-modal retrieval while alleviating data scarcity. We conclude that dermatoglyphic language-guided biometrics can overcome vision-only limitations, enabling textual-to-visual identity recovery underpinned by human-verifiable matchings. This represents a significant advance towards explainability in Re-ID and a language-driven unification of descriptive modalities in ecological monitoring.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u76ae\u80a4\u7eb9\u7406\uff08dermatoglyphic\uff09\u6587\u672c\u63cf\u8ff0\u4e0e\u56fe\u50cf\u7684\u8de8\u6a21\u6001\u52a8\u7269\u91cd\u8bc6\u522b\uff08Re-ID\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u8bed\u8a00\u6807\u7b7e\u7f16\u7801\u864e\u7684\u6591\u7eb9\u62d3\u6251\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u6587\u672c-\u56fe\u50cf\u534f\u540c\u5408\u6210\u751f\u6210\u865a\u62df\u4e2a\u4f53\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347AI\u5728\u8de8\u6a21\u6001\u8eab\u4efd\u68c0\u7d22\u4e2d\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709AI\u91cd\u8bc6\u522b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u56fe\u50cf\uff0c\u96be\u4ee5\u878d\u5408\u751f\u6001\u5b66\u5bb6\u957f\u671f\u4f7f\u7528\u7684\u6587\u672c\u63cf\u8ff0\uff1b\u4f5c\u8005\u5e0c\u671b\u5f15\u5165\u6cd5\u533b\u5b66\u4e2d\u4f7f\u7528\u7684\u7cbe\u786e\u76ae\u80a4\u7eb9\u7406\u6587\u672c\u63cf\u8ff0\uff0c\u63d0\u5347Re-ID\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u8de8\u6a21\u6001\u80fd\u529b\u3002", "method": "\u57fa\u4e8e185\u53ea\u8001\u864e\u51713,355\u5f20\u56fe\u50cf\u548c84,264\u4e2a\u624b\u52a8\u6807\u6ce8\u7684\u7ec6\u8282\u7279\u5f81\uff0c\u6784\u5efa\u89c6\u89c9-\u6587\u672c\u8054\u5408\u6a21\u578b\uff1b\u5f00\u53d1\u6587\u672c-\u56fe\u50cf\u534f\u540c\u5408\u6210\u7ba1\u9053\uff0c\u751f\u6210\u5305\u542b\u903c\u771f\u56fe\u50cf\u4e0e\u5bf9\u5e94\u76ae\u80a4\u7eb9\u7406\u6587\u672c\u63cf\u8ff0\u7684\u201c\u865a\u62df\u4e2a\u4f53\u201d\u7528\u4e8e\u6570\u636e\u589e\u5f3a\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u6a21\u6001\u8eab\u4efd\u68c0\u7d22\u7684\u51c6\u786e\u7387\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u4eba\u7c7b\u53ef\u9a8c\u8bc1\u7684\u8eab\u4efd\u5339\u914d\u3002", "conclusion": "\u5f15\u5165\u76ae\u80a4\u7eb9\u7406\u8bed\u8a00\u5f15\u5bfc\u7684\u751f\u7269\u8bc6\u522b\u65b9\u6cd5\u53ef\u7a81\u7834\u7eaf\u89c6\u89c9\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5b9e\u73b0\u6587\u672c\u5230\u89c6\u89c9\u7684\u8eab\u4efd\u6062\u590d\uff0c\u63a8\u52a8Re-ID\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4fc3\u8fdb\u751f\u6001\u76d1\u6d4b\u4e2d\u63cf\u8ff0\u6a21\u6001\u7684\u8bed\u8a00\u7edf\u4e00\u3002", "summary_cn": "\u751f\u7269\u5b66\u5bb6\u957f\u671f\u4ee5\u6765\u7ed3\u5408\u89c6\u89c9\u56fe\u50cf\u4e0e\u6587\u5b57\u91ce\u5916\u7b14\u8bb0\u6765\u8fdb\u884c\u52a8\u7269\u91cd\u8bc6\u522b\uff08Re-ID\uff09\u3002\u5f53\u524d\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u867d\u5df2\u80fd\u81ea\u52a8\u5316\u5904\u7406\u5177\u6709\u72ec\u7279\u5f62\u6001\u7279\u5f81\u7684\u7269\u79cd\uff0c\u4f46\u4e3b\u8981\u4ecd\u57fa\u4e8e\u56fe\u50cf\u3002\u672c\u6587\u901a\u8fc7\u5f15\u5165\u7cbe\u786e\u7684\u76ae\u80a4\u7eb9\u7406\uff08dermatoglyphic\uff09\u6587\u672c\u63cf\u8ff0\u2014\u2014\u8fd9\u4e00\u5728\u6cd5\u533b\u5b66\u4e2d\u5e38\u7528\u4f46\u5728\u751f\u6001\u5b66\u4e2d\u5c1a\u5c5e\u65b0\u9896\u7684\u65b9\u6cd5\u2014\u2014\u62d3\u5c55\u4e86Re-ID\u6280\u672f\u3002\u6211\u4eec\u8bc1\u660e\uff0c\u8fd9\u7c7b\u4e13\u4e1a\u8bed\u4e49\u53ef\u901a\u8fc7\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u8bed\u8a00\u6807\u7b7e\u5bf9\u52a8\u7269\u76ae\u6bdb\u62d3\u6251\u7ed3\u6784\u8fdb\u884c\u62bd\u8c61\u4e0e\u7f16\u7801\u3002\u57fa\u4e8e185\u53ea\u8001\u864e\uff08Panthera tigris\uff09\u76843,355\u5f20\u56fe\u50cf\u4e2d\u624b\u52a8\u6807\u6ce8\u768484,264\u4e2a\u7ec6\u8282\u7279\u5f81\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u8fd9\u79cd\u89c6\u89c9-\u6587\u672c\u65b9\u6cd5\uff0c\u63ed\u793a\u5176\u5728\u8de8\u6a21\u6001\u8eab\u4efd\u68c0\u7d22\u4e2d\u7684\u65b0\u80fd\u529b\u3002\u4e3a\u4f18\u5316\u6027\u80fd\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u6587\u672c-\u56fe\u50cf\u534f\u540c\u5408\u6210\u6d41\u7a0b\uff0c\u751f\u6210\u201c\u865a\u62df\u4e2a\u4f53\u201d\uff0c\u6bcf\u4e2a\u4e2a\u4f53\u5305\u542b\u6570\u5341\u5f20\u903c\u771f\u7684\u56fe\u50cf\u53ca\u5176\u5bf9\u5e94\u7684\u76ae\u80a4\u7eb9\u7406\u6587\u672c\u63cf\u8ff0\u3002\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u8fd9\u79cd\u6570\u636e\u589e\u5f3a\u663e\u8457\u63d0\u5347\u4e86AI\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u7f13\u89e3\u4e86\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff1a\u76ae\u80a4\u7eb9\u7406\u8bed\u8a00\u5f15\u5bfc\u7684\u751f\u7269\u8bc6\u522b\u65b9\u6cd5\u80fd\u591f\u514b\u670d\u7eaf\u89c6\u89c9\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5b9e\u73b0\u57fa\u4e8e\u4eba\u7c7b\u53ef\u9a8c\u8bc1\u5339\u914d\u7684\u6587\u672c\u5230\u89c6\u89c9\u8eab\u4efd\u6062\u590d\u3002\u8fd9\u6807\u5fd7\u7740Re-ID\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u4e5f\u662f\u751f\u6001\u76d1\u6d4b\u4e2d\u63cf\u8ff0\u6a21\u6001\u8bed\u8a00\u9a71\u52a8\u7edf\u4e00\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2512.14884", "pdf": "https://arxiv.org/pdf/2512.14884", "abs": "https://arxiv.org/abs/2512.14884", "authors": ["Huzheng Yang", "Katherine Xu", "Andrew Lu", "Michael D. Grossberg", "Yutong Bai", "Jianbo Shi"], "title": "Vibe Spaces for Creatively Connecting and Expressing Visual Concepts", "categories": ["cs.CV"], "comment": "Project page: https://huzeyann.github.io/VibeSpace-webpage/", "summary": "Creating new visual concepts often requires connecting distinct ideas through their most relevant shared attributes -- their vibe. We introduce Vibe Blending, a novel task for generating coherent and meaningful hybrids that reveals these shared attributes between images. Achieving such blends is challenging for current methods, which struggle to identify and traverse nonlinear paths linking distant concepts in latent space. We propose Vibe Space, a hierarchical graph manifold that learns low-dimensional geodesics in feature spaces like CLIP, enabling smooth and semantically consistent transitions between concepts. To evaluate creative quality, we design a cognitively inspired framework combining human judgments, LLM reasoning, and a geometric path-based difficulty score. We find that Vibe Space produces blends that humans consistently rate as more creative and coherent than current methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u6c1b\u56f4\u878d\u5408\u201d\uff08Vibe Blending\uff09\u4efb\u52a1\u53ca\u201c\u6c1b\u56f4\u7a7a\u95f4\u201d\uff08Vibe Space\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728CLIP\u7b49\u7279\u5f81\u7a7a\u95f4\u4e2d\u6784\u5efa\u5206\u5c42\u56fe\u6d41\u5f62\uff0c\u5b66\u4e60\u4f4e\u7ef4\u6d4b\u5730\u7ebf\u4ee5\u5b9e\u73b0\u4e0d\u540c\u89c6\u89c9\u6982\u5ff5\u95f4\u7684\u8bed\u4e49\u8fde\u8d2f\u878d\u5408\uff0c\u5e76\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u5224\u65ad\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u51e0\u4f55\u8def\u5f84\u96be\u5ea6\u8bc4\u5206\u7684\u8bc4\u4f30\u6846\u67b6\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u96be\u4ee5\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8bc6\u522b\u5e76\u7a7f\u8d8a\u8fde\u63a5\u8fdc\u8ddd\u79bb\u6982\u5ff5\u7684\u975e\u7ebf\u6027\u8def\u5f84\uff0c\u4ece\u800c\u65e0\u6cd5\u6709\u6548\u751f\u6210\u5177\u6709\u5171\u4eab\u5c5e\u6027\uff08\u5373\u201c\u6c1b\u56f4\u201d\uff09\u7684\u8fde\u8d2f\u4e14\u6709\u610f\u4e49\u7684\u65b0\u89c6\u89c9\u6982\u5ff5\u3002", "method": "\u63d0\u51fa\u201c\u6c1b\u56f4\u7a7a\u95f4\u201d\uff08Vibe Space\uff09\uff0c\u4e00\u79cd\u5206\u5c42\u56fe\u6d41\u5f62\u7ed3\u6784\uff0c\u5728CLIP\u7b49\u7279\u5f81\u7a7a\u95f4\u4e2d\u5b66\u4e60\u4f4e\u7ef4\u6d4b\u5730\u7ebf\uff0c\u4ee5\u5b9e\u73b0\u6982\u5ff5\u4e4b\u95f4\u5e73\u6ed1\u4e14\u8bed\u4e49\u4e00\u81f4\u7684\u8fc7\u6e21\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVibe Space \u751f\u6210\u7684\u6982\u5ff5\u878d\u5408\u7ed3\u679c\u5728\u4eba\u7c7b\u8bc4\u4ef7\u4e2d\u59cb\u7ec8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5177\u521b\u610f\u6027\u548c\u8fde\u8d2f\u6027\u3002", "conclusion": "Vibe Space \u80fd\u6709\u6548\u6355\u6349\u5e76\u5229\u7528\u56fe\u50cf\u95f4\u7684\u5171\u4eab\u6c1b\u56f4\u5c5e\u6027\uff0c\u663e\u8457\u63d0\u5347\u8de8\u6982\u5ff5\u89c6\u89c9\u878d\u5408\u7684\u521b\u9020\u6027\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "summary_cn": "\u521b\u9020\u65b0\u7684\u89c6\u89c9\u6982\u5ff5\u901a\u5e38\u9700\u8981\u901a\u8fc7\u5176\u6700\u76f8\u5173\u7684\u5171\u4eab\u5c5e\u6027\u2014\u2014\u5373\u201c\u6c1b\u56f4\u201d\uff08vibe\uff09\u2014\u2014\u5c06\u4e0d\u540c\u7684\u60f3\u6cd5\u8054\u7cfb\u8d77\u6765\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u6c1b\u56f4\u878d\u5408\u201d\uff08Vibe Blending\uff09\u8fd9\u4e00\u65b0\u4efb\u52a1\uff0c\u7528\u4e8e\u751f\u6210\u8fde\u8d2f\u4e14\u6709\u610f\u4e49\u7684\u6df7\u5408\u56fe\u50cf\uff0c\u4ece\u800c\u63ed\u793a\u56fe\u50cf\u4e4b\u95f4\u7684\u5171\u4eab\u5c5e\u6027\u3002\u5f53\u524d\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u6b64\u7c7b\u878d\u5408\uff0c\u56e0\u5176\u96be\u4ee5\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8bc6\u522b\u5e76\u7a7f\u8d8a\u8fde\u63a5\u9065\u8fdc\u6982\u5ff5\u7684\u975e\u7ebf\u6027\u8def\u5f84\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u6c1b\u56f4\u7a7a\u95f4\u201d\uff08Vibe Space\uff09\uff0c\u4e00\u79cd\u5206\u5c42\u56fe\u6d41\u5f62\u7ed3\u6784\uff0c\u53ef\u5728CLIP\u7b49\u7279\u5f81\u7a7a\u95f4\u4e2d\u5b66\u4e60\u4f4e\u7ef4\u6d4b\u5730\u7ebf\uff0c\u4ece\u800c\u5b9e\u73b0\u6982\u5ff5\u4e4b\u95f4\u5e73\u6ed1\u4e14\u8bed\u4e49\u4e00\u81f4\u7684\u8fc7\u6e21\u3002\u4e3a\u8bc4\u4f30\u751f\u6210\u7ed3\u679c\u7684\u521b\u9020\u6027\u8d28\u91cf\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53d7\u8ba4\u77e5\u542f\u53d1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u4eba\u7c7b\u5224\u65ad\u3001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4ee5\u53ca\u57fa\u4e8e\u51e0\u4f55\u8def\u5f84\u7684\u96be\u5ea6\u8bc4\u5206\u3002\u7814\u7a76\u53d1\u73b0\uff0cVibe Space \u751f\u6210\u7684\u878d\u5408\u7ed3\u679c\u5728\u4eba\u7c7b\u8bc4\u4ef7\u4e2d\u59cb\u7ec8\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5177\u521b\u610f\u6027\u548c\u8fde\u8d2f\u6027\u3002"}}
{"id": "2512.14922", "pdf": "https://arxiv.org/pdf/2512.14922", "abs": "https://arxiv.org/abs/2512.14922", "authors": ["Joshua L. Ebbert", "Dennis Della Corte"], "title": "PANDA-PLUS-Bench: A Clinical Benchmark for Evaluating Robustness of AI Foundation Models in Prostate Cancer Diagnosis", "categories": ["cs.CV"], "comment": "21 pages, 5 figures, 6 Tables", "summary": "Artificial intelligence foundation models are increasingly deployed for prostate cancer Gleason grading, where GP3/GP4 distinction directly impacts treatment decisions. However, these models may achieve high validation accuracy by learning specimen-specific artifacts rather than generalizable biological features, limiting real-world clinical utility. We introduce PANDA-PLUS-Bench, a curated benchmark dataset derived from expert-annotated prostate biopsies designed specifically to quantify this failure mode. The benchmark comprises nine carefully selected whole slide images from nine unique patients containing diverse Gleason patterns, with non-overlapping tissue patches extracted at both 512x512 and 224x224 pixel resolutions across eight augmentation conditions. Using this benchmark, we evaluate seven foundation models on their ability to separate biological signal from slide-level confounders. Our results reveal substantial variation in robustness across models: Virchow2 achieved the lowest slide-level encoding among large-scale models (81.0%) yet exhibited the second-lowest cross-slide accuracy (47.2%). HistoEncoder, trained specifically on prostate tissue, demonstrated the highest cross-slide accuracy (59.7%) and the strongest slide-level encoding (90.3%), suggesting tissue-specific training may enhance both biological feature capture and slide-specific signatures. All models exhibited measurable within-slide vs. cross-slide accuracy gaps, though the magnitude varied from 19.9 percentage points to 26.9 percentage points. We provide an open-source Google Colab notebook enabling researchers to evaluate additional foundation models against our benchmark using standardized metrics. PANDA-PLUS-Bench addresses a critical gap in foundation model evaluation by providing a purpose-built resource for robustness assessment in the clinically important context of Gleason grading.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PANDA-PLUS-Bench\uff0c\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u524d\u5217\u817a\u764cGleason\u5206\u7ea7\u4e2dAI\u57fa\u7840\u6a21\u578b\u662f\u5426\u4f9d\u8d56\u5207\u7247\u7279\u5f02\u6027\u4f2a\u5f71\u800c\u975e\u751f\u7269\u5b66\u7279\u5f81\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002\u901a\u8fc7\u5728\u4e5d\u4f4d\u60a3\u8005\u7684\u6d3b\u68c0\u5207\u7247\u4e0a\u63d0\u53d6\u4e0d\u540c\u5206\u8fa8\u7387\u548c\u589e\u5f3a\u6761\u4ef6\u4e0b\u7684\u56fe\u50cf\u5757\uff0c\u4f5c\u8005\u6d4b\u8bd5\u4e86\u4e03\u4e2a\u57fa\u7840\u6a21\u578b\u5bf9\u751f\u7269\u4fe1\u53f7\u4e0e\u5207\u7247\u6df7\u6742\u56e0\u7d20\u7684\u533a\u5206\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\u6a21\u578b\u95f4\u9c81\u68d2\u6027\u5dee\u5f02\u663e\u8457\uff1aHistoEncoder\uff08\u4e13\u4e3a\u524d\u5217\u817a\u7ec4\u7ec7\u8bad\u7ec3\uff09\u8868\u73b0\u6700\u4f73\uff0c\u800cVirchow2\u867d\u5207\u7247\u7f16\u7801\u6700\u4f4e\u4f46\u8de8\u5207\u7247\u51c6\u786e\u7387\u4e5f\u8f83\u4f4e\u3002\u6240\u6709\u6a21\u578b\u5747\u5b58\u5728\u660e\u663e\u7684\u7247\u5185\u4e0e\u8de8\u7247\u51c6\u786e\u7387\u5dee\u8ddd\u3002\u8be5\u57fa\u51c6\u586b\u8865\u4e86\u4e34\u5e8a\u76f8\u5173\u4efb\u52a1\u4e2d\u6a21\u578b\u9c81\u68d2\u6027\u8bc4\u4f30\u7684\u7a7a\u767d\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u524d\u5217\u817a\u764cGleason\u5206\u7ea7\u7684\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u5b66\u4e60\u5207\u7247\u7279\u5f02\u6027\u4f2a\u5f71\uff08\u5982\u67d3\u8272\u3001\u5236\u7247\u5de5\u827a\u7b49\uff09\u800c\u975e\u53ef\u6cdb\u5316\u7684\u751f\u7269\u5b66\u7279\u5f81\u6765\u83b7\u5f97\u9ad8\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u5bfc\u81f4\u5176\u5728\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u6027\u80fd\u53d7\u9650\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u57fa\u51c6\u6765\u91cf\u5316\u8fd9\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u5bf9\u751f\u7269\u4fe1\u53f7\u4e0e\u5207\u7247\u6df7\u6742\u56e0\u7d20\u7684\u533a\u5206\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86PANDA-PLUS-Bench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u6765\u81ea9\u4f4d\u72ec\u7279\u60a3\u8005\u7684\u4e13\u5bb6\u6807\u6ce8\u524d\u5217\u817a\u6d3b\u68c0\u5168\u5207\u7247\u56fe\u50cf\uff0c\u4ece\u4e2d\u63d0\u53d6\u975e\u91cd\u53e0\u7ec4\u7ec7\u56fe\u50cf\u5757\uff08512x512\u548c224x224\u50cf\u7d20\uff09\uff0c\u5e76\u57288\u79cd\u589e\u5f3a\u6761\u4ef6\u4e0b\u751f\u6210\u591a\u6837\u672c\u3002\u5229\u7528\u8be5\u57fa\u51c6\uff0c\u8bc4\u4f307\u4e2a\u57fa\u7840\u6a21\u578b\u5728\u5206\u79bb\u751f\u7269\u4fe1\u53f7\u4e0e\u5207\u7247\u7ea7\u6df7\u6742\u56e0\u7d20\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e3b\u8981\u6307\u6807\u5305\u62ec\u8de8\u5207\u7247\u51c6\u786e\u7387\u548c\u5207\u7247\u7ea7\u7f16\u7801\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u9c81\u68d2\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1aHistoEncoder\uff08\u4e13\u4e3a\u524d\u5217\u817a\u7ec4\u7ec7\u8bad\u7ec3\uff09\u53d6\u5f97\u6700\u9ad8\u7684\u8de8\u5207\u7247\u51c6\u786e\u7387\uff0859.7%\uff09\u548c\u6700\u5f3a\u7684\u5207\u7247\u7ea7\u7f16\u7801\uff0890.3%\uff09\uff1bVirchow2\u5728\u5927\u6a21\u578b\u4e2d\u5207\u7247\u7f16\u7801\u6700\u4f4e\uff0881.0%\uff09\uff0c\u4f46\u8de8\u5207\u7247\u51c6\u786e\u7387\u4e5f\u8f83\u4f4e\uff0847.2%\uff09\u3002\u6240\u6709\u6a21\u578b\u5747\u8868\u73b0\u51fa\u7247\u5185\u4e0e\u8de8\u7247\u51c6\u786e\u7387\u5dee\u8ddd\uff0819.9\u201326.9\u4e2a\u767e\u5206\u70b9\uff09\u3002\u4f5c\u8005\u8fd8\u63d0\u4f9b\u4e86\u5f00\u6e90Colab\u7b14\u8bb0\u672c\u4ee5\u652f\u6301\u540e\u7eed\u8bc4\u4f30\u3002", "conclusion": "PANDA-PLUS-Bench\u4e3a\u8bc4\u4f30Gleason\u5206\u7ea7\u4efb\u52a1\u4e2d\u57fa\u7840\u6a21\u578b\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e13\u95e8\u6784\u5efa\u7684\u8d44\u6e90\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u666e\u904d\u5b58\u5728\u7684\u5bf9\u5207\u7247\u7279\u5f02\u6027\u4f2a\u5f71\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u5e76\u8868\u660e\u7ec4\u7ec7\u7279\u5f02\u6027\u8bad\u7ec3\u53ef\u80fd\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u5bf9\u771f\u5b9e\u751f\u7269\u7279\u5f81\u7684\u6355\u6349\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u586b\u8865\u4e86\u4e34\u5e8aAI\u6a21\u578b\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u7a7a\u767d\u3002", "summary_cn": "\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u5e94\u7528\u4e8e\u524d\u5217\u817a\u764cGleason\u5206\u7ea7\u4efb\u52a1\uff0c\u5176\u4e2dGP3\u4e0eGP4\u7684\u533a\u5206\u76f4\u63a5\u5f71\u54cd\u6cbb\u7597\u51b3\u7b56\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u53ef\u80fd\u901a\u8fc7\u5b66\u4e60\u5207\u7247\u7279\u5f02\u6027\u4f2a\u5f71\u800c\u975e\u53ef\u6cdb\u5316\u7684\u751f\u7269\u5b66\u7279\u5f81\u6765\u5b9e\u73b0\u8f83\u9ad8\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u4ece\u800c\u9650\u5236\u4e86\u5176\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86PANDA-PLUS-Bench\u2014\u2014\u4e00\u4e2a\u7531\u4e13\u5bb6\u6807\u6ce8\u7684\u524d\u5217\u817a\u6d3b\u68c0\u6837\u672c\u6784\u5efa\u7684\u7cbe\u9009\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u7528\u4e8e\u91cf\u5316\u6b64\u7c7b\u5931\u6548\u6a21\u5f0f\u3002\u8be5\u57fa\u51c6\u5305\u542b\u6765\u81ea\u4e5d\u4f4d\u4e0d\u540c\u60a3\u8005\u7684\u4e5d\u5f20\u5168\u5207\u7247\u56fe\u50cf\uff0c\u6db5\u76d6\u591a\u79cdGleason\u6a21\u5f0f\uff0c\u5e76\u5728\u516b\u79cd\u589e\u5f3a\u6761\u4ef6\u4e0b\u63d0\u53d6\u4e86512\u00d7512\u548c224\u00d7224\u50cf\u7d20\u5206\u8fa8\u7387\u7684\u975e\u91cd\u53e0\u7ec4\u7ec7\u56fe\u50cf\u5757\u3002\u5229\u7528\u8be5\u57fa\u51c6\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u4e03\u4e2a\u57fa\u7840\u6a21\u578b\u5728\u5206\u79bb\u751f\u7269\u4fe1\u53f7\u4e0e\u5207\u7247\u7ea7\u6df7\u6742\u56e0\u7d20\u65b9\u9762\u7684\u80fd\u529b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5404\u6a21\u578b\u7684\u9c81\u68d2\u6027\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1aVirchow2\u5728\u5927\u89c4\u6a21\u6a21\u578b\u4e2d\u5177\u6709\u6700\u4f4e\u7684\u5207\u7247\u7ea7\u7f16\u7801\uff0881.0%\uff09\uff0c\u4f46\u5176\u8de8\u5207\u7247\u51c6\u786e\u7387\u4e5f\u4f4d\u5c45\u7b2c\u4e8c\u4f4e\uff0847.2%\uff09\uff1b\u800c\u4e13\u4e3a\u524d\u5217\u817a\u7ec4\u7ec7\u8bad\u7ec3\u7684HistoEncoder\u5219\u5c55\u73b0\u51fa\u6700\u9ad8\u7684\u8de8\u5207\u7247\u51c6\u786e\u7387\uff0859.7%\uff09\u548c\u6700\u5f3a\u7684\u5207\u7247\u7ea7\u7f16\u7801\uff0890.3%\uff09\uff0c\u8868\u660e\u7ec4\u7ec7\u7279\u5f02\u6027\u8bad\u7ec3\u53ef\u80fd\u540c\u65f6\u589e\u5f3a\u6a21\u578b\u5bf9\u751f\u7269\u7279\u5f81\u7684\u6355\u6349\u80fd\u529b\u548c\u5bf9\u5207\u7247\u7279\u5f02\u6027\u4fe1\u53f7\u7684\u5b66\u4e60\u3002\u6240\u6709\u6a21\u578b\u5747\u8868\u73b0\u51fa\u53ef\u6d4b\u91cf\u7684\u7247\u5185\u4e0e\u8de8\u7247\u51c6\u786e\u7387\u5dee\u8ddd\uff0c\u5dee\u8ddd\u5e45\u5ea6\u4ece19.9\u4e2a\u767e\u5206\u70b9\u523026.9\u4e2a\u767e\u5206\u70b9\u4e0d\u7b49\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u6e90\u7684Google Colab\u7b14\u8bb0\u672c\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u4f7f\u7528\u6807\u51c6\u5316\u6307\u6807\u5728\u8be5\u57fa\u51c6\u4e0a\u8bc4\u4f30\u66f4\u591a\u57fa\u7840\u6a21\u578b\u3002PANDA-PLUS-Bench\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u4e13\u4e3a\u6b64\u76ee\u7684\u6784\u5efa\u7684\u8d44\u6e90\uff0c\u5728Gleason\u5206\u7ea7\u8fd9\u4e00\u4e34\u5e8a\u91cd\u8981\u4efb\u52a1\u4e2d\u586b\u8865\u4e86\u57fa\u7840\u6a21\u578b\u8bc4\u4f30\u7684\u5173\u952e\u7a7a\u767d\u3002"}}
