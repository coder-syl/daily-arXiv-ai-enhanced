{"id": "2602.03878", "pdf": "https://arxiv.org/pdf/2602.03878", "abs": "https://arxiv.org/abs/2602.03878", "authors": ["Longjie Zhao", "Ziming Hong", "Jiaxin Huang", "Runnan Chen", "Mingming Gong", "Tongliang Liu"], "title": "Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey", "categories": ["cs.CV", "cs.CR"], "comment": "A collection of relevant papers is summarized and will be continuously updated at \\url{https://github.com/tmllab/Awesome-3DGS-IP-Protection}", "summary": "3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and robustness challenges. To address this gap, we present the first systematic survey on 3DGS IP protection and introduce a bottom-up framework that examines (i) underlying Gaussian-based perturbation mechanisms, (ii) passive and active protection paradigms, and (iii) robustness threats under emerging generative AI era, revealing gaps in technical foundations and robustness characterization and indicating opportunities for deeper investigation. Finally, we outline six research directions across robustness, efficiency, and protection paradigms, offering a roadmap toward reliable and trustworthy IP protection for 3DGS assets.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf93D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u9886\u57df\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u4e0b\u800c\u4e0a\u7684\u5206\u6790\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u516d\u5927\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u77403D\u9ad8\u65af\u6cfc\u6e85\u5728\u5b9e\u65f63D\u573a\u666f\u5408\u6210\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u53ca\u5176\u5546\u4e1a\u4ef7\u503c\u63d0\u5347\uff0c\u5176\u663e\u5f0f\u7684\u53c2\u6570\u5316\u7ed3\u6784\u5f15\u53d1\u4e86\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u65b0\u9700\u6c42\uff0c\u4f46\u5f53\u524d\u7814\u7a76\u5206\u6563\uff0c\u7f3a\u4e4f\u7edf\u4e00\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u6027\u7efc\u8ff0\u6846\u67b6\uff0c\u4ece\u5e95\u5c42\u9ad8\u65af\u6270\u52a8\u673a\u5236\u3001\u88ab\u52a8\u4e0e\u4e3b\u52a8\u4fdd\u62a4\u8303\u5f0f\u3001\u4ee5\u53ca\u751f\u6210\u5f0fAI\u65f6\u4ee3\u4e0b\u7684\u9c81\u68d2\u6027\u5a01\u80c1\u4e09\u4e2a\u5c42\u9762\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u57fa\u7840\u548c\u9c81\u68d2\u6027\u8868\u5f81\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u8bc6\u522b\u51fa\u6df1\u5165\u7814\u7a76\u7684\u673a\u4f1a\u3002", "conclusion": "\u4e3a3DGS\u8d44\u4ea7\u7684\u53ef\u9760\u53ef\u4fe1\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u6db5\u76d6\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u4fdd\u62a4\u8303\u5f0f\u7b49\u516d\u4e2a\u65b9\u5411\u3002", "summary_cn": "3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5df2\u6210\u4e3a\u5b9e\u73b0\u5b9e\u65f63D\u573a\u666f\u5408\u6210\u7684\u4e3b\u6d41\u8868\u793a\u65b9\u6cd5\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u865a\u62df\u4e0e\u589e\u5f3a\u73b0\u5b9e\u3001\u673a\u5668\u4eba\u6280\u672f\u548c3D\u5185\u5bb9\u521b\u4f5c\u7b49\u9886\u57df\u3002\u5176\u65e5\u76ca\u589e\u957f\u7684\u5546\u4e1a\u4ef7\u503c\u548c\u663e\u5f0f\u7684\u53c2\u6570\u5316\u7ed3\u6784\u5f15\u53d1\u4e86\u65b0\u5174\u7684\u77e5\u8bc6\u4ea7\u6743\uff08IP\uff09\u4fdd\u62a4\u95ee\u9898\uff0c\u4fc3\u4f7f\u5b66\u754c\u5bf93DGS\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u5c55\u5f00\u5927\u91cf\u7814\u7a76\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u7814\u7a76\u4ecd\u8f83\u4e3a\u96f6\u6563\uff0c\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u673a\u5236\u3001\u4fdd\u62a4\u8303\u5f0f\u53ca\u9c81\u68d2\u6027\u6311\u6218\u7684\u7edf\u4e00\u8ba4\u8bc6\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6211\u4eec\u9996\u6b21\u5bf93DGS\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u81ea\u4e0b\u800c\u4e0a\u7684\u5206\u6790\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6db5\u76d6\uff1a\uff08i\uff09\u57fa\u4e8e\u9ad8\u65af\u7684\u5e95\u5c42\u6270\u52a8\u673a\u5236\uff0c\uff08ii\uff09\u88ab\u52a8\u4e0e\u4e3b\u52a8\u4fdd\u62a4\u8303\u5f0f\uff0c\u4ee5\u53ca\uff08iii\uff09\u5728\u65b0\u5174\u751f\u6210\u5f0fAI\u65f6\u4ee3\u4e0b\u9762\u4e34\u7684\u9c81\u68d2\u6027\u5a01\u80c1\u3002\u8be5\u7efc\u8ff0\u63ed\u793a\u4e86\u5f53\u524d\u5728\u6280\u672f\u57fa\u7840\u548c\u9c81\u68d2\u6027\u8868\u5f81\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u6307\u51fa\u4e86\u8fdb\u4e00\u6b65\u6df1\u5165\u7814\u7a76\u7684\u673a\u4f1a\u3002\u6700\u540e\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6db5\u76d6\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u4fdd\u62a4\u8303\u5f0f\u7b49\u516d\u4e2a\u65b9\u9762\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u4fe1\u76843DGS\u8d44\u4ea7\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53d1\u5c55\u8def\u7ebf\u56fe\u3002"}}
{"id": "2602.03879", "pdf": "https://arxiv.org/pdf/2602.03879", "abs": "https://arxiv.org/abs/2602.03879", "authors": ["Ali Bayeh", "Samira Sadaoui", "Malek Mouhoub"], "title": "TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "23 pages, 9 figures", "summary": "To address the trade-off between computational efficiency and adherence to Kolmogorov-Arnold Network (KAN) principles, we propose TruKAN, a new architecture based on the KAN structure and learnable activation functions. TruKAN replaces the B-spline basis in KAN with a family of truncated power functions derived from k-order spline theory. This change maintains the KAN's expressiveness while enhancing accuracy and training time. Each TruKAN layer combines a truncated power term with a polynomial term and employs either shared or individual knots. TruKAN exhibits greater interpretability than other KAN variants due to its simplified basis functions and knot configurations. By prioritizing interpretable basis functions, TruKAN aims to balance approximation efficacy with transparency. We develop the TruKAN model and integrate it into an advanced EfficientNet-V2-based framework, which is then evaluated on computer vision benchmark datasets. To ensure a fair comparison, we develop various models: MLP-, KAN-, SineKAN and TruKAN-based EfficientNet frameworks and assess their training time and accuracy across small and deep architectures. The training phase uses hybrid optimization to improve convergence stability. Additionally, we investigate layer normalization techniques for all the models and assess the impact of shared versus individual knots in TruKAN. Overall, TruKAN outperforms other KAN models in terms of accuracy, computational efficiency and memory usage on the complex vision task, demonstrating advantages beyond the limited settings explored in prior KAN studies.", "AI": {"tldr": "\u63d0\u51faTruKAN\uff0c\u4e00\u79cd\u57fa\u4e8e\u622a\u65ad\u5e42\u51fd\u6570\u7684\u65b0KAN\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387\u3001\u8bad\u7ec3\u901f\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709KAN\u53d8\u4f53\u3002", "motivation": "\u73b0\u6709Kolmogorov-Arnold Network\uff08KAN\uff09\u5728\u8ba1\u7b97\u6548\u7387\u4e0e\u7406\u8bba\u539f\u5219\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u4f5c\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u79cd\u517c\u987e\u903c\u8fd1\u80fd\u529b\u4e0e\u900f\u660e\u6027\u7684\u65b0\u67b6\u6784\u3002", "method": "\u5c06KAN\u4e2d\u7684B\u6837\u6761\u57fa\u66ff\u6362\u4e3a\u6e90\u81eak\u9636\u6837\u6761\u7406\u8bba\u7684\u622a\u65ad\u5e42\u51fd\u6570\u65cf\uff1b\u6bcf\u5c42\u7ed3\u5408\u622a\u65ad\u5e42\u9879\u4e0e\u591a\u9879\u5f0f\u9879\uff0c\u5e76\u652f\u6301\u5171\u4eab\u6216\u72ec\u7acb\u8282\u70b9\uff1b\u5c06\u5176\u96c6\u6210\u5230EfficientNet-V2\u6846\u67b6\u4e2d\uff0c\u91c7\u7528\u6df7\u5408\u4f18\u5316\u7b56\u7565\u548c\u5c42\u5f52\u4e00\u5316\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "TruKAN\u5728\u591a\u4e2a\u89c6\u89c9\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4MLP\u3001KAN\u548cSineKAN\u7b49\u6a21\u578b\uff0c\u5728\u51c6\u786e\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u5360\u7528\u65b9\u9762\u5747\u8868\u73b0\u66f4\u4f18\uff0c\u5c24\u5176\u5728\u5c0f\u578b\u548c\u6df1\u5c42\u67b6\u6784\u4e2d\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u7efc\u5408\u6027\u80fd\u3002", "conclusion": "TruKAN\u901a\u8fc7\u7b80\u5316\u57fa\u51fd\u6570\u548c\u8282\u70b9\u914d\u7f6e\uff0c\u5728\u4fdd\u6301KAN\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u62d3\u5c55\u4e86KAN\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002", "summary_cn": "\u4e3a\u89e3\u51b3\u8ba1\u7b97\u6548\u7387\u4e0eKolmogorov-Arnold\u7f51\u7edc\uff08KAN\uff09\u539f\u5219\u9075\u5faa\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86TruKAN\u2014\u2014\u4e00\u79cd\u57fa\u4e8eKAN\u7ed3\u6784\u548c\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u7684\u65b0\u67b6\u6784\u3002TruKAN\u7528\u6e90\u81eak\u9636\u6837\u6761\u7406\u8bba\u7684\u4e00\u65cf\u622a\u65ad\u5e42\u51fd\u6570\u66ff\u4ee3\u4e86KAN\u4e2d\u7684B\u6837\u6761\u57fa\uff0c\u8fd9\u4e00\u6539\u52a8\u5728\u4fdd\u6301KAN\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u4e86\u51c6\u786e\u7387\u548c\u8bad\u7ec3\u901f\u5ea6\u3002\u6bcf\u4e2aTruKAN\u5c42\u7ed3\u5408\u4e86\u4e00\u4e2a\u622a\u65ad\u5e42\u9879\u4e0e\u4e00\u4e2a\u591a\u9879\u5f0f\u9879\uff0c\u5e76\u91c7\u7528\u5171\u4eab\u6216\u72ec\u7acb\u7684\u8282\u70b9\uff08knots\uff09\u3002\u7531\u4e8e\u5176\u7b80\u5316\u7684\u57fa\u51fd\u6570\u548c\u8282\u70b9\u914d\u7f6e\uff0cTruKAN\u76f8\u6bd4\u5176\u4ed6KAN\u53d8\u4f53\u5177\u6709\u66f4\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u4f18\u5148\u9009\u62e9\u53ef\u89e3\u91ca\u7684\u57fa\u51fd\u6570\uff0cTruKAN\u65e8\u5728\u5e73\u8861\u903c\u8fd1\u6548\u679c\u4e0e\u900f\u660e\u6027\u3002\u6211\u4eec\u5f00\u53d1\u4e86TruKAN\u6a21\u578b\u5e76\u5c06\u5176\u96c6\u6210\u5230\u57fa\u4e8eEfficientNet-V2\u7684\u5148\u8fdb\u6846\u67b6\u4e2d\uff0c\u5e76\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u4e3a\u786e\u4fdd\u516c\u5e73\u6bd4\u8f83\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u591a\u79cd\u6a21\u578b\uff1a\u57fa\u4e8eMLP\u3001KAN\u3001SineKAN\u548cTruKAN\u7684EfficientNet\u6846\u67b6\uff0c\u5e76\u5728\u5c0f\u578b\u548c\u6df1\u5c42\u67b6\u6784\u4e0b\u8bc4\u4f30\u5b83\u4eec\u7684\u8bad\u7ec3\u65f6\u95f4\u548c\u51c6\u786e\u7387\u3002\u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u6df7\u5408\u4f18\u5316\u7b56\u7565\u4ee5\u63d0\u9ad8\u6536\u655b\u7a33\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7814\u7a76\u4e86\u6240\u6709\u6a21\u578b\u7684\u5c42\u5f52\u4e00\u5316\u6280\u672f\uff0c\u5e76\u8bc4\u4f30\u4e86TruKAN\u4e2d\u5171\u4eab\u8282\u70b9\u4e0e\u72ec\u7acb\u8282\u70b9\u7684\u5f71\u54cd\u3002\u603b\u4f53\u800c\u8a00\uff0cTruKAN\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u4e2d\u5728\u51c6\u786e\u7387\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u5747\u4f18\u4e8e\u5176\u4ed6KAN\u6a21\u578b\uff0c\u5c55\u73b0\u51fa\u8d85\u8d8a\u4ee5\u5f80KAN\u7814\u7a76\u6709\u9650\u8bbe\u5b9a\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.03881", "pdf": "https://arxiv.org/pdf/2602.03881", "abs": "https://arxiv.org/abs/2602.03881", "authors": ["Maxx Richard Rahman", "Mostafa Hammouda", "Wolfgang Maass"], "title": "DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and modality irregularities inherent in real-world clinical data. To address these limitations, we propose the Diffusion-Guided Attention Network (DiGAN), which integrates latent diffusion modelling with an attention-guided convolutional network. The diffusion model synthesizes realistic longitudinal neuroimaging trajectories from limited training data, enriching temporal context and improving robustness to unevenly spaced visits. The attention-convolutional layer then captures discriminative structural--temporal patterns that distinguish cognitively normal subjects from those with mild cognitive impairment and subjective cognitive decline. Experiments on synthetic and ADNI datasets demonstrate that DiGAN outperforms existing state-of-the-art baselines, showing its potential for early-stage AD detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiGAN\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u6269\u6563\u6a21\u578b\u4e0e\u6ce8\u610f\u529b\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u4ece\u6709\u9650\u4e14\u4e0d\u89c4\u5219\u7684\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u4e2d\u589e\u5f3a\u65f6\u95f4\u4e0a\u4e0b\u6587\u5e76\u63d0\u5347\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u4e2d\u53d7\u9650\u4e8e\u5bf9\u5927\u89c4\u6a21\u7eb5\u5411\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4e14\u96be\u4ee5\u5904\u7406\u4e34\u5e8a\u6570\u636e\u4e2d\u56fa\u6709\u7684\u65f6\u95f4\u8fde\u7eed\u6027\u548c\u6a21\u6001\u4e0d\u89c4\u5219\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faDiffusion-Guided Attention Network\uff08DiGAN\uff09\uff0c\u5c06\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e0e\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5377\u79ef\u7f51\u7edc\u76f8\u7ed3\u5408\uff1a\u6269\u6563\u6a21\u578b\u4ece\u6709\u9650\u6570\u636e\u5408\u6210\u903c\u771f\u7684\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u8f68\u8ff9\uff0c\u6ce8\u610f\u529b\u5377\u79ef\u5c42\u5219\u6355\u6349\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\u3001\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u548c\u4e3b\u89c2\u8ba4\u77e5\u4e0b\u964d\u4e2a\u4f53\u7684\u7ed3\u6784-\u65f6\u95f4\u6a21\u5f0f\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548cADNI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDiGAN\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u65b9\u9762\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "DiGAN\u901a\u8fc7\u878d\u5408\u6269\u6563\u5efa\u6a21\u4e0e\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u5e94\u5bf9\u4e86\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u6570\u636e\u7a00\u758f\u4e0e\u4e0d\u89c4\u5219\u7684\u95ee\u9898\uff0c\u4e3a\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u81ea\u52a8\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u7531\u4e8e\u524d\u9a71\u671f\u9636\u6bb5\u8111\u7ed3\u6784\u53d8\u5316\u7ec6\u5fae\u4e14\u65f6\u95f4\u8fdb\u7a0b\u4e0d\u89c4\u5219\uff0c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u7684\u65e9\u671f\u8bca\u65ad\u4ecd\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5927\u91cf\u7eb5\u5411\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u5f80\u5f80\u65e0\u6cd5\u6709\u6548\u5efa\u6a21\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u4e2d\u56fa\u6709\u7684\u65f6\u95f4\u8fde\u7eed\u6027\u548c\u6a21\u6001\u4e0d\u89c4\u5219\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6269\u6563\u5f15\u5bfc\u6ce8\u610f\u529b\u7f51\u7edc\uff08DiGAN\uff09\uff0c\u8be5\u65b9\u6cd5\u5c06\u6f5c\u5728\u6269\u6563\u5efa\u6a21\u4e0e\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5377\u79ef\u7f51\u7edc\u76f8\u7ed3\u5408\u3002\u6269\u6563\u6a21\u578b\u80fd\u591f\u4ece\u6709\u9650\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u5408\u6210\u903c\u771f\u7684\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u8f68\u8ff9\uff0c\u4ece\u800c\u4e30\u5bcc\u65f6\u95f4\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u63d0\u9ad8\u5bf9\u8bbf\u89c6\u65f6\u95f4\u95f4\u9694\u4e0d\u5747\u7684\u9c81\u68d2\u6027\u3002\u968f\u540e\uff0c\u6ce8\u610f\u529b\u5377\u79ef\u5c42\u53ef\u6355\u6349\u5177\u6709\u5224\u522b\u6027\u7684\u7ed3\u6784-\u65f6\u95f4\u6a21\u5f0f\uff0c\u4ee5\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\u4e2a\u4f53\u3001\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u60a3\u8005\u548c\u4e3b\u89c2\u8ba4\u77e5\u4e0b\u964d\u4e2a\u4f53\u3002\u5728\u5408\u6210\u6570\u636e\u96c6\u548cADNI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDiGAN\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u5176\u5728\u65e9\u671fAD\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.03882", "pdf": "https://arxiv.org/pdf/2602.03882", "abs": "https://arxiv.org/abs/2602.03882", "authors": ["Haijiang Yan", "Nick Chater", "Adam Sanborn"], "title": "PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Incorporating individual-level cognitive priors offers an important route to personalizing neural networks, yet accurately eliciting such priors remains challenging: existing methods either fail to uniquely identify them or introduce systematic biases. Here, we introduce PriorProbe, a novel elicitation approach grounded in Markov Chain Monte Carlo with People that recovers fine-grained, individual-specific priors. Focusing on a facial expression recognition task, we apply PriorProbe to individual participants and test whether integrating the recovered priors with a state-of-the-art neural network improves its ability to predict an individual's classification on ambiguous stimuli. The PriorProbe-derived priors yield substantial performance gains, outperforming both the neural network alone and alternative sources of priors, while preserving the network's inference on ground-truth labels. Together, these results demonstrate that PriorProbe provides a general and interpretable framework for personalizing deep neural networks.", "AI": {"tldr": "PriorProbe \u662f\u4e00\u79cd\u57fa\u4e8e MCMC \u4e0e\u4eba\u7c7b\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u63d0\u53d6\u4e2a\u4f53\u7ec6\u7c92\u5ea6\u8ba4\u77e5\u5148\u9a8c\uff0c\u5e76\u7528\u4e8e\u63d0\u5347\u795e\u7ecf\u7f51\u7edc\u5bf9\u6a21\u7cca\u523a\u6fc0\u7684\u4e2a\u6027\u5316\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u63d0\u53d6\u4e2a\u4f53\u8ba4\u77e5\u5148\u9a8c\u65f6\u5b58\u5728\u65e0\u6cd5\u552f\u4e00\u8bc6\u522b\u6216\u5f15\u5165\u7cfb\u7edf\u6027\u504f\u5dee\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u795e\u7ecf\u7f51\u7edc\u7684\u4e2a\u6027\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa PriorProbe \u65b9\u6cd5\uff0c\u57fa\u4e8e\u201c\u4e0e\u4eba\u7ed3\u5408\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u201d\uff08MCMC with People\uff09\uff0c\u4ece\u4e2a\u4f53\u53c2\u4e0e\u8005\u4e2d\u6062\u590d\u5176\u7279\u5b9a\u7684\u8ba4\u77e5\u5148\u9a8c\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u5148\u8fdb\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002", "result": "\u5728\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u6574\u5408 PriorProbe \u63d0\u53d6\u7684\u5148\u9a8c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u6a21\u7cca\u523a\u6fc0\u7684\u4e2a\u4f53\u5206\u7c7b\u9884\u6d4b\u6027\u80fd\uff0c\u4f18\u4e8e\u4ec5\u7528\u795e\u7ecf\u7f51\u7edc\u6216\u5176\u4ed6\u5148\u9a8c\u6765\u6e90\uff0c\u4e14\u4e0d\u635f\u5bb3\u5bf9\u771f\u5b9e\u6807\u7b7e\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "PriorProbe \u4e3a\u4e2a\u6027\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002", "summary_cn": "\u5f15\u5165\u4e2a\u4f53\u5c42\u9762\u7684\u8ba4\u77e5\u5148\u9a8c\u662f\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e2a\u6027\u5316\u7684\u91cd\u8981\u9014\u5f84\uff0c\u4f46\u51c6\u786e\u83b7\u53d6\u6b64\u7c7b\u5148\u9a8c\u4ecd\u5177\u6311\u6218\u6027\uff1a\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u552f\u4e00\u8bc6\u522b\u8fd9\u4e9b\u5148\u9a8c\uff0c\u8981\u4e48\u4f1a\u5f15\u5165\u7cfb\u7edf\u6027\u504f\u5dee\u3002\u672c\u6587\u63d0\u51fa PriorProbe\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u201c\u4e0e\u4eba\u7ed3\u5408\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u201d\uff08Markov Chain Monte Carlo with People\uff09\u7684\u65b0\u9896\u5148\u9a8c\u63d0\u53d6\u65b9\u6cd5\uff0c\u80fd\u591f\u6062\u590d\u7ec6\u7c92\u5ea6\u7684\u3001\u4e2a\u4f53\u7279\u5b9a\u7684\u5148\u9a8c\u3002\u6211\u4eec\u4ee5\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4efb\u52a1\u4e3a\u4f8b\uff0c\u5bf9\u4e2a\u4f53\u53c2\u4e0e\u8005\u5e94\u7528 PriorProbe\uff0c\u5e76\u6d4b\u8bd5\u5c06\u6240\u6062\u590d\u7684\u5148\u9a8c\u6574\u5408\u5230\u5f53\u524d\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u7f51\u7edc\u4e2d\u662f\u5426\u80fd\u63d0\u5347\u5176\u5bf9\u6a21\u7cca\u523a\u6fc0\u4e0b\u4e2a\u4f53\u5206\u7c7b\u5224\u65ad\u7684\u9884\u6d4b\u80fd\u529b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7531 PriorProbe \u63d0\u53d6\u7684\u5148\u9a8c\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e0d\u4ec5\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u4f18\u4e8e\u5176\u4ed6\u5148\u9a8c\u6765\u6e90\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u7f51\u7edc\u5bf9\u771f\u5b9e\u6807\u7b7e\u7684\u63a8\u7406\u80fd\u529b\u3002\u7efc\u4e0a\u6240\u8ff0\uff0c\u672c\u7814\u7a76\u8bc1\u660e PriorProbe \u4e3a\u4e2a\u6027\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002"}}
{"id": "2602.03883", "pdf": "https://arxiv.org/pdf/2602.03883", "abs": "https://arxiv.org/abs/2602.03883", "authors": ["Akshansh Mishra", "Rakesh Morisetty"], "title": "Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG"], "comment": "6 figures", "summary": "Internal porosity remains a critical defect mode in additively manufactured components, compromising structural performance and limiting industrial adoption. Automated defect detection methods exist but lack interpretability, preventing engineers from understanding the physical basis of criticality predictions. This study presents an explainable computer vision framework for pore detection and criticality assessment in three-dimensional tomographic volumes. Sequential grayscale slices were reconstructed into volumetric datasets, and intensity-based thresholding with connected component analysis identified 500 individual pores. Each pore was characterized using geometric descriptors including size, aspect ratio, extent, and spatial position relative to the specimen boundary. A pore interaction network was constructed using percentile-based Euclidean distance criteria, yielding 24,950 inter-pore connections. Machine learning models predicted pore criticality scores from extracted features, and SHAP analysis quantified individual feature contributions. Results demonstrate that normalized surface distance dominates model predictions, contributing more than an order of magnitude greater importance than all other descriptors. Pore size provides minimal influence, while geometric parameters show negligible impact. The strong inverse relationship between surface proximity and criticality reveals boundary-driven failure mechanisms. This interpretable framework enables transparent defect assessment and provides actionable insights for process optimization and quality control in additive manufacturing.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u589e\u6750\u5236\u9020\u90e8\u4ef6\u7684\u4e09\u7ef4\u65ad\u5c42\u56fe\u50cf\u4e2d\u68c0\u6d4b\u5b54\u9699\u5e76\u8bc4\u4f30\u5176\u4e34\u754c\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5b54\u9699\u5230\u8868\u9762\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\u662f\u9884\u6d4b\u4e34\u754c\u6027\u7684\u4e3b\u5bfc\u56e0\u7d20\uff0c\u8fdc\u8d85\u5176\u4ed6\u51e0\u4f55\u7279\u5f81\u3002", "motivation": "\u589e\u6750\u5236\u9020\u90e8\u4ef6\u4e2d\u7684\u5185\u90e8\u5b54\u9699\u662f\u5f71\u54cd\u7ed3\u6784\u6027\u80fd\u7684\u5173\u952e\u7f3a\u9677\uff0c\u73b0\u6709\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5de5\u7a0b\u5e08\u96be\u4ee5\u7406\u89e3\u4e34\u754c\u6027\u9884\u6d4b\u7684\u7269\u7406\u4f9d\u636e\u3002", "method": "\u5c06\u7070\u5ea6\u5207\u7247\u91cd\u5efa\u4e3a\u4e09\u7ef4\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u57fa\u4e8e\u5f3a\u5ea6\u7684\u9608\u503c\u5206\u5272\u548c\u8fde\u901a\u6210\u5206\u5206\u6790\u8bc6\u522b\u51fa500\u4e2a\u72ec\u7acb\u5b54\u9699\uff1b\u5229\u7528\u5c3a\u5bf8\u3001\u957f\u5bbd\u6bd4\u3001\u8303\u56f4\u548c\u8ddd\u8fb9\u754c\u8ddd\u79bb\u7b49\u51e0\u4f55\u63cf\u8ff0\u7b26\u5bf9\u5b54\u9699\u8fdb\u884c\u8868\u5f81\uff1b\u57fa\u4e8e\u767e\u5206\u4f4d\u6570\u7684\u6b27\u6c0f\u8ddd\u79bb\u6784\u5efa\u5b54\u9699\u4ea4\u4e92\u7f51\u7edc\uff08\u542b24,950\u6761\u8fde\u63a5\uff09\uff1b\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u5b54\u9699\u4e34\u754c\u6027\uff0c\u5e76\u901a\u8fc7SHAP\u5206\u6790\u91cf\u5316\u5404\u7279\u5f81\u8d21\u732e\u3002", "result": "\u5f52\u4e00\u5316\u8868\u9762\u8ddd\u79bb\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u8d21\u732e\u6bd4\u5176\u4ed6\u6240\u6709\u63cf\u8ff0\u7b26\u9ad8\u51fa\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff1b\u5b54\u9699\u5c3a\u5bf8\u5f71\u54cd\u5fae\u5f31\uff0c\u5176\u4ed6\u51e0\u4f55\u53c2\u6570\u51e0\u4e4e\u65e0\u5f71\u54cd\uff1b\u8868\u9762\u90bb\u8fd1\u6027\u4e0e\u4e34\u754c\u6027\u5448\u5f3a\u8d1f\u76f8\u5173\uff0c\u63ed\u793a\u4e86\u8fb9\u754c\u9a71\u52a8\u7684\u5931\u6548\u673a\u5236\u3002", "conclusion": "\u8be5\u53ef\u89e3\u91ca\u6846\u67b6\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u7f3a\u9677\u8bc4\u4f30\uff0c\u4e3a\u589e\u6750\u5236\u9020\u7684\u5de5\u827a\u4f18\u5316\u548c\u8d28\u91cf\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "summary_cn": "\u5185\u90e8\u5b54\u9699\u4ecd\u662f\u589e\u6750\u5236\u9020\u90e8\u4ef6\u4e2d\u4e00\u79cd\u5173\u952e\u7f3a\u9677\u6a21\u5f0f\uff0c\u4f1a\u635f\u5bb3\u7ed3\u6784\u6027\u80fd\u5e76\u9650\u5236\u5176\u5de5\u4e1a\u5e94\u7528\u3002\u5c3d\u7ba1\u5df2\u6709\u81ea\u52a8\u5316\u7f3a\u9677\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5de5\u7a0b\u5e08\u65e0\u6cd5\u7406\u89e3\u4e34\u754c\u6027\u9884\u6d4b\u7684\u7269\u7406\u57fa\u7840\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e09\u7ef4\u65ad\u5c42\u626b\u63cf\u4f53\u79ef\u4e2d\u8fdb\u884c\u5b54\u9699\u68c0\u6d4b\u548c\u4e34\u754c\u6027\u8bc4\u4f30\u3002\u9996\u5148\u5c06\u8fde\u7eed\u7684\u7070\u5ea6\u5207\u7247\u91cd\u5efa\u4e3a\u4f53\u79ef\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5f3a\u5ea6\u7684\u9608\u503c\u5206\u5272\u7ed3\u5408\u8fde\u901a\u6210\u5206\u5206\u6790\u8bc6\u522b\u51fa500\u4e2a\u72ec\u7acb\u5b54\u9699\u3002\u6bcf\u4e2a\u5b54\u9699\u5747\u91c7\u7528\u51e0\u4f55\u63cf\u8ff0\u7b26\u8fdb\u884c\u8868\u5f81\uff0c\u5305\u62ec\u5c3a\u5bf8\u3001\u957f\u5bbd\u6bd4\u3001\u8303\u56f4\u4ee5\u53ca\u76f8\u5bf9\u4e8e\u8bd5\u6837\u8fb9\u754c\u7684\u51e0\u4f55\u4f4d\u7f6e\u3002\u63a5\u7740\uff0c\u5229\u7528\u57fa\u4e8e\u767e\u5206\u4f4d\u6570\u7684\u6b27\u6c0f\u8ddd\u79bb\u51c6\u5219\u6784\u5efa\u5b54\u9699\u4ea4\u4e92\u7f51\u7edc\uff0c\u5171\u5f97\u523024,950\u6761\u5b54\u9699\u95f4\u8fde\u63a5\u3002\u968f\u540e\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u57fa\u4e8e\u63d0\u53d6\u7684\u7279\u5f81\u9884\u6d4b\u5b54\u9699\u4e34\u754c\u6027\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7SHAP\u5206\u6790\u91cf\u5316\u5404\u7279\u5f81\u7684\u8d21\u732e\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5f52\u4e00\u5316\u8868\u9762\u8ddd\u79bb\u5728\u6a21\u578b\u9884\u6d4b\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5176\u91cd\u8981\u6027\u6bd4\u6240\u6709\u5176\u4ed6\u63cf\u8ff0\u7b26\u9ad8\u51fa\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff1b\u5b54\u9699\u5c3a\u5bf8\u7684\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\uff0c\u800c\u5176\u4ed6\u51e0\u4f55\u53c2\u6570\u7684\u5f71\u54cd\u5219\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002\u8868\u9762\u90bb\u8fd1\u6027\u4e0e\u4e34\u754c\u6027\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u8d1f\u76f8\u5173\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u7531\u8fb9\u754c\u9a71\u52a8\u7684\u5931\u6548\u673a\u5236\u3002\u8be5\u53ef\u89e3\u91ca\u6846\u67b6\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u7f3a\u9677\u8bc4\u4f30\uff0c\u5e76\u4e3a\u589e\u6750\u5236\u9020\u4e2d\u7684\u5de5\u827a\u4f18\u5316\u548c\u8d28\u91cf\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.03890", "pdf": "https://arxiv.org/pdf/2602.03890", "abs": "https://arxiv.org/abs/2602.03890", "authors": ["Xindan Zhang", "Weilong Yan", "Yufei Shi", "Xuerui Qiu", "Tao He", "Ying Li", "Ming Li", "Hehe Fan"], "title": "4DPC$^2$hat: Towards Dynamic Point Cloud Understanding with Failure-Aware Bootstrapping", "categories": ["cs.CV"], "comment": null, "summary": "Point clouds provide a compact and expressive representation of 3D objects, and have recently been integrated into multimodal large language models (MLLMs). However, existing methods primarily focus on static objects, while understanding dynamic point cloud sequences remains largely unexplored. This limitation is mainly caused by the lack of large-scale cross-modal datasets and the difficulty of modeling motions in spatio-temporal contexts. To bridge this gap, we present 4DPC$^2$hat, the first MLLM tailored for dynamic point cloud understanding. To this end, we construct a large-scale cross-modal dataset 4DPC$^2$hat-200K via a meticulous two-stage pipeline consisting of topology-consistent 4D point construction and two-level captioning. The dataset contains over 44K dynamic object sequences, 700K point cloud frames, and 200K curated question-answer (QA) pairs, supporting inquiries about counting, temporal relationship, action, spatial relationship, and appearance. At the core of the framework, we introduce a Mamba-enhanced temporal reasoning MLLM to capture long-range dependencies and dynamic patterns among a point cloud sequence. Furthermore, we propose a failure-aware bootstrapping learning strategy that iteratively identifies model deficiencies and generates targeted QA supervision to continuously strengthen corresponding reasoning capabilities. Extensive experiments demonstrate that our 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e864DPC\u00b2hat\uff0c\u9996\u4e2a\u9762\u5411\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c64DPC\u00b2hat-200K\uff0c\u5305\u542b44K\u52a8\u6001\u7269\u4f53\u5e8f\u5217\u3001700K\u70b9\u4e91\u5e27\u548c200K\u95ee\u7b54\u5bf9\u3002\u901a\u8fc7\u5f15\u5165Mamba\u589e\u5f3a\u7684\u65f6\u5e8f\u63a8\u7406\u6a21\u5757\u548c\u5931\u8d25\u611f\u77e5\u7684\u81ea\u4e3e\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u4f5c\u7406\u89e3\u548c\u65f6\u5e8f\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u70b9\u4e91\u5bf9\u8c61\uff0c\u5bf9\u52a8\u6001\u70b9\u4e91\u5e8f\u5217\u7684\u7406\u89e3\u7814\u7a76\u4e0d\u8db3\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c6\u4ee5\u53ca\u65f6\u7a7a\u4e0a\u4e0b\u6587\u4e2d\u5efa\u6a21\u8fd0\u52a8\u7684\u56f0\u96be\u3002", "method": "1\uff09\u6784\u5efa\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c64DPC\u00b2hat-200K\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a\u62d3\u6251\u4e00\u81f4\u76844D\u70b9\u4e91\u6784\u5efa\u548c\u4e24\u7ea7\u6807\u6ce8\uff1b2\uff09\u63d0\u51fa\u57fa\u4e8eMamba\u589e\u5f3a\u7684\u65f6\u5e8f\u63a8\u7406MLLM\uff0c\u4ee5\u6355\u6349\u70b9\u4e91\u5e8f\u5217\u4e2d\u7684\u957f\u7a0b\u4f9d\u8d56\u548c\u52a8\u6001\u6a21\u5f0f\uff1b3\uff09\u8bbe\u8ba1\u5931\u8d25\u611f\u77e5\u7684\u81ea\u4e3e\u5b66\u4e60\u7b56\u7565\uff0c\u8fed\u4ee3\u8bc6\u522b\u6a21\u578b\u7f3a\u9677\u5e76\u751f\u6210\u9488\u5bf9\u6027\u95ee\u7b54\u76d1\u7763\u4fe1\u53f7\uff0c\u6301\u7eed\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c4DPC\u00b2hat\u5728\u52a8\u4f5c\u7406\u89e3\u548c\u65f6\u5e8f\u63a8\u7406\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4e3a4D\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u9996\u4e2a\u9762\u5411\u52a8\u6001\u70b9\u4e91\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u4e13\u7528MLLM\u67b6\u6784\uff0c\u6709\u6548\u63a8\u52a8\u4e864D\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u7684\u53d1\u5c55\uff0c\u5c24\u5176\u5728\u590d\u6742\u65f6\u7a7a\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\u3002", "summary_cn": "\u70b9\u4e91\u4e3a\u4e09\u7ef4\u7269\u4f53\u63d0\u4f9b\u4e86\u4e00\u79cd\u7d27\u51d1\u4e14\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5e76\u5df2\u88ab\u8fd1\u671f\u6574\u5408\u5230\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e2d\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u805a\u7126\u4e8e\u9759\u6001\u7269\u4f53\uff0c\u800c\u5bf9\u52a8\u6001\u70b9\u4e91\u5e8f\u5217\u7684\u7406\u89e3\u4ecd\u57fa\u672c\u672a\u88ab\u63a2\u7d22\u3002\u8fd9\u4e00\u5c40\u9650\u6027\u4e3b\u8981\u6e90\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u5728\u65f6\u7a7a\u4e0a\u4e0b\u6587\u4e2d\u5efa\u6a21\u8fd0\u52a8\u7684\u56f0\u96be\u3002\u4e3a\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e864DPC\u00b2hat\u2014\u2014\u9996\u4e2a\u4e13\u4e3a\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u5b9a\u5236\u7684MLLM\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\uff08\u5305\u62ec\u62d3\u6251\u4e00\u81f4\u76844D\u70b9\u4e91\u6784\u5efa\u548c\u4e24\u7ea7\u6807\u6ce8\uff09\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c64DPC\u00b2hat-200K\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b\u8d85\u8fc744K\u4e2a\u52a8\u6001\u7269\u4f53\u5e8f\u5217\u3001700K\u4e2a\u70b9\u4e91\u5e27\u548c200K\u4e2a\u7cbe\u5fc3\u6574\u7406\u7684\u95ee\u9898-\u7b54\u6848\uff08QA\uff09\u5bf9\uff0c\u652f\u6301\u5173\u4e8e\u8ba1\u6570\u3001\u65f6\u5e8f\u5173\u7cfb\u3001\u52a8\u4f5c\u3001\u7a7a\u95f4\u5173\u7cfb\u548c\u5916\u89c2\u7b49\u65b9\u9762\u7684\u67e5\u8be2\u3002\u5728\u6846\u67b6\u6838\u5fc3\u90e8\u5206\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2aMamba\u589e\u5f3a\u7684\u65f6\u5e8f\u63a8\u7406MLLM\uff0c\u4ee5\u6355\u6349\u70b9\u4e91\u5e8f\u5217\u4e2d\u7684\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u548c\u52a8\u6001\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5931\u8d25\u611f\u77e5\u7684\u81ea\u4e3e\u5b66\u4e60\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u80fd\u8fed\u4ee3\u8bc6\u522b\u6a21\u578b\u7f3a\u9677\u5e76\u751f\u6210\u9488\u5bf9\u6027\u7684QA\u76d1\u7763\u4fe1\u53f7\uff0c\u4ece\u800c\u6301\u7eed\u5f3a\u5316\u76f8\u5e94\u7684\u63a8\u7406\u80fd\u529b\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6a21\u578b\u76f8\u6bd4\uff0c\u6211\u4eec\u76844DPC\u00b2hat\u5728\u52a8\u4f5c\u7406\u89e3\u548c\u65f6\u5e8f\u63a8\u7406\u65b9\u9762\u663e\u8457\u63d0\u5347\uff0c\u4e3a4D\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.03892", "pdf": "https://arxiv.org/pdf/2602.03892", "abs": "https://arxiv.org/abs/2602.03892", "authors": ["Jinxing Zhou", "Yanghao Zhou", "Yaoting Wang", "Zongyan Han", "Jiaqi Ma", "Henghui Ding", "Rao Muhammad Anwer", "Hisham Cholakkal"], "title": "Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this work, we introduce Mask Quality Assessment in the Ref-AVS context (MQA-RefAVS), a new task that evaluates the quality of candidate segmentation masks without relying on ground-truth annotations as references at inference time. Given audio-visual-language inputs and each provided segmentation mask, the task requires estimating its IoU with the unobserved ground truth, identifying the corresponding error type, and recommending an actionable quality-control decision. To support this task, we construct MQ-RAVSBench, a benchmark featuring diverse and representative mask error modes that span both geometric and semantic issues. We further propose MQ-Auditor, a multimodal large language model (MLLM)-based auditor that explicitly reasons over multimodal cues and mask information to produce quantitative and qualitative mask quality assessments. Extensive experiments demonstrate that MQ-Auditor outperforms strong open-source and commercial MLLMs and can be integrated with existing Ref-AVS systems to detect segmentation failures and support downstream segmentation improvement. Data and codes will be released at https://github.com/jasongief/MQA-RefAVS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMQA-RefAVS\u4efb\u52a1\uff0c\u7528\u4e8e\u5728\u65e0\u771f\u5b9e\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u8bed\u8a00\u5f15\u5bfc\u97f3\u89c6\u9891\u5206\u5272\uff08Ref-AVS\uff09\u4e2d\u5019\u9009\u5206\u5272\u63a9\u7801\u7684\u8d28\u91cf\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b\u591a\u79cd\u9519\u8bef\u6a21\u5f0f\u7684\u57fa\u51c6MQ-RAVSBench\u53ca\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u5668MQ-Auditor\u3002", "motivation": "\u73b0\u6709Ref-AVS\u65b9\u6cd5\u867d\u80fd\u751f\u6210\u5206\u5272\u63a9\u7801\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u63a9\u7801\u8d28\u91cf\u8fdb\u884c\u4e30\u5bcc\u4e14\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\uff1b\u5c24\u5176\u5728\u63a8\u7406\u9636\u6bb5\u65e0\u6cd5\u4f9d\u8d56\u771f\u5b9e\u6807\u6ce8\u6765\u8bc4\u4f30\u63a9\u7801\u8d28\u91cf\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u65e0\u9700\u771f\u503c\u53c2\u8003\u7684\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u673a\u5236\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u65b0\u4efb\u52a1MQA-RefAVS\uff0c\u8981\u6c42\u6a21\u578b\u57fa\u4e8e\u97f3\u89c6\u9891-\u8bed\u8a00\u8f93\u5165\u548c\u7ed9\u5b9a\u63a9\u7801\uff0c\u4f30\u8ba1\u5176\u4e0e\u672a\u77e5\u771f\u503c\u7684IoU\u3001\u8bc6\u522b\u9519\u8bef\u7c7b\u578b\u5e76\u7ed9\u51fa\u8d28\u91cf\u63a7\u5236\u5efa\u8bae\uff1b\u540c\u65f6\u6784\u5efa\u4e86\u6db5\u76d6\u51e0\u4f55\u4e0e\u8bed\u4e49\u9519\u8bef\u7684\u57fa\u51c6MQ-RAVSBench\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684MQ-Auditor\uff0c\u901a\u8fc7\u663e\u5f0f\u63a8\u7406\u591a\u6a21\u6001\u7ebf\u7d22\u548c\u63a9\u7801\u4fe1\u606f\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMQ-Auditor\u5728\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u4e0a\u4f18\u4e8e\u591a\u4e2a\u5f00\u6e90\u548c\u5546\u7528MLLM\uff0c\u5e76\u53ef\u6709\u6548\u96c6\u6210\u5230\u73b0\u6709Ref-AVS\u7cfb\u7edf\u4e2d\uff0c\u7528\u4e8e\u68c0\u6d4b\u5206\u5272\u5931\u8d25\u5e76\u652f\u6301\u540e\u7eed\u5206\u5272\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u672c\u5de5\u4f5c\u9996\u6b21\u5c06\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u5f15\u5165Ref-AVS\u9886\u57df\uff0c\u63d0\u51fa\u7684MQA-RefAVS\u4efb\u52a1\u3001MQ-RAVSBench\u57fa\u51c6\u548cMQ-Auditor\u6a21\u578b\u4e3a\u63d0\u5347Ref-AVS\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u8bed\u8a00\u5f15\u5bfc\u7684\u97f3\u89c6\u9891\u5206\u5272\uff08Ref-AVS\uff09\u65e8\u5728\u901a\u8fc7\u8054\u5408\u63a8\u7406\u89c6\u9891\u3001\u97f3\u9891\u548c\u6587\u672c\uff0c\u5206\u5272\u51fa\u81ea\u7136\u8bed\u8a00\u6240\u63cf\u8ff0\u7684\u76ee\u6807\u7269\u4f53\u3002\u9664\u4e86\u751f\u6210\u5206\u5272\u63a9\u7801\u5916\uff0c\u5982\u4f55\u63d0\u4f9b\u4e30\u5bcc\u4e14\u53ef\u89e3\u91ca\u7684\u63a9\u7801\u8d28\u91cf\u8bca\u65ad\u4ecd\u9c9c\u6709\u7814\u7a76\u3002\u672c\u6587\u63d0\u51fa\u4e86Ref-AVS\u573a\u666f\u4e0b\u7684\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u4efb\u52a1\uff08MQA-RefAVS\uff09\uff0c\u8be5\u4efb\u52a1\u5728\u63a8\u7406\u9636\u6bb5\u65e0\u9700\u4f9d\u8d56\u771f\u5b9e\u6807\u6ce8\u5373\u53ef\u8bc4\u4f30\u5019\u9009\u5206\u5272\u63a9\u7801\u7684\u8d28\u91cf\u3002\u7ed9\u5b9a\u97f3\u89c6\u9891-\u8bed\u8a00\u8f93\u5165\u53ca\u6bcf\u4e2a\u63d0\u4f9b\u7684\u5206\u5272\u63a9\u7801\uff0c\u8be5\u4efb\u52a1\u9700\u4f30\u8ba1\u5176\u4e0e\u672a\u89c2\u6d4b\u5230\u7684\u771f\u5b9e\u6807\u6ce8\u4e4b\u95f4\u7684IoU\u3001\u8bc6\u522b\u5bf9\u5e94\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u5e76\u63a8\u8350\u53ef\u64cd\u4f5c\u7684\u8d28\u91cf\u63a7\u5236\u51b3\u7b56\u3002\u4e3a\u652f\u6301\u8be5\u4efb\u52a1\uff0c\u6211\u4eec\u6784\u5efa\u4e86MQ-RAVSBench\u57fa\u51c6\uff0c\u5176\u4e2d\u5305\u542b\u6db5\u76d6\u51e0\u4f55\u4e0e\u8bed\u4e49\u95ee\u9898\u7684\u591a\u6837\u5316\u4e14\u5177\u4ee3\u8868\u6027\u7684\u63a9\u7801\u9519\u8bef\u6a21\u5f0f\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86MQ-Auditor\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u8bc4\u4f30\u5668\uff0c\u80fd\u591f\u663e\u5f0f\u5730\u63a8\u7406\u591a\u6a21\u6001\u7ebf\u7d22\u548c\u63a9\u7801\u4fe1\u606f\uff0c\u4ece\u800c\u751f\u6210\u5b9a\u91cf\u4e0e\u5b9a\u6027\u7684\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMQ-Auditor\u4f18\u4e8e\u591a\u4e2a\u5f3a\u5927\u7684\u5f00\u6e90\u548c\u5546\u7528MLLM\uff0c\u5e76\u53ef\u4e0e\u73b0\u6709Ref-AVS\u7cfb\u7edf\u96c6\u6210\uff0c\u7528\u4e8e\u68c0\u6d4b\u5206\u5272\u5931\u8d25\u5e76\u652f\u6301\u4e0b\u6e38\u5206\u5272\u6027\u80fd\u7684\u63d0\u5347\u3002\u6570\u636e\u4e0e\u4ee3\u7801\u5c06\u53d1\u5e03\u4e8e https://github.com/jasongief/MQA-RefAVS\u3002"}}
{"id": "2602.03893", "pdf": "https://arxiv.org/pdf/2602.03893", "abs": "https://arxiv.org/abs/2602.03893", "authors": ["Yibing Wang", "Shuang Li", "Tingting Huang", "Yu Zhang", "Chulhong Kim", "Seongwook Choi", "Changhui Li"], "title": "GPAIR: Gaussian-Kernel-Based Ultrafast 3D Photoacoustic Iterative Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Although the iterative reconstruction (IR) algorithm can substantially correct reconstruction artifacts in photoacoustic (PA) computed tomography (PACT), it suffers from long reconstruction times, especially for large-scale three-dimensional (3D) imaging in which IR takes hundreds of seconds to hours. The computing burden severely limits the practical applicability of IR algorithms. In this work, we proposed an ultrafast IR method for 3D PACT, called Gaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction (GPAIR), which achieves orders-of-magnitude acceleration in computing. GPAIR transforms traditional spatial grids with continuous isotropic Gaussian kernels. By deriving analytical closed-form expression for pressure waves and implementing powerful GPU-accelerated differentiable Triton operators, GPAIR demonstrates extraordinary ultrafast sub-second reconstruction speed for 3D targets containing 8.4 million voxels in animal experiments. This revolutionary ultrafast image reconstruction enables near-real-time large-scale 3D PA reconstruction, significantly advancing 3D PACT toward clinical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u6838\u7684\u8d85\u5feb\u4e09\u7ef4\u5149\u58f0\u8fed\u4ee3\u91cd\u5efa\u65b9\u6cd5\uff08GPAIR\uff09\uff0c\u5c06\u4f20\u7edf\u8017\u65f6\u6570\u767e\u79d2\u81f3\u6570\u5c0f\u65f6\u7684\u8fed\u4ee3\u91cd\u5efa\u52a0\u901f\u81f3\u4e9a\u79d2\u7ea7\uff0c\u663e\u8457\u63d0\u5347\u4e09\u7ef4\u5149\u58f0\u8ba1\u7b97\u673a\u65ad\u5c42\u6210\u50cf\uff08PACT\uff09\u7684\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u8fed\u4ee3\u91cd\u5efa\uff08IR\uff09\u7b97\u6cd5\u867d\u80fd\u6709\u6548\u6821\u6b63\u5149\u58f0\u8ba1\u7b97\u673a\u65ad\u5c42\u6210\u50cf\uff08PACT\uff09\u4e2d\u7684\u91cd\u5efa\u4f2a\u5f71\uff0c\u4f46\u5176\u8ba1\u7b97\u8017\u65f6\u6781\u957f\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u4e09\u7ef4\u6210\u50cf\u4e2d\u9700\u6570\u767e\u79d2\u751a\u81f3\u6570\u5c0f\u65f6\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faGPAIR\u65b9\u6cd5\uff1a\u4f7f\u7528\u8fde\u7eed\u5404\u5411\u540c\u6027\u9ad8\u65af\u6838\u66ff\u4ee3\u4f20\u7edf\u7a7a\u95f4\u7f51\u683c\uff0c\u63a8\u5bfc\u538b\u529b\u6ce2\u7684\u89e3\u6790\u95ed\u5f0f\u8868\u8fbe\uff0c\u5e76\u7ed3\u5408GPU\u52a0\u901f\u7684\u53ef\u5fae\u5206Triton\u7b97\u5b50\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u5728\u52a8\u7269\u5b9e\u9a8c\u4e2d\uff0cGPAIR\u5bf9\u5305\u542b840\u4e07\u4f53\u7d20\u7684\u4e09\u7ef4\u76ee\u6807\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u91cd\u5efa\u901f\u5ea6\uff0c\u6bd4\u4f20\u7edfIR\u65b9\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u8d85\u5feb\u91cd\u5efa\u65b9\u6cd5\u4f7f\u5927\u89c4\u6a21\u4e09\u7ef4\u5149\u58f0\u6210\u50cf\u63a5\u8fd1\u5b9e\u65f6\uff0c\u6781\u5927\u63a8\u52a8\u4e86\u4e09\u7ef4PACT\u5411\u4e34\u5e8a\u5e94\u7528\u7684\u8f6c\u5316\u3002", "summary_cn": "\u5c3d\u7ba1\u8fed\u4ee3\u91cd\u5efa\uff08IR\uff09\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u6821\u6b63\u5149\u58f0\uff08PA\uff09\u8ba1\u7b97\u673a\u65ad\u5c42\u6210\u50cf\uff08PACT\uff09\u4e2d\u7684\u91cd\u5efa\u4f2a\u5f71\uff0c\u4f46\u5176\u91cd\u5efa\u65f6\u95f4\u8fc7\u957f\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u4e09\u7ef4\uff083D\uff09\u6210\u50cf\u4e2d\uff0cIR\u7b97\u6cd5\u9700\u8981\u6570\u767e\u79d2\u751a\u81f3\u6570\u5c0f\u65f6\uff0c\u8ba1\u7b97\u8d1f\u62c5\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u4e09\u7ef4PACT\u7684\u8d85\u5febIR\u65b9\u6cd5\uff0c\u79f0\u4e3a\u57fa\u4e8e\u9ad8\u65af\u6838\u7684\u8d85\u5feb\u4e09\u7ef4\u5149\u58f0\u8fed\u4ee3\u91cd\u5efa\uff08GPAIR\uff09\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7ea7\u522b\u7684\u8ba1\u7b97\u52a0\u901f\u3002GPAIR\u5229\u7528\u8fde\u7eed\u5404\u5411\u540c\u6027\u7684\u9ad8\u65af\u6838\u66ff\u4ee3\u4f20\u7edf\u7684\u7a7a\u95f4\u7f51\u683c\uff0c\u901a\u8fc7\u63a8\u5bfc\u538b\u529b\u6ce2\u7684\u89e3\u6790\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u7ed3\u5408\u5f3a\u5927\u7684GPU\u52a0\u901f\u53ef\u5fae\u5206Triton\u7b97\u5b50\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u8d85\u5feb\u91cd\u5efa\u6027\u80fd\u3002\u5728\u52a8\u7269\u5b9e\u9a8c\u4e2d\uff0cGPAIR\u5bf9\u5305\u542b840\u4e07\u4f53\u7d20\u7684\u4e09\u7ef4\u76ee\u6807\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u7684\u91cd\u5efa\u901f\u5ea6\u3002\u8fd9\u4e00\u9769\u547d\u6027\u7684\u8d85\u5feb\u56fe\u50cf\u91cd\u5efa\u6280\u672f\u4f7f\u5927\u89c4\u6a21\u4e09\u7ef4\u5149\u58f0\u91cd\u5efa\u63a5\u8fd1\u5b9e\u65f6\uff0c\u663e\u8457\u63a8\u52a8\u4e86\u4e09\u7ef4PACT\u5411\u4e34\u5e8a\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.03894", "pdf": "https://arxiv.org/pdf/2602.03894", "abs": "https://arxiv.org/abs/2602.03894", "authors": ["Hugo Markoff", "Stefan Hein Bengtson", "Michael \u00d8rsted"], "title": "Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images directly to species-level clusters. We present a comprehensive benchmarking framework evaluating five ViT models combined with five dimensionality reduction techniques and four clustering algorithms, two supervised and two unsupervised, across 60 species (30 mammals and 30 birds), with each test using a random subset of 200 validated images per species. We investigate when clustering succeeds at species-level, where it fails, and whether clustering within the species-level reveals ecologically meaningful patterns such as sex, age, or phenotypic variation. Our results demonstrate near-perfect species-level clustering (V-measure: 0.958) using DINOv3 embeddings with t-SNE and supervised hierarchical clustering methods. Unsupervised approaches achieve competitive performance (0.943) while requiring no prior species knowledge, rejecting only 1.14% of images as outliers requiring expert review. We further demonstrate robustness to realistic long-tailed distributions of species and show that intentional over-clustering can reliably extract intra-specific variation including age classes, sexual dimorphism, and pelage differences. We introduce an open-source benchmarking toolkit and provide recommendations for ecologists to select appropriate methods for sorting their specific taxonomic groups and data.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eVision Transformer\uff08ViT\uff09\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u80fd\u5426\u76f4\u63a5\u5c06\u5927\u91cf\u672a\u6807\u6ce8\u7684\u52a8\u7269\u56fe\u50cf\u805a\u7c7b\u5230\u7269\u79cd\u7ea7\u522b\uff0c\u5e76\u8fdb\u4e00\u6b65\u63ed\u793a\u79cd\u5185\u53d8\u5f02\uff08\u5982\u6027\u522b\u3001\u5e74\u9f84\u7b49\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDINOv3\u5d4c\u5165\u7ed3\u5408t-SNE\u548c\u5c42\u6b21\u805a\u7c7b\u53ef\u5b9e\u73b0\u63a5\u8fd1\u5b8c\u7f8e\u7684\u7269\u79cd\u7ea7\u805a\u7c7b\uff08V-measure: 0.958\uff09\uff0c\u4e14\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u4e5f\u8868\u73b0\u4f18\u5f02\uff080.943\uff09\uff0c\u4ec5\u9700\u5254\u96641.14%\u7684\u5f02\u5e38\u56fe\u50cf\u3002\u4f5c\u8005\u8fd8\u5f00\u6e90\u4e86\u57fa\u51c6\u5de5\u5177\u5305\uff0c\u4e3a\u751f\u6001\u5b66\u5bb6\u63d0\u4f9b\u65b9\u6cd5\u9009\u62e9\u5efa\u8bae\u3002", "motivation": "\u624b\u52a8\u6807\u6ce8\u52a8\u7269\u56fe\u50cf\u5728\u751f\u6001\u7814\u7a76\u4e2d\u662f\u4e00\u4e2a\u91cd\u5927\u74f6\u9888\uff0c\u9650\u5236\u4e86\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u7684\u89c4\u6a21\u548c\u6548\u7387\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u51cf\u5c11\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u7269\u79cd\u7ea7\u522b\u7684\u81ea\u52a8\u805a\u7c7b\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u7efc\u5408\u57fa\u51c6\u6846\u67b6\uff0c\u8bc4\u4f30\u4e94\u79cdViT\u6a21\u578b\uff08\u5305\u62ecDINOv3\uff09\u3001\u4e94\u79cd\u964d\u7ef4\u6280\u672f\u4e0e\u56db\u79cd\u805a\u7c7b\u7b97\u6cd5\uff08\u4e24\u79cd\u6709\u76d1\u7763\u3001\u4e24\u79cd\u65e0\u76d1\u7763\uff09\u572860\u4e2a\u7269\u79cd\uff0830\u79cd\u54fa\u4e73\u52a8\u7269\u548c30\u79cd\u9e1f\u7c7b\uff09\u4e0a\u7684\u8868\u73b0\u3002\u6bcf\u79cd\u7269\u79cd\u4f7f\u7528200\u5f20\u7ecf\u9a8c\u8bc1\u7684\u56fe\u50cf\u8fdb\u884c\u6d4b\u8bd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u805a\u7c7b\u7ed3\u679c\u662f\u5426\u80fd\u63ed\u793a\u79cd\u5185\u751f\u6001\u5b66\u4e0a\u6709\u610f\u4e49\u7684\u53d8\u5f02\uff08\u5982\u6027\u522b\u3001\u5e74\u9f84\u3001\u8868\u578b\u5dee\u5f02\uff09\u3002", "result": "\u4f7f\u7528DINOv3\u5d4c\u5165\u914d\u5408t-SNE\u548c\u6709\u76d1\u7763\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\uff0c\u5728\u7269\u79cd\u7ea7\u522b\u805a\u7c7b\u4e0a\u8fbe\u5230V-measure 0.958\uff1b\u65e0\u76d1\u7763\u65b9\u6cd5\u4e5f\u53d6\u5f970.943\u7684\u9ad8\u5206\uff0c\u4ec5\u9700\u5254\u96641.14%\u7684\u5f02\u5e38\u56fe\u50cf\u3002\u8be5\u65b9\u6cd5\u5bf9\u957f\u5c3e\u5206\u5e03\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4e14\u901a\u8fc7\u6709\u610f\u8fc7\u805a\u7c7b\u53ef\u6709\u6548\u63d0\u53d6\u79cd\u5185\u53d8\u5f02\u4fe1\u606f\u3002", "conclusion": "ViT\u57fa\u7840\u6a21\u578b\uff08\u5c24\u5176\u662fDINOv3\uff09\u7ed3\u5408\u5408\u9002\u7684\u964d\u7ef4\u4e0e\u805a\u7c7b\u7b56\u7565\uff0c\u80fd\u591f\u5728\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u5b9e\u73b0\u7269\u79cd\u7ea7\u56fe\u50cf\u805a\u7c7b\uff0c\u5e76\u63ed\u793a\u79cd\u5185\u751f\u6001\u7279\u5f81\u3002\u8be5\u7814\u7a76\u4e3a\u751f\u6001\u5b66\u5bb6\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5f00\u6e90\u5de5\u5177\u548c\u65b9\u6cd5\u9009\u62e9\u6307\u5357\uff0c\u6709\u671b\u663e\u8457\u63d0\u5347\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "summary_cn": "\u624b\u52a8\u6807\u6ce8\u52a8\u7269\u56fe\u50cf\u4ecd\u7136\u662f\u751f\u6001\u5b66\u7814\u7a76\u4e2d\u7684\u4e00\u4e2a\u91cd\u5927\u74f6\u9888\uff0c\u9650\u5236\u4e86\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u5de5\u4f5c\u7684\u89c4\u6a21\u548c\u6548\u7387\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u6700\u5148\u8fdb\u7684\u89c6\u89c9Transformer\uff08ViT\uff09\u57fa\u7840\u6a21\u578b\u662f\u5426\u80fd\u591f\u76f4\u63a5\u5c06\u6570\u5343\u5f20\u672a\u6807\u6ce8\u7684\u52a8\u7269\u56fe\u50cf\u805a\u7c7b\u5230\u7269\u79cd\u7ea7\u522b\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cdViT\u6a21\u578b\u7ed3\u5408\u4e94\u79cd\u964d\u7ef4\u6280\u672f\u548c\u56db\u79cd\u805a\u7c7b\u7b97\u6cd5\uff08\u4e24\u79cd\u6709\u76d1\u7763\u3001\u4e24\u79cd\u65e0\u76d1\u7763\uff09\u572860\u4e2a\u7269\u79cd\uff0830\u79cd\u54fa\u4e73\u52a8\u7269\u548c30\u79cd\u9e1f\u7c7b\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u6bcf\u4e2a\u6d4b\u8bd5\u4f7f\u7528\u6bcf\u79cd\u7269\u79cd200\u5f20\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u968f\u673a\u56fe\u50cf\u5b50\u96c6\u3002\u6211\u4eec\u7814\u7a76\u4e86\u805a\u7c7b\u5728\u54ea\u4e9b\u60c5\u51b5\u4e0b\u80fd\u6210\u529f\u5b9e\u73b0\u7269\u79cd\u7ea7\u522b\u533a\u5206\u3001\u5728\u54ea\u4e9b\u60c5\u51b5\u4e0b\u5931\u8d25\uff0c\u4ee5\u53ca\u7269\u79cd\u5185\u90e8\u7684\u805a\u7c7b\u662f\u5426\u80fd\u63ed\u793a\u5177\u6709\u751f\u6001\u5b66\u610f\u4e49\u7684\u6a21\u5f0f\uff0c\u4f8b\u5982\u6027\u522b\u3001\u5e74\u9f84\u6216\u8868\u578b\u53d8\u5f02\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528DINOv3\u5d4c\u5165\u7ed3\u5408t-SNE\u548c\u6709\u76d1\u7763\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\uff0c\u53ef\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u7269\u79cd\u7ea7\u805a\u7c7b\uff08V-measure\uff1a0.958\uff09\u3002\u65e0\u76d1\u7763\u65b9\u6cd5\u5728\u65e0\u9700\u4efb\u4f55\u5148\u9a8c\u7269\u79cd\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u4e5f\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff080.943\uff09\uff0c\u4ec5\u5c061.14%\u7684\u56fe\u50cf\u4f5c\u4e3a\u5f02\u5e38\u503c\u5254\u9664\u4ee5\u4f9b\u4e13\u5bb6\u5ba1\u67e5\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5bf9\u771f\u5b9e\u573a\u666f\u4e2d\u5e38\u89c1\u7684\u7269\u79cd\u957f\u5c3e\u5206\u5e03\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u8868\u660e\u6709\u610f\u8fdb\u884c\u8fc7\u805a\u7c7b\u53ef\u4ee5\u53ef\u9760\u5730\u63d0\u53d6\u79cd\u5185\u53d8\u5f02\u4fe1\u606f\uff0c\u5305\u62ec\u5e74\u9f84\u9636\u6bb5\u3001\u6027\u522b\u4e8c\u6001\u6027\u548c\u6bdb\u8272\u5dee\u5f02\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u4e00\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u5305\uff0c\u5e76\u4e3a\u751f\u6001\u5b66\u5bb6\u63d0\u4f9b\u4e86\u9488\u5bf9\u5176\u7279\u5b9a\u5206\u7c7b\u7fa4\u548c\u6570\u636e\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u7684\u5efa\u8bae\u3002"}}
{"id": "2602.03895", "pdf": "https://arxiv.org/pdf/2602.03895", "abs": "https://arxiv.org/abs/2602.03895", "authors": ["Xuwei Tan", "Ziyu Hu", "Xueru Zhang"], "title": "Benchmarking Bias Mitigation Toward Fairness Without Harm from Vision to LVLMs", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICLR 26", "summary": "Machine learning models trained on real-world data often inherit and amplify biases against certain social groups, raising urgent concerns about their deployment at scale. While numerous bias mitigation methods have been proposed, comparing the effectiveness of bias mitigation methods remains difficult due to heterogeneous datasets, inconsistent fairness metrics, isolated evaluation of vision versus multi-modal models, and insufficient hyperparameter tuning that undermines fair comparisons. We introduce NH-Fair, a unified benchmark for fairness without harm that spans both vision models and large vision-language models (LVLMs) under standardized data, metrics, and training protocols, covering supervised and zero-shot regimes. Our key contributions are: (1) a systematic ERM tuning study that identifies training choices with large influence on both utility and disparities, yielding empirically grounded guidelines to help practitioners reduce expensive hyperparameter tuning space in achieving strong fairness and accuracy; (2) evidence that many debiasing methods do not reliably outperform a well-tuned ERM baseline, whereas a composite data-augmentation method consistently delivers parity gains without sacrificing utility, emerging as a promising practical strategy. (3) an analysis showing that while LVLMs achieve higher average accuracy, they still exhibit subgroup disparities, and gains from scaling are typically smaller than those from architectural or training-protocol choices. NH-Fair provides a reproducible, tuning-aware pipeline for rigorous, harm-aware fairness evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NH-Fair\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u516c\u5e73\u6027\u57fa\u51c6\uff0c\u7528\u4e8e\u5728\u6807\u51c6\u5316\u6761\u4ef6\u4e0b\u8bc4\u4f30\u89c6\u89c9\u548c\u5927\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u53d1\u73b0\u826f\u597d\u8c03\u4f18\u7684ERM\u57fa\u7ebf\u5e38\u4f18\u4e8e\u8bb8\u591a\u53bb\u504f\u65b9\u6cd5\uff0c\u800c\u590d\u5408\u6570\u636e\u589e\u5f3a\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u516c\u5e73\u6027\u800c\u4e0d\u727a\u7272\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e38\u7ee7\u627f\u5e76\u653e\u5927\u5bf9\u67d0\u4e9b\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u89c1\uff0c\u4f46\u73b0\u6709\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u56e0\u6570\u636e\u96c6\u3001\u516c\u5e73\u6027\u6307\u6807\u3001\u6a21\u578b\u7c7b\u578b\u548c\u8d85\u53c2\u8c03\u4f18\u4e0d\u4e00\u81f4\uff0c\u96be\u4ee5\u516c\u5e73\u6bd4\u8f83\u5176\u6709\u6548\u6027\u3002", "method": "\u6784\u5efaNH-Fair\u7edf\u4e00\u57fa\u51c6\uff0c\u5728\u6807\u51c6\u5316\u6570\u636e\u3001\u6307\u6807\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\uff0c\u7cfb\u7edf\u8bc4\u4f30ERM\uff08\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff09\u8c03\u4f18\u5bf9\u6548\u7528\u4e0e\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u5bf9\u6bd4\u591a\u79cd\u53bb\u504f\u65b9\u6cd5\u5728\u89c6\u89c9\u6a21\u578b\u548c\u5927\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u76d1\u7763\u548c\u96f6\u6837\u672c\u573a\u666f\u3002", "result": "(1) ERM\u8c03\u4f18\u53ef\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6548\u7528\u4e0e\u516c\u5e73\u6027\uff0c\u63d0\u4f9b\u51cf\u5c11\u8d85\u53c2\u641c\u7d22\u7a7a\u95f4\u7684\u5b9e\u7528\u6307\u5357\uff1b(2) \u591a\u6570\u53bb\u504f\u65b9\u6cd5\u4e0d\u5982\u826f\u597d\u8c03\u4f18\u7684ERM\u57fa\u7ebf\uff0c\u800c\u590d\u5408\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u80fd\u7a33\u5b9a\u63d0\u5347\u516c\u5e73\u6027\u4e14\u4e0d\u635f\u5931\u6027\u80fd\uff1b(3) LVLMs\u867d\u5e73\u5747\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u4ecd\u5b58\u5728\u5b50\u7fa4\u5dee\u5f02\uff0c\u6a21\u578b\u7f29\u653e\u5e26\u6765\u7684\u6536\u76ca\u901a\u5e38\u5c0f\u4e8e\u67b6\u6784\u6216\u8bad\u7ec3\u534f\u8bae\u9009\u62e9\u7684\u5f71\u54cd\u3002", "conclusion": "NH-Fair\u4e3a\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u3001\u8003\u8651\u8c03\u4f18\u7684\u6807\u51c6\u5316\u6d41\u7a0b\uff0c\u5f3a\u8c03\u5728\u8ffd\u6c42\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u5fc5\u987b\u5173\u6ce8\u5b50\u7fa4\u516c\u5e73\u6027\uff0c\u5e76\u6307\u51fa\u590d\u5408\u6570\u636e\u589e\u5f3a\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u5b9e\u7528\u53bb\u504f\u7b56\u7565\u3002", "summary_cn": "\u5728\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f80\u5f80\u4f1a\u7ee7\u627f\u5e76\u653e\u5927\u5bf9\u67d0\u4e9b\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u89c1\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u5176\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u7d27\u8feb\u62c5\u5fe7\u3002\u5c3d\u7ba1\u5df2\u63d0\u51fa\u4f17\u591a\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u5f02\u6784\u3001\u516c\u5e73\u6027\u6307\u6807\u4e0d\u4e00\u81f4\u3001\u89c6\u89c9\u6a21\u578b\u4e0e\u591a\u6a21\u6001\u6a21\u578b\u8bc4\u4f30\u76f8\u4e92\u5b64\u7acb\uff0c\u4ee5\u53ca\u8d85\u53c2\u6570\u8c03\u4f18\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u4f7f\u5f97\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u96be\u4ee5\u8fdb\u884c\u516c\u5e73\u6bd4\u8f83\u3002\u6211\u4eec\u63d0\u51fa\u4e86NH-Fair\u2014\u2014\u4e00\u4e2a\u201c\u65e0\u5bb3\u516c\u5e73\u6027\u201d\uff08fairness without harm\uff09\u7684\u7edf\u4e00\u57fa\u51c6\uff0c\u6db5\u76d6\u89c6\u89c9\u6a21\u578b\u548c\u5927\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\uff0c\u5728\u6807\u51c6\u5316\u7684\u6570\u636e\u3001\u6307\u6807\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\u8fdb\u884c\u8bc4\u4f30\uff0c\u8986\u76d6\u76d1\u7763\u5b66\u4e60\u548c\u96f6\u6837\u672c\u573a\u666f\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a\uff081\uff09\u4e00\u9879\u7cfb\u7edf\u7684ERM\uff08\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff09\u8c03\u4f18\u7814\u7a76\uff0c\u8bc6\u522b\u51fa\u5bf9\u6a21\u578b\u6548\u7528\u548c\u7fa4\u4f53\u5dee\u5f02\u5177\u6709\u663e\u8457\u5f71\u54cd\u7684\u8bad\u7ec3\u9009\u62e9\uff0c\u4ece\u800c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6307\u5bfc\u65b9\u9488\uff0c\u4ee5\u7f29\u5c0f\u5b9e\u73b0\u9ad8\u516c\u5e73\u6027\u4e0e\u9ad8\u51c6\u786e\u7387\u6240\u9700\u7684\u6602\u8d35\u8d85\u53c2\u6570\u641c\u7d22\u7a7a\u95f4\uff1b\uff082\uff09\u8bc1\u636e\u8868\u660e\uff0c\u8bb8\u591a\u53bb\u504f\u65b9\u6cd5\u5e76\u4e0d\u80fd\u7a33\u5b9a\u5730\u8d85\u8d8a\u7ecf\u8fc7\u826f\u597d\u8c03\u4f18\u7684ERM\u57fa\u7ebf\uff0c\u800c\u4e00\u79cd\u590d\u5408\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5219\u80fd\u6301\u7eed\u5e26\u6765\u516c\u5e73\u6027\u63d0\u5347\u4e14\u4e0d\u727a\u7272\u6a21\u578b\u6548\u7528\uff0c\u5c55\u73b0\u51fa\u4f5c\u4e3a\u5b9e\u7528\u7b56\u7565\u7684\u6f5c\u529b\uff1b\uff083\uff09\u5206\u6790\u663e\u793a\uff0c\u5c3d\u7ba1LVLMs\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4f46\u4ecd\u8868\u73b0\u51fa\u5b50\u7fa4\u4f53\u95f4\u7684\u5dee\u5f02\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u6240\u5e26\u6765\u7684\u6536\u76ca\u901a\u5e38\u5c0f\u4e8e\u67b6\u6784\u8bbe\u8ba1\u6216\u8bad\u7ec3\u534f\u8bae\u9009\u62e9\u6240\u5e26\u6765\u7684\u6539\u8fdb\u3002NH-Fair\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u5173\u6ce8\u8c03\u4f18\u8fc7\u7a0b\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u652f\u6301\u4e25\u683c\u4e14\u6ce8\u91cd\u907f\u514d\u4f24\u5bb3\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u3002"}}
{"id": "2602.03878", "pdf": "https://arxiv.org/pdf/2602.03878", "abs": "https://arxiv.org/abs/2602.03878", "authors": ["Longjie Zhao", "Ziming Hong", "Jiaxin Huang", "Runnan Chen", "Mingming Gong", "Tongliang Liu"], "title": "Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey", "categories": ["cs.CV", "cs.CR"], "comment": "A collection of relevant papers is summarized and will be continuously updated at \\url{https://github.com/tmllab/Awesome-3DGS-IP-Protection}", "summary": "3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and robustness challenges. To address this gap, we present the first systematic survey on 3DGS IP protection and introduce a bottom-up framework that examines (i) underlying Gaussian-based perturbation mechanisms, (ii) passive and active protection paradigms, and (iii) robustness threats under emerging generative AI era, revealing gaps in technical foundations and robustness characterization and indicating opportunities for deeper investigation. Finally, we outline six research directions across robustness, efficiency, and protection paradigms, offering a roadmap toward reliable and trustworthy IP protection for 3DGS assets.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7efc\u8ff0\u4e863D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u5e95\u5411\u4e0a\u7684\u5206\u6790\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u516d\u4e2a\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u77403D\u9ad8\u65af\u6cfc\u6e85\u5728\u5b9e\u65f63D\u573a\u666f\u5408\u6210\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u53ca\u5176\u5546\u4e1a\u4ef7\u503c\u63d0\u5347\uff0c\u5176\u663e\u5f0f\u53c2\u6570\u5316\u7ed3\u6784\u5f15\u53d1\u4e86\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u65b0\u9700\u6c42\uff0c\u4f46\u5f53\u524d\u7814\u7a76\u8f83\u4e3a\u96f6\u6563\uff0c\u7f3a\u4e4f\u7edf\u4e00\u89c6\u89d2\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u5e95\u5411\u4e0a\u7684\u5206\u6790\u6846\u67b6\uff0c\u6db5\u76d6\uff1a(i) \u57fa\u4e8e\u9ad8\u65af\u7684\u6270\u52a8\u673a\u5236\uff0c(ii) \u88ab\u52a8\u4e0e\u4e3b\u52a8\u4fdd\u62a4\u8303\u5f0f\uff0c(iii) \u751f\u6210\u5f0fAI\u65f6\u4ee3\u4e0b\u7684\u9c81\u68d2\u6027\u5a01\u80c1\u3002", "result": "\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u57fa\u7840\u548c\u9c81\u68d2\u6027\u8868\u5f81\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u660e\u786e\u4e86\u6df1\u5165\u7814\u7a76\u7684\u673a\u4f1a\u3002", "conclusion": "\u4e3a3DGS\u8d44\u4ea7\u7684\u53ef\u9760\u3001\u53ef\u4fe1\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\uff0c\u5e76\u63d0\u51fa\u4e86\u516d\u4e2a\u8de8\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u4fdd\u62a4\u8303\u5f0f\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "summary_cn": "3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5df2\u6210\u4e3a\u5b9e\u73b0\u5b9e\u65f63D\u573a\u666f\u5408\u6210\u7684\u4e3b\u6d41\u8868\u793a\u65b9\u6cd5\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u865a\u62df\u73b0\u5b9e\u3001\u589e\u5f3a\u73b0\u5b9e\u3001\u673a\u5668\u4eba\u6280\u672f\u548c3D\u5185\u5bb9\u521b\u4f5c\u7b49\u9886\u57df\u3002\u5176\u65e5\u76ca\u589e\u957f\u7684\u5546\u4e1a\u4ef7\u503c\u548c\u663e\u5f0f\u7684\u53c2\u6570\u5316\u7ed3\u6784\u5f15\u53d1\u4e86\u65b0\u5174\u7684\u77e5\u8bc6\u4ea7\u6743\uff08IP\uff09\u4fdd\u62a4\u95ee\u9898\uff0c\u4fc3\u4f7f\u5b66\u754c\u5bf93DGS\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u7684\u7814\u7a76\u8fc5\u901f\u589e\u957f\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u7814\u7a76\u4ecd\u8f83\u4e3a\u96f6\u6563\uff0c\u7f3a\u4e4f\u5bf9\u5e95\u5c42\u673a\u5236\u3001\u4fdd\u62a4\u8303\u5f0f\u53ca\u9c81\u68d2\u6027\u6311\u6218\u7684\u7edf\u4e00\u8ba4\u8bc6\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u6587\u9996\u6b21\u5bf93DGS\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7efc\u8ff0\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u81ea\u5e95\u5411\u4e0a\u7684\u5206\u6790\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u8003\u5bdf\u4e86\uff1a(i) \u57fa\u4e8e\u9ad8\u65af\u7684\u6270\u52a8\u673a\u5236\uff0c(ii) \u88ab\u52a8\u4e0e\u4e3b\u52a8\u4fdd\u62a4\u8303\u5f0f\uff0c\u4ee5\u53ca(iii) \u5728\u65b0\u5174\u751f\u6210\u5f0fAI\u65f6\u4ee3\u4e0b\u9762\u4e34\u7684\u9c81\u68d2\u6027\u5a01\u80c1\u3002\u901a\u8fc7\u8be5\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5728\u6280\u672f\u57fa\u7840\u548c\u9c81\u68d2\u6027\u8868\u5f81\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u6307\u51fa\u4e86\u6df1\u5165\u7814\u7a76\u7684\u673a\u9047\u3002\u6700\u540e\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u516d\u4e2a\u6db5\u76d6\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u4fdd\u62a4\u8303\u5f0f\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u5b9e\u73b0\u53ef\u9760\u4e14\u53ef\u4fe1\u76843DGS\u8d44\u4ea7\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u53d1\u5c55\u8def\u7ebf\u56fe\u3002"}}
{"id": "2602.03879", "pdf": "https://arxiv.org/pdf/2602.03879", "abs": "https://arxiv.org/abs/2602.03879", "authors": ["Ali Bayeh", "Samira Sadaoui", "Malek Mouhoub"], "title": "TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "23 pages, 9 figures", "summary": "To address the trade-off between computational efficiency and adherence to Kolmogorov-Arnold Network (KAN) principles, we propose TruKAN, a new architecture based on the KAN structure and learnable activation functions. TruKAN replaces the B-spline basis in KAN with a family of truncated power functions derived from k-order spline theory. This change maintains the KAN's expressiveness while enhancing accuracy and training time. Each TruKAN layer combines a truncated power term with a polynomial term and employs either shared or individual knots. TruKAN exhibits greater interpretability than other KAN variants due to its simplified basis functions and knot configurations. By prioritizing interpretable basis functions, TruKAN aims to balance approximation efficacy with transparency. We develop the TruKAN model and integrate it into an advanced EfficientNet-V2-based framework, which is then evaluated on computer vision benchmark datasets. To ensure a fair comparison, we develop various models: MLP-, KAN-, SineKAN and TruKAN-based EfficientNet frameworks and assess their training time and accuracy across small and deep architectures. The training phase uses hybrid optimization to improve convergence stability. Additionally, we investigate layer normalization techniques for all the models and assess the impact of shared versus individual knots in TruKAN. Overall, TruKAN outperforms other KAN models in terms of accuracy, computational efficiency and memory usage on the complex vision task, demonstrating advantages beyond the limited settings explored in prior KAN studies.", "AI": {"tldr": "\u63d0\u51faTruKAN\uff0c\u4e00\u79cd\u57fa\u4e8e\u622a\u65ad\u5e42\u51fd\u6570\u7684KAN\u65b0\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u51c6\u786e\u7387\u3001\u8bad\u7ec3\u901f\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709KAN\u53d8\u4f53\u3002", "motivation": "\u73b0\u6709KAN\u6a21\u578b\u5728\u8ba1\u7b97\u6548\u7387\u4e0e\u9075\u5faaKolmogorov-Arnold\u8868\u793a\u5b9a\u7406\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u4e14\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002\u4f5c\u8005\u65e8\u5728\u8bbe\u8ba1\u4e00\u79cd\u517c\u987e\u903c\u8fd1\u80fd\u529b\u3001\u6548\u7387\u4e0e\u900f\u660e\u5ea6\u7684\u65b0\u67b6\u6784\u3002", "method": "\u5c06KAN\u4e2d\u7684B\u6837\u6761\u57fa\u66ff\u6362\u4e3a\u6e90\u81eak\u9636\u6837\u6761\u7406\u8bba\u7684\u622a\u65ad\u5e42\u51fd\u6570\u65cf\uff1b\u6bcf\u5c42\u7ed3\u5408\u622a\u65ad\u5e42\u9879\u4e0e\u591a\u9879\u5f0f\u9879\uff0c\u652f\u6301\u5171\u4eab\u6216\u72ec\u7acb\u8282\u70b9\uff1b\u6784\u5efaTruKAN-EfficientNet-V2\u6a21\u578b\uff0c\u5e76\u4e0eMLP\u3001KAN\u3001SineKAN\u7b49\u53d8\u4f53\u5728\u76f8\u540c\u6846\u67b6\u4e0b\u5bf9\u6bd4\uff1b\u91c7\u7528\u6df7\u5408\u4f18\u5316\u7b56\u7565\u8bad\u7ec3\uff0c\u5e76\u7814\u7a76\u5c42\u5f52\u4e00\u5316\u53ca\u8282\u70b9\u914d\u7f6e\u7684\u5f71\u54cd\u3002", "result": "TruKAN\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6KAN\u53d8\u4f53\uff0c\u5728\u51c6\u786e\u7387\u3001\u8bad\u7ec3\u65f6\u95f4\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u5c24\u5176\u5728\u5c0f\u578b\u548c\u6df1\u5c42\u67b6\u6784\u4e2d\u5747\u5177\u4f18\u52bf\u3002", "conclusion": "TruKAN\u901a\u8fc7\u7b80\u5316\u57fa\u51fd\u6570\u548c\u8282\u70b9\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301KAN\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8d85\u8d8a\u4e86\u5148\u524dKAN\u7814\u7a76\u7684\u5c40\u9650\u573a\u666f\u3002", "summary_cn": "\u4e3a\u89e3\u51b3\u8ba1\u7b97\u6548\u7387\u4e0e\u9075\u5faaKolmogorov-Arnold\u7f51\u7edc\uff08KAN\uff09\u539f\u5219\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86TruKAN\u2014\u2014\u4e00\u79cd\u57fa\u4e8eKAN\u7ed3\u6784\u548c\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u7684\u65b0\u67b6\u6784\u3002TruKAN\u7528\u6e90\u81eak\u9636\u6837\u6761\u7406\u8bba\u7684\u4e00\u65cf\u622a\u65ad\u5e42\u51fd\u6570\u66ff\u4ee3\u4e86KAN\u4e2d\u7684B\u6837\u6761\u57fa\uff0c\u8fd9\u4e00\u6539\u52a8\u5728\u4fdd\u6301KAN\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u548c\u8bad\u7ec3\u901f\u5ea6\u3002\u6bcf\u4e2aTruKAN\u5c42\u7ed3\u5408\u4e86\u622a\u65ad\u5e42\u9879\u4e0e\u591a\u9879\u5f0f\u9879\uff0c\u5e76\u91c7\u7528\u5171\u4eab\u6216\u72ec\u7acb\u7684\u8282\u70b9\uff08knots\uff09\u3002\u7531\u4e8e\u5176\u7b80\u5316\u7684\u57fa\u51fd\u6570\u548c\u8282\u70b9\u914d\u7f6e\uff0cTruKAN\u76f8\u6bd4\u5176\u4ed6KAN\u53d8\u4f53\u5177\u6709\u66f4\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u4f18\u5148\u8003\u8651\u53ef\u89e3\u91ca\u7684\u57fa\u51fd\u6570\uff0cTruKAN\u65e8\u5728\u5e73\u8861\u903c\u8fd1\u6548\u679c\u4e0e\u900f\u660e\u5ea6\u3002\u6211\u4eec\u5f00\u53d1\u4e86TruKAN\u6a21\u578b\u5e76\u5c06\u5176\u96c6\u6210\u5230\u5148\u8fdb\u7684EfficientNet-V2\u6846\u67b6\u4e2d\uff0c\u5e76\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u4e3a\u786e\u4fdd\u516c\u5e73\u6bd4\u8f83\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u57fa\u4e8eMLP\u3001KAN\u3001SineKAN\u548cTruKAN\u7684\u591a\u79cdEfficientNet\u6846\u67b6\uff0c\u5e76\u5728\u5c0f\u578b\u548c\u6df1\u5c42\u67b6\u6784\u4e2d\u8bc4\u4f30\u5176\u8bad\u7ec3\u65f6\u95f4\u548c\u51c6\u786e\u7387\u3002\u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u6df7\u5408\u4f18\u5316\u7b56\u7565\u4ee5\u63d0\u5347\u6536\u655b\u7a33\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7814\u7a76\u4e86\u6240\u6709\u6a21\u578b\u7684\u5c42\u5f52\u4e00\u5316\u6280\u672f\uff0c\u5e76\u8bc4\u4f30\u4e86TruKAN\u4e2d\u5171\u4eab\u8282\u70b9\u4e0e\u72ec\u7acb\u8282\u70b9\u7684\u5f71\u54cd\u3002\u603b\u4f53\u800c\u8a00\uff0cTruKAN\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u4e2d\u5728\u51c6\u786e\u7387\u3001\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u5747\u4f18\u4e8e\u5176\u4ed6KAN\u6a21\u578b\uff0c\u5c55\u73b0\u51fa\u8d85\u8d8a\u4ee5\u5f80KAN\u7814\u7a76\u6709\u9650\u573a\u666f\u7684\u4f18\u52bf\u3002"}}
{"id": "2602.03881", "pdf": "https://arxiv.org/pdf/2602.03881", "abs": "https://arxiv.org/abs/2602.03881", "authors": ["Maxx Richard Rahman", "Mostafa Hammouda", "Wolfgang Maass"], "title": "DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and modality irregularities inherent in real-world clinical data. To address these limitations, we propose the Diffusion-Guided Attention Network (DiGAN), which integrates latent diffusion modelling with an attention-guided convolutional network. The diffusion model synthesizes realistic longitudinal neuroimaging trajectories from limited training data, enriching temporal context and improving robustness to unevenly spaced visits. The attention-convolutional layer then captures discriminative structural--temporal patterns that distinguish cognitively normal subjects from those with mild cognitive impairment and subjective cognitive decline. Experiments on synthetic and ADNI datasets demonstrate that DiGAN outperforms existing state-of-the-art baselines, showing its potential for early-stage AD detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDiGAN\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u6269\u6563\u6a21\u578b\u4e0e\u6ce8\u610f\u529b\u5377\u79ef\u7f51\u7edc\uff0c\u7528\u4e8e\u4ece\u6709\u9650\u4e14\u4e0d\u89c4\u5219\u7684\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u4e2d\u589e\u5f3a\u65f6\u95f4\u4e0a\u4e0b\u6587\u5e76\u63d0\u5347\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u4e2d\u53d7\u9650\u4e8e\u5bf9\u5927\u89c4\u6a21\u7eb5\u5411\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4e14\u96be\u4ee5\u5904\u7406\u4e34\u5e8a\u6570\u636e\u4e2d\u56fa\u6709\u7684\u65f6\u95f4\u8fde\u7eed\u6027\u548c\u6a21\u6001\u4e0d\u89c4\u5219\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faDiffusion-Guided Attention Network\uff08DiGAN\uff09\uff0c\u5c06\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e0e\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5377\u79ef\u7f51\u7edc\u76f8\u7ed3\u5408\uff1a\u6269\u6563\u6a21\u578b\u4ece\u6709\u9650\u6570\u636e\u5408\u6210\u903c\u771f\u7684\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u8f68\u8ff9\uff0c\u6ce8\u610f\u529b\u5377\u79ef\u5c42\u5219\u6355\u6349\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\u3001\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u548c\u4e3b\u89c2\u8ba4\u77e5\u4e0b\u964d\u4e2a\u4f53\u7684\u7ed3\u6784-\u65f6\u95f4\u6a21\u5f0f\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548cADNI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDiGAN\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u65b9\u9762\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "DiGAN\u901a\u8fc7\u878d\u5408\u6269\u6563\u5efa\u6a21\u4e0e\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u5e94\u5bf9\u4e86\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u6570\u636e\u7a00\u758f\u4e0e\u4e0d\u89c4\u5219\u7684\u6311\u6218\uff0c\u4e3a\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u81ea\u52a8\u8bca\u65ad\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u7531\u4e8e\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u524d\u9a71\u9636\u6bb5\u8111\u7ed3\u6784\u53d8\u5316\u7ec6\u5fae\u4e14\u65f6\u95f4\u8fdb\u7a0b\u4e0d\u89c4\u5219\uff0c\u5176\u65e9\u671f\u8bca\u65ad\u4ecd\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5927\u91cf\u7eb5\u5411\u6570\u636e\u96c6\uff0c\u5e76\u4e14\u5f80\u5f80\u96be\u4ee5\u5efa\u6a21\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u4e2d\u56fa\u6709\u7684\u65f6\u95f4\u8fde\u7eed\u6027\u548c\u6a21\u6001\u4e0d\u89c4\u5219\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6269\u6563\u5f15\u5bfc\u6ce8\u610f\u529b\u7f51\u7edc\uff08DiGAN\uff09\uff0c\u8be5\u65b9\u6cd5\u5c06\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e0e\u6ce8\u610f\u529b\u5f15\u5bfc\u7684\u5377\u79ef\u7f51\u7edc\u76f8\u7ed3\u5408\u3002\u6269\u6563\u6a21\u578b\u80fd\u591f\u4ece\u6709\u9650\u7684\u8bad\u7ec3\u6570\u636e\u4e2d\u5408\u6210\u903c\u771f\u7684\u7eb5\u5411\u795e\u7ecf\u5f71\u50cf\u8f68\u8ff9\uff0c\u4ece\u800c\u4e30\u5bcc\u65f6\u95f4\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u63d0\u5347\u5bf9\u8bbf\u89c6\u65f6\u95f4\u4e0d\u5747\u5300\u5206\u5e03\u7684\u9c81\u68d2\u6027\u3002\u968f\u540e\uff0c\u6ce8\u610f\u529b\u5377\u79ef\u5c42\u53ef\u6355\u6349\u5177\u6709\u5224\u522b\u6027\u7684\u7ed3\u6784-\u65f6\u95f4\u6a21\u5f0f\uff0c\u4ee5\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\u4e2a\u4f53\u4e0e\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\u53ca\u4e3b\u89c2\u8ba4\u77e5\u4e0b\u964d\u60a3\u8005\u3002\u5728\u5408\u6210\u6570\u636e\u96c6\u548cADNI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDiGAN\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u5728\u65e9\u671fAD\u68c0\u6d4b\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.03882", "pdf": "https://arxiv.org/pdf/2602.03882", "abs": "https://arxiv.org/abs/2602.03882", "authors": ["Haijiang Yan", "Nick Chater", "Adam Sanborn"], "title": "PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Incorporating individual-level cognitive priors offers an important route to personalizing neural networks, yet accurately eliciting such priors remains challenging: existing methods either fail to uniquely identify them or introduce systematic biases. Here, we introduce PriorProbe, a novel elicitation approach grounded in Markov Chain Monte Carlo with People that recovers fine-grained, individual-specific priors. Focusing on a facial expression recognition task, we apply PriorProbe to individual participants and test whether integrating the recovered priors with a state-of-the-art neural network improves its ability to predict an individual's classification on ambiguous stimuli. The PriorProbe-derived priors yield substantial performance gains, outperforming both the neural network alone and alternative sources of priors, while preserving the network's inference on ground-truth labels. Together, these results demonstrate that PriorProbe provides a general and interpretable framework for personalizing deep neural networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPriorProbe\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u4e2a\u4f53\u8ba4\u77e5\u5148\u9a8c\u6765\u4e2a\u6027\u5316\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u578b\u5bf9\u6a21\u7cca\u523a\u6fc0\u7684\u4e2a\u4f53\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u83b7\u53d6\u4e2a\u4f53\u8ba4\u77e5\u5148\u9a8c\u65f6\u5b58\u5728\u65e0\u6cd5\u552f\u4e00\u8bc6\u522b\u6216\u5f15\u5165\u7cfb\u7edf\u504f\u5dee\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u795e\u7ecf\u7f51\u7edc\u4e2a\u6027\u5316\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51faPriorProbe\u65b9\u6cd5\uff0c\u57fa\u4e8e\u201c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u201d\uff08MCMCP\uff09\u6280\u672f\uff0c\u4ece\u4e2a\u4f53\u53c2\u4e0e\u8005\u4e2d\u6062\u590d\u7ec6\u7c92\u5ea6\u3001\u4e2a\u4f53\u7279\u5f02\u7684\u8ba4\u77e5\u5148\u9a8c\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u524d\u6cbf\u795e\u7ecf\u7f51\u7edc\u4e2d\u3002", "result": "\u5728\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4efb\u52a1\u4e2d\uff0c\u6574\u5408PriorProbe\u83b7\u5f97\u7684\u5148\u9a8c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u4e2a\u4f53\u5728\u6a21\u7cca\u523a\u6fc0\u4e0b\u5206\u7c7b\u884c\u4e3a\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6216\u5176\u4ed6\u5148\u9a8c\u6765\u6e90\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u771f\u5b9e\u6807\u7b7e\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "PriorProbe\u4e3a\u4e2a\u6027\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002", "summary_cn": "\u878d\u5165\u4e2a\u4f53\u5c42\u9762\u7684\u8ba4\u77e5\u5148\u9a8c\u662f\u5b9e\u73b0\u795e\u7ecf\u7f51\u7edc\u4e2a\u6027\u5316\u7684\u91cd\u8981\u9014\u5f84\uff0c\u7136\u800c\u51c6\u786e\u83b7\u53d6\u6b64\u7c7b\u5148\u9a8c\u4ecd\u5177\u6311\u6218\u6027\uff1a\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u552f\u4e00\u8bc6\u522b\u8fd9\u4e9b\u5148\u9a8c\uff0c\u8981\u4e48\u4f1a\u5f15\u5165\u7cfb\u7edf\u6027\u504f\u5dee\u3002\u672c\u6587\u63d0\u51faPriorProbe\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u201c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u201d\uff08Markov Chain Monte Carlo with People\uff09\u7684\u65b0\u9896\u5148\u9a8c\u83b7\u53d6\u65b9\u6cd5\uff0c\u80fd\u591f\u6062\u590d\u7ec6\u7c92\u5ea6\u3001\u4e2a\u4f53\u7279\u5f02\u7684\u8ba4\u77e5\u5148\u9a8c\u3002\u6211\u4eec\u805a\u7126\u4e8e\u9762\u90e8\u8868\u60c5\u8bc6\u522b\u4efb\u52a1\uff0c\u5c06PriorProbe\u5e94\u7528\u4e8e\u4e2a\u4f53\u53c2\u4e0e\u8005\uff0c\u5e76\u68c0\u9a8c\u5c06\u6240\u6062\u590d\u7684\u5148\u9a8c\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u7f51\u7edc\u76f8\u7ed3\u5408\u662f\u5426\u80fd\u63d0\u5347\u6a21\u578b\u5bf9\u4e2a\u4f53\u5728\u6a21\u7cca\u523a\u6fc0\u4e0b\u5206\u7c7b\u884c\u4e3a\u7684\u9884\u6d4b\u80fd\u529b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7531PriorProbe\u5bfc\u51fa\u7684\u5148\u9a8c\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e0d\u4ec5\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\uff0c\u4e5f\u4f18\u4e8e\u5176\u4ed6\u5148\u9a8c\u6765\u6e90\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u7f51\u7edc\u5bf9\u771f\u5b9e\u6807\u7b7e\u7684\u63a8\u7406\u80fd\u529b\u3002\u7efc\u4e0a\u6240\u8ff0\uff0c\u672c\u7814\u7a76\u8bc1\u660ePriorProbe\u4e3a\u4e2a\u6027\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\u3002"}}
{"id": "2602.03883", "pdf": "https://arxiv.org/pdf/2602.03883", "abs": "https://arxiv.org/abs/2602.03883", "authors": ["Akshansh Mishra", "Rakesh Morisetty"], "title": "Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing", "categories": ["cs.CV", "cs.AI", "cs.CE", "cs.LG"], "comment": "6 figures", "summary": "Internal porosity remains a critical defect mode in additively manufactured components, compromising structural performance and limiting industrial adoption. Automated defect detection methods exist but lack interpretability, preventing engineers from understanding the physical basis of criticality predictions. This study presents an explainable computer vision framework for pore detection and criticality assessment in three-dimensional tomographic volumes. Sequential grayscale slices were reconstructed into volumetric datasets, and intensity-based thresholding with connected component analysis identified 500 individual pores. Each pore was characterized using geometric descriptors including size, aspect ratio, extent, and spatial position relative to the specimen boundary. A pore interaction network was constructed using percentile-based Euclidean distance criteria, yielding 24,950 inter-pore connections. Machine learning models predicted pore criticality scores from extracted features, and SHAP analysis quantified individual feature contributions. Results demonstrate that normalized surface distance dominates model predictions, contributing more than an order of magnitude greater importance than all other descriptors. Pore size provides minimal influence, while geometric parameters show negligible impact. The strong inverse relationship between surface proximity and criticality reveals boundary-driven failure mechanisms. This interpretable framework enables transparent defect assessment and provides actionable insights for process optimization and quality control in additive manufacturing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u589e\u6750\u5236\u9020\u90e8\u4ef6\u7684\u4e09\u7ef4\u65ad\u5c42\u56fe\u50cf\u4e2d\u68c0\u6d4b\u5b54\u9699\u5e76\u8bc4\u4f30\u5176\u4e34\u754c\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5b54\u9699\u8ddd\u8868\u9762\u7684\u5f52\u4e00\u5316\u8ddd\u79bb\u662f\u9884\u6d4b\u4e34\u754c\u6027\u7684\u4e3b\u5bfc\u56e0\u7d20\uff0c\u8fdc\u8d85\u5176\u4ed6\u51e0\u4f55\u7279\u5f81\u7684\u5f71\u54cd\u3002", "motivation": "\u589e\u6750\u5236\u9020\u90e8\u4ef6\u4e2d\u7684\u5185\u90e8\u5b54\u9699\u4f1a\u663e\u8457\u964d\u4f4e\u7ed3\u6784\u6027\u80fd\u5e76\u963b\u788d\u5de5\u4e1a\u5e94\u7528\uff1b\u73b0\u6709\u81ea\u52a8\u7f3a\u9677\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5de5\u7a0b\u5e08\u96be\u4ee5\u7406\u89e3\u4e34\u754c\u6027\u9884\u6d4b\u7684\u7269\u7406\u4f9d\u636e\u3002", "method": "\u5c06\u7070\u5ea6\u5207\u7247\u91cd\u5efa\u4e3a\u4e09\u7ef4\u4f53\u6570\u636e\uff0c\u901a\u8fc7\u5f3a\u5ea6\u9608\u503c\u548c\u8fde\u901a\u6210\u5206\u5206\u6790\u8bc6\u522b\u51fa500\u4e2a\u72ec\u7acb\u5b54\u9699\uff1b\u5229\u7528\u51e0\u4f55\u63cf\u8ff0\u7b26\uff08\u5c3a\u5bf8\u3001\u957f\u5bbd\u6bd4\u3001\u8303\u56f4\u3001\u8ddd\u8fb9\u754c\u4f4d\u7f6e\uff09\u8868\u5f81\u6bcf\u4e2a\u5b54\u9699\uff1b\u57fa\u4e8e\u767e\u5206\u4f4d\u6b27\u6c0f\u8ddd\u79bb\u6784\u5efa\u5b54\u9699\u4ea4\u4e92\u7f51\u7edc\uff08\u542b24,950\u6761\u8fde\u63a5\uff09\uff1b\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u5b54\u9699\u4e34\u754c\u6027\uff0c\u5e76\u901a\u8fc7SHAP\u5206\u6790\u91cf\u5316\u5404\u7279\u5f81\u8d21\u732e\u3002", "result": "\u5f52\u4e00\u5316\u8868\u9762\u8ddd\u79bb\u5bf9\u6a21\u578b\u9884\u6d4b\u8d77\u51b3\u5b9a\u6027\u4f5c\u7528\uff0c\u5176\u91cd\u8981\u6027\u6bd4\u5176\u4ed6\u6240\u6709\u63cf\u8ff0\u7b26\u9ad8\u51fa\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff1b\u5b54\u9699\u5c3a\u5bf8\u5f71\u54cd\u5fae\u5f31\uff0c\u51e0\u4f55\u53c2\u6570\u51e0\u4e4e\u65e0\u5f71\u54cd\uff1b\u8868\u9762\u90bb\u8fd1\u6027\u4e0e\u4e34\u754c\u6027\u5448\u5f3a\u8d1f\u76f8\u5173\uff0c\u63ed\u793a\u4e86\u8fb9\u754c\u9a71\u52a8\u7684\u5931\u6548\u673a\u5236\u3002", "conclusion": "\u8be5\u53ef\u89e3\u91ca\u6846\u67b6\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u7f3a\u9677\u8bc4\u4f30\uff0c\u4e3a\u589e\u6750\u5236\u9020\u4e2d\u7684\u5de5\u827a\u4f18\u5316\u548c\u8d28\u91cf\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "summary_cn": "\u5185\u90e8\u5b54\u9699\u4ecd\u662f\u589e\u6750\u5236\u9020\u90e8\u4ef6\u4e2d\u7684\u5173\u952e\u7f3a\u9677\u6a21\u5f0f\uff0c\u4f1a\u635f\u5bb3\u7ed3\u6784\u6027\u80fd\u5e76\u9650\u5236\u5176\u5de5\u4e1a\u5e94\u7528\u3002\u5c3d\u7ba1\u5df2\u6709\u81ea\u52a8\u5316\u7f3a\u9677\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5de5\u7a0b\u5e08\u65e0\u6cd5\u7406\u89e3\u4e34\u754c\u6027\u9884\u6d4b\u7684\u7269\u7406\u57fa\u7840\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e09\u7ef4\u65ad\u5c42\u626b\u63cf\u4f53\u79ef\u4e2d\u8fdb\u884c\u5b54\u9699\u68c0\u6d4b\u4e0e\u4e34\u754c\u6027\u8bc4\u4f30\u3002\u9996\u5148\u5c06\u8fde\u7eed\u7684\u7070\u5ea6\u5207\u7247\u91cd\u5efa\u4e3a\u4f53\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u5f3a\u5ea6\u7684\u9608\u503c\u5206\u5272\u7ed3\u5408\u8fde\u901a\u6210\u5206\u5206\u6790\u8bc6\u522b\u51fa500\u4e2a\u72ec\u7acb\u5b54\u9699\u3002\u6bcf\u4e2a\u5b54\u9699\u5747\u91c7\u7528\u51e0\u4f55\u63cf\u8ff0\u7b26\u8fdb\u884c\u8868\u5f81\uff0c\u5305\u62ec\u5c3a\u5bf8\u3001\u957f\u5bbd\u6bd4\u3001\u8303\u56f4\u4ee5\u53ca\u76f8\u5bf9\u4e8e\u8bd5\u6837\u8fb9\u754c\u7684\u51e0\u4f55\u4f4d\u7f6e\u3002\u968f\u540e\uff0c\u57fa\u4e8e\u767e\u5206\u4f4d\u6570\u7684\u6b27\u6c0f\u8ddd\u79bb\u51c6\u5219\u6784\u5efa\u4e86\u5b54\u9699\u4ea4\u4e92\u7f51\u7edc\uff0c\u5171\u83b7\u5f9724,950\u6761\u5b54\u9699\u95f4\u8fde\u63a5\u3002\u5229\u7528\u63d0\u53d6\u7684\u7279\u5f81\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ee5\u9884\u6d4b\u5b54\u9699\u4e34\u754c\u6027\u5f97\u5206\uff0c\u5e76\u901a\u8fc7SHAP\u5206\u6790\u91cf\u5316\u5404\u7279\u5f81\u7684\u8d21\u732e\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5f52\u4e00\u5316\u8868\u9762\u8ddd\u79bb\u5728\u6a21\u578b\u9884\u6d4b\u4e2d\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5176\u91cd\u8981\u6027\u6bd4\u6240\u6709\u5176\u4ed6\u63cf\u8ff0\u7b26\u9ad8\u51fa\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff1b\u5b54\u9699\u5c3a\u5bf8\u7684\u5f71\u54cd\u6781\u5c0f\uff0c\u800c\u5176\u4ed6\u51e0\u4f55\u53c2\u6570\u7684\u5f71\u54cd\u5219\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002\u8868\u9762\u90bb\u8fd1\u6027\u4e0e\u4e34\u754c\u6027\u4e4b\u95f4\u5b58\u5728\u5f3a\u70c8\u7684\u8d1f\u76f8\u5173\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u7531\u8fb9\u754c\u9a71\u52a8\u7684\u5931\u6548\u673a\u5236\u3002\u8be5\u53ef\u89e3\u91ca\u6846\u67b6\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u7f3a\u9677\u8bc4\u4f30\uff0c\u5e76\u4e3a\u589e\u6750\u5236\u9020\u4e2d\u7684\u5de5\u827a\u4f18\u5316\u4e0e\u8d28\u91cf\u63a7\u5236\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6d1e\u89c1\u3002"}}
{"id": "2602.03890", "pdf": "https://arxiv.org/pdf/2602.03890", "abs": "https://arxiv.org/abs/2602.03890", "authors": ["Xindan Zhang", "Weilong Yan", "Yufei Shi", "Xuerui Qiu", "Tao He", "Ying Li", "Ming Li", "Hehe Fan"], "title": "4DPC$^2$hat: Towards Dynamic Point Cloud Understanding with Failure-Aware Bootstrapping", "categories": ["cs.CV"], "comment": null, "summary": "Point clouds provide a compact and expressive representation of 3D objects, and have recently been integrated into multimodal large language models (MLLMs). However, existing methods primarily focus on static objects, while understanding dynamic point cloud sequences remains largely unexplored. This limitation is mainly caused by the lack of large-scale cross-modal datasets and the difficulty of modeling motions in spatio-temporal contexts. To bridge this gap, we present 4DPC$^2$hat, the first MLLM tailored for dynamic point cloud understanding. To this end, we construct a large-scale cross-modal dataset 4DPC$^2$hat-200K via a meticulous two-stage pipeline consisting of topology-consistent 4D point construction and two-level captioning. The dataset contains over 44K dynamic object sequences, 700K point cloud frames, and 200K curated question-answer (QA) pairs, supporting inquiries about counting, temporal relationship, action, spatial relationship, and appearance. At the core of the framework, we introduce a Mamba-enhanced temporal reasoning MLLM to capture long-range dependencies and dynamic patterns among a point cloud sequence. Furthermore, we propose a failure-aware bootstrapping learning strategy that iteratively identifies model deficiencies and generates targeted QA supervision to continuously strengthen corresponding reasoning capabilities. Extensive experiments demonstrate that our 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e864DPC\u00b2hat\uff0c\u9996\u4e2a\u4e13\u4e3a\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u8bbe\u8ba1\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b44K\u52a8\u6001\u7269\u4f53\u5e8f\u5217\u548c200K\u95ee\u7b54\u5bf9\u7684\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c64DPC\u00b2hat-200K\u3002\u901a\u8fc7Mamba\u589e\u5f3a\u7684\u65f6\u95f4\u63a8\u7406\u67b6\u6784\u4e0e\u5931\u8d25\u611f\u77e5\u7684\u81ea\u4e3e\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u4f5c\u7406\u89e3\u548c\u65f6\u5e8f\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u70b9\u4e91\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u70b9\u4e91\u5e8f\u5217\u7684\u7406\u89e3\u80fd\u529b\uff0c\u539f\u56e0\u5728\u4e8e\u7f3a\u5c11\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c6\u4ee5\u53ca\u96be\u4ee5\u5728\u65f6\u7a7a\u4e0a\u4e0b\u6587\u4e2d\u5efa\u6a21\u8fd0\u52a8\u4fe1\u606f\u3002", "method": "\u6784\u5efa\u4e24\u9636\u6bb5\u6d41\u7a0b\u751f\u6210\u5927\u89c4\u6a21\u6570\u636e\u96c64DPC\u00b2hat-200K\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eMamba\u7684\u65f6\u95f4\u63a8\u7406MLLM\u67b6\u6784\uff1b\u540c\u65f6\u91c7\u7528\u5931\u8d25\u611f\u77e5\u7684\u81ea\u4e3e\u5b66\u4e60\u7b56\u7565\uff0c\u8fed\u4ee3\u8bc6\u522b\u6a21\u578b\u5f31\u70b9\u5e76\u751f\u6210\u9488\u5bf9\u6027\u95ee\u7b54\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c4DPC\u00b2hat\u5728\u52a8\u4f5c\u7406\u89e3\u548c\u65f6\u5e8f\u63a8\u7406\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5728\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u4efb\u52a1\u4e0a\u5efa\u7acb\u4e86\u5f3a\u5927\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u9886\u57df\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u67654D\u573a\u666f\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u8d44\u6e90\u3001\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u8303\u5f0f\u3002", "summary_cn": "\u70b9\u4e91\u4e3a\u4e09\u7ef4\u7269\u4f53\u63d0\u4f9b\u4e86\u4e00\u79cd\u7d27\u51d1\u800c\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5e76\u5df2\u88ab\u8fd1\u671f\u6574\u5408\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e2d\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u805a\u7126\u4e8e\u9759\u6001\u7269\u4f53\uff0c\u5bf9\u52a8\u6001\u70b9\u4e91\u5e8f\u5217\u7684\u7406\u89e3\u4ecd\u9c9c\u6709\u63a2\u7d22\u3002\u8fd9\u4e00\u5c40\u9650\u6027\u4e3b\u8981\u6e90\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u5728\u65f6\u7a7a\u4e0a\u4e0b\u6587\u4e2d\u5efa\u6a21\u8fd0\u52a8\u7684\u56f0\u96be\u3002\u4e3a\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6211\u4eec\u63d0\u51fa\u4e864DPC\u00b2hat\u2014\u2014\u9996\u4e2a\u4e13\u4e3a\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u5b9a\u5236\u7684MLLM\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u7cbe\u7ec6\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u8de8\u6a21\u6001\u6570\u636e\u96c64DPC\u00b2hat-200K\uff0c\u8be5\u6d41\u7a0b\u5305\u62ec\u62d3\u6251\u4e00\u81f4\u76844D\u70b9\u4e91\u6784\u5efa\u548c\u4e24\u7ea7\u63cf\u8ff0\u751f\u6210\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b\u8d85\u8fc744K\u4e2a\u52a8\u6001\u7269\u4f53\u5e8f\u5217\u300170\u4e07\u5e27\u70b9\u4e91\u4ee5\u53ca20\u4e07\u6761\u7cbe\u5fc3\u6574\u7406\u7684\u95ee\u9898-\u7b54\u6848\uff08QA\uff09\u5bf9\uff0c\u652f\u6301\u5173\u4e8e\u8ba1\u6570\u3001\u65f6\u5e8f\u5173\u7cfb\u3001\u52a8\u4f5c\u3001\u7a7a\u95f4\u5173\u7cfb\u548c\u5916\u89c2\u7b49\u65b9\u9762\u7684\u67e5\u8be2\u3002\u5728\u6846\u67b6\u6838\u5fc3\u90e8\u5206\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cdMamba\u589e\u5f3a\u7684\u65f6\u95f4\u63a8\u7406MLLM\uff0c\u4ee5\u6355\u6349\u70b9\u4e91\u5e8f\u5217\u4e2d\u7684\u957f\u7a0b\u4f9d\u8d56\u548c\u52a8\u6001\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5931\u8d25\u611f\u77e5\u7684\u81ea\u4e3e\u5b66\u4e60\u7b56\u7565\uff0c\u53ef\u8fed\u4ee3\u8bc6\u522b\u6a21\u578b\u7f3a\u9677\u5e76\u751f\u6210\u6709\u9488\u5bf9\u6027\u7684QA\u76d1\u7763\u4fe1\u53f7\uff0c\u6301\u7eed\u5f3a\u5316\u76f8\u5e94\u7684\u63a8\u7406\u80fd\u529b\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u76844DPC\u00b2hat\u5728\u52a8\u4f5c\u7406\u89e3\u548c\u65f6\u5e8f\u63a8\u7406\u65b9\u9762\u76f8\u6bd4\u73b0\u6709\u6a21\u578b\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a4D\u52a8\u6001\u70b9\u4e91\u7406\u89e3\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.03892", "pdf": "https://arxiv.org/pdf/2602.03892", "abs": "https://arxiv.org/abs/2602.03892", "authors": ["Jinxing Zhou", "Yanghao Zhou", "Yaoting Wang", "Zongyan Han", "Jiaqi Ma", "Henghui Ding", "Rao Muhammad Anwer", "Hisham Cholakkal"], "title": "Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM", "cs.SD", "eess.AS"], "comment": null, "summary": "Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this work, we introduce Mask Quality Assessment in the Ref-AVS context (MQA-RefAVS), a new task that evaluates the quality of candidate segmentation masks without relying on ground-truth annotations as references at inference time. Given audio-visual-language inputs and each provided segmentation mask, the task requires estimating its IoU with the unobserved ground truth, identifying the corresponding error type, and recommending an actionable quality-control decision. To support this task, we construct MQ-RAVSBench, a benchmark featuring diverse and representative mask error modes that span both geometric and semantic issues. We further propose MQ-Auditor, a multimodal large language model (MLLM)-based auditor that explicitly reasons over multimodal cues and mask information to produce quantitative and qualitative mask quality assessments. Extensive experiments demonstrate that MQ-Auditor outperforms strong open-source and commercial MLLMs and can be integrated with existing Ref-AVS systems to detect segmentation failures and support downstream segmentation improvement. Data and codes will be released at https://github.com/jasongief/MQA-RefAVS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMQA-RefAVS\u4efb\u52a1\uff0c\u7528\u4e8e\u5728\u65e0\u771f\u5b9e\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u8bed\u8a00\u5f15\u5bfc\u97f3\u89c6\u9891\u5206\u5272\uff08Ref-AVS\uff09\u4e2d\u5019\u9009\u5206\u5272\u63a9\u7801\u7684\u8d28\u91cf\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b\u591a\u79cd\u9519\u8bef\u6a21\u5f0f\u7684\u57fa\u51c6MQ-RAVSBench\u53ca\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u5668MQ-Auditor\u3002", "motivation": "\u73b0\u6709Ref-AVS\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u751f\u6210\u5206\u5272\u63a9\u7801\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u63a9\u7801\u8d28\u91cf\u8fdb\u884c\u4e30\u5bcc\u4e14\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u5728\u63a8\u7406\u9636\u6bb5\u65e0\u9700\u771f\u5b9e\u6807\u6ce8\u5373\u53ef\u8bc4\u4f30\u63a9\u7801\u8d28\u91cf\u7684\u65b0\u4efb\u52a1\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86MQ-RAVSBench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u51e0\u4f55\u4e0e\u8bed\u4e49\u5c42\u9762\u7684\u591a\u6837\u5316\u63a9\u7801\u9519\u8bef\u7c7b\u578b\uff1b\u5e76\u63d0\u51faMQ-Auditor\u6a21\u578b\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u97f3\u89c6\u9891\u3001\u6587\u672c\u548c\u63a9\u7801\u4fe1\u606f\u8fdb\u884c\u8054\u5408\u63a8\u7406\uff0c\u8f93\u51fa\u5b9a\u91cfIoU\u4f30\u8ba1\u3001\u9519\u8bef\u7c7b\u578b\u8bc6\u522b\u548c\u8d28\u91cf\u63a7\u5236\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMQ-Auditor\u5728\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u5f00\u6e90\u548c\u5546\u4e1a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u80fd\u6709\u6548\u96c6\u6210\u5230\u73b0\u6709Ref-AVS\u7cfb\u7edf\u4e2d\uff0c\u7528\u4e8e\u68c0\u6d4b\u5206\u5272\u5931\u8d25\u5e76\u4fc3\u8fdb\u4e0b\u6e38\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "MQA-RefAVS\u4efb\u52a1\u4e3aRef-AVS\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u8d28\u91cf\u8bc4\u4f30\u673a\u5236\uff0cMQ-Auditor\u5c55\u793a\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u7c7b\u8bca\u65ad\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u9c81\u68d2\u548c\u53ef\u4fe1\u7684\u591a\u6a21\u6001\u5206\u5272\u7cfb\u7edf\u53d1\u5c55\u3002", "summary_cn": "\u8bed\u8a00\u5f15\u5bfc\u7684\u97f3\u89c6\u9891\u5206\u5272\uff08Ref-AVS\uff09\u65e8\u5728\u901a\u8fc7\u8054\u5408\u63a8\u7406\u89c6\u9891\u3001\u97f3\u9891\u548c\u6587\u672c\uff0c\u5206\u5272\u51fa\u81ea\u7136\u8bed\u8a00\u6240\u63cf\u8ff0\u7684\u76ee\u6807\u7269\u4f53\u3002\u9664\u4e86\u751f\u6210\u5206\u5272\u63a9\u7801\u5916\uff0c\u5982\u4f55\u63d0\u4f9b\u4e30\u5bcc\u4e14\u53ef\u89e3\u91ca\u7684\u63a9\u7801\u8d28\u91cf\u8bca\u65ad\u4ecd\u9c9c\u6709\u7814\u7a76\u3002\u672c\u6587\u63d0\u51fa\u4e86Ref-AVS\u573a\u666f\u4e0b\u7684\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u4efb\u52a1\uff08MQA-RefAVS\uff09\uff0c\u8be5\u4efb\u52a1\u5728\u63a8\u7406\u9636\u6bb5\u65e0\u9700\u4f9d\u8d56\u771f\u5b9e\u6807\u6ce8\uff0c\u5373\u53ef\u8bc4\u4f30\u5019\u9009\u5206\u5272\u63a9\u7801\u7684\u8d28\u91cf\u3002\u7ed9\u5b9a\u97f3\u89c6\u9891-\u8bed\u8a00\u8f93\u5165\u53ca\u6bcf\u4e2a\u63d0\u4f9b\u7684\u5206\u5272\u63a9\u7801\uff0c\u8be5\u4efb\u52a1\u8981\u6c42\u4f30\u8ba1\u5176\u4e0e\u672a\u77e5\u771f\u5b9e\u6807\u6ce8\u7684IoU\u3001\u8bc6\u522b\u5bf9\u5e94\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u5e76\u7ed9\u51fa\u53ef\u64cd\u4f5c\u7684\u8d28\u91cf\u63a7\u5236\u51b3\u7b56\u3002\u4e3a\u652f\u6301\u8be5\u4efb\u52a1\uff0c\u6211\u4eec\u6784\u5efa\u4e86MQ-RAVSBench\u57fa\u51c6\uff0c\u5176\u4e2d\u5305\u542b\u6db5\u76d6\u51e0\u4f55\u4e0e\u8bed\u4e49\u95ee\u9898\u7684\u591a\u6837\u5316\u4e14\u5177\u4ee3\u8868\u6027\u7684\u63a9\u7801\u9519\u8bef\u6a21\u5f0f\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86MQ-Auditor\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7684\u8bc4\u4f30\u5668\uff0c\u80fd\u591f\u663e\u5f0f\u5730\u5bf9\u591a\u6a21\u6001\u7ebf\u7d22\u548c\u63a9\u7801\u4fe1\u606f\u8fdb\u884c\u63a8\u7406\uff0c\u4ece\u800c\u751f\u6210\u5b9a\u91cf\u4e0e\u5b9a\u6027\u7684\u63a9\u7801\u8d28\u91cf\u8bc4\u4f30\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMQ-Auditor\u4f18\u4e8e\u5f3a\u5927\u7684\u5f00\u6e90\u548c\u5546\u4e1aMLLM\uff0c\u5e76\u53ef\u4e0e\u73b0\u6709Ref-AVS\u7cfb\u7edf\u96c6\u6210\uff0c\u4ee5\u68c0\u6d4b\u5206\u5272\u5931\u8d25\u5e76\u652f\u6301\u4e0b\u6e38\u5206\u5272\u6027\u80fd\u7684\u63d0\u5347\u3002\u6570\u636e\u548c\u4ee3\u7801\u5c06\u53d1\u5e03\u4e8e https://github.com/jasongief/MQA-RefAVS\u3002"}}
{"id": "2602.03893", "pdf": "https://arxiv.org/pdf/2602.03893", "abs": "https://arxiv.org/abs/2602.03893", "authors": ["Yibing Wang", "Shuang Li", "Tingting Huang", "Yu Zhang", "Chulhong Kim", "Seongwook Choi", "Changhui Li"], "title": "GPAIR: Gaussian-Kernel-Based Ultrafast 3D Photoacoustic Iterative Reconstruction", "categories": ["cs.CV"], "comment": null, "summary": "Although the iterative reconstruction (IR) algorithm can substantially correct reconstruction artifacts in photoacoustic (PA) computed tomography (PACT), it suffers from long reconstruction times, especially for large-scale three-dimensional (3D) imaging in which IR takes hundreds of seconds to hours. The computing burden severely limits the practical applicability of IR algorithms. In this work, we proposed an ultrafast IR method for 3D PACT, called Gaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction (GPAIR), which achieves orders-of-magnitude acceleration in computing. GPAIR transforms traditional spatial grids with continuous isotropic Gaussian kernels. By deriving analytical closed-form expression for pressure waves and implementing powerful GPU-accelerated differentiable Triton operators, GPAIR demonstrates extraordinary ultrafast sub-second reconstruction speed for 3D targets containing 8.4 million voxels in animal experiments. This revolutionary ultrafast image reconstruction enables near-real-time large-scale 3D PA reconstruction, significantly advancing 3D PACT toward clinical applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGPAIR\u7684\u8d85\u5feb\u901f\u8fed\u4ee3\u91cd\u5efa\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e09\u7ef4\u5149\u58f0\u8ba1\u7b97\u673a\u65ad\u5c42\u6210\u50cf\uff08PACT\uff09\uff0c\u901a\u8fc7\u4f7f\u7528\u9ad8\u65af\u6838\u548cGPU\u52a0\u901f\uff0c\u5728\u4e9a\u79d2\u7ea7\u65f6\u95f4\u5185\u5b8c\u6210\u5305\u542b840\u4e07\u4f53\u7d20\u76843D\u56fe\u50cf\u91cd\u5efa\uff0c\u6781\u5927\u63d0\u5347\u4e86\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u8fed\u4ee3\u91cd\u5efa\uff08IR\uff09\u7b97\u6cd5\u867d\u80fd\u6709\u6548\u6821\u6b63\u5149\u58f0\u6210\u50cf\u4e2d\u7684\u4f2a\u5f71\uff0c\u4f46\u8ba1\u7b97\u8017\u65f6\u6781\u957f\uff08\u6570\u767e\u79d2\u81f3\u6570\u5c0f\u65f6\uff09\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u4e09\u7ef4\u6210\u50cf\u4e2d\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faGaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction\uff08GPAIR\uff09\u65b9\u6cd5\uff0c\u5c06\u4f20\u7edf\u7a7a\u95f4\u7f51\u683c\u66ff\u6362\u4e3a\u8fde\u7eed\u5404\u5411\u540c\u6027\u9ad8\u65af\u6838\uff0c\u5e76\u63a8\u5bfc\u51fa\u58f0\u538b\u6ce2\u7684\u89e3\u6790\u95ed\u5f0f\u8868\u8fbe\uff0c\u7ed3\u5408GPU\u52a0\u901f\u7684\u53ef\u5faeTriton\u7b97\u5b50\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u5728\u52a8\u7269\u5b9e\u9a8c\u4e2d\uff0cGPAIR\u5bf9\u542b840\u4e07\u4f53\u7d20\u76843D\u76ee\u6807\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u91cd\u5efa\u901f\u5ea6\uff0c\u6bd4\u4f20\u7edfIR\u65b9\u6cd5\u5feb\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u8d85\u5feb\u901f\u91cd\u5efa\u65b9\u6cd5\u4f7f\u5927\u89c4\u6a213D\u5149\u58f0\u6210\u50cf\u63a5\u8fd1\u5b9e\u65f6\uff0c\u663e\u8457\u63a8\u52a8\u4e863D PACT\u5411\u4e34\u5e8a\u5e94\u7528\u7684\u8f6c\u5316\u3002", "summary_cn": "\u5c3d\u7ba1\u8fed\u4ee3\u91cd\u5efa\uff08IR\uff09\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u6821\u6b63\u5149\u58f0\uff08PA\uff09\u8ba1\u7b97\u673a\u65ad\u5c42\u6210\u50cf\uff08PACT\uff09\u4e2d\u7684\u91cd\u5efa\u4f2a\u5f71\uff0c\u4f46\u5176\u91cd\u5efa\u65f6\u95f4\u8fc7\u957f\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u4e09\u7ef4\uff083D\uff09\u6210\u50cf\u4e2d\uff0cIR\u7b97\u6cd5\u9700\u8981\u6570\u767e\u79d2\u751a\u81f3\u6570\u5c0f\u65f6\uff0c\u8ba1\u7b97\u8d1f\u62c5\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e3D PACT\u7684\u8d85\u5feb\u901fIR\u65b9\u6cd5\uff0c\u79f0\u4e3a\u57fa\u4e8e\u9ad8\u65af\u6838\u7684\u8d85\u5feb\u901f\u4e09\u7ef4\u5149\u58f0\u8fed\u4ee3\u91cd\u5efa\uff08GPAIR\uff09\uff0c\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7ea7\u522b\u7684\u8ba1\u7b97\u52a0\u901f\u3002GPAIR\u5229\u7528\u8fde\u7eed\u5404\u5411\u540c\u6027\u7684\u9ad8\u65af\u6838\u66ff\u4ee3\u4f20\u7edf\u7684\u7a7a\u95f4\u7f51\u683c\uff0c\u5e76\u63a8\u5bfc\u51fa\u58f0\u538b\u6ce2\u7684\u89e3\u6790\u95ed\u5f0f\u8868\u8fbe\uff0c\u540c\u65f6\u91c7\u7528\u5f3a\u5927\u7684GPU\u52a0\u901f\u53ef\u5faeTriton\u7b97\u5b50\u3002\u5728\u52a8\u7269\u5b9e\u9a8c\u4e2d\uff0cGPAIR\u5bf9\u5305\u542b840\u4e07\u4f53\u7d20\u76843D\u76ee\u6807\u5b9e\u73b0\u4e86\u4e9a\u79d2\u7ea7\u7684\u8d85\u5feb\u91cd\u5efa\u901f\u5ea6\u3002\u8fd9\u4e00\u9769\u547d\u6027\u7684\u8d85\u5feb\u901f\u56fe\u50cf\u91cd\u5efa\u6280\u672f\u4f7f\u5f97\u5927\u89c4\u6a213D\u5149\u58f0\u91cd\u5efa\u63a5\u8fd1\u5b9e\u65f6\uff0c\u663e\u8457\u63a8\u52a8\u4e863D PACT\u5411\u4e34\u5e8a\u5e94\u7528\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.03894", "pdf": "https://arxiv.org/pdf/2602.03894", "abs": "https://arxiv.org/abs/2602.03894", "authors": ["Hugo Markoff", "Stefan Hein Bengtson", "Michael \u00d8rsted"], "title": "Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images directly to species-level clusters. We present a comprehensive benchmarking framework evaluating five ViT models combined with five dimensionality reduction techniques and four clustering algorithms, two supervised and two unsupervised, across 60 species (30 mammals and 30 birds), with each test using a random subset of 200 validated images per species. We investigate when clustering succeeds at species-level, where it fails, and whether clustering within the species-level reveals ecologically meaningful patterns such as sex, age, or phenotypic variation. Our results demonstrate near-perfect species-level clustering (V-measure: 0.958) using DINOv3 embeddings with t-SNE and supervised hierarchical clustering methods. Unsupervised approaches achieve competitive performance (0.943) while requiring no prior species knowledge, rejecting only 1.14% of images as outliers requiring expert review. We further demonstrate robustness to realistic long-tailed distributions of species and show that intentional over-clustering can reliably extract intra-specific variation including age classes, sexual dimorphism, and pelage differences. We introduce an open-source benchmarking toolkit and provide recommendations for ecologists to select appropriate methods for sorting their specific taxonomic groups and data.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u57fa\u4e8eVision Transformer\uff08ViT\uff09\u7684\u65e0\u76d1\u7763/\u534a\u76d1\u7763\u65b9\u6cd5\u5728\u52a8\u7269\u56fe\u50cf\u7269\u79cd\u7ea7\u805a\u7c7b\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0DINOv3\u7ed3\u5408t-SNE\u548c\u5c42\u6b21\u805a\u7c7b\u53ef\u5b9e\u73b0\u63a5\u8fd1\u5b8c\u7f8e\u7684\u7269\u79cd\u5206\u79bb\uff0c\u5e76\u80fd\u8fdb\u4e00\u6b65\u63ed\u793a\u79cd\u5185\u53d8\u5f02\uff08\u5982\u5e74\u9f84\u3001\u6027\u522b\u7b49\uff09\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5f00\u6e90\u5de5\u5177\u5305\u4f9b\u751f\u6001\u5b66\u5bb6\u4f7f\u7528\u3002", "motivation": "\u624b\u52a8\u6807\u6ce8\u52a8\u7269\u56fe\u50cf\u662f\u751f\u6001\u5b66\u7814\u7a76\u4e2d\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u9650\u5236\u4e86\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u7684\u89c4\u6a21\u4e0e\u6548\u7387\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u5c06\u5927\u91cf\u672a\u6807\u6ce8\u56fe\u50cf\u76f4\u63a5\u805a\u7c7b\u5230\u7269\u79cd\u7ea7\u522b\uff0c\u751a\u81f3\u63ed\u793a\u79cd\u5185\u751f\u6001\u7279\u5f81\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u7efc\u5408\u57fa\u51c6\u6846\u67b6\uff0c\u8bc4\u4f305\u79cdViT\u6a21\u578b\u30015\u79cd\u964d\u7ef4\u65b9\u6cd5\u548c4\u79cd\u805a\u7c7b\u7b97\u6cd5\uff082\u79cd\u6709\u76d1\u7763\u30012\u79cd\u65e0\u76d1\u7763\uff09\u572860\u4e2a\u7269\u79cd\uff0830\u79cd\u54fa\u4e73\u52a8\u7269+30\u79cd\u9e1f\u7c7b\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u6bcf\u79cd\u4f7f\u7528200\u5f20\u7ecf\u9a8c\u8bc1\u7684\u56fe\u50cf\u3002\u540c\u65f6\u6d4b\u8bd5\u6a21\u578b\u5728\u957f\u5c3e\u5206\u5e03\u4e0b\u7684\u9c81\u68d2\u6027\u53ca\u8fc7\u805a\u7c7b\u5bf9\u79cd\u5185\u53d8\u5f02\u7684\u63d0\u53d6\u80fd\u529b\u3002", "result": "\u4f7f\u7528DINOv3\u5d4c\u5165\u3001t-SNE\u964d\u7ef4\u548c\u6709\u76d1\u7763\u5c42\u6b21\u805a\u7c7b\u65f6\uff0c\u7269\u79cd\u7ea7\u805a\u7c7bV-measure\u8fbe0.958\uff1b\u65e0\u76d1\u7763\u65b9\u6cd5\u4e5f\u8fbe\u52300.943\uff0c\u4ec51.14%\u56fe\u50cf\u88ab\u8bc6\u522b\u4e3a\u5f02\u5e38\u9700\u4eba\u5de5\u5ba1\u6838\u3002\u8fc7\u805a\u7c7b\u80fd\u6709\u6548\u63ed\u793a\u5e74\u9f84\u3001\u6027\u522b\u548c\u6bdb\u8272\u7b49\u79cd\u5185\u5dee\u5f02\u3002", "conclusion": "ViT\u57fa\u7840\u6a21\u578b\uff08\u5c24\u5176\u662fDINOv3\uff09\u7ed3\u5408\u9002\u5f53\u805a\u7c7b\u6d41\u7a0b\u53ef\u9ad8\u6548\u5b9e\u73b0\u7269\u79cd\u7ea7\u81ea\u52a8\u805a\u7c7b\uff0c\u5e76\u6316\u6398\u751f\u6001\u4e0a\u6709\u610f\u4e49\u7684\u79cd\u5185\u53d8\u5f02\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u8d1f\u62c5\u3002\u4f5c\u8005\u5f00\u6e90\u4e86\u76f8\u5173\u5de5\u5177\u5e76\u4e3a\u751f\u6001\u5b66\u5bb6\u63d0\u4f9b\u4e86\u65b9\u6cd5\u9009\u62e9\u5efa\u8bae\u3002", "summary_cn": "\u52a8\u7269\u56fe\u50cf\u7684\u4eba\u5de5\u6807\u6ce8\u4ecd\u662f\u751f\u6001\u5b66\u7814\u7a76\u4e2d\u7684\u91cd\u5927\u74f6\u9888\uff0c\u9650\u5236\u4e86\u751f\u7269\u591a\u6837\u6027\u76d1\u6d4b\u5de5\u4f5c\u7684\u89c4\u6a21\u4e0e\u6548\u7387\u3002\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u89c6\u89c9Transformer\uff08ViT\uff09\u57fa\u7840\u6a21\u578b\u662f\u5426\u80fd\u591f\u76f4\u63a5\u5c06\u6570\u5343\u5f20\u672a\u6807\u6ce8\u7684\u52a8\u7269\u56fe\u50cf\u805a\u7c7b\u81f3\u7269\u79cd\u7ea7\u522b\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cdViT\u6a21\u578b\u7ed3\u5408\u4e94\u79cd\u964d\u7ef4\u6280\u672f\u548c\u56db\u79cd\u805a\u7c7b\u7b97\u6cd5\uff08\u4e24\u79cd\u6709\u76d1\u7763\u3001\u4e24\u79cd\u65e0\u76d1\u7763\uff09\u572860\u4e2a\u7269\u79cd\uff0830\u79cd\u54fa\u4e73\u52a8\u7269\u548c30\u79cd\u9e1f\u7c7b\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u6bcf\u4e2a\u6d4b\u8bd5\u5747\u4f7f\u7528\u6bcf\u7269\u79cd200\u5f20\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u56fe\u50cf\u7684\u968f\u673a\u5b50\u96c6\u3002\u6211\u4eec\u7814\u7a76\u4e86\u805a\u7c7b\u5728\u4f55\u65f6\u80fd\u6210\u529f\u5b9e\u73b0\u7269\u79cd\u7ea7\u533a\u5206\u3001\u5728\u4f55\u5904\u5931\u8d25\uff0c\u4ee5\u53ca\u7269\u79cd\u5185\u90e8\u7684\u805a\u7c7b\u662f\u5426\u80fd\u63ed\u793a\u5177\u6709\u751f\u6001\u5b66\u610f\u4e49\u7684\u6a21\u5f0f\uff0c\u4f8b\u5982\u6027\u522b\u3001\u5e74\u9f84\u6216\u8868\u578b\u53d8\u5f02\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528DINOv3\u5d4c\u5165\u7ed3\u5408t-SNE\u548c\u6709\u76d1\u7763\u5c42\u6b21\u805a\u7c7b\u65b9\u6cd5\u53ef\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u7269\u79cd\u7ea7\u805a\u7c7b\uff08V-measure\uff1a0.958\uff09\u3002\u65e0\u76d1\u7763\u65b9\u6cd5\u5728\u65e0\u9700\u5148\u9a8c\u7269\u79cd\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u4e5f\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff080.943\uff09\uff0c\u4ec5\u5c061.14%\u7684\u56fe\u50cf\u4f5c\u4e3a\u5f02\u5e38\u503c\u5254\u9664\uff0c\u9700\u4e13\u5bb6\u590d\u6838\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u8bc1\u660e\u8be5\u65b9\u6cd5\u5bf9\u73b0\u5b9e\u4e2d\u5e38\u89c1\u7684\u7269\u79cd\u957f\u5c3e\u5206\u5e03\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u8868\u660e\u6709\u610f\u8fdb\u884c\u8fc7\u805a\u7c7b\u53ef\u53ef\u9760\u5730\u63d0\u53d6\u79cd\u5185\u53d8\u5f02\uff0c\u5305\u62ec\u5e74\u9f84\u9636\u6bb5\u3001\u4e24\u6027\u5f02\u5f62\u548c\u6bdb\u8272\u5dee\u5f02\u3002\u6211\u4eec\u53d1\u5e03\u4e86\u4e00\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u5305\uff0c\u5e76\u4e3a\u751f\u6001\u5b66\u5bb6\u9488\u5bf9\u5176\u7279\u5b9a\u5206\u7c7b\u7fa4\u548c\u6570\u636e\u9009\u62e9\u5408\u9002\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5efa\u8bae\u3002"}}
{"id": "2602.03895", "pdf": "https://arxiv.org/pdf/2602.03895", "abs": "https://arxiv.org/abs/2602.03895", "authors": ["Xuwei Tan", "Ziyu Hu", "Xueru Zhang"], "title": "Benchmarking Bias Mitigation Toward Fairness Without Harm from Vision to LVLMs", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at ICLR 26", "summary": "Machine learning models trained on real-world data often inherit and amplify biases against certain social groups, raising urgent concerns about their deployment at scale. While numerous bias mitigation methods have been proposed, comparing the effectiveness of bias mitigation methods remains difficult due to heterogeneous datasets, inconsistent fairness metrics, isolated evaluation of vision versus multi-modal models, and insufficient hyperparameter tuning that undermines fair comparisons. We introduce NH-Fair, a unified benchmark for fairness without harm that spans both vision models and large vision-language models (LVLMs) under standardized data, metrics, and training protocols, covering supervised and zero-shot regimes. Our key contributions are: (1) a systematic ERM tuning study that identifies training choices with large influence on both utility and disparities, yielding empirically grounded guidelines to help practitioners reduce expensive hyperparameter tuning space in achieving strong fairness and accuracy; (2) evidence that many debiasing methods do not reliably outperform a well-tuned ERM baseline, whereas a composite data-augmentation method consistently delivers parity gains without sacrificing utility, emerging as a promising practical strategy. (3) an analysis showing that while LVLMs achieve higher average accuracy, they still exhibit subgroup disparities, and gains from scaling are typically smaller than those from architectural or training-protocol choices. NH-Fair provides a reproducible, tuning-aware pipeline for rigorous, harm-aware fairness evaluation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86NH-Fair\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u516c\u5e73\u6027\u57fa\u51c6\uff0c\u7528\u4e8e\u5728\u6807\u51c6\u6570\u636e\u3001\u6307\u6807\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\u8bc4\u4f30\u89c6\u89c9\u6a21\u578b\u548c\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u516c\u5e73\u6027\uff0c\u5f3a\u8c03\u4e86\u826f\u597d\u8c03\u53c2\u7684ERM\u57fa\u7ebf\u7684\u91cd\u8981\u6027\uff0c\u5e76\u53d1\u73b0\u4e00\u79cd\u590d\u5408\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u6548\u7528\u7684\u524d\u63d0\u4e0b\u6709\u6548\u63d0\u5347\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e38\u7ee7\u627f\u5e76\u653e\u5927\u5bf9\u67d0\u4e9b\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u89c1\uff0c\u800c\u73b0\u6709\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\u56e0\u6570\u636e\u96c6\u5f02\u6784\u3001\u516c\u5e73\u6027\u6307\u6807\u4e0d\u4e00\u81f4\u3001\u4ec5\u5355\u72ec\u8bc4\u4f30\u89c6\u89c9\u6216\u591a\u6a21\u6001\u6a21\u578b\u4ee5\u53ca\u8d85\u53c2\u6570\u8c03\u4f18\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u8fdb\u884c\u516c\u5e73\u6709\u6548\u7684\u6bd4\u8f83\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86NH-Fair\u7edf\u4e00\u57fa\u51c6\uff0c\u6db5\u76d6\u76d1\u7763\u548c\u96f6\u6837\u672c\u573a\u666f\uff0c\u5728\u6807\u51c6\u5316\u7684\u6570\u636e\u3001\u6307\u6807\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\u8bc4\u4f30\u89c6\u89c9\u6a21\u578b\u548c\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u3002\u901a\u8fc7\u7cfb\u7edf\u6027\u7684ERM\u8c03\u53c2\u7814\u7a76\uff0c\u8bc6\u522b\u5f71\u54cd\u6548\u7528\u548c\u5dee\u5f02\u7684\u5173\u952e\u8bad\u7ec3\u9009\u62e9\uff0c\u5e76\u8bc4\u4f30\u591a\u79cd\u53bb\u504f\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(1) \u8bad\u7ec3\u9009\u62e9\u5bf9\u6548\u7528\u548c\u5dee\u5f02\u6709\u663e\u8457\u5f71\u54cd\uff0c\u53ef\u636e\u6b64\u7f29\u5c0f\u8d85\u53c2\u6570\u641c\u7d22\u7a7a\u95f4\uff1b(2) \u8bb8\u591a\u53bb\u504f\u65b9\u6cd5\u65e0\u6cd5\u7a33\u5b9a\u8d85\u8d8a\u826f\u597d\u8c03\u53c2\u7684ERM\u57fa\u7ebf\uff0c\u800c\u590d\u5408\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u80fd\u6301\u7eed\u63d0\u5347\u516c\u5e73\u6027\u4e14\u4e0d\u727a\u7272\u6548\u7528\uff1b(3) LVLMs\u867d\u5e73\u5747\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u4f46\u4ecd\u5b58\u5728\u5b50\u7fa4\u5dee\u5f02\uff0c\u4e14\u6a21\u578b\u6269\u5c55\u5e26\u6765\u7684\u6536\u76ca\u901a\u5e38\u5c0f\u4e8e\u67b6\u6784\u6216\u8bad\u7ec3\u534f\u8bae\u9009\u62e9\u7684\u5f71\u54cd\u3002", "conclusion": "NH-Fair\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u8003\u8651\u8c03\u53c2\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u6709\u52a9\u4e8e\u8fdb\u884c\u4e25\u8c28\u4e14\u5173\u6ce8\u5371\u5bb3\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u57fa\u7ebf\u8c03\u4f18\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u590d\u5408\u6570\u636e\u589e\u5f3a\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u5b9e\u7528\u7b56\u7565\u3002", "summary_cn": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5e38\u5e38\u4f1a\u7ee7\u627f\u5e76\u653e\u5927\u9488\u5bf9\u67d0\u4e9b\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u89c1\uff0c\u8fd9\u5f15\u53d1\u4e86\u4eba\u4eec\u5bf9\u5176\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u7d27\u8feb\u62c5\u5fe7\u3002\u5c3d\u7ba1\u5df2\u63d0\u51fa\u4f17\u591a\u504f\u89c1\u7f13\u89e3\u65b9\u6cd5\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u5f02\u6784\u3001\u516c\u5e73\u6027\u6307\u6807\u4e0d\u4e00\u81f4\u3001\u4ec5\u5b64\u7acb\u5730\u8bc4\u4f30\u89c6\u89c9\u6a21\u578b\u6216\u591a\u6a21\u6001\u6a21\u578b\uff0c\u4ee5\u53ca\u8d85\u53c2\u6570\u8c03\u4f18\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u4f7f\u5f97\u6bd4\u8f83\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4ecd\u7136\u5341\u5206\u56f0\u96be\u3002\u6211\u4eec\u63d0\u51fa\u4e86NH-Fair\u2014\u2014\u4e00\u4e2a\u201c\u65e0\u5bb3\u516c\u5e73\u6027\u201d\u7684\u7edf\u4e00\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5728\u6807\u51c6\u5316\u7684\u6570\u636e\u3001\u6307\u6807\u548c\u8bad\u7ec3\u534f\u8bae\u4e0b\uff0c\u540c\u65f6\u6db5\u76d6\u89c6\u89c9\u6a21\u578b\u548c\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\uff0c\u5e76\u8986\u76d6\u76d1\u7763\u5b66\u4e60\u548c\u96f6\u6837\u672c\u5b66\u4e60\u573a\u666f\u3002\u6211\u4eec\u7684\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a\uff081\uff09\u4e00\u9879\u7cfb\u7edf\u6027\u7684\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316\uff08ERM\uff09\u8c03\u53c2\u7814\u7a76\uff0c\u8bc6\u522b\u51fa\u5bf9\u6a21\u578b\u6548\u7528\u548c\u7fa4\u4f53\u5dee\u5f02\u5177\u6709\u91cd\u5927\u5f71\u54cd\u7684\u8bad\u7ec3\u9009\u62e9\uff0c\u4ece\u800c\u4e3a\u4ece\u4e1a\u8005\u63d0\u4f9b\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6307\u5bfc\u65b9\u9488\uff0c\u4ee5\u51cf\u5c11\u5728\u8ffd\u6c42\u9ad8\u516c\u5e73\u6027\u548c\u9ad8\u51c6\u786e\u6027\u65f6\u6240\u9700\u7684\u6602\u8d35\u8d85\u53c2\u6570\u641c\u7d22\u7a7a\u95f4\uff1b\uff082\uff09\u8bc1\u636e\u8868\u660e\uff0c\u8bb8\u591a\u53bb\u504f\u65b9\u6cd5\u5e76\u4e0d\u80fd\u7a33\u5b9a\u5730\u8d85\u8d8a\u4e00\u4e2a\u7ecf\u8fc7\u826f\u597d\u8c03\u53c2\u7684ERM\u57fa\u7ebf\uff0c\u800c\u4e00\u79cd\u590d\u5408\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u5219\u80fd\u6301\u7eed\u5e26\u6765\u516c\u5e73\u6027\u63d0\u5347\u4e14\u4e0d\u727a\u7272\u6a21\u578b\u6548\u7528\uff0c\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u5b9e\u7528\u7b56\u7565\uff1b\uff083\uff09\u5206\u6790\u663e\u793a\uff0c\u5c3d\u7ba1LVLMs\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u8868\u73b0\u51fa\u5b50\u7fa4\u4f53\u95f4\u7684\u5dee\u5f02\uff0c\u4e14\u5355\u7eaf\u901a\u8fc7\u6a21\u578b\u89c4\u6a21\u6269\u5c55\u6240\u5e26\u6765\u7684\u6536\u76ca\u901a\u5e38\u5c0f\u4e8e\u7531\u67b6\u6784\u8bbe\u8ba1\u6216\u8bad\u7ec3\u534f\u8bae\u9009\u62e9\u6240\u5e26\u6765\u7684\u6536\u76ca\u3002NH-Fair\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u4e14\u5145\u5206\u8003\u8651\u8c03\u53c2\u56e0\u7d20\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u7528\u4e8e\u8fdb\u884c\u4e25\u8c28\u4e14\u5173\u6ce8\u6f5c\u5728\u5371\u5bb3\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u3002"}}
{"id": "2602.04994", "pdf": "https://arxiv.org/pdf/2602.04994", "abs": "https://arxiv.org/abs/2602.04994", "authors": ["Zhuosen Bao", "Xia Du", "Zheng Lin", "Jizhe Zhou", "Zihan Fang", "Jiening Wu", "Yuxin Zhang", "Zhe Chen", "Chi-man Pun", "Wei Ni", "Jun Luo"], "title": "SIDeR: Semantic Identity Decoupling for Unrestricted Face Privacy", "categories": ["cs.CV", "cs.LG"], "comment": "14 pages, 8 figures", "summary": "With the deep integration of facial recognition into online banking, identity verification, and other networked services, achieving effective decoupling of identity information from visual representations during image storage and transmission has become a critical challenge for privacy protection. To address this issue, we propose SIDeR, a Semantic decoupling-driven framework for unrestricted face privacy protection. SIDeR decomposes a facial image into a machine-recognizable identity feature vector and a visually perceptible semantic appearance component. By leveraging semantic-guided recomposition in the latent space of a diffusion model, it generates visually anonymous adversarial faces while maintaining machine-level identity consistency. The framework incorporates momentum-driven unrestricted perturbation optimization and a semantic-visual balancing factor to synthesize multiple visually diverse, highly natural adversarial samples. Furthermore, for authorized access, the protected image can be restored to its original form when the correct password is provided. Extensive experiments on the CelebA-HQ and FFHQ datasets demonstrate that SIDeR achieves a 99% attack success rate in black-box scenarios and outperforms baseline methods by 41.28% in PSNR-based restoration quality.", "AI": {"tldr": "SIDeR \u662f\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u89e3\u8026\u7684\u65e0\u9650\u5236\u4eba\u8138\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u6269\u6563\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8bed\u4e49\u5f15\u5bfc\u91cd\u7ec4\uff0c\u5728\u4fdd\u6301\u673a\u5668\u53ef\u8bc6\u522b\u8eab\u4efd\u4e00\u81f4\u6027\u7684\u540c\u65f6\u751f\u6210\u89c6\u89c9\u4e0a\u533f\u540d\u4f46\u81ea\u7136\u7684\u4eba\u8138\u56fe\u50cf\uff0c\u5e76\u652f\u6301\u5bc6\u7801\u6388\u6743\u4e0b\u7684\u539f\u59cb\u56fe\u50cf\u6062\u590d\u3002", "motivation": "\u968f\u7740\u4eba\u8138\u8bc6\u522b\u6280\u672f\u6df1\u5ea6\u878d\u5165\u5728\u7ebf\u94f6\u884c\u3001\u8eab\u4efd\u9a8c\u8bc1\u7b49\u7f51\u7edc\u670d\u52a1\uff0c\u5982\u4f55\u5728\u56fe\u50cf\u5b58\u50a8\u4e0e\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u6709\u6548\u5c06\u8eab\u4efd\u4fe1\u606f\u4e0e\u89c6\u89c9\u8868\u5f81\u89e3\u8026\uff0c\u6210\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u5173\u952e\u6311\u6218\u3002", "method": "SIDeR \u5c06\u4eba\u8138\u56fe\u50cf\u5206\u89e3\u4e3a\u673a\u5668\u53ef\u8bc6\u522b\u7684\u8eab\u4efd\u7279\u5f81\u5411\u91cf\u548c\u89c6\u89c9\u53ef\u611f\u77e5\u7684\u8bed\u4e49\u5916\u89c2\u6210\u5206\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u5f15\u5bfc\u91cd\u7ec4\u673a\u5236\u751f\u6210\u5bf9\u6297\u6027\u533f\u540d\u4eba\u8138\uff1b\u5f15\u5165\u52a8\u91cf\u9a71\u52a8\u7684\u65e0\u9650\u5236\u6270\u52a8\u4f18\u5316\u548c\u8bed\u4e49-\u89c6\u89c9\u5e73\u8861\u56e0\u5b50\uff0c\u5408\u6210\u591a\u6837\u4e14\u81ea\u7136\u7684\u5bf9\u6297\u6837\u672c\uff1b\u540c\u65f6\u652f\u6301\u901a\u8fc7\u5bc6\u7801\u6388\u6743\u6062\u590d\u539f\u59cb\u56fe\u50cf\u3002", "result": "\u5728 CelebA-HQ \u548c FFHQ \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSIDeR \u5728\u9ed1\u76d2\u573a\u666f\u4e0b\u653b\u51fb\u6210\u529f\u7387\u8fbe 99%\uff0c\u4e14\u5728\u57fa\u4e8e PSNR \u7684\u6062\u590d\u8d28\u91cf\u4e0a\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa 41.28%\u3002", "conclusion": "SIDeR \u5728\u4fdd\u969c\u4eba\u8138\u56fe\u50cf\u9690\u79c1\u7684\u540c\u65f6\u517c\u987e\u4e86\u8eab\u4efd\u4e00\u81f4\u6027\u548c\u89c6\u89c9\u81ea\u7136\u6027\uff0c\u5e76\u652f\u6301\u53ef\u63a7\u6062\u590d\uff0c\u4e3a\u4eba\u8138\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u65b0\u8303\u5f0f\u3002", "summary_cn": "\u968f\u7740\u4eba\u8138\u8bc6\u522b\u6280\u672f\u6df1\u5ea6\u878d\u5165\u5728\u7ebf\u94f6\u884c\u3001\u8eab\u4efd\u9a8c\u8bc1\u7b49\u8054\u7f51\u670d\u52a1\uff0c\u5728\u56fe\u50cf\u5b58\u50a8\u4e0e\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u8eab\u4efd\u4fe1\u606f\u4e0e\u89c6\u89c9\u8868\u5f81\u7684\u6709\u6548\u89e3\u8026\u5df2\u6210\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u5173\u952e\u6311\u6218\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 SIDeR\u2014\u2014\u4e00\u79cd\u57fa\u4e8e\u8bed\u4e49\u89e3\u8026\u9a71\u52a8\u7684\u65e0\u9650\u5236\u4eba\u8138\u9690\u79c1\u4fdd\u62a4\u6846\u67b6\u3002SIDeR \u5c06\u4eba\u8138\u56fe\u50cf\u5206\u89e3\u4e3a\u673a\u5668\u53ef\u8bc6\u522b\u7684\u8eab\u4efd\u7279\u5f81\u5411\u91cf\u548c\u89c6\u89c9\u53ef\u611f\u77e5\u7684\u8bed\u4e49\u5916\u89c2\u6210\u5206\uff0c\u901a\u8fc7\u5728\u6269\u6563\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8bed\u4e49\u5f15\u5bfc\u7684\u91cd\u7ec4\uff0c\u751f\u6210\u89c6\u89c9\u4e0a\u533f\u540d\u4f46\u4fdd\u6301\u673a\u5668\u7ea7\u8eab\u4efd\u4e00\u81f4\u6027\u7684\u5bf9\u6297\u6027\u4eba\u8138\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u52a8\u91cf\u9a71\u52a8\u7684\u65e0\u9650\u5236\u6270\u52a8\u4f18\u5316\u7b56\u7565\u4e0e\u8bed\u4e49-\u89c6\u89c9\u5e73\u8861\u56e0\u5b50\uff0c\u53ef\u5408\u6210\u591a\u79cd\u89c6\u89c9\u591a\u6837\u4e14\u9ad8\u5ea6\u81ea\u7136\u7684\u5bf9\u6297\u6837\u672c\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u6388\u6743\u8bbf\u95ee\uff0c\u5f53\u63d0\u4f9b\u6b63\u786e\u5bc6\u7801\u65f6\uff0c\u53d7\u4fdd\u62a4\u56fe\u50cf\u53ef\u88ab\u8fd8\u539f\u4e3a\u5176\u539f\u59cb\u5f62\u5f0f\u3002\u5728 CelebA-HQ \u548c FFHQ \u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSIDeR \u5728\u9ed1\u76d2\u573a\u666f\u4e0b\u653b\u51fb\u6210\u529f\u7387\u8fbe\u5230 99%\uff0c\u5e76\u4e14\u5728\u57fa\u4e8e PSNR \u7684\u6062\u590d\u8d28\u91cf\u65b9\u9762\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa 41.28%\u3002"}}
{"id": "2602.05037", "pdf": "https://arxiv.org/pdf/2602.05037", "abs": "https://arxiv.org/abs/2602.05037", "authors": ["Bishoy Galoaa", "Xiangyu Bai", "Utsav Nandi", "Sai Siddhartha Vivek Dhir Rangoju", "Somaieh Amraee", "Sarah Ostadabbas"], "title": "UniTrack: Differentiable Graph Representation Learning for Multi-Object Tracking", "categories": ["cs.CV"], "comment": null, "summary": "We present UniTrack, a plug-and-play graph-theoretic loss function designed to significantly enhance multi-object tracking (MOT) performance by directly optimizing tracking-specific objectives through unified differentiable learning. Unlike prior graph-based MOT methods that redesign tracking architectures, UniTrack provides a universal training objective that integrates detection accuracy, identity preservation, and spatiotemporal consistency into a single end-to-end trainable loss function, enabling seamless integration with existing MOT systems without architectural modifications. Through differentiable graph representation learning, UniTrack enables networks to learn holistic representations of motion continuity and identity relationships across frames. We validate UniTrack across diverse tracking models and multiple challenging benchmarks, demonstrating consistent improvements across all tested architectures and datasets including Trackformer, MOTR, FairMOT, ByteTrack, GTR, and MOTE. Extensive evaluations show up to 53\\% reduction in identity switches and 12\\% IDF1 improvements across challenging benchmarks, with GTR achieving peak performance gains of 9.7\\% MOTA on SportsMOT.", "AI": {"tldr": "UniTrack \u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u56fe\u8bba\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u53ef\u5fae\u5b66\u4e60\u7edf\u4e00\u4f18\u5316\u68c0\u6d4b\u3001\u8eab\u4efd\u4fdd\u6301\u548c\u65f6\u7a7a\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u5347\u591a\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u8ddf\u8e2a\u67b6\u6784\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\uff1b\u4f5c\u8005\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u901a\u7528\u3001\u53ef\u63d2\u62d4\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u76f4\u63a5\u4f18\u5316\u8ddf\u8e2a\u4efb\u52a1\u7684\u6838\u5fc3\u6307\u6807\uff0c\u540c\u65f6\u517c\u5bb9\u73b0\u6709\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa UniTrack\uff0c\u4e00\u79cd\u7edf\u4e00\u7684\u53ef\u5fae\u56fe\u8bba\u635f\u5931\u51fd\u6570\uff0c\u5c06\u68c0\u6d4b\u7cbe\u5ea6\u3001\u8eab\u4efd\u4fdd\u6301\u548c\u65f6\u7a7a\u4e00\u81f4\u6027\u6574\u5408\u4e3a\u5355\u4e00\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u76ee\u6807\uff0c\u901a\u8fc7\u53ef\u5fae\u56fe\u8868\u793a\u5b66\u4e60\u5efa\u6a21\u8de8\u5e27\u8fd0\u52a8\u8fde\u7eed\u6027\u548c\u8eab\u4efd\u5173\u7cfb\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\uff08\u5982 Trackformer\u3001MOTR\u3001FairMOT\u3001ByteTrack\u3001GTR\u3001MOTE\uff09\u548c\u57fa\u51c6\u4e0a\u9a8c\u8bc1\uff0cUniTrack \u4e00\u81f4\u63d0\u5347\u6027\u80fd\uff0c\u8eab\u4efd\u5207\u6362\u6700\u591a\u51cf\u5c11 53%\uff0cIDF1 \u6700\u9ad8\u63d0\u5347 12%\uff0cGTR \u5728 SportsMOT \u4e0a MOTA \u63d0\u5347 9.7%\u3002", "conclusion": "UniTrack \u4f5c\u4e3a\u4e00\u79cd\u901a\u7528\u3001\u5373\u63d2\u5373\u7528\u7684\u635f\u5931\u51fd\u6570\uff0c\u80fd\u6709\u6548\u63d0\u5347\u5404\u7c7b\u591a\u76ee\u6807\u8ddf\u8e2a\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u7edf\u4e00\u53ef\u5fae\u4f18\u5316\u5728 MOT \u4e2d\u7684\u6709\u6548\u6027\u548c\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86 UniTrack\uff0c\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u56fe\u8bba\u635f\u5931\u51fd\u6570\uff0c\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u7684\u53ef\u5fae\u5b66\u4e60\u76f4\u63a5\u4f18\u5316\u591a\u76ee\u6807\u8ddf\u8e2a\uff08MOT\uff09\u7279\u5b9a\u76ee\u6807\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u8ddf\u8e2a\u6027\u80fd\u3002\u4e0e\u4ee5\u5f80\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u8ddf\u8e2a\u67b6\u6784\u7684\u57fa\u4e8e\u56fe\u7684 MOT \u65b9\u6cd5\u4e0d\u540c\uff0cUniTrack \u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u5c06\u68c0\u6d4b\u7cbe\u5ea6\u3001\u8eab\u4efd\u4fdd\u6301\u548c\u65f6\u7a7a\u4e00\u81f4\u6027\u6574\u5408\u5230\u4e00\u4e2a\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u7684\u635f\u5931\u51fd\u6570\u4e2d\uff0c\u80fd\u591f\u5728\u4e0d\u4fee\u6539\u73b0\u6709 MOT \u7cfb\u7edf\u67b6\u6784\u7684\u60c5\u51b5\u4e0b\u65e0\u7f1d\u96c6\u6210\u3002\u901a\u8fc7\u53ef\u5fae\u56fe\u8868\u793a\u5b66\u4e60\uff0cUniTrack \u4f7f\u7f51\u7edc\u80fd\u591f\u5b66\u4e60\u8de8\u5e27\u7684\u8fd0\u52a8\u8fde\u7eed\u6027\u548c\u8eab\u4efd\u5173\u7cfb\u7684\u6574\u4f53\u8868\u793a\u3002\u6211\u4eec\u5728\u591a\u79cd\u8ddf\u8e2a\u6a21\u578b\u548c\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u4e86 UniTrack\uff0c\u7ed3\u679c\u8868\u660e\u5176\u5728\u6240\u6709\u6d4b\u8bd5\u7684\u67b6\u6784\u548c\u6570\u636e\u96c6\uff08\u5305\u62ec Trackformer\u3001MOTR\u3001FairMOT\u3001ByteTrack\u3001GTR \u548c MOTE\uff09\u4e0a\u5747\u5e26\u6765\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u4e0a\uff0c\u8eab\u4efd\u5207\u6362\u6700\u591a\u51cf\u5c11\u4e86 53%\uff0cIDF1 \u6307\u6807\u6700\u9ad8\u63d0\u5347\u4e86 12%\uff0c\u5176\u4e2d GTR \u5728 SportsMOT \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86 MOTA \u6307\u6807 9.7% \u7684\u5cf0\u503c\u6027\u80fd\u589e\u76ca\u3002"}}
{"id": "2602.05049", "pdf": "https://arxiv.org/pdf/2602.05049", "abs": "https://arxiv.org/abs/2602.05049", "authors": ["Yiye Chen", "Yanan Jian", "Xiaoyi Dong", "Shuxin Cao", "Jing Wu", "Patricio Vela", "Benjamin E. Lundell", "Dongdong Chen"], "title": "VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "comment": "In submission. Project website: https://vista-vla.github.io/", "summary": "Vision-Language-Action (VLA) models have demonstrated strong performance across a wide range of robotic manipulation tasks. Despite the success, extending large pretrained Vision-Language Models (VLMs) to the action space can induce vision-action misalignment, where action predictions exhibit weak dependence on the current visual state, leading to unreliable action outputs. In this work, we study VLA models through the lens of visual conditioning and empirically show that successful rollouts consistently exhibit stronger visual dependence than failed ones. Motivated by this observation, we propose a training framework that explicitly strengthens visual conditioning in VLA models. Our approach first aligns action prediction with visual input via preference optimization on a track-following surrogate task, and then transfers the enhanced alignment to instruction-following task through latent-space distillation during supervised finetuning. Without introducing architectural modifications or additional data collection, our method improves both visual conditioning and task performance for discrete OpenVLA, and further yields consistent gains when extended to the continuous OpenVLA-OFT setting. Project website: https://vista-vla.github.io/ .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4fee\u6539\u67b6\u6784\u6216\u989d\u5916\u6570\u636e\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u89c6\u89c9\u6761\u4ef6\u6027\u6765\u63d0\u5347Vision-Language-Action\uff08VLA\uff09\u6a21\u578b\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5c06\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u6269\u5c55\u5230\u52a8\u4f5c\u7a7a\u95f4\u7684\u65b9\u6cd5\u5bb9\u6613\u5bfc\u81f4\u89c6\u89c9-\u52a8\u4f5c\u9519\u4f4d\uff0c\u5373\u52a8\u4f5c\u9884\u6d4b\u5bf9\u5f53\u524d\u89c6\u89c9\u72b6\u6001\u4f9d\u8d56\u8f83\u5f31\uff0c\u4ece\u800c\u5f71\u54cd\u52a8\u4f5c\u8f93\u51fa\u7684\u53ef\u9760\u6027\u3002\u4f5c\u8005\u89c2\u5bdf\u5230\u6210\u529f\u6267\u884c\u8f68\u8ff9\u6bd4\u5931\u8d25\u8f68\u8ff9\u5177\u6709\u66f4\u5f3a\u7684\u89c6\u89c9\u4f9d\u8d56\u6027\uff0c\u56e0\u6b64\u5e0c\u671b\u663e\u5f0f\u589e\u5f3aVLA\u6a21\u578b\u7684\u89c6\u89c9\u6761\u4ef6\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u9996\u5148\u5728\u4e00\u4e2a\u8f68\u8ff9\u8ddf\u968f\u4ee3\u7406\u4efb\u52a1\u4e0a\u901a\u8fc7\u504f\u597d\u4f18\u5316\u4f7f\u52a8\u4f5c\u9884\u6d4b\u4e0e\u89c6\u89c9\u8f93\u5165\u5bf9\u9f50\uff0c\u7136\u540e\u5728\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u84b8\u998f\u5c06\u8fd9\u79cd\u589e\u5f3a\u7684\u5bf9\u9f50\u80fd\u529b\u8fc1\u79fb\u5230\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e2d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u5f15\u5165\u67b6\u6784\u4fee\u6539\u6216\u989d\u5916\u6570\u636e\u6536\u96c6\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u5347\u4e86\u79bb\u6563OpenVLA\u6a21\u578b\u7684\u89c6\u89c9\u6761\u4ef6\u6027\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684OpenVLA-OFT\u8bbe\u7f6e\u4e0b\u4e5f\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u663e\u5f0f\u589e\u5f3aVLA\u6a21\u578b\u5bf9\u89c6\u89c9\u8f93\u5165\u7684\u4f9d\u8d56\u6027\u53ef\u6709\u6548\u7f13\u89e3\u89c6\u89c9-\u52a8\u4f5c\u9519\u4f4d\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u5728\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "summary_cn": "\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u5728\u591a\u79cd\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u6027\u80fd\u3002\u7136\u800c\uff0c\u5c3d\u7ba1\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u5c06\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u6269\u5c55\u5230\u52a8\u4f5c\u7a7a\u95f4\u53ef\u80fd\u5bfc\u81f4\u89c6\u89c9-\u52a8\u4f5c\u9519\u4f4d\u95ee\u9898\uff0c\u5373\u52a8\u4f5c\u9884\u6d4b\u5bf9\u5f53\u524d\u89c6\u89c9\u72b6\u6001\u7684\u4f9d\u8d56\u8f83\u5f31\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u53ef\u9760\u7684\u52a8\u4f5c\u8f93\u51fa\u3002\u672c\u6587\u4ece\u89c6\u89c9\u6761\u4ef6\u6027\u7684\u89d2\u5ea6\u7814\u7a76VLA\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6210\u529f\u7684\u6267\u884c\u8f68\u8ff9\u59cb\u7ec8\u6bd4\u5931\u8d25\u7684\u8f68\u8ff9\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u89c6\u89c9\u4f9d\u8d56\u6027\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8bad\u7ec3\u6846\u67b6\uff0c\u663e\u5f0f\u5730\u589e\u5f3aVLA\u6a21\u578b\u4e2d\u7684\u89c6\u89c9\u6761\u4ef6\u6027\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u9996\u5148\u5728\u4e00\u4e2a\u8f68\u8ff9\u8ddf\u968f\u4ee3\u7406\u4efb\u52a1\u4e0a\u901a\u8fc7\u504f\u597d\u4f18\u5316\u5b9e\u73b0\u52a8\u4f5c\u9884\u6d4b\u4e0e\u89c6\u89c9\u8f93\u5165\u7684\u5bf9\u9f50\uff0c\u7136\u540e\u5728\u76d1\u7763\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u6f5c\u5728\u7a7a\u95f4\u84b8\u998f\u5c06\u8fd9\u79cd\u589e\u5f3a\u7684\u5bf9\u9f50\u80fd\u529b\u8fc1\u79fb\u5230\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u4e2d\u3002\u5728\u4e0d\u5f15\u5165\u67b6\u6784\u4fee\u6539\u6216\u989d\u5916\u6570\u636e\u6536\u96c6\u7684\u524d\u63d0\u4e0b\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u79bb\u6563OpenVLA\u6a21\u578b\u7684\u89c6\u89c9\u6761\u4ef6\u6027\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u5728\u6269\u5c55\u5230\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u7684OpenVLA-OFT\u8bbe\u7f6e\u65f6\u4e5f\u6301\u7eed\u5e26\u6765\u6027\u80fd\u589e\u76ca\u3002\u9879\u76ee\u7f51\u7ad9\uff1ahttps://vista-vla.github.io/\u3002"}}
{"id": "2602.05078", "pdf": "https://arxiv.org/pdf/2602.05078", "abs": "https://arxiv.org/abs/2602.05078", "authors": ["Gautham Vinod", "Fengqing Zhu"], "title": "Food Portion Estimation: From Pixels to Calories", "categories": ["cs.CV", "cs.AI", "cs.MM", "eess.IV"], "comment": null, "summary": "Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensional size of food from 2D image inputs. Many strategies have been devised to overcome this critical limitation such as the use of auxiliary inputs like depth maps, multi-view inputs, or model-based approaches such as template matching. Deep learning also helps bridge the gap by either using monocular images or combinations of the image and the auxillary inputs to precisely predict the output portion from the image input. In this paper, we explore the different strategies employed for accurate portion estimation.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u56fe\u50cf\u7684\u81b3\u98df\u8bc4\u4f30\u4e2d\u7528\u4e8e\u7cbe\u786e\u4f30\u7b97\u98df\u7269\u4efd\u91cf\u7684\u5404\u79cd\u7b56\u7565\uff0c\u91cd\u70b9\u89e3\u51b3\u4ece2D\u56fe\u50cf\u4f30\u8ba13D\u98df\u7269\u5c3a\u5bf8\u7684\u96be\u9898\u3002", "motivation": "\u57fa\u4e8e\u56fe\u50cf\u7684\u81b3\u98df\u8bc4\u4f30\u5728\u4e2a\u4f53\u5065\u5eb7\u76d1\u6d4b\u3001\u6162\u6027\u75c5\u53ca\u80a5\u80d6\u9632\u63a7\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u5176\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u4ece\u4e8c\u7ef4\u56fe\u50cf\u51c6\u786e\u4f30\u8ba1\u98df\u7269\u7684\u4e09\u7ef4\u4f53\u79ef\u3002", "method": "\u6587\u7ae0\u63a2\u8ba8\u4e86\u591a\u79cd\u5e94\u5bf9\u8be5\u6311\u6218\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4f7f\u7528\u6df1\u5ea6\u56fe\u3001\u591a\u89c6\u89d2\u56fe\u50cf\u7b49\u8f85\u52a9\u8f93\u5165\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u6a21\u677f\u5339\u914d\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u4ece\u5355\u76ee\u56fe\u50cf\u6216\u7ed3\u5408\u8f85\u52a9\u4fe1\u606f\u8fdb\u884c\u4efd\u91cf\u9884\u6d4b\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u5e76\u6bd4\u8f83\u4e86\u73b0\u6709\u4e0d\u540c\u7b56\u7565\u5728\u63d0\u5347\u98df\u7269\u4efd\u91cf\u4f30\u8ba1\u51c6\u786e\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7efc\u5408\u8fd0\u7528\u8f85\u52a9\u4fe1\u606f\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u662f\u514b\u670d2D\u56fe\u50cf\u5728\u98df\u7269\u4e09\u7ef4\u5c3a\u5bf8\u4f30\u8ba1\u5c40\u9650\u6027\u7684\u5173\u952e\u65b9\u5411\u3002", "summary_cn": "\u4f9d\u8d56\u56fe\u50cf\u8fdb\u884c\u81b3\u98df\u8bc4\u4f30\u662f\u4e00\u79cd\u91cd\u8981\u7b56\u7565\uff0c\u80fd\u591f\u51c6\u786e\u4e14\u4fbf\u6377\u5730\u76d1\u6d4b\u4e2a\u4f53\u5065\u5eb7\u72b6\u51b5\uff0c\u4ece\u800c\u5728\u6162\u6027\u75be\u75c5\u548c\u80a5\u80d6\u7684\u9884\u9632\u4e0e\u7ba1\u7406\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u56fe\u50cf\u7684\u81b3\u98df\u8bc4\u4f30\u9762\u4e34\u4e00\u4e2a\u6838\u5fc3\u96be\u9898\uff1a\u5982\u4f55\u4ece\u4e8c\u7ef4\u56fe\u50cf\u8f93\u5165\u4e2d\u4f30\u7b97\u98df\u7269\u7684\u4e09\u7ef4\u5c3a\u5bf8\u3002\u4e3a\u514b\u670d\u8fd9\u4e00\u5173\u952e\u9650\u5236\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u591a\u79cd\u7b56\u7565\uff0c\u4f8b\u5982\u4f7f\u7528\u6df1\u5ea6\u56fe\u3001\u591a\u89c6\u89d2\u8f93\u5165\u7b49\u8f85\u52a9\u4fe1\u606f\uff0c\u6216\u91c7\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\uff08\u5982\u6a21\u677f\u5339\u914d\uff09\u3002\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u4e5f\u6709\u52a9\u4e8e\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u53ef\u901a\u8fc7\u5355\u76ee\u56fe\u50cf\u6216\u7ed3\u5408\u56fe\u50cf\u4e0e\u8f85\u52a9\u8f93\u5165\uff0c\u7cbe\u786e\u9884\u6d4b\u56fe\u50cf\u4e2d\u7684\u98df\u7269\u4efd\u91cf\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u7528\u4e8e\u5b9e\u73b0\u51c6\u786e\u4efd\u91cf\u4f30\u7b97\u7684\u4e0d\u540c\u7b56\u7565\u3002"}}
{"id": "2602.05096", "pdf": "https://arxiv.org/pdf/2602.05096", "abs": "https://arxiv.org/abs/2602.05096", "authors": ["Joseph D. Janizek", "Sonnet Xu", "Junayd Lateef", "Roxana Daneshjou"], "title": "Visual concept ranking uncovers medical shortcuts used by large multimodal models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Ensuring the reliability of machine learning models in safety-critical domains such as healthcare requires auditing methods that can uncover model shortcomings. We introduce a method for identifying important visual concepts within large multimodal models (LMMs) and use it to investigate the behaviors these models exhibit when prompted with medical tasks. We primarily focus on the task of classifying malignant skin lesions from clinical dermatology images, with supplemental experiments including both chest radiographs and natural images. After showing how LMMs display unexpected gaps in performance between different demographic subgroups when prompted with demonstrating examples, we apply our method, Visual Concept Ranking (VCR), to these models and prompts. VCR generates hypotheses related to different visual feature dependencies, which we are then able to validate with manual interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u89c6\u89c9\u6982\u5ff5\u6392\u5e8f\uff08VCR\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u4f9d\u8d56\u7684\u5173\u952e\u89c6\u89c9\u6982\u5ff5\uff0c\u5e76\u63ed\u793a\u5176\u5728\u4e0d\u540c\u4eba\u7fa4\u5b50\u7ec4\u95f4\u7684\u8868\u73b0\u5dee\u5f02\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u5ba1\u8ba1\u65b9\u6cd5\u6765\u63ed\u793a\u6a21\u578b\u7684\u7f3a\u9677\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u89e3\u91caLMM\u5728\u5904\u7406\u533b\u5b66\u56fe\u50cf\u65f6\u7684\u884c\u4e3a\uff0c\u5c24\u5176\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b66\u7fa4\u4f53\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u201c\u89c6\u89c9\u6982\u5ff5\u6392\u5e8f\u201d\uff08Visual Concept Ranking, VCR\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522bLMM\u5728\u5904\u7406\u533b\u5b66\u4efb\u52a1\uff08\u5982\u76ae\u80a4\u75c5\u53d8\u5206\u7c7b\u3001\u80f8\u90e8X\u5149\u7247\u5206\u6790\u7b49\uff09\u65f6\u6240\u4f9d\u8d56\u7684\u91cd\u8981\u89c6\u89c9\u6982\u5ff5\u3002\u901a\u8fc7\u63d0\u4f9b\u793a\u4f8b\u63d0\u793a\uff0c\u7ed3\u5408\u4eba\u5de5\u5e72\u9884\u9a8c\u8bc1VCR\u751f\u6210\u7684\u5173\u4e8e\u89c6\u89c9\u7279\u5f81\u4f9d\u8d56\u7684\u5047\u8bbe\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cLMM\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b66\u5b50\u7ec4\u4e4b\u95f4\u5b58\u5728\u610f\u6599\u4e4b\u5916\u7684\u6027\u80fd\u5dee\u8ddd\uff1bVCR\u80fd\u591f\u6709\u6548\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u89c6\u89c9\u7279\u5f81\u4f9d\u8d56\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u5e72\u9884\u52a0\u4ee5\u786e\u8ba4\u3002", "conclusion": "VCR\u4e3a\u7406\u89e3\u548c\u5ba1\u8ba1LMM\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63ed\u793a\u6a21\u578b\u504f\u89c1\u548c\u6f5c\u5728\u5931\u6548\u6a21\u5f0f\uff0c\u4ece\u800c\u63d0\u5347\u5176\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002", "summary_cn": "\u786e\u4fdd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u80fd\u591f\u63ed\u793a\u6a21\u578b\u7f3a\u9677\u7684\u5ba1\u8ba1\u65b9\u6cd5\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8bc6\u522b\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u4e2d\u91cd\u8981\u89c6\u89c9\u6982\u5ff5\u7684\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8be5\u65b9\u6cd5\u7814\u7a76\u8fd9\u4e9b\u6a21\u578b\u5728\u9762\u5bf9\u533b\u7597\u4efb\u52a1\u63d0\u793a\u65f6\u6240\u8868\u73b0\u51fa\u7684\u884c\u4e3a\u3002\u6211\u4eec\u4e3b\u8981\u805a\u7126\u4e8e\u4ece\u4e34\u5e8a\u76ae\u80a4\u79d1\u56fe\u50cf\u4e2d\u5bf9\u6076\u6027\u76ae\u80a4\u75c5\u53d8\u8fdb\u884c\u5206\u7c7b\u7684\u4efb\u52a1\uff0c\u5e76\u8f85\u4ee5\u80f8\u90e8X\u5149\u7247\u548c\u81ea\u7136\u56fe\u50cf\u7684\u8865\u5145\u5b9e\u9a8c\u3002\u5728\u5c55\u793aLMM\u5728\u4f7f\u7528\u793a\u4f8b\u63d0\u793a\u65f6\u5728\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u5b66\u5b50\u7fa4\u4f53\u4e4b\u95f4\u5b58\u5728\u610f\u5916\u7684\u6027\u80fd\u5dee\u8ddd\u540e\uff0c\u6211\u4eec\u5c06\u6240\u63d0\u51fa\u7684\u201c\u89c6\u89c9\u6982\u5ff5\u6392\u5e8f\u201d\uff08Visual Concept Ranking, VCR\uff09\u65b9\u6cd5\u5e94\u7528\u4e8e\u8fd9\u4e9b\u6a21\u578b\u548c\u63d0\u793a\u3002VCR\u80fd\u591f\u751f\u6210\u4e0e\u4e0d\u540c\u89c6\u89c9\u7279\u5f81\u4f9d\u8d56\u76f8\u5173\u7684\u5047\u8bbe\uff0c\u968f\u540e\u6211\u4eec\u901a\u8fc7\u4eba\u5de5\u5e72\u9884\u5bf9\u8fd9\u4e9b\u5047\u8bbe\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002"}}
{"id": "2602.05126", "pdf": "https://arxiv.org/pdf/2602.05126", "abs": "https://arxiv.org/abs/2602.05126", "authors": ["Weiyi Qin", "Yingci Liu-Swetz", "Shiwei Tan", "Hao Wang"], "title": "CLEAR-HPV: Interpretable Concept Discovery for HPV-Associated Morphology in Whole-Slide Histology", "categories": ["cs.CV"], "comment": null, "summary": "Human papillomavirus (HPV) status is a critical determinant of prognosis and treatment response in head and neck and cervical cancers. Although attention-based multiple instance learning (MIL) achieves strong slide-level prediction for HPV-related whole-slide histopathology, it provides limited morphologic interpretability. To address this limitation, we introduce Concept-Level Explainable Attention-guided Representation for HPV (CLEAR-HPV), a framework that restructures the MIL latent space using attention to enable concept discovery without requiring concept labels during training. Operating in an attention-weighted latent space, CLEAR-HPV automatically discovers keratinizing, basaloid, and stromal morphologic concepts, generates spatial concept maps, and represents each slide using a compact concept-fraction vector. CLEAR-HPV's concept-fraction vectors preserve the predictive information of the original MIL embeddings while reducing the high-dimensional feature space (e.g., 1536 dimensions) to only 10 interpretable concepts. CLEAR-HPV generalizes consistently across TCGA-HNSCC, TCGA-CESC, and CPTAC-HNSCC, providing compact, concept-level interpretability through a general, backbone-agnostic framework for attention-based MIL models of whole-slide histopathology.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCLEAR-HPV\u6846\u67b6\uff0c\u5728\u65e0\u9700\u6982\u5ff5\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5728MIL\u6a21\u578b\u4e2d\u81ea\u52a8\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u5f62\u6001\u5b66\u6982\u5ff5\uff08\u5982\u89d2\u5316\u3001\u57fa\u5e95\u6837\u548c\u95f4\u8d28\uff09\uff0c\u5c06\u9ad8\u7ef4\u7279\u5f81\u538b\u7f29\u4e3a\u4ec510\u4e2a\u53ef\u89e3\u91ca\u6982\u5ff5\u7684\u5411\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u764c\u75c7\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u5b9e\u4f8b\u5b66\u4e60\uff08MIL\uff09\u65b9\u6cd5\u867d\u7136\u5728HPV\u76f8\u5173\u5168\u5207\u7247\u75c5\u7406\u56fe\u50cf\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7f3a\u4e4f\u5f62\u6001\u5b66\u5c42\u9762\u7684\u53ef\u89e3\u91ca\u6027\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u80fd\u5728\u4e0d\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6982\u5ff5\u6807\u7b7e\u7684\u524d\u63d0\u4e0b\uff0c\u81ea\u52a8\u53d1\u73b0\u5e76\u53ef\u89c6\u5316\u7ec4\u7ec7\u5f62\u6001\u5b66\u6982\u5ff5\u7684\u53ef\u89e3\u91ca\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u63d0\u51faCLEAR-HPV\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u6ce8\u610f\u529b\u6743\u91cd\u91cd\u6784MIL\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u5728\u5176\u4e2d\u81ea\u52a8\u53d1\u73b0\u5173\u952e\u5f62\u6001\u5b66\u6982\u5ff5\uff08\u5982\u89d2\u5316\u3001\u57fa\u5e95\u6837\u3001\u95f4\u8d28\uff09\uff0c\u751f\u6210\u7a7a\u95f4\u6982\u5ff5\u56fe\uff0c\u5e76\u7528\u4e00\u4e2a\u7d27\u51d1\u7684\u6982\u5ff5\u6bd4\u4f8b\u5411\u91cf\uff08concept-fraction vector\uff09\u6765\u8868\u793a\u6574\u5f20\u5207\u7247\u3002", "result": "CLEAR-HPV\u6210\u529f\u5730\u5c06\u539f\u59cb\u9ad8\u7ef4\uff08\u59821536\u7ef4\uff09MIL\u5d4c\u5165\u538b\u7f29\u4e3a\u4ec5\u5305\u542b10\u4e2a\u53ef\u89e3\u91ca\u6982\u5ff5\u7684\u5411\u91cf\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u539f\u6709\u7684\u9884\u6d4b\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u5728TCGA-HNSCC\u3001TCGA-CESC\u548cCPTAC-HNSCC\u7b49\u591a\u4e2a\u72ec\u7acb\u6570\u636e\u96c6\u4e0a\u5747\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4e00\u81f4\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "CLEAR-HPV\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u4e0e\u4e3b\u5e72\u7f51\u7edc\u65e0\u5173\u7684\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6ce8\u610f\u529bMIL\u6a21\u578b\u5728\u5168\u5207\u7247\u75c5\u7406\u56fe\u50cf\u5206\u6790\u4e2d\u7684\u6982\u5ff5\u7ea7\u53ef\u89e3\u91ca\u6027\uff0c\u4e3aHPV\u72b6\u6001\u9884\u6d4b\u63d0\u4f9b\u4e86\u517c\u5177\u9ad8\u6027\u80fd\u4e0e\u900f\u660e\u5ea6\u7684\u65b0\u65b9\u6cd5\u3002", "summary_cn": "\u4eba\u4e73\u5934\u7624\u75c5\u6bd2\uff08HPV\uff09\u72b6\u6001\u662f\u5934\u9888\u764c\u548c\u5bab\u9888\u764c\u9884\u540e\u53ca\u6cbb\u7597\u53cd\u5e94\u7684\u5173\u952e\u51b3\u5b9a\u56e0\u7d20\u3002\u5c3d\u7ba1\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u5b9e\u4f8b\u5b66\u4e60\uff08MIL\uff09\u5728HPV\u76f8\u5173\u7684\u5168\u5207\u7247\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u7684\u5207\u7247\u7ea7\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u5f62\u6001\u5b66\u4e0a\u7684\u53ef\u89e3\u91ca\u6027\u6709\u9650\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u7528\u4e8eHPV\u7684\u6982\u5ff5\u7ea7\u53ef\u89e3\u91ca\u6ce8\u610f\u529b\u5f15\u5bfc\u8868\u5f81\u201d\uff08CLEAR-HPV\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u91cd\u6784MIL\u7684\u6f5c\u5728\u7a7a\u95f4\uff0c\u4ece\u800c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u65e0\u9700\u6982\u5ff5\u6807\u7b7e\u5373\u53ef\u5b9e\u73b0\u6982\u5ff5\u53d1\u73b0\u3002CLEAR-HPV\u5728\u6ce8\u610f\u529b\u52a0\u6743\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u81ea\u52a8\u8bc6\u522b\u51fa\u89d2\u5316\u3001\u57fa\u5e95\u6837\u548c\u95f4\u8d28\u7b49\u5f62\u6001\u5b66\u6982\u5ff5\uff0c\u751f\u6210\u7a7a\u95f4\u6982\u5ff5\u56fe\uff0c\u5e76\u4f7f\u7528\u4e00\u4e2a\u7d27\u51d1\u7684\u6982\u5ff5\u6bd4\u4f8b\u5411\u91cf\u6765\u8868\u5f81\u6bcf\u5f20\u5207\u7247\u3002CLEAR-HPV\u7684\u6982\u5ff5\u6bd4\u4f8b\u5411\u91cf\u5728\u4fdd\u7559\u539f\u59cbMIL\u5d4c\u5165\u9884\u6d4b\u4fe1\u606f\u7684\u540c\u65f6\uff0c\u5c06\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\uff08\u4f8b\u59821536\u7ef4\uff09\u7f29\u51cf\u81f3\u4ec510\u4e2a\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u3002CLEAR-HPV\u5728TCGA-HNSCC\u3001TCGA-CESC\u548cCPTAC-HNSCC\u7b49\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u901a\u8fc7\u4e00\u4e2a\u901a\u7528\u4e14\u4e0e\u4e3b\u5e72\u7f51\u7edc\u65e0\u5173\u7684\u6846\u67b6\uff0c\u4e3a\u5168\u5207\u7247\u7ec4\u7ec7\u75c5\u7406\u5b66\u7684\u6ce8\u610f\u529bMIL\u6a21\u578b\u63d0\u4f9b\u4e86\u7d27\u51d1\u7684\u6982\u5ff5\u7ea7\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.05132", "pdf": "https://arxiv.org/pdf/2602.05132", "abs": "https://arxiv.org/abs/2602.05132", "authors": ["Jia Li", "Wenjie Zhao", "Shijian Deng", "Bolin Lai", "Yuheng Wu", "RUijia Chen", "Jon E. Froehlich", "Yuhang Zhao", "Yapeng Tian"], "title": "ARGaze: Autoregressive Transformers for Online Egocentric Gaze Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Online egocentric gaze estimation predicts where a camera wearer is looking from first-person video using only past and current frames, a task essential for augmented reality and assistive technologies. Unlike third-person gaze estimation, this setting lacks explicit head or eye signals, requiring models to infer current visual attention from sparse, indirect cues such as hand-object interactions and salient scene content. We observe that gaze exhibits strong temporal continuity during goal-directed activities: knowing where a person looked recently provides a powerful prior for predicting where they look next. Inspired by vision-conditioned autoregressive decoding in vision-language models, we propose ARGaze, which reformulates gaze estimation as sequential prediction: at each timestep, a transformer decoder predicts current gaze by conditioning on (i) current visual features and (ii) a fixed-length Gaze Context Window of recent gaze target estimates. This design enforces causality and enables bounded-resource streaming inference. We achieve state-of-the-art performance across multiple egocentric benchmarks under online evaluation, with extensive ablations validating that autoregressive modeling with bounded gaze history is critical for robust prediction. We will release our source code and pre-trained models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faARGaze\uff0c\u4e00\u79cd\u57fa\u4e8e\u81ea\u56de\u5f52\u5e8f\u5217\u5efa\u6a21\u7684\u5728\u7ebf\u7b2c\u4e00\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5728\u7ebf\u7b2c\u4e00\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u7f3a\u4e4f\u660e\u786e\u7684\u5934\u90e8\u6216\u773c\u90e8\u4fe1\u53f7\uff0c\u9700\u4ece\u7a00\u758f\u3001\u95f4\u63a5\u7ebf\u7d22\u63a8\u65ad\u89c6\u89c9\u6ce8\u610f\u529b\uff1b\u73b0\u6709\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u89c6\u7ebf\u5728\u76ee\u6807\u5bfc\u5411\u6d3b\u52a8\u4e2d\u7684\u65f6\u95f4\u8fde\u7eed\u6027\u3002", "method": "\u5c06\u89c6\u7ebf\u4f30\u8ba1\u91cd\u6784\u4e3a\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\uff0c\u4f7f\u7528Transformer\u89e3\u7801\u5668\uff0c\u7ed3\u5408\u5f53\u524d\u89c6\u89c9\u7279\u5f81\u4e0e\u56fa\u5b9a\u957f\u5ea6\u7684\u8fd1\u671f\u89c6\u7ebf\u76ee\u6807\u4f30\u8ba1\u7a97\u53e3\uff08Gaze Context Window\uff09\u8fdb\u884c\u81ea\u56de\u5f52\u9884\u6d4b\uff0c\u786e\u4fdd\u56e0\u679c\u6027\u548c\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u6d41\u5f0f\u63a8\u7406\u3002", "result": "\u5728\u591a\u4e2a\u7b2c\u4e00\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u57fa\u51c6\u7684\u5728\u7ebf\u8bc4\u4f30\u4e2d\u53d6\u5f97SOTA\u7ed3\u679c\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u6709\u9650\u5386\u53f2\u89c6\u7ebf\u4fe1\u606f\u7684\u81ea\u56de\u5f52\u5efa\u6a21\u5bf9\u9c81\u68d2\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u5229\u7528\u89c6\u7ebf\u7684\u65f6\u95f4\u8fde\u7eed\u6027\u5e76\u901a\u8fc7\u81ea\u56de\u5f52\u65b9\u5f0f\u5efa\u6a21\uff0c\u80fd\u663e\u8457\u63d0\u5347\u5728\u7ebf\u7b2c\u4e00\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u7684\u6027\u80fd\uff0c\u9002\u7528\u4e8eAR\u548c\u8f85\u52a9\u6280\u672f\u7b49\u5b9e\u9645\u573a\u666f\u3002", "summary_cn": "\u5728\u7ebf\u7b2c\u4e00\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u65e8\u5728\u4ec5\u4f7f\u7528\u8fc7\u53bb\u548c\u5f53\u524d\u5e27\u7684\u7b2c\u4e00\u4eba\u79f0\u89c6\u9891\u6765\u9884\u6d4b\u4f69\u6234\u6444\u50cf\u5934\u8005\u6b63\u5728\u6ce8\u89c6\u7684\u4f4d\u7f6e\uff0c\u8fd9\u4e00\u4efb\u52a1\u5bf9\u589e\u5f3a\u73b0\u5b9e\u548c\u8f85\u52a9\u6280\u672f\u81f3\u5173\u91cd\u8981\u3002\u4e0e\u7b2c\u4e09\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u4e0d\u540c\uff0c\u8be5\u8bbe\u5b9a\u7f3a\u4e4f\u663e\u5f0f\u7684\u5934\u90e8\u6216\u773c\u90e8\u4fe1\u53f7\uff0c\u8981\u6c42\u6a21\u578b\u4ece\u624b-\u7269\u4ea4\u4e92\u548c\u663e\u8457\u573a\u666f\u5185\u5bb9\u7b49\u7a00\u758f\u4e14\u95f4\u63a5\u7684\u7ebf\u7d22\u4e2d\u63a8\u65ad\u5f53\u524d\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u3002\u6211\u4eec\u89c2\u5bdf\u5230\uff0c\u5728\u76ee\u6807\u5bfc\u5411\u6d3b\u52a8\u4e2d\uff0c\u89c6\u7ebf\u8868\u73b0\u51fa\u5f3a\u70c8\u7684\u65f6\u95f4\u8fde\u7eed\u6027\uff1a\u4e86\u89e3\u4e00\u4e2a\u4eba\u6700\u8fd1\u6ce8\u89c6\u7684\u4f4d\u7f6e\u53ef\u4e3a\u9884\u6d4b\u5176\u4e0b\u4e00\u6b65\u6ce8\u89c6\u4f4d\u7f6e\u63d0\u4f9b\u6709\u529b\u5148\u9a8c\u3002\u53d7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e2d\u89c6\u89c9\u6761\u4ef6\u81ea\u56de\u5f52\u89e3\u7801\u7684\u542f\u53d1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86ARGaze\u65b9\u6cd5\uff0c\u5c06\u89c6\u7ebf\u4f30\u8ba1\u91cd\u65b0\u8868\u8ff0\u4e3a\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\uff1a\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\uff0cTransformer\u89e3\u7801\u5668\u901a\u8fc7\u7ed3\u5408\uff08i\uff09\u5f53\u524d\u89c6\u89c9\u7279\u5f81\u548c\uff08ii\uff09\u4e00\u4e2a\u56fa\u5b9a\u957f\u5ea6\u7684\u8fd1\u671f\u89c6\u7ebf\u76ee\u6807\u4f30\u8ba1\u7a97\u53e3\uff08Gaze Context Window\uff09\u6765\u9884\u6d4b\u5f53\u524d\u89c6\u7ebf\u3002\u8be5\u8bbe\u8ba1\u4fdd\u8bc1\u4e86\u56e0\u679c\u6027\uff0c\u5e76\u652f\u6301\u6709\u9650\u8d44\u6e90\u4e0b\u7684\u6d41\u5f0f\u63a8\u7406\u3002\u6211\u4eec\u5728\u591a\u79cd\u7b2c\u4e00\u4eba\u79f0\u89c6\u7ebf\u4f30\u8ba1\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u5728\u7ebf\u8bc4\u4f30\u4e0b\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5927\u91cf\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4f7f\u7528\u6709\u9650\u89c6\u7ebf\u5386\u53f2\u7684\u81ea\u56de\u5f52\u5efa\u6a21\u5bf9\u9c81\u68d2\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u3002\u6211\u4eec\u5c06\u5f00\u6e90\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u3002"}}
{"id": "2602.05159", "pdf": "https://arxiv.org/pdf/2602.05159", "abs": "https://arxiv.org/abs/2602.05159", "authors": ["Wenhui Cui", "Ziyi Kou", "Chuan Qin", "Ergys Ristani", "Li Guan"], "title": "AirGlove: Exploring Egocentric 3D Hand Tracking and Appearance Generalization for Sensing Gloves", "categories": ["cs.CV"], "comment": "Accepted by ICASSP 2026", "summary": "Sensing gloves have become important tools for teleoperation and robotic policy learning as they are able to provide rich signals like speed, acceleration and tactile feedback. A common approach to track gloved hands is to directly use the sensor signals (e.g., angular velocity, gravity orientation) to estimate 3D hand poses. However, sensor-based tracking can be restrictive in practice as the accuracy is often impacted by sensor signal and calibration quality. Recent advances in vision-based approaches have achieved strong performance on human hands via large-scale pre-training, but their performance on gloved hands with distinct visual appearances remains underexplored. In this work, we present the first systematic evaluation of vision-based hand tracking models on gloved hands under both zero-shot and fine-tuning setups. Our analysis shows that existing bare-hand models suffer from substantial performance degradation on sensing gloves due to large appearance gap between bare-hand and glove designs. We therefore propose AirGlove, which leverages existing gloves to generalize the learned glove representations towards new gloves with limited data. Experiments with multiple sensing gloves show that AirGlove effectively generalizes the hand pose models to new glove designs and achieves a significant performance boost over the compared schemes.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u57fa\u4e8e\u89c6\u89c9\u7684\u624b\u90e8\u8ffd\u8e2a\u6a21\u578b\u5728\u6234\u624b\u5957\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u88f8\u624b\u6a21\u578b\u56e0\u5916\u89c2\u5dee\u5f02\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u63d0\u51faAirGlove\u65b9\u6cd5\uff0c\u5229\u7528\u5df2\u6709\u624b\u5957\u6570\u636e\u63d0\u5347\u5bf9\u65b0\u7c7b\u578b\u624b\u5957\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4f20\u611f\u5668\u7684\u624b\u5957\u8ffd\u8e2a\u65b9\u6cd5\u53d7\u9650\u4e8e\u4fe1\u53f7\u8d28\u91cf\u548c\u6821\u51c6\u7cbe\u5ea6\uff0c\u800c\u57fa\u4e8e\u89c6\u89c9\u7684\u65b9\u6cd5\u867d\u5728\u88f8\u624b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4e0d\u540c\u5916\u89c2\u7684\u624b\u5957\u4e0a\u6548\u679c\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u66f4\u9c81\u68d2\u7684\u89c6\u89c9\u8ffd\u8e2a\u65b9\u6848\u3002", "method": "\u63d0\u51faAirGlove\u65b9\u6cd5\uff0c\u5728\u96f6\u6837\u672c\u548c\u5fae\u8c03\u4e24\u79cd\u8bbe\u7f6e\u4e0b\uff0c\u5229\u7528\u5df2\u6709\u7684\u624b\u5957\u6570\u636e\u5b66\u4e60\u53ef\u6cdb\u5316\u7684\u624b\u5957\u8868\u5f81\uff0c\u4ee5\u9002\u5e94\u65b0\u7c7b\u578b\u624b\u5957\u7684\u624b\u52bf\u59ff\u6001\u4f30\u8ba1\u3002", "result": "\u5728\u591a\u79cd\u4f20\u611f\u624b\u5957\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAirGlove\u80fd\u6709\u6548\u5c06\u624b\u90e8\u59ff\u6001\u6a21\u578b\u6cdb\u5316\u5230\u65b0\u624b\u5957\u8bbe\u8ba1\u4e0a\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u89c6\u89c9\u9a71\u52a8\u7684\u624b\u90e8\u8ffd\u8e2a\u5728\u6234\u624b\u5957\u573a\u666f\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u89e3\u51b3\u5916\u89c2\u5dee\u5f02\u95ee\u9898\uff1bAirGlove\u901a\u8fc7\u8868\u5f81\u8fc1\u79fb\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u65b0\u624b\u5957\u7684\u9002\u5e94\u6027\u3002", "summary_cn": "\u4f20\u611f\u624b\u5957\u5df2\u6210\u4e3a\u9065\u64cd\u4f5c\u548c\u673a\u5668\u4eba\u7b56\u7565\u5b66\u4e60\u7684\u91cd\u8981\u5de5\u5177\uff0c\u56e0\u5176\u80fd\u591f\u63d0\u4f9b\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u548c\u89e6\u89c9\u53cd\u9988\u7b49\u4e30\u5bcc\u4fe1\u53f7\u3002\u4e00\u79cd\u5e38\u89c1\u7684\u8ffd\u8e2a\u6234\u624b\u5957\u624b\u90e8\u7684\u65b9\u6cd5\u662f\u76f4\u63a5\u4f7f\u7528\u4f20\u611f\u5668\u4fe1\u53f7\uff08\u5982\u89d2\u901f\u5ea6\u3001\u91cd\u529b\u65b9\u5411\uff09\u6765\u4f30\u8ba1\u4e09\u7ef4\u624b\u90e8\u59ff\u6001\u3002\u7136\u800c\uff0c\u57fa\u4e8e\u4f20\u611f\u5668\u7684\u8ffd\u8e2a\u5728\u5b9e\u8df5\u4e2d\u5f80\u5f80\u53d7\u9650\uff0c\u56e0\u4e3a\u5176\u7cbe\u5ea6\u5e38\u53d7\u4f20\u611f\u5668\u4fe1\u53f7\u8d28\u91cf\u548c\u6821\u51c6\u8d28\u91cf\u7684\u5f71\u54cd\u3002\u8fd1\u671f\u57fa\u4e8e\u89c6\u89c9\u7684\u65b9\u6cd5\u901a\u8fc7\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u5728\u4eba\u7c7b\u88f8\u624b\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\uff0c\u4f46\u5b83\u4eec\u5728\u5177\u6709\u663e\u8457\u4e0d\u540c\u89c6\u89c9\u5916\u89c2\u7684\u6234\u624b\u5957\u624b\u90e8\u4e0a\u7684\u8868\u73b0\u4ecd\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002\u672c\u6587\u9996\u6b21\u5bf9\u57fa\u4e8e\u89c6\u89c9\u7684\u624b\u90e8\u8ffd\u8e2a\u6a21\u578b\u5728\u6234\u624b\u5957\u573a\u666f\u4e0b\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6db5\u76d6\u96f6\u6837\u672c\u548c\u5fae\u8c03\u4e24\u79cd\u8bbe\u7f6e\u3002\u5206\u6790\u8868\u660e\uff0c\u73b0\u6709\u88f8\u624b\u6a21\u578b\u7531\u4e8e\u88f8\u624b\u4e0e\u624b\u5957\u8bbe\u8ba1\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5916\u89c2\u5dee\u5f02\uff0c\u5728\u4f20\u611f\u624b\u5957\u4e0a\u6027\u80fd\u5927\u5e45\u4e0b\u964d\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86AirGlove\u65b9\u6cd5\uff0c\u5229\u7528\u5df2\u6709\u624b\u5957\u6570\u636e\u5c06\u6240\u5b66\u7684\u624b\u5957\u8868\u5f81\u6cdb\u5316\u81f3\u4ec5\u6709\u5c11\u91cf\u6570\u636e\u7684\u65b0\u7c7b\u578b\u624b\u5957\u3002\u5728\u591a\u79cd\u4f20\u611f\u624b\u5957\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAirGlove\u80fd\u6709\u6548\u5c06\u624b\u90e8\u59ff\u6001\u6a21\u578b\u6cdb\u5316\u5230\u65b0\u624b\u5957\u8bbe\u8ba1\uff0c\u5e76\u663e\u8457\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6848\u3002"}}
{"id": "2602.05162", "pdf": "https://arxiv.org/pdf/2602.05162", "abs": "https://arxiv.org/abs/2602.05162", "authors": ["Anay Majee", "Rishabh Iyer"], "title": "SHaSaM: Submodular Hard Sample Mining for Fair Facial Attribute Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "21 pages, 7 tables, 10 figures", "summary": "Deep neural networks often inherit social and demographic biases from annotated data during model training, leading to unfair predictions, especially in the presence of sensitive attributes like race, age, gender etc. Existing methods fall prey to the inherent data imbalance between attribute groups and inadvertently emphasize on sensitive attributes, worsening unfairness and performance. To surmount these challenges, we propose SHaSaM (Submodular Hard Sample Mining), a novel combinatorial approach that models fairness-driven representation learning as a submodular hard-sample mining problem. Our two-stage approach comprises of SHaSaM-MINE, which introduces a submodular subset selection strategy to mine hard positives and negatives - effectively mitigating data imbalance, and SHaSaM-LEARN, which introduces a family of combinatorial loss functions based on Submodular Conditional Mutual Information to maximize the decision boundary between target classes while minimizing the influence of sensitive attributes. This unified formulation restricts the model from learning features tied to sensitive attributes, significantly enhancing fairness without sacrificing performance. Experiments on CelebA and UTKFace demonstrate that SHaSaM achieves state-of-the-art results, with up to 2.7 points improvement in model fairness (Equalized Odds) and a 3.5% gain in Accuracy, within fewer epochs as compared to existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSHaSaM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b50\u6a21\u786c\u6837\u672c\u6316\u6398\u63d0\u5347\u6a21\u578b\u516c\u5e73\u6027\u4e0e\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u4e2d\u6613\u4ece\u6807\u6ce8\u6570\u636e\u7ee7\u627f\u793e\u4f1a\u548c\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\uff0c\u5bfc\u81f4\u5bf9\u79cd\u65cf\u3001\u5e74\u9f84\u3001\u6027\u522b\u7b49\u654f\u611f\u5c5e\u6027\u7684\u4e0d\u516c\u5e73\u9884\u6d4b\uff1b\u73b0\u6709\u65b9\u6cd5\u56e0\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u53cd\u800c\u52a0\u5267\u4e86\u4e0d\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51faSHaSaM\uff08Submodular Hard Sample Mining\uff09\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1aSHaSaM-MINE\u5229\u7528\u5b50\u6a21\u5b50\u96c6\u9009\u62e9\u7b56\u7565\u6316\u6398\u96be\u6b63\u8d1f\u6837\u672c\u4ee5\u7f13\u89e3\u6570\u636e\u4e0d\u5e73\u8861\uff1bSHaSaM-LEARN\u57fa\u4e8e\u5b50\u6a21\u6761\u4ef6\u4e92\u4fe1\u606f\u8bbe\u8ba1\u7ec4\u5408\u635f\u5931\u51fd\u6570\uff0c\u5728\u6700\u5927\u5316\u76ee\u6807\u7c7b\u522b\u51b3\u7b56\u8fb9\u754c\u7684\u540c\u65f6\u6700\u5c0f\u5316\u654f\u611f\u5c5e\u6027\u5f71\u54cd\u3002", "result": "\u5728CelebA\u548cUTKFace\u6570\u636e\u96c6\u4e0a\uff0cSHaSaM\u5728\u66f4\u5c11\u8bad\u7ec3\u8f6e\u6b21\u5185\u5b9e\u73b0SOTA\u7ed3\u679c\uff0cEqualized Odds\u516c\u5e73\u6027\u6307\u6807\u63d0\u5347\u6700\u591a2.7\u70b9\uff0c\u51c6\u786e\u7387\u63d0\u9ad83.5%\u3002", "conclusion": "SHaSaM\u901a\u8fc7\u7edf\u4e00\u7684\u5b50\u6a21\u4f18\u5316\u6846\u67b6\u6709\u6548\u6291\u5236\u6a21\u578b\u5b66\u4e60\u654f\u611f\u5c5e\u6027\u76f8\u5173\u7279\u5f81\uff0c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u516c\u5e73\u6027\u3002", "summary_cn": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e38\u5e38\u4ece\u6807\u6ce8\u6570\u636e\u4e2d\u7ee7\u627f\u793e\u4f1a\u548c\u4eba\u53e3\u7edf\u8ba1\u504f\u89c1\uff0c\u5bfc\u81f4\u4e0d\u516c\u5e73\u7684\u9884\u6d4b\uff0c\u5c24\u5176\u662f\u5728\u5b58\u5728\u79cd\u65cf\u3001\u5e74\u9f84\u3001\u6027\u522b\u7b49\u654f\u611f\u5c5e\u6027\u7684\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5c5e\u6027\u7ec4\u4e4b\u95f4\u56fa\u6709\u6570\u636e\u4e0d\u5e73\u8861\u7684\u5f71\u54cd\uff0c\u65e0\u610f\u4e2d\u5f3a\u5316\u4e86\u5bf9\u654f\u611f\u5c5e\u6027\u7684\u5173\u6ce8\uff0c\u4ece\u800c\u52a0\u5267\u4e86\u4e0d\u516c\u5e73\u6027\u548c\u6027\u80fd\u4e0b\u964d\u3002\u4e3a\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86SHaSaM\uff08Submodular Hard Sample Mining\uff09\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u9762\u5411\u516c\u5e73\u6027\u7684\u8868\u5f81\u5b66\u4e60\u5efa\u6a21\u4e3a\u5b50\u6a21\u786c\u6837\u672c\u6316\u6398\u95ee\u9898\u3002\u6211\u4eec\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u5305\u62ec\uff1aSHaSaM-MINE\uff0c\u5f15\u5165\u5b50\u6a21\u5b50\u96c6\u9009\u62e9\u7b56\u7565\u6765\u6316\u6398\u96be\u6b63\u6837\u672c\u548c\u96be\u8d1f\u6837\u672c\uff0c\u6709\u6548\u7f13\u89e3\u6570\u636e\u4e0d\u5e73\u8861\uff1b\u4ee5\u53caSHaSaM-LEARN\uff0c\u57fa\u4e8e\u5b50\u6a21\u6761\u4ef6\u4e92\u4fe1\u606f\u6784\u5efa\u4e00\u7c7b\u7ec4\u5408\u635f\u5931\u51fd\u6570\uff0c\u5728\u6700\u5927\u5316\u76ee\u6807\u7c7b\u522b\u95f4\u51b3\u7b56\u8fb9\u754c\u7684\u540c\u65f6\u6700\u5c0f\u5316\u654f\u611f\u5c5e\u6027\u7684\u5f71\u54cd\u3002\u8fd9\u4e00\u7edf\u4e00\u6846\u67b6\u9650\u5236\u6a21\u578b\u5b66\u4e60\u4e0e\u654f\u611f\u5c5e\u6027\u76f8\u5173\u7684\u7279\u5f81\uff0c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u516c\u5e73\u6027\u3002\u5728CelebA\u548cUTKFace\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSHaSaM\u53d6\u5f97\u4e86\u5f53\u524d\u6700\u4f18\u7ed3\u679c\uff0c\u5728\u66f4\u5c11\u7684\u8bad\u7ec3\u8f6e\u6b21\u5185\uff0c\u6a21\u578b\u516c\u5e73\u6027\uff08Equalized Odds\uff09\u6700\u591a\u63d0\u53472.7\u70b9\uff0c\u51c6\u786e\u7387\u63d0\u9ad83.5%\u3002"}}
{"id": "2602.05163", "pdf": "https://arxiv.org/pdf/2602.05163", "abs": "https://arxiv.org/abs/2602.05163", "authors": ["Andreas Mentzelopoulos", "Keith Ellenbogen"], "title": "LOBSTgER-enhance: an underwater image enhancement pipeline", "categories": ["cs.CV"], "comment": "12 pages, 30 figures, work done as part of LOBSTgER", "summary": "Underwater photography presents significant inherent challenges including reduced contrast, spatial blur, and wavelength-dependent color distortions. These effects can obscure the vibrancy of marine life and awareness photographers in particular are often challenged with heavy post-processing pipelines to correct for these distortions.\n  We develop an image-to-image pipeline that learns to reverse underwater degradations by introducing a synthetic corruption pipeline and learning to reverse its effects with diffusion-based generation. Training and evaluation are performed on a small high-quality dataset of awareness photography images by Keith Ellenbogen. The proposed methodology achieves high perceptual consistency and strong generalization in synthesizing 512x768 images using a model of ~11M parameters after training from scratch on ~2.5k images.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u56fe\u50cf\u5230\u56fe\u50cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u6210\u6c34\u4e0b\u9000\u5316\u6548\u679c\u5e76\u5b66\u4e60\u9006\u8f6c\u8fd9\u4e9b\u9000\u5316\uff0c\u4ece\u800c\u6709\u6548\u589e\u5f3a\u6c34\u4e0b\u6444\u5f71\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u6c34\u4e0b\u6444\u5f71\u5b58\u5728\u5bf9\u6bd4\u5ea6\u964d\u4f4e\u3001\u7a7a\u95f4\u6a21\u7cca\u548c\u6ce2\u957f\u76f8\u5173\u7684\u8272\u5f69\u5931\u771f\u7b49\u56fa\u6709\u6311\u6218\uff0c\u4e25\u91cd\u5f71\u54cd\u6d77\u6d0b\u751f\u7269\u7684\u89c6\u89c9\u8868\u73b0\u529b\uff0c\u6444\u5f71\u5e08\u901a\u5e38\u9700\u4f9d\u8d56\u7e41\u91cd\u7684\u540e\u671f\u5904\u7406\u6765\u6821\u6b63\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5408\u6210\u6c34\u4e0b\u9000\u5316\u6548\u679c\u7684\u6d41\u7a0b\uff0c\u5e76\u5229\u7528\u6269\u6563\u751f\u6210\u6a21\u578b\u5b66\u4e60\u9006\u8f6c\u8fd9\u4e9b\u9000\u5316\uff1b\u5728Keith Ellenbogen\u63d0\u4f9b\u7684\u9ad8\u8d28\u91cf\u5c0f\u89c4\u6a21\u6c34\u4e0b\u610f\u8bc6\u6444\u5f71\u6570\u636e\u96c6\u4e0a\u4ece\u5934\u8bad\u7ec3\u7ea61100\u4e07\u53c2\u6570\u7684\u6a21\u578b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4ec5\u4f7f\u7528\u7ea62500\u5f20\u56fe\u50cf\u8bad\u7ec3\u540e\uff0c\u80fd\u751f\u6210512x768\u5206\u8fa8\u7387\u7684\u56fe\u50cf\uff0c\u5728\u611f\u77e5\u4e00\u81f4\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6269\u6563\u7684\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u6c34\u4e0b\u6444\u5f71\u4e2d\u7684\u5178\u578b\u9000\u5316\u95ee\u9898\uff0c\u4e3a\u6c34\u4e0b\u56fe\u50cf\u590d\u539f\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "summary_cn": "\u6c34\u4e0b\u6444\u5f71\u5b58\u5728\u663e\u8457\u7684\u56fa\u6709\u6311\u6218\uff0c\u5305\u62ec\u5bf9\u6bd4\u5ea6\u964d\u4f4e\u3001\u7a7a\u95f4\u6a21\u7cca\u4ee5\u53ca\u4e0e\u6ce2\u957f\u76f8\u5173\u7684\u8272\u5f69\u5931\u771f\u3002\u8fd9\u4e9b\u6548\u5e94\u4f1a\u63a9\u76d6\u6d77\u6d0b\u751f\u7269\u7684\u751f\u52a8\u6027\uff0c\u5c24\u5176\u5bf9\u6ce8\u91cd\u751f\u6001\u610f\u8bc6\u7684\u6444\u5f71\u5e08\u800c\u8a00\uff0c\u5f80\u5f80\u9700\u8981\u4f9d\u8d56\u7e41\u91cd\u7684\u540e\u671f\u5904\u7406\u6d41\u7a0b\u6765\u6821\u6b63\u8fd9\u4e9b\u5931\u771f\u3002\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u5904\u7406\u6d41\u7a0b\uff0c\u901a\u8fc7\u5f15\u5165\u5408\u6210\u7684\u6c34\u4e0b\u9000\u5316\u6d41\u7a0b\uff0c\u5e76\u5229\u7528\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\u5b66\u4e60\u9006\u8f6c\u8fd9\u4e9b\u9000\u5316\u6548\u5e94\u3002\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u57fa\u4e8eKeith Ellenbogen\u63d0\u4f9b\u7684\u5c0f\u89c4\u6a21\u9ad8\u8d28\u91cf\u751f\u6001\u610f\u8bc6\u6444\u5f71\u56fe\u50cf\u6570\u636e\u96c6\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7ea62500\u5f20\u56fe\u50cf\u540e\uff0c\u4f7f\u7528\u7ea61100\u4e07\u53c2\u6570\u7684\u6a21\u578b\u5373\u53ef\u751f\u6210512\u00d7768\u5206\u8fa8\u7387\u7684\u56fe\u50cf\uff0c\u5728\u611f\u77e5\u4e00\u81f4\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
