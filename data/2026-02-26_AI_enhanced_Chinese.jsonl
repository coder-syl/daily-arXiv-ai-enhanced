{"id": "2602.21273", "pdf": "https://arxiv.org/pdf/2602.21273", "abs": "https://arxiv.org/abs/2602.21273", "authors": ["Jinghao Hu", "Yuhe Zhang", "GuoHua Geng", "Kang Li", "Han Zhang"], "title": "StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives", "categories": ["cs.CV"], "comment": "24 pages,19 figures,accepted by CVPR2026", "summary": "Generating multi-frame, action-rich visual narratives without fine-tuning faces a threefold tension: action text faithfulness, subject identity fidelity, and cross-frame background continuity. We propose StoryTailor, a zero-shot pipeline that runs on a single RTX 4090 (24 GB) and produces temporally coherent, identity-preserving image sequences from a long narrative prompt, per-subject references, and grounding boxes. Three synergistic modules drive the system: Gaussian-Centered Attention (GCA) to dynamically focus on each subject core and ease grounding-box overlaps; Action-Boost Singular Value Reweighting (AB-SVR) to amplify action-related directions in the text embedding space; and Selective Forgetting Cache (SFC) that retains transferable background cues, forgets nonessential history, and selectively surfaces retained cues to build cross-scene semantic ties. Compared with baseline methods, experiments show that CLIP-T improves by up to 10-15%, with DreamSim lower than strong baselines, while CLIP-I stays in a visually acceptable, competitive range. With matched resolution and steps on a 24 GB GPU, inference is faster than FluxKontext. Qualitatively, StoryTailor delivers expressive interactions and evolving yet stable scenes.", "AI": {"tldr": "StoryTailor is a zero-shot pipeline that generates temporally coherent, multi-frame visual narratives with preserved subject identity and background continuity using only a single RTX 4090 GPU.", "motivation": "Existing methods struggle to simultaneously maintain action faithfulness to text, subject identity consistency, and background continuity across frames without fine-tuning.", "method": "StoryTailor employs three modules: Gaussian-Centered Attention (GCA) for subject focus and grounding-box handling, Action-Boost Singular Value Reweighting (AB-SVR) to enhance action-related text embeddings, and Selective Forgetting Cache (SFC) to manage background continuity by retaining useful cues and discarding irrelevant history.", "result": "Experiments show CLIP-T scores improve by 10\u201315%, DreamSim scores are lower than strong baselines, and CLIP-I remains competitive; inference is faster than FluxKontext under matched settings, with qualitative improvements in scene stability and expressiveness.", "conclusion": "StoryTailor effectively addresses the triad of challenges in zero-shot narrative image generation, achieving high-quality, coherent multi-frame outputs on consumer-grade hardware.", "summary_cn": "\u5728\u65e0\u9700\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u591a\u5e27\u3001\u52a8\u4f5c\u4e30\u5bcc\u7684\u89c6\u89c9\u53d9\u4e8b\u9762\u4e34\u4e09\u91cd\u6311\u6218\uff1a\u5bf9\u52a8\u4f5c\u6587\u672c\u7684\u5fe0\u5b9e\u5ea6\u3001\u4e3b\u4f53\u8eab\u4efd\u7684\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u8de8\u5e27\u80cc\u666f\u7684\u8fde\u7eed\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86 StoryTailor\uff0c\u4e00\u79cd\u96f6\u6837\u672c\u6d41\u6c34\u7ebf\uff0c\u4ec5\u9700\u5355\u5757 RTX 4090\uff0824 GB\uff09\u663e\u5361\uff0c\u5373\u53ef\u6839\u636e\u957f\u7bc7\u53d9\u4e8b\u63d0\u793a\u3001\u6bcf\u4e2a\u4e3b\u4f53\u7684\u53c2\u8003\u56fe\u50cf\u548c\u5b9a\u4f4d\u6846\uff0c\u751f\u6210\u65f6\u95f4\u4e0a\u8fde\u8d2f\u4e14\u8eab\u4efd\u4fdd\u6301\u4e00\u81f4\u7684\u56fe\u50cf\u5e8f\u5217\u3002\u8be5\u7cfb\u7edf\u7531\u4e09\u4e2a\u534f\u540c\u6a21\u5757\u9a71\u52a8\uff1a\u9ad8\u65af\u4e2d\u5fc3\u6ce8\u610f\u529b\uff08GCA\uff09\u52a8\u6001\u805a\u7126\u4e8e\u6bcf\u4e2a\u4e3b\u4f53\u6838\u5fc3\u5e76\u7f13\u89e3\u5b9a\u4f4d\u6846\u91cd\u53e0\uff1b\u52a8\u4f5c\u589e\u5f3a\u5947\u5f02\u503c\u91cd\u52a0\u6743\uff08AB-SVR\uff09\u5728\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u4e2d\u653e\u5927\u4e0e\u52a8\u4f5c\u76f8\u5173\u7684\u4fe1\u606f\u65b9\u5411\uff1b\u9009\u62e9\u6027\u9057\u5fd8\u7f13\u5b58\uff08SFC\uff09\u4fdd\u7559\u53ef\u8fc1\u79fb\u7684\u80cc\u666f\u7ebf\u7d22\uff0c\u9057\u5fd8\u975e\u5fc5\u8981\u5386\u53f2\uff0c\u5e76\u6709\u9009\u62e9\u5730\u8c03\u7528\u4fdd\u7559\u7ebf\u7d22\u4ee5\u6784\u5efa\u8de8\u573a\u666f\u7684\u8bed\u4e49\u5173\u8054\u3002\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b9e\u9a8c\u8868\u660e CLIP-T \u6307\u6807\u63d0\u5347\u9ad8\u8fbe 10\u201315%\uff0cDreamSim \u8868\u73b0\u4f4e\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u800c CLIP-I \u4fdd\u6301\u5728\u89c6\u89c9\u4e0a\u53ef\u63a5\u53d7\u4e14\u5177\u7ade\u4e89\u529b\u7684\u6c34\u5e73\u3002\u5728\u76f8\u540c\u5206\u8fa8\u7387\u548c\u6b65\u6570\u4e0b\uff0cStoryTailor \u5728 24 GB GPU \u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u4f18\u4e8e FluxKontext\u3002\u5b9a\u6027\u6765\u770b\uff0cStoryTailor \u80fd\u751f\u6210\u5bcc\u6709\u8868\u73b0\u529b\u7684\u4ea4\u4e92\u548c\u65e2\u6f14\u53d8\u53c8\u7a33\u5b9a\u7684\u573a\u666f\u3002"}}
{"id": "2602.21333", "pdf": "https://arxiv.org/pdf/2602.21333", "abs": "https://arxiv.org/abs/2602.21333", "authors": ["Yifan Wang", "Francesco Pittaluga", "Zaid Tasneem", "Chenyu You", "Manmohan Chandraker", "Ziyu Jiang"], "title": "HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2026", "summary": "Controllable driving scene generation is critical for realistic and scalable autonomous driving simulation, yet existing approaches struggle to jointly achieve photorealism and precise control. We introduce HorizonForge, a unified framework that reconstructs scenes as editable Gaussian Splats and Meshes, enabling fine-grained 3D manipulation and language-driven vehicle insertion. Edits are rendered through a noise-aware video diffusion process that enforces spatial and temporal consistency, producing diverse scene variations in a single feed-forward pass without per-trajectory optimization. To standardize evaluation, we further propose HorizonSuite, a comprehensive benchmark spanning ego- and agent-level editing tasks such as trajectory modifications and object manipulation. Extensive experiments show that Gaussian-Mesh representation delivers substantially higher fidelity than alternative 3D representations, and that temporal priors from video diffusion are essential for coherent synthesis. Combining these findings, HorizonForge establishes a simple yet powerful paradigm for photorealistic, controllable driving simulation, achieving an 83.4% user-preference gain and a 25.19% FID improvement over the second best state-of-the-art method. Project page: https://horizonforge.github.io/ .", "AI": {"tldr": "HorizonForge \u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u7f16\u8f91\u7684\u9ad8\u65af\u70b9\u4e91\u4e0e\u7f51\u683c\u8868\u793a\u548c\u566a\u58f0\u611f\u77e5\u89c6\u9891\u6269\u6563\u6e32\u67d3\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u3001\u53ef\u63a7\u7684\u9a7e\u9a76\u573a\u666f\u751f\u6210\uff0c\u5e76\u5728\u65b0\u57fa\u51c6 HorizonSuite \u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u9a7e\u9a76\u573a\u666f\u751f\u6210\u4e2d\u7684\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u548c\u7cbe\u786e\u63a7\u5236\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u9a7e\u9a76\u4eff\u771f\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa HorizonForge \u6846\u67b6\uff1a1\uff09\u5c06\u573a\u666f\u91cd\u5efa\u4e3a\u53ef\u7f16\u8f91\u7684\u9ad8\u65af\u70b9\u4e91\uff08Gaussian Splats\uff09\u548c\u7f51\u683c\uff08Meshes\uff09\uff1b2\uff09\u652f\u6301\u7ec6\u7c92\u5ea63D\u64cd\u4f5c\u548c\u8bed\u8a00\u9a71\u52a8\u7684\u8f66\u8f86\u63d2\u5165\uff1b3\uff09\u901a\u8fc7\u566a\u58f0\u611f\u77e5\u89c6\u9891\u6269\u6563\u8fc7\u7a0b\u6e32\u67d3\u7f16\u8f91\u7ed3\u679c\uff0c\u786e\u4fdd\u65f6\u7a7a\u4e00\u81f4\u6027\uff0c\u65e0\u9700\u9010\u8f68\u8ff9\u4f18\u5316\uff1b4\uff09\u5f15\u5165\u65b0\u57fa\u51c6 HorizonSuite \u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9ad8\u65af-\u7f51\u683c\u8868\u793a\u6bd4\u5176\u4ed63D\u8868\u793a\u5177\u6709\u66f4\u9ad8\u4fdd\u771f\u5ea6\uff0c\u89c6\u9891\u6269\u6563\u4e2d\u7684\u65f6\u95f4\u5148\u9a8c\u5bf9\u4e00\u81f4\u5408\u6210\u81f3\u5173\u91cd\u8981\u3002HorizonForge \u5728\u7528\u6237\u504f\u597d\u4e0a\u63d0\u534783.4%\uff0cFID\u6307\u6807\u63d0\u534725.19%\uff0c\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u3002", "conclusion": "HorizonForge \u4e3a\u53ef\u63a7\u3001\u9ad8\u4fdd\u771f\u7684\u81ea\u52a8\u9a7e\u9a76\u4eff\u771f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u5f3a\u5927\u7684\u65b0\u8303\u5f0f\uff0c\u7ed3\u5408\u53ef\u7f16\u8f913D\u8868\u793a\u4e0e\u65f6\u7a7a\u4e00\u81f4\u7684\u6269\u6563\u6e32\u67d3\uff0c\u5728\u8d28\u91cf\u548c\u53ef\u63a7\u6027\u4e0a\u53d6\u5f97\u7a81\u7834\u3002", "summary_cn": "\u53ef\u63a7\u9a7e\u9a76\u573a\u666f\u751f\u6210\u5bf9\u4e8e\u5b9e\u73b0\u903c\u771f\u4e14\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u9a7e\u9a76\u4eff\u771f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u548c\u7cbe\u786e\u63a7\u5236\u3002\u6211\u4eec\u63d0\u51fa\u4e86 HorizonForge\uff0c\u8fd9\u662f\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u573a\u666f\u91cd\u5efa\u4e3a\u53ef\u7f16\u8f91\u7684\u9ad8\u65af\u70b9\u4e91\u548c\u7f51\u683c\uff0c\u4ece\u800c\u652f\u6301\u7ec6\u7c92\u5ea6\u7684\u4e09\u7ef4\u64cd\u63a7\u4ee5\u53ca\u57fa\u4e8e\u8bed\u8a00\u6307\u4ee4\u7684\u8f66\u8f86\u63d2\u5165\u3002\u7f16\u8f91\u7ed3\u679c\u901a\u8fc7\u4e00\u79cd\u566a\u58f0\u611f\u77e5\u7684\u89c6\u9891\u6269\u6563\u8fc7\u7a0b\u8fdb\u884c\u6e32\u67d3\uff0c\u8be5\u8fc7\u7a0b\u5f3a\u5236\u4fdd\u8bc1\u7a7a\u95f4\u548c\u65f6\u95f4\u4e00\u81f4\u6027\uff0c\u80fd\u591f\u5728\u5355\u6b21\u524d\u9988\u8fc7\u7a0b\u4e2d\u751f\u6210\u591a\u6837\u5316\u7684\u573a\u666f\u53d8\u4f53\uff0c\u800c\u65e0\u9700\u9488\u5bf9\u6bcf\u6761\u8f68\u8ff9\u8fdb\u884c\u4f18\u5316\u3002\u4e3a\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\uff0c\u6211\u4eec\u8fdb\u4e00\u6b65\u63d0\u51fa\u4e86 HorizonSuite\uff0c\u8fd9\u662f\u4e00\u4e2a\u6db5\u76d6\u81ea\u8f66\u548c\u4ed6\u8f66\u5c42\u9762\u7f16\u8f91\u4efb\u52a1\uff08\u5982\u8f68\u8ff9\u4fee\u6539\u548c\u7269\u4f53\u64cd\u63a7\uff09\u7684\u7efc\u5408\u6027\u57fa\u51c6\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u9ad8\u65af-\u7f51\u683c\u8868\u793a\u76f8\u6bd4\u5176\u4ed6\u4e09\u7ef4\u8868\u793a\u80fd\u663e\u8457\u63d0\u5347\u4fdd\u771f\u5ea6\uff0c\u800c\u89c6\u9891\u6269\u6563\u4e2d\u7684\u65f6\u95f4\u5148\u9a8c\u5bf9\u4e8e\u8fde\u8d2f\u5408\u6210\u81f3\u5173\u91cd\u8981\u3002\u7ed3\u5408\u8fd9\u4e9b\u53d1\u73b0\uff0cHorizonForge \u5efa\u7acb\u4e86\u4e00\u79cd\u7b80\u5355\u800c\u5f3a\u5927\u7684\u8303\u5f0f\uff0c\u7528\u4e8e\u5b9e\u73b0\u7167\u7247\u7ea7\u771f\u5b9e\u611f\u4e14\u53ef\u63a7\u7684\u9a7e\u9a76\u4eff\u771f\uff0c\u5728\u7528\u6237\u504f\u597d\u4e0a\u6bd4\u7b2c\u4e8c\u4f18\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u5347\u4e8683.4%\uff0cFID\u6307\u6807\u63d0\u5347\u4e8625.19%\u3002\u9879\u76ee\u9875\u9762\uff1ahttps://horizonforge.github.io/\u3002"}}
{"id": "2602.21341", "pdf": "https://arxiv.org/pdf/2602.21341", "abs": "https://arxiv.org/abs/2602.21341", "authors": ["Evan Kim", "Hyunwoo Ryu", "Thomas W. Mitchel", "Vincent Sitzmann"], "title": "Scaling View Synthesis Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://www.evn.kim/research/svsm", "summary": "Geometry-free view synthesis transformers have recently achieved state-of-the-art performance in Novel View Synthesis (NVS), outperforming traditional approaches that rely on explicit geometry modeling. Yet the factors governing their scaling with compute remain unclear. We present a systematic study of scaling laws for view synthesis transformers and derive design principles for training compute-optimal NVS models. Contrary to prior findings, we show that encoder-decoder architectures can be compute-optimal; we trace earlier negative results to suboptimal architectural choices and comparisons across unequal training compute budgets. Across several compute levels, we demonstrate that our encoder-decoder architecture, which we call the Scalable View Synthesis Model (SVSM), scales as effectively as decoder-only models, achieves a superior performance-compute Pareto frontier, and surpasses the previous state-of-the-art on real-world NVS benchmarks with substantially reduced training compute.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u89c6\u56fe\u5408\u6210Transformer\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784SVSM\uff0c\u5728\u591a\u4e2a\u8ba1\u7b97\u91cf\u7ea7\u4e0a\u4f18\u4e8e\u7eaf\u89e3\u7801\u5668\u6a21\u578b\uff0c\u5e76\u4ee5\u66f4\u5c11\u8bad\u7ec3\u8ba1\u7b97\u91cf\u8fbe\u5230\u65b0\u7684SOTA\u3002", "motivation": "\u73b0\u6709\u51e0\u4f55\u65e0\u5173\u7684\u89c6\u56fe\u5408\u6210Transformer\u867d\u5728\u65b0\u89c6\u89d2\u5408\u6210\uff08NVS\uff09\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u968f\u8ba1\u7b97\u8d44\u6e90\u589e\u52a0\u7684\u7f29\u653e\u89c4\u5f8b\u5c1a\u4e0d\u660e\u786e\uff0c\u4e14\u6b64\u524d\u5bf9\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684\u8bc4\u4f30\u5b58\u5728\u504f\u5dee\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u5206\u6790\u4e86\u4e0d\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u89c6\u56fe\u5408\u6210Transformer\u7f29\u653e\u884c\u4e3a\uff0c\u63d0\u51fa\u540d\u4e3aScalable View Synthesis Model (SVSM)\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u53d8\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd\u4f18\u52bf\u3002", "result": "SVSM\u5728\u591a\u4e2a\u8ba1\u7b97\u7ea7\u522b\u4e0a\u4e0e\u7eaf\u89e3\u7801\u5668\u6a21\u578b\u5177\u6709\u76f8\u5f53\u7684\u7f29\u653e\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6027\u80fd-\u8ba1\u7b97\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754cNVS\u57fa\u51c6\u4e0a\u4ee5\u663e\u8457\u51cf\u5c11\u7684\u8bad\u7ec3\u8ba1\u7b97\u91cf\u8d85\u8d8a\u5148\u524dSOTA\u3002", "conclusion": "\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u5728\u5408\u7406\u8bbe\u8ba1\u4e0b\u53ef\u6210\u4e3a\u8ba1\u7b97\u6700\u4f18\u7684NVS\u6a21\u578b\uff0c\u5148\u524d\u5bf9\u5176\u4e0d\u5229\u7684\u7ed3\u8bba\u6e90\u4e8e\u6b21\u4f18\u67b6\u6784\u9009\u62e9\u548c\u4e0d\u516c\u5e73\u7684\u8ba1\u7b97\u9884\u7b97\u6bd4\u8f83\u3002", "summary_cn": "\u51e0\u4f55\u65e0\u5173\u7684\u89c6\u56fe\u5408\u6210Transformer\u6700\u8fd1\u5728\u65b0\u89c6\u89d2\u5408\u6210\uff08NVS\uff09\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u663e\u5f0f\u51e0\u4f55\u5efa\u6a21\u7684\u4f20\u7edf\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5176\u6027\u80fd\u968f\u8ba1\u7b97\u8d44\u6e90\u589e\u52a0\u7684\u7f29\u653e\u89c4\u5f8b\u4ecd\u4e0d\u6e05\u695a\u3002\u6211\u4eec\u5bf9\u89c6\u56fe\u5408\u6210Transformer\u7684\u7f29\u653e\u89c4\u5f8b\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u5e76\u63a8\u5bfc\u51fa\u8bad\u7ec3\u8ba1\u7b97\u6700\u4f18NVS\u6a21\u578b\u7684\u8bbe\u8ba1\u539f\u5219\u3002\u4e0e\u4ee5\u5f80\u7684\u7814\u7a76\u7ed3\u8bba\u76f8\u53cd\uff0c\u6211\u4eec\u8bc1\u660e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u53ef\u4ee5\u662f\u8ba1\u7b97\u6700\u4f18\u7684\uff1b\u6211\u4eec\u5c06\u65e9\u671f\u7684\u8d1f\u9762\u7ed3\u679c\u5f52\u56e0\u4e8e\u6b21\u4f18\u7684\u67b6\u6784\u9009\u62e9\u4ee5\u53ca\u5728\u4e0d\u7b49\u8bad\u7ec3\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u4e0d\u516c\u5e73\u6bd4\u8f83\u3002\u5728\u591a\u4e2a\u8ba1\u7b97\u91cf\u7ea7\u4e0a\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff08\u79f0\u4e3a\u53ef\u6269\u5c55\u89c6\u56fe\u5408\u6210\u6a21\u578b\uff0cSVSM\uff09\u5c55\u73b0\u51fa\u4e0e\u7eaf\u89e3\u7801\u5668\u6a21\u578b\u76f8\u5f53\u7684\u7f29\u653e\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6027\u80fd-\u8ba1\u7b97\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754cNVS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4ee5\u663e\u8457\u51cf\u5c11\u7684\u8bad\u7ec3\u8ba1\u7b97\u91cf\u8d85\u8d8a\u4e86\u5148\u524d\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2602.21365", "pdf": "https://arxiv.org/pdf/2602.21365", "abs": "https://arxiv.org/abs/2602.21365", "authors": ["Dominik Schneider", "Lalithkumar Seenivasan", "Sampath Rapuri", "Vishalroshan Anil", "Aiza Maksutova", "Yiqing Shen", "Jan Emily Mangulabnan", "Hao Ding", "Jose L. Porras", "Masaru Ishii", "Mathias Unberath"], "title": "Towards Controllable Video Synthesis of Routine and Rare OR Events", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "Accepted to IPCAI 2026 and submitted to IJCARs", "summary": "Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR.\n  Methods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations.\n  Results: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices.\n  Conclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u624b\u672f\u5ba4\u89c6\u9891\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u51e0\u4f55\u62bd\u8c61\u548c\u6761\u4ef6\u63a7\u5236\u751f\u6210\u7f55\u89c1\u4e14\u5b89\u5168\u5173\u952e\u4e8b\u4ef6\u7684\u903c\u771f\u89c6\u9891\uff0c\u5e76\u5229\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3AI\u6a21\u578b\u4ee5\u68c0\u6d4b\u65e0\u83cc\u533a\u8fdd\u89c4\u4e34\u8fd1\u4e8b\u4ef6\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u63d0\u5347\u73af\u5883\u667a\u80fd\u7cfb\u7edf\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u4f26\u7406\u548c\u64cd\u4f5c\u4e0a\u7684\u56f0\u96be\uff0c\u96be\u4ee5\u6536\u96c6\u5305\u542b\u7f55\u89c1\u3001\u5b89\u5168\u5173\u952e\u6216\u975e\u5178\u578b\u4e8b\u4ef6\u7684\u5927\u89c4\u6a21\u624b\u672f\u5ba4\u5de5\u4f5c\u6d41\u6570\u636e\u96c6\uff0c\u8fd9\u9650\u5236\u4e86\u7528\u4e8e\u68c0\u6d4b\u3001\u7406\u89e3\u548c\u7f13\u89e3\u6b64\u7c7b\u4e8b\u4ef6\u7684\u73af\u5883\u667a\u80fd\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u624b\u672f\u5ba4\u89c6\u9891\u6269\u6563\u6846\u67b6\uff0c\u6574\u5408\u4e86\u51e0\u4f55\u62bd\u8c61\u6a21\u5757\u3001\u6761\u4ef6\u63a7\u5236\u6a21\u5757\u548c\u5fae\u8c03\u540e\u7684\u6269\u6563\u6a21\u578b\uff1a\u9996\u5148\u5c06\u624b\u672f\u5ba4\u573a\u666f\u8f6c\u6362\u4e3a\u62bd\u8c61\u51e0\u4f55\u8868\u793a\uff0c\u518d\u4ee5\u6b64\u4e3a\u6761\u4ef6\u5f15\u5bfc\u5408\u6210\u8fc7\u7a0b\uff0c\u6700\u7ec8\u751f\u6210\u903c\u771f\u7684\u624b\u672f\u5ba4\u4e8b\u4ef6\u89c6\u9891\uff1b\u5e76\u57fa\u4e8e\u6b64\u6846\u67b6\u6784\u5efa\u4e86\u4e00\u4e2a\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u65e0\u83cc\u533a\u8fdd\u89c4\u4e34\u8fd1\u4e8b\u4ef6\u7684\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u5728\u5e38\u89c4\u624b\u672f\u5ba4\u4e8b\u4ef6\u89c6\u9891\u5408\u6210\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6210\u7684\u89c6\u9891\u6269\u6563\u57fa\u7ebf\uff0c\u5728\u57df\u5185\u548c\u57df\u5916\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u66f4\u4f4e\u7684FVD/LPIPS\u548c\u66f4\u9ad8\u7684SSIM/PSNR\uff1b\u5b9a\u6027\u7ed3\u679c\u5c55\u793a\u4e86\u5176\u53ef\u63a7\u5408\u6210\u53cd\u4e8b\u5b9e\u4e8b\u4ef6\u7684\u80fd\u529b\uff1b\u57fa\u4e8e\u5408\u6210\u6570\u636e\u8bad\u7ec3\u7684AI\u6a21\u578b\u5728\u68c0\u6d4b\u4e34\u8fd1\u5b89\u5168\u5173\u952e\u4e8b\u4ef6\u65f6\u8fbe\u523070.13%\u7684\u53ec\u56de\u7387\uff1b\u6d88\u878d\u5b9e\u9a8c\u91cf\u5316\u4e86\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u62bd\u8c61\u51e0\u4f55\u8868\u793a\u4e2d\u53ef\u63a7\u5730\u5408\u6210\u5e38\u89c4\u548c\u7f55\u89c1\u7684\u624b\u672f\u5ba4\u4e8b\u4ef6\u89c6\u9891\uff0c\u4e0d\u4ec5\u6210\u529f\u751f\u6210\u4e86\u7f55\u89c1\u4e14\u5b89\u5168\u5173\u952e\u7684\u573a\u666f\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u5728\u652f\u6301\u73af\u5883\u667a\u80fd\u6a21\u578b\u5f00\u53d1\u65b9\u9762\u7684\u5e94\u7528\u6f5c\u529b\u3002", "summary_cn": "\u76ee\u7684\uff1a\u6574\u7406\u6db5\u76d6\u7f55\u89c1\u3001\u5b89\u5168\u5173\u952e\u6216\u975e\u5178\u578b\u4e8b\u4ef6\u7684\u5927\u89c4\u6a21\u624b\u672f\u5ba4\uff08OR\uff09\u5de5\u4f5c\u6d41\u6570\u636e\u96c6\uff0c\u5728\u64cd\u4f5c\u548c\u4f26\u7406\u5c42\u9762\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002\u8fd9\u4e00\u6570\u636e\u74f6\u9888\u4f7f\u5f97\u5f00\u53d1\u7528\u4e8e\u68c0\u6d4b\u3001\u7406\u89e3\u548c\u7f13\u89e3\u624b\u672f\u5ba4\u4e2d\u7f55\u89c1\u6216\u5b89\u5168\u5173\u952e\u4e8b\u4ef6\u7684\u73af\u5883\u667a\u80fd\u7cfb\u7edf\u53d8\u5f97\u590d\u6742\u3002  \n\u65b9\u6cd5\uff1a\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u624b\u672f\u5ba4\u89c6\u9891\u6269\u6563\u6846\u67b6\uff0c\u53ef\u5b9e\u73b0\u5bf9\u7f55\u89c1\u53ca\u5b89\u5168\u5173\u952e\u4e8b\u4ef6\u7684\u53ef\u63a7\u5408\u6210\u3002\u8be5\u6846\u67b6\u6574\u5408\u4e86\u51e0\u4f55\u62bd\u8c61\u6a21\u5757\u3001\u6761\u4ef6\u63a7\u5236\u6a21\u5757\u548c\u5fae\u8c03\u540e\u7684\u6269\u6563\u6a21\u578b\uff0c\u9996\u5148\u5c06\u624b\u672f\u5ba4\u573a\u666f\u8f6c\u5316\u4e3a\u62bd\u8c61\u51e0\u4f55\u8868\u793a\uff0c\u7136\u540e\u4ee5\u6b64\u4f5c\u4e3a\u6761\u4ef6\u5f15\u5bfc\u5408\u6210\u8fc7\u7a0b\uff0c\u6700\u7ec8\u751f\u6210\u903c\u771f\u7684\u624b\u672f\u5ba4\u4e8b\u4ef6\u89c6\u9891\u3002\u5229\u7528\u8be5\u6846\u67b6\uff0c\u6211\u4eec\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u5408\u6210\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u68c0\u6d4b\u65e0\u83cc\u533a\u8fdd\u89c4\u4e34\u8fd1\u4e8b\u4ef6\u7684AI\u6a21\u578b\u3002  \n\u7ed3\u679c\uff1a\u5728\u5408\u6210\u5e38\u89c4\u624b\u672f\u5ba4\u4e8b\u4ef6\u65b9\u9762\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6210\u7684\u89c6\u9891\u6269\u6563\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u57df\u5185\u548c\u57df\u5916\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u4e86\u66f4\u4f4e\u7684FVD/LPIPS\u503c\u4ee5\u53ca\u66f4\u9ad8\u7684SSIM/PSNR\u503c\u3002\u901a\u8fc7\u5b9a\u6027\u7ed3\u679c\uff0c\u6211\u4eec\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u53ef\u63a7\u5408\u6210\u53cd\u4e8b\u5b9e\u4e8b\u4ef6\u65b9\u9762\u7684\u80fd\u529b\u3002\u5728\u6240\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u4e0a\u8bad\u7ec3\u548c\u9a8c\u8bc1\u7684AI\u6a21\u578b\uff0c\u5728\u68c0\u6d4b\u4e34\u8fd1\u5b89\u5168\u5173\u952e\u4e8b\u4ef6\u65f6\u8fbe\u5230\u4e8670.13%\u7684\u53ec\u56de\u7387\u3002\u6700\u540e\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u6d88\u878d\u5b9e\u9a8c\uff0c\u4ee5\u91cf\u5316\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\u6240\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u3002  \n\u7ed3\u8bba\uff1a\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u4ece\u62bd\u8c61\u51e0\u4f55\u8868\u793a\u4e2d\u53ef\u63a7\u5730\u5408\u6210\u5e38\u89c4\u548c\u7f55\u89c1\u7684\u624b\u672f\u5ba4\u4e8b\u4ef6\u3002\u9664\u4e86\u5c55\u793a\u5176\u751f\u6210\u7f55\u89c1\u4e14\u5b89\u5168\u5173\u952e\u573a\u666f\u7684\u80fd\u529b\u5916\uff0c\u6211\u4eec\u8fd8\u8bc1\u660e\u4e86\u5176\u5728\u652f\u6301\u73af\u5883\u667a\u80fd\u6a21\u578b\u5f00\u53d1\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.21395", "pdf": "https://arxiv.org/pdf/2602.21395", "abs": "https://arxiv.org/abs/2602.21395", "authors": ["Yongxin Guo", "Hao Lu", "Onur C. Koyun", "Zhengjie Zhu", "Muhammet Fatih Demir", "Metin Nafi Gurcan"], "title": "Momentum Memory for Knowledge Distillation in Computational Pathology", "categories": ["cs.CV"], "comment": "Accepted by CVPR 2026", "summary": "Multimodal learning that integrates genomics and histopathology has shown strong potential in cancer diagnosis, yet its clinical translation is hindered by the limited availability of paired histology-genomics data. Knowledge distillation (KD) offers a practical solution by transferring genomic supervision into histopathology models, enabling accurate inference using histology alone. However, existing KD methods rely on batch-local alignment, which introduces instability due to limited within-batch comparisons and ultimately degrades performance.\n  To address these limitations, we propose Momentum Memory Knowledge Distillation (MoMKD), a cross-modal distillation framework driven by a momentum-updated memory. This memory aggregates genomic and histopathology information across batches, effectively enlarging the supervisory context available to each mini-batch. Furthermore, we decouple the gradients of the genomics and histology branches, preventing genomic signals from dominating histology feature learning during training and eliminating the modality-gap issue at inference time.\n  Extensive experiments on the TCGA-BRCA benchmark (HER2, PR, and ODX classification tasks) and an independent in-house testing dataset demonstrate that MoMKD consistently outperforms state-of-the-art MIL and multimodal KD baselines, delivering strong performance and generalization under histology-only inference. Overall, MoMKD establishes a robust and generalizable knowledge distillation paradigm for computational pathology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMoMKD\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u91cf\u66f4\u65b0\u7684\u8bb0\u5fc6\u673a\u5236\u548c\u68af\u5ea6\u89e3\u8026\uff0c\u5728\u4ec5\u4f7f\u7528\u7ec4\u7ec7\u75c5\u7406\u5b66\u56fe\u50cf\u8fdb\u884c\u63a8\u7406\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u7684\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\uff08\u6574\u5408\u57fa\u56e0\u7ec4\u5b66\u4e0e\u7ec4\u7ec7\u75c5\u7406\u5b66\uff09\u5728\u764c\u75c7\u8bca\u65ad\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u4e34\u5e8a\u5e94\u7528\u53d7\u9650\u4e8e\u914d\u5bf9\u6570\u636e\u7a00\u7f3a\uff1b\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u56e0\u4f9d\u8d56\u6279\u6b21\u5185\u5c40\u90e8\u5bf9\u9f50\u800c\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faMomentum Memory Knowledge Distillation (MoMKD)\uff0c\u5229\u7528\u52a8\u91cf\u66f4\u65b0\u7684\u8bb0\u5fc6\u5e93\u8de8\u6279\u6b21\u805a\u5408\u57fa\u56e0\u7ec4\u4e0e\u75c5\u7406\u4fe1\u606f\uff0c\u5e76\u89e3\u8026\u57fa\u56e0\u7ec4\u4e0e\u75c5\u7406\u5206\u652f\u7684\u68af\u5ea6\uff0c\u9632\u6b62\u6a21\u6001\u4e3b\u5bfc\u548c\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\u3002", "result": "\u5728TCGA-BRCA\u57fa\u51c6\uff08HER2\u3001PR\u3001ODX\u5206\u7c7b\uff09\u53ca\u72ec\u7acb\u5185\u90e8\u6d4b\u8bd5\u96c6\u4e0a\uff0cMoMKD\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684MIL\u548c\u591a\u6a21\u6001KD\u65b9\u6cd5\uff0c\u5728\u4ec5\u7528\u7ec4\u7ec7\u75c5\u7406\u56fe\u50cf\u63a8\u7406\u65f6\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "MoMKD\u4e3a\u8ba1\u7b97\u75c5\u7406\u5b66\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u7684\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u8303\u5f0f\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u591a\u6a21\u6001\u6a21\u578b\u5728\u4e34\u5e8a\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "summary_cn": "\u6574\u5408\u57fa\u56e0\u7ec4\u5b66\u4e0e\u7ec4\u7ec7\u75c5\u7406\u5b66\u7684\u591a\u6a21\u6001\u5b66\u4e60\u5728\u764c\u75c7\u8bca\u65ad\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u4e34\u5e8a\u8f6c\u5316\u53d7\u9650\u4e8e\u914d\u5bf9\u7ec4\u7ec7\u75c5\u7406-\u57fa\u56e0\u7ec4\u6570\u636e\u7684\u7a00\u7f3a\u6027\u3002\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u901a\u8fc7\u5c06\u57fa\u56e0\u7ec4\u76d1\u7763\u4fe1\u53f7\u8fc1\u79fb\u5230\u7ec4\u7ec7\u75c5\u7406\u6a21\u578b\u4e2d\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5f97\u4ec5\u4f7f\u7528\u7ec4\u7ec7\u75c5\u7406\u56fe\u50cf\u5373\u53ef\u5b9e\u73b0\u51c6\u786e\u63a8\u65ad\u3002\u7136\u800c\uff0c\u73b0\u6709KD\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6279\u6b21\u5185\u7684\u5c40\u90e8\u5bf9\u9f50\uff0c\u7531\u4e8e\u6279\u6b21\u5185\u6837\u672c\u5bf9\u6bd4\u6709\u9650\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u5e76\u6700\u7ec8\u635f\u5bb3\u6027\u80fd\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u52a8\u91cf\u8bb0\u5fc6\u77e5\u8bc6\u84b8\u998f\uff08Momentum Memory Knowledge Distillation, MoMKD\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u52a8\u91cf\u66f4\u65b0\u8bb0\u5fc6\u5e93\u7684\u8de8\u6a21\u6001\u84b8\u998f\u6846\u67b6\u3002\u8be5\u8bb0\u5fc6\u5e93\u5b58\u50a8\u5e76\u805a\u5408\u8de8\u6279\u6b21\u7684\u57fa\u56e0\u7ec4\u4e0e\u7ec4\u7ec7\u75c5\u7406\u4fe1\u606f\uff0c\u6709\u6548\u6269\u5927\u4e86\u6bcf\u4e2a\u5c0f\u6279\u6b21\u53ef\u7528\u7684\u76d1\u7763\u4e0a\u4e0b\u6587\u3002\u6b64\u5916\uff0c\u6211\u4eec\u89e3\u8026\u4e86\u57fa\u56e0\u7ec4\u5206\u652f\u4e0e\u7ec4\u7ec7\u75c5\u7406\u5206\u652f\u7684\u68af\u5ea6\uff0c\u9632\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u57fa\u56e0\u7ec4\u4fe1\u53f7\u4e3b\u5bfc\u7ec4\u7ec7\u75c5\u7406\u7279\u5f81\u7684\u5b66\u4e60\uff0c\u5e76\u5728\u63a8\u7406\u9636\u6bb5\u6d88\u9664\u6a21\u6001\u5dee\u8ddd\u95ee\u9898\u3002\u5728TCGA-BRCA\u57fa\u51c6\uff08HER2\u3001PR\u548cODX\u5206\u7c7b\u4efb\u52a1\uff09\u4ee5\u53ca\u4e00\u4e2a\u72ec\u7acb\u7684\u5185\u90e8\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMoMKD\u59cb\u7ec8\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684MIL\u548c\u591a\u6a21\u6001KD\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4ec5\u4f7f\u7528\u7ec4\u7ec7\u75c5\u7406\u56fe\u50cf\u8fdb\u884c\u63a8\u7406\u65f6\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002\u603b\u4f53\u800c\u8a00\uff0cMoMKD\u4e3a\u8ba1\u7b97\u75c5\u7406\u5b66\u5efa\u7acb\u4e86\u4e00\u4e2a\u7a33\u5065\u4e14\u53ef\u6cdb\u5316\u7684\u77e5\u8bc6\u84b8\u998f\u8303\u5f0f\u3002"}}
{"id": "2602.21397", "pdf": "https://arxiv.org/pdf/2602.21397", "abs": "https://arxiv.org/abs/2602.21397", "authors": ["Sajjad Ghiasvand", "Haniyeh Ehsani Oskouie", "Mahnoosh Alizadeh", "Ramtin Pedarsani"], "title": "MMLoP: Multi-Modal Low-Rank Prompting for Efficient Vision-Language Adaptation", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Prompt learning has become a dominant paradigm for adapting vision-language models (VLMs) such as CLIP to downstream tasks without modifying pretrained weights. While extending prompts to both vision and text encoders across multiple transformer layers significantly boosts performance, it dramatically increases the number of trainable parameters, with state-of-the-art methods requiring millions of parameters and abandoning the parameter efficiency that makes prompt tuning attractive. In this work, we propose \\textbf{MMLoP} (\\textbf{M}ulti-\\textbf{M}odal \\textbf{Lo}w-Rank \\textbf{P}rompting), a framework that achieves deep multi-modal prompting with only \\textbf{11.5K trainable parameters}, comparable to early text-only methods like CoOp. MMLoP parameterizes vision and text prompts at each transformer layer through a low-rank factorization, which serves as an implicit regularizer against overfitting on few-shot training data. To further close the accuracy gap with state-of-the-art methods, we introduce three complementary components: a self-regulating consistency loss that anchors prompted representations to frozen zero-shot CLIP features at both the feature and logit levels, a uniform drift correction that removes the global embedding shift induced by prompt tuning to preserve class-discriminative structure, and a shared up-projection that couples vision and text prompts through a common low-rank factor to enforce cross-modal alignment. Extensive experiments across three benchmarks and 11 diverse datasets demonstrate that MMLoP achieves a highly favorable accuracy-efficiency tradeoff, outperforming the majority of existing methods including those with orders of magnitude more parameters, while achieving a harmonic mean of 79.70\\% on base-to-novel generalization.", "AI": {"tldr": "MMLoP \u662f\u4e00\u79cd\u4ec5\u9700 11.5K \u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u591a\u6a21\u6001\u4f4e\u79e9\u63d0\u793a\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u9ad8\u53c2\u6570\u6548\u7387\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u4f4e\u79e9\u5206\u89e3\u3001\u4e00\u81f4\u6027\u635f\u5931\u3001\u5747\u5300\u6f02\u79fb\u6821\u6b63\u548c\u5171\u4eab\u4e0a\u6295\u5f71\u673a\u5236\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\u7684\u51c6\u786e\u7387-\u6548\u7387\u5e73\u8861\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u63d0\u793a\u65b9\u6cd5\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u9700\u8981\u6570\u767e\u4e07\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u4e27\u5931\u4e86\u63d0\u793a\u8c03\u4f18\u539f\u672c\u5177\u6709\u7684\u53c2\u6570\u9ad8\u6548\u4f18\u52bf\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u65e2\u80fd\u5b9e\u73b0\u6df1\u5ea6\u591a\u6a21\u6001\u63d0\u793a\uff0c\u53c8\u80fd\u4fdd\u6301\u6781\u4f4e\u53c2\u6570\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa MMLoP \u6846\u67b6\uff1a1\uff09\u5728\u89c6\u89c9\u548c\u6587\u672c\u7f16\u7801\u5668\u7684\u6bcf\u4e00\u5c42\u4f7f\u7528\u4f4e\u79e9\u5206\u89e3\u53c2\u6570\u5316\u63d0\u793a\uff1b2\uff09\u5f15\u5165\u81ea\u8c03\u8282\u4e00\u81f4\u6027\u635f\u5931\uff0c\u5c06\u63d0\u793a\u540e\u7684\u8868\u793a\u951a\u5b9a\u5230\u51bb\u7ed3\u7684\u96f6\u6837\u672c CLIP \u7279\u5f81\uff1b3\uff09\u91c7\u7528\u5747\u5300\u6f02\u79fb\u6821\u6b63\u4ee5\u6d88\u9664\u63d0\u793a\u8c03\u4f18\u5f15\u8d77\u7684\u5168\u5c40\u5d4c\u5165\u504f\u79fb\uff1b4\uff09\u8bbe\u8ba1\u5171\u4eab\u4e0a\u6295\u5f71\u673a\u5236\uff0c\u901a\u8fc7\u516c\u5171\u4f4e\u79e9\u56e0\u5b50\u8026\u5408\u89c6\u89c9\u4e0e\u6587\u672c\u63d0\u793a\uff0c\u4fc3\u8fdb\u8de8\u6a21\u6001\u5bf9\u9f50\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u548c11\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMMLoP \u4ee5\u4ec5 11.5K \u53c2\u6570\u663e\u8457\u4f18\u4e8e\u591a\u6570\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u53c2\u6570\u91cf\u9ad8\u51fa\u51e0\u4e2a\u6570\u91cf\u7ea7\u7684\u65b9\u6cd5\uff09\uff0c\u5e76\u5728\u57fa\u7840\u5230\u65b0\u7c7b\u6cdb\u5316\u4efb\u52a1\u4e2d\u8fbe\u5230 79.70% \u7684\u8c03\u548c\u5e73\u5747\u51c6\u786e\u7387\u3002", "conclusion": "MMLoP \u6210\u529f\u5b9e\u73b0\u4e86\u6df1\u5ea6\u591a\u6a21\u6001\u63d0\u793a\u5b66\u4e60\u4e2d\u7684\u9ad8\u51c6\u786e\u6027\u4e0e\u9ad8\u53c2\u6570\u6548\u7387\u7684\u7edf\u4e00\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u9002\u914d\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002", "summary_cn": "\u63d0\u793a\u5b66\u4e60\u5df2\u6210\u4e3a\u9002\u5e94\u5982 CLIP \u7b49\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5230\u4e0b\u6e38\u4efb\u52a1\u7684\u4e3b\u6d41\u8303\u5f0f\uff0c\u65e0\u9700\u4fee\u6539\u9884\u8bad\u7ec3\u6743\u91cd\u3002\u5c3d\u7ba1\u5c06\u63d0\u793a\u6269\u5c55\u5230\u89c6\u89c9\u548c\u6587\u672c\u7f16\u7801\u5668\u7684\u591a\u4e2a Transformer \u5c42\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u8fd9\u4f1a\u5927\u5e45\u589e\u52a0\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u9700\u8981\u6570\u767e\u4e07\u53c2\u6570\uff0c\u653e\u5f03\u4e86\u4f7f\u63d0\u793a\u8c03\u4f18\u5177\u6709\u5438\u5f15\u529b\u7684\u53c2\u6570\u6548\u7387\u3002\u672c\u6587\u63d0\u51fa MMLoP\uff08\u591a\u6a21\u6001\u4f4e\u79e9\u63d0\u793a\uff09\uff0c\u8be5\u6846\u67b6\u4ec5\u9700 11.5K \u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570\u5373\u53ef\u5b9e\u73b0\u6df1\u5ea6\u591a\u6a21\u6001\u63d0\u793a\uff0c\u4e0e\u65e9\u671f\u4ec5\u6587\u672c\u7684\u65b9\u6cd5\uff08\u5982 CoOp\uff09\u76f8\u5f53\u3002MMLoP \u901a\u8fc7\u5bf9\u6bcf\u4e2a Transformer \u5c42\u7684\u89c6\u89c9\u548c\u6587\u672c\u63d0\u793a\u8fdb\u884c\u4f4e\u79e9\u5206\u89e3\u6765\u53c2\u6570\u5316\uff0c\u8fd9\u79cd\u5206\u89e3\u53ef\u4f5c\u4e3a\u9488\u5bf9\u5c11\u6837\u672c\u8bad\u7ec3\u6570\u636e\u8fc7\u62df\u5408\u7684\u9690\u5f0f\u6b63\u5219\u5316\u5668\u3002\u4e3a\u8fdb\u4e00\u6b65\u7f29\u5c0f\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u7cbe\u5ea6\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e09\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff1a\u4e00\u79cd\u81ea\u8c03\u8282\u4e00\u81f4\u6027\u635f\u5931\uff0c\u5728\u7279\u5f81\u548c logits \u5c42\u9762\u5c06\u63d0\u793a\u540e\u7684\u8868\u793a\u951a\u5b9a\u5230\u51bb\u7ed3\u7684\u96f6\u6837\u672c CLIP \u7279\u5f81\uff1b\u4e00\u79cd\u5747\u5300\u6f02\u79fb\u6821\u6b63\uff0c\u6d88\u9664\u63d0\u793a\u8c03\u4f18\u5f15\u8d77\u7684\u5168\u5c40\u5d4c\u5165\u504f\u79fb\u4ee5\u4fdd\u7559\u7c7b\u522b\u5224\u522b\u7ed3\u6784\uff1b\u4ee5\u53ca\u4e00\u79cd\u5171\u4eab\u4e0a\u6295\u5f71\uff0c\u901a\u8fc7\u516c\u5171\u4f4e\u79e9\u56e0\u5b50\u8026\u5408\u89c6\u89c9\u548c\u6587\u672c\u63d0\u793a\u4ee5\u5f3a\u5236\u8de8\u6a21\u6001\u5bf9\u9f50\u3002\u5728\u4e09\u4e2a\u57fa\u51c6\u548c11\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMMLoP \u5b9e\u73b0\u4e86\u6781\u5177\u4f18\u52bf\u7684\u7cbe\u5ea6-\u6548\u7387\u6743\u8861\uff0c\u4f18\u4e8e\u5927\u591a\u6570\u73b0\u6709\u65b9\u6cd5\uff08\u5305\u62ec\u53c2\u6570\u91cf\u9ad8\u51fa\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u65b9\u6cd5\uff09\uff0c\u5e76\u5728\u57fa\u7840\u5230\u65b0\u7c7b\u6cdb\u5316\u4efb\u52a1\u4e2d\u8fbe\u5230 79.70% \u7684\u8c03\u548c\u5e73\u5747\u51c6\u786e\u7387\u3002"}}
{"id": "2602.21402", "pdf": "https://arxiv.org/pdf/2602.21402", "abs": "https://arxiv.org/abs/2602.21402", "authors": ["Jinyoung Jun", "Won-Dong Jang", "Wenbin Ouyang", "Raghudeep Gadde", "Jungbeom Lee"], "title": "FlowFixer: Towards Detail-Preserving Subject-Driven Generation", "categories": ["cs.CV"], "comment": null, "summary": "We present FlowFixer, a refinement framework for subject-driven generation (SDG) that restores fine details lost during generation caused by changes in scale and perspective of a subject. FlowFixer proposes direct image-to-image translation from visual references, avoiding ambiguities in language prompts. To enable image-to-image training, we introduce a one-step denoising scheme to generate self-supervised training data, which automatically removes high-frequency details while preserving global structure, effectively simulating real-world SDG errors. We further propose a keypoint matching-based metric to properly assess fidelity in details beyond semantic similarities usually measured by CLIP or DINO. Experimental results demonstrate that FlowFixer outperforms state-of-the-art SDG methods in both qualitative and quantitative evaluations, setting a new benchmark for high-fidelity subject-driven generation.", "AI": {"tldr": "FlowFixer \u662f\u4e00\u4e2a\u7528\u4e8e\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\uff08SDG\uff09\u7684\u7ec6\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u76f4\u63a5\u8f6c\u6362\u6062\u590d\u56e0\u5c3a\u5ea6\u548c\u89c6\u89d2\u53d8\u5316\u800c\u4e22\u5931\u7684\u7ec6\u8282\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\u4e2d\uff0c\u7531\u4e8e\u4e3b\u4f53\u7684\u5c3a\u5ea6\u548c\u89c6\u89d2\u53d8\u5316\uff0c\u751f\u6210\u56fe\u50cf\u5e38\u4f1a\u4e22\u5931\u7cbe\u7ec6\u7ec6\u8282\uff1b\u540c\u65f6\uff0c\u57fa\u4e8e\u8bed\u8a00\u63d0\u793a\u7684\u65b9\u6cd5\u5b58\u5728\u8bed\u4e49\u6a21\u7cca\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u80fd\u4fdd\u7559\u7ec6\u8282\u7684\u7ec6\u5316\u673a\u5236\u3002", "method": "FlowFixer \u91c7\u7528\u76f4\u63a5\u7684\u56fe\u50cf\u5230\u56fe\u50cf\u7ffb\u8bd1\u65b9\u5f0f\uff0c\u4ece\u89c6\u89c9\u53c2\u8003\u56fe\u51fa\u53d1\uff0c\u907f\u514d\u8bed\u8a00\u63d0\u793a\u7684\u6b67\u4e49\uff1b\u5f15\u5165\u4e00\u6b65\u53bb\u566a\u65b9\u6848\u81ea\u52a8\u751f\u6210\u81ea\u76d1\u7763\u8bad\u7ec3\u6570\u636e\uff0c\u8be5\u6570\u636e\u5728\u4fdd\u7559\u5168\u5c40\u7ed3\u6784\u7684\u540c\u65f6\u53bb\u9664\u9ad8\u9891\u7ec6\u8282\uff0c\u6a21\u62df\u771f\u5b9e SDG \u9519\u8bef\uff1b\u5e76\u63d0\u51fa\u57fa\u4e8e\u5173\u952e\u70b9\u5339\u914d\u7684\u8bc4\u4f30\u6307\u6807\u4ee5\u8861\u91cf\u7ec6\u8282\u4fdd\u771f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFlowFixer \u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684 SDG \u65b9\u6cd5\uff0c\u5728\u9ad8\u4fdd\u771f\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\u4efb\u52a1\u4e2d\u6811\u7acb\u4e86\u65b0\u57fa\u51c6\u3002", "conclusion": "FlowFixer \u6709\u6548\u89e3\u51b3\u4e86 SDG \u4e2d\u7ec6\u8282\u4e22\u5931\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u56fe\u50cf\u7ea7\u76d1\u7763\u548c\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u9ad8\u4fdd\u771f\u56fe\u50cf\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86 FlowFixer\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\uff08SDG\uff09\u7684\u7ec6\u5316\u6846\u67b6\uff0c\u65e8\u5728\u6062\u590d\u56e0\u4e3b\u4f53\u5c3a\u5ea6\u548c\u89c6\u89d2\u53d8\u5316\u800c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4e22\u5931\u7684\u7cbe\u7ec6\u7ec6\u8282\u3002FlowFixer \u63d0\u51fa\u76f4\u63a5\u4ece\u89c6\u89c9\u53c2\u8003\u56fe\u8fdb\u884c\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u7ffb\u8bd1\uff0c\u907f\u514d\u4e86\u8bed\u8a00\u63d0\u793a\u6240\u5e26\u6765\u7684\u8bed\u4e49\u6b67\u4e49\u3002\u4e3a\u4e86\u5b9e\u73b0\u56fe\u50cf\u5230\u56fe\u50cf\u7684\u8bad\u7ec3\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u4e00\u6b65\u53bb\u566a\u65b9\u6848\uff0c\u7528\u4e8e\u751f\u6210\u81ea\u76d1\u7763\u8bad\u7ec3\u6570\u636e\uff0c\u8be5\u65b9\u6848\u5728\u81ea\u52a8\u53bb\u9664\u9ad8\u9891\u7ec6\u8282\u7684\u540c\u65f6\u4fdd\u7559\u5168\u5c40\u7ed3\u6784\uff0c\u6709\u6548\u6a21\u62df\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684 SDG \u9519\u8bef\u3002\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5173\u952e\u70b9\u5339\u914d\u7684\u5ea6\u91cf\u6307\u6807\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u7ec6\u8282\u4fdd\u771f\u5ea6\uff0c\u8d85\u8d8a\u4e86\u901a\u5e38\u7531 CLIP \u6216 DINO \u8861\u91cf\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFlowFixer \u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u4e2d\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684 SDG \u65b9\u6cd5\uff0c\u4e3a\u9ad8\u4fdd\u771f\u4e3b\u4f53\u9a71\u52a8\u751f\u6210\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u3002"}}
{"id": "2602.21406", "pdf": "https://arxiv.org/pdf/2602.21406", "abs": "https://arxiv.org/abs/2602.21406", "authors": ["Asim Unmesh", "Kaki Ramesh", "Mayank Patel", "Rahul Jain", "Karthik Ramani"], "title": "Exploring Vision-Language Models for Open-Vocabulary Zero-Shot Action Segmentation", "categories": ["cs.CV"], "comment": "ICRA 2026", "summary": "Temporal Action Segmentation (TAS) requires dividing videos into action segments, yet the vast space of activities and alternative breakdowns makes collecting comprehensive datasets infeasible. Existing methods remain limited to closed vocabularies and fixed label sets. In this work, we explore the largely unexplored problem of Open-Vocabulary Zero-Shot Temporal Action Segmentation (OVTAS) by leveraging the strong zero-shot capabilities of Vision-Language Models (VLMs). We introduce a training-free pipeline that follows a segmentation-by-classification design: Frame-Action Embedding Similarity (FAES) matches video frames to candidate action labels, and Similarity-Matrix Temporal Segmentation (SMTS) enforces temporal consistency. Beyond proposing OVTAS, we present a systematic study across 14 diverse VLMs, providing the first broad analysis of their suitability for open-vocabulary action segmentation. Experiments on standard benchmarks show that OVTAS achieves strong results without task-specific supervision, underscoring the potential of VLMs for structured temporal understanding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f00\u653e\u8bcd\u6c47\u96f6\u6837\u672c\u65f6\u5e8f\u52a8\u4f5c\u5206\u5272\uff08OVTAS\uff09\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u5206\u5272\u6d41\u7a0b\uff0c\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65f6\u5e8f\u52a8\u4f5c\u5206\u5272\u65b9\u6cd5\u53d7\u9650\u4e8e\u5c01\u95ed\u8bcd\u6c47\u548c\u56fa\u5b9a\u6807\u7b7e\u96c6\uff0c\u800c\u73b0\u5b9e\u4e2d\u52a8\u4f5c\u79cd\u7c7b\u7e41\u591a\u3001\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u6784\u5efa\u5168\u9762\u6570\u636e\u96c6\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u5f00\u653e\u8bcd\u6c47\u3001\u96f6\u6837\u672c\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684OVTAS\u6d41\u7a0b\uff0c\u5305\u62ec\u5e27-\u52a8\u4f5c\u5d4c\u5165\u76f8\u4f3c\u6027\uff08FAES\uff09\u7528\u4e8e\u5339\u914d\u89c6\u9891\u5e27\u4e0e\u5019\u9009\u52a8\u4f5c\u6807\u7b7e\uff0c\u4ee5\u53ca\u76f8\u4f3c\u6027\u77e9\u9635\u65f6\u5e8f\u5206\u5272\uff08SMTS\uff09\u7528\u4e8e\u589e\u5f3a\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u65e0\u4efb\u52a1\u7279\u5b9a\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\uff1b\u540c\u65f6\u5bf914\u79cd\u4e0d\u540cVLM\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\uff0c\u9996\u6b21\u5168\u9762\u5206\u6790\u5176\u5728\u5f00\u653e\u8bcd\u6c47\u52a8\u4f5c\u5206\u5272\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5f3a\u5927\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u53ef\u6709\u6548\u652f\u6301\u5f00\u653e\u8bcd\u6c47\u7684\u7ed3\u6784\u5316\u65f6\u5e8f\u7406\u89e3\uff0c\u4e3a\u672a\u6765\u65f6\u5e8f\u52a8\u4f5c\u5206\u5272\u7814\u7a76\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "summary_cn": "\u65f6\u5e8f\u52a8\u4f5c\u5206\u5272\uff08TAS\uff09\u8981\u6c42\u5c06\u89c6\u9891\u5212\u5206\u4e3a\u82e5\u5e72\u52a8\u4f5c\u7247\u6bb5\uff0c\u7136\u800c\u7531\u4e8e\u6d3b\u52a8\u7a7a\u95f4\u5e9e\u5927\u4e14\u5b58\u5728\u591a\u79cd\u53ef\u80fd\u7684\u5212\u5206\u65b9\u5f0f\uff0c\u6536\u96c6\u5168\u9762\u7684\u6570\u636e\u96c6\u662f\u4e0d\u53ef\u884c\u7684\u3002\u73b0\u6709\u65b9\u6cd5\u4ecd\u5c40\u9650\u4e8e\u5c01\u95ed\u8bcd\u6c47\u8868\u548c\u56fa\u5b9a\u7684\u6807\u7b7e\u96c6\u5408\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5f3a\u5927\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u63a2\u7d22\u4e86\u5f00\u653e\u8bcd\u6c47\u96f6\u6837\u672c\u65f6\u5e8f\u52a8\u4f5c\u5206\u5272\uff08OVTAS\uff09\u8fd9\u4e00\u9c9c\u6709\u7814\u7a76\u7684\u95ee\u9898\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6d41\u7a0b\uff0c\u91c7\u7528\u201c\u5148\u5206\u7c7b\u540e\u5206\u5272\u201d\u7684\u8bbe\u8ba1\uff1a\u5e27-\u52a8\u4f5c\u5d4c\u5165\u76f8\u4f3c\u6027\uff08FAES\uff09\u7528\u4e8e\u5c06\u89c6\u9891\u5e27\u4e0e\u5019\u9009\u52a8\u4f5c\u6807\u7b7e\u8fdb\u884c\u5339\u914d\uff0c\u800c\u76f8\u4f3c\u6027\u77e9\u9635\u65f6\u5e8f\u5206\u5272\uff08SMTS\uff09\u5219\u7528\u4e8e\u589e\u5f3a\u65f6\u95f4\u4e00\u81f4\u6027\u3002\u9664\u4e86\u63d0\u51faOVTAS\u4efb\u52a1\u5916\uff0c\u6211\u4eec\u8fd8\u5bf914\u79cd\u4e0d\u540c\u7684VLM\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u9996\u6b21\u5168\u9762\u5206\u6790\u4e86\u5b83\u4eec\u5728\u5f00\u653e\u8bcd\u6c47\u52a8\u4f5c\u5206\u5272\u4e2d\u7684\u9002\u7528\u6027\u3002\u5728\u6807\u51c6\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOVTAS\u5728\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u7ed3\u679c\uff0c\u51f8\u663e\u4e86VLM\u5728\u7ed3\u6784\u5316\u65f6\u5e8f\u7406\u89e3\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.21416", "pdf": "https://arxiv.org/pdf/2602.21416", "abs": "https://arxiv.org/abs/2602.21416", "authors": ["Marco Terral", "Haotian Zhang", "Tianyang Zhang", "Meng Lin", "Xiaoqing Xie", "Haoran Dai", "Darsh Kaushik", "Pai Peng", "Nicklas Scharpff", "David Vazquez", "Joan Rodriguez"], "title": "WildSVG: Towards Reliable SVG Generation Under Real-Word Conditions", "categories": ["cs.CV"], "comment": "10 pages, 6 pages of additional material", "summary": "We introduce the task of SVG extraction, which consists in translating specific visual inputs from an image into scalable vector graphics. Existing multimodal models achieve strong results when generating SVGs from clean renderings or textual descriptions, but they fall short in real-world scenarios where natural images introduce noise, clutter, and domain shifts. A central challenge in this direction is the lack of suitable benchmarks. To address this need, we introduce the WildSVG Benchmark, formed by two complementary datasets: Natural WildSVG, built from real images containing company logos paired with their SVG annotations, and Synthetic WildSVG, which blends complex SVG renderings into real scenes to simulate difficult conditions. Together, these resources provide the first foundation for systematic benchmarking SVG extraction. We benchmark state-of-the-art multimodal models and find that current approaches perform well below what is needed for reliable SVG extraction in real scenarios. Nonetheless, iterative refinement methods point to a promising path forward, and model capabilities are steadily improving", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSVG\u63d0\u53d6\u4efb\u52a1\uff0c\u65e8\u5728\u4ece\u81ea\u7136\u56fe\u50cf\u4e2d\u63d0\u53d6\u53ef\u7f29\u653e\u77e2\u91cf\u56fe\u5f62\uff08SVG\uff09\uff0c\u5e76\u53d1\u5e03WildSVG\u57fa\u51c6\uff08\u5305\u542bNatural\u548cSynthetic\u4e24\u4e2a\u5b50\u96c6\uff09\u4ee5\u8bc4\u4f30\u73b0\u6709\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u65b9\u6cd5\u4ecd\u8fdc\u672a\u8fbe\u6807\uff0c\u4f46\u8fed\u4ee3\u4f18\u5316\u7b56\u7565\u663e\u793a\u51fa\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5728\u5e72\u51c0\u6e32\u67d3\u56fe\u6216\u6587\u672c\u63cf\u8ff0\u751f\u6210SVG\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u771f\u5b9e\u81ea\u7136\u56fe\u50cf\u4e2d\u56e0\u566a\u58f0\u3001\u6742\u4e71\u548c\u57df\u504f\u79fb\u800c\u6548\u679c\u4e0d\u4f73\uff1b\u4e14\u7f3a\u4e4f\u5408\u9002\u7684\u8bc4\u6d4b\u57fa\u51c6\u6765\u63a8\u52a8\u8be5\u65b9\u5411\u7684\u7814\u7a76\u3002", "method": "\u6784\u5efaWildSVG\u57fa\u51c6\uff0c\u5305\u62ecNatural WildSVG\uff08\u771f\u5b9e\u56fe\u50cf\u4e0e\u5bf9\u5e94SVG\u6807\u6ce8\uff09\u548cSynthetic WildSVG\uff08\u5c06\u590d\u6742SVG\u6e32\u67d3\u5d4c\u5165\u771f\u5b9e\u573a\u666f\u4ee5\u6a21\u62df\u56f0\u96be\u6761\u4ef6\uff09\uff1b\u5e76\u5728\u8be5\u57fa\u51c6\u4e0a\u8bc4\u6d4b\u5f53\u524d\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u6a21\u578b\u3002", "result": "\u73b0\u6709\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684SVG\u63d0\u53d6\u6027\u80fd\u8fdc\u672a\u8fbe\u5230\u5b9e\u7528\u6c34\u5e73\uff0c\u4f46\u91c7\u7528\u8fed\u4ee3\u4f18\u5316\u7684\u65b9\u6cd5\u5c55\u73b0\u51fa\u6539\u8fdb\u6f5c\u529b\u3002", "conclusion": "WildSVG\u662f\u9996\u4e2a\u9762\u5411SVG\u63d0\u53d6\u4efb\u52a1\u7684\u7cfb\u7edf\u6027\u8bc4\u6d4b\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5e76\u6307\u51fa\u8fed\u4ee3\u7cbe\u70bc\u7b49\u65b9\u5411\u53ef\u80fd\u63a8\u52a8\u672a\u6765\u8fdb\u5c55\u3002", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86SVG\u63d0\u53d6\u4efb\u52a1\uff0c\u5373\u4ece\u56fe\u50cf\u4e2d\u5c06\u7279\u5b9a\u89c6\u89c9\u5185\u5bb9\u8f6c\u6362\u4e3a\u53ef\u7f29\u653e\u77e2\u91cf\u56fe\u5f62\uff08SVG\uff09\u3002\u73b0\u6709\u7684\u4e00\u4e9b\u591a\u6a21\u6001\u6a21\u578b\u5728\u4ece\u5e72\u51c0\u6e32\u67d3\u56fe\u6216\u6587\u672c\u63cf\u8ff0\u751f\u6210SVG\u65b9\u9762\u53d6\u5f97\u4e86\u826f\u597d\u6548\u679c\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u81ea\u7136\u56fe\u50cf\u5b58\u5728\u566a\u58f0\u3001\u6742\u4e71\u80cc\u666f\u548c\u57df\u504f\u79fb\u7b49\u95ee\u9898\uff0c\u5176\u8868\u73b0\u660e\u663e\u4e0d\u8db3\u3002\u8be5\u65b9\u5411\u7684\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u7f3a\u4e4f\u5408\u9002\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86WildSVG\u57fa\u51c6\uff0c\u5b83\u7531\u4e24\u4e2a\u4e92\u8865\u7684\u6570\u636e\u96c6\u7ec4\u6210\uff1aNatural WildSVG\uff0c\u7531\u5305\u542b\u516c\u53f8Logo\u7684\u771f\u5b9e\u56fe\u50cf\u53ca\u5176\u5bf9\u5e94\u7684SVG\u6807\u6ce8\u6784\u6210\uff1b\u4ee5\u53caSynthetic WildSVG\uff0c\u901a\u8fc7\u5c06\u590d\u6742\u7684SVG\u6e32\u67d3\u56fe\u878d\u5408\u5230\u771f\u5b9e\u573a\u666f\u4e2d\uff0c\u4ee5\u6a21\u62df\u66f4\u5177\u6311\u6218\u6027\u7684\u6761\u4ef6\u3002\u8fd9\u4e24\u4e2a\u6570\u636e\u96c6\u5171\u540c\u6784\u6210\u4e86\u9996\u4e2a\u7528\u4e8e\u7cfb\u7edf\u6027\u8bc4\u6d4bSVG\u63d0\u53d6\u4efb\u52a1\u7684\u57fa\u7840\u8d44\u6e90\u3002\u6211\u4eec\u5728\u8be5\u57fa\u51c6\u4e0a\u5bf9\u5f53\u524d\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\u8ddd\u79bb\u53ef\u9760\u5e94\u7528\u4ecd\u6709\u8f83\u5927\u5dee\u8ddd\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\u663e\u793a\u51fa\u826f\u597d\u7684\u524d\u666f\uff0c\u6a21\u578b\u80fd\u529b\u4e5f\u5728\u7a33\u6b65\u63d0\u5347\u3002"}}
{"id": "2602.21421", "pdf": "https://arxiv.org/pdf/2602.21421", "abs": "https://arxiv.org/abs/2602.21421", "authors": ["Jan Pauls", "Karsten Schr\u00f6dter", "Sven Ligensa", "Martin Schwartz", "Berkant Turan", "Max Zimmer", "Sassan Saatchi", "Sebastian Pokutta", "Philippe Ciais", "Fabian Gieseke"], "title": "ECHOSAT: Estimating Canopy Height Over Space And Time", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 12 figures, 6 tables", "summary": "Forest monitoring is critical for climate change mitigation. However, existing global tree height maps provide only static snapshots and do not capture temporal forest dynamics, which are essential for accurate carbon accounting. We introduce ECHOSAT, a global and temporally consistent tree height map at 10 m resolution spanning multiple years. To this end, we resort to multi-sensor satellite data to train a specialized vision transformer model, which performs pixel-level temporal regression. A self-supervised growth loss regularizes the predictions to follow growth curves that are in line with natural tree development, including gradual height increases over time, but also abrupt declines due to forest loss events such as fires. Our experimental evaluation shows that our model improves state-of-the-art accuracies in the context of single-year predictions. We also provide the first global-scale height map that accurately quantifies tree growth and disturbances over time. We expect ECHOSAT to advance global efforts in carbon monitoring and disturbance assessment. The maps can be accessed at https://github.com/ai4forest/echosat.", "AI": {"tldr": "ECHOSAT \u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6e90\u536b\u661f\u6570\u636e\u548c\u89c6\u89c9Transformer\u6a21\u578b\u6784\u5efa\u7684\u5168\u740310\u7c73\u5206\u8fa8\u7387\u3001\u591a\u5e74\u4efd\u4e00\u81f4\u7684\u6811\u6728\u9ad8\u5ea6\u52a8\u6001\u5730\u56fe\uff0c\u80fd\u51c6\u786e\u6355\u6349\u68ee\u6797\u751f\u957f\u4e0e\u6270\u52a8\u4e8b\u4ef6\u3002", "motivation": "\u73b0\u6709\u5168\u7403\u6811\u9ad8\u56fe\u4ec5\u63d0\u4f9b\u9759\u6001\u5feb\u7167\uff0c\u65e0\u6cd5\u53cd\u6620\u68ee\u6797\u968f\u65f6\u95f4\u53d8\u5316\u7684\u52a8\u6001\u7279\u5f81\uff0c\u800c\u8fd9\u5bf9\u7cbe\u51c6\u78b3\u6838\u7b97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u591a\u4f20\u611f\u5668\u536b\u661f\u6570\u636e\u8bad\u7ec3\u4e13\u7528\u89c6\u89c9Transformer\u6a21\u578b\uff0c\u8fdb\u884c\u50cf\u7d20\u7ea7\u65f6\u95f4\u5e8f\u5217\u56de\u5f52\uff0c\u5e76\u5f15\u5165\u81ea\u76d1\u7763\u201c\u751f\u957f\u635f\u5931\u201d\u7ea6\u675f\u9884\u6d4b\u7ed3\u679c\u7b26\u5408\u81ea\u7136\u6811\u6728\u751f\u957f\u89c4\u5f8b\uff08\u5982\u9010\u5e74\u589e\u9ad8\u6216\u56e0\u706b\u707e\u7b49\u6270\u52a8\u5bfc\u81f4\u9aa4\u964d\uff09\u3002", "result": "\u8be5\u6a21\u578b\u5728\u5355\u5e74\u9884\u6d4b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u63d0\u4f9b\u4e86\u53ef\u91cf\u5316\u5168\u7403\u5c3a\u5ea6\u6811\u6728\u751f\u957f\u4e0e\u6270\u52a8\u7684\u591a\u5e74\u4efd\u9ad8\u5ea6\u56fe\u3002", "conclusion": "ECHOSAT\u6709\u671b\u63a8\u52a8\u5168\u7403\u78b3\u76d1\u6d4b\u4e0e\u68ee\u6797\u6270\u52a8\u8bc4\u4f30\u5de5\u4f5c\uff0c\u76f8\u5173\u6570\u636e\u5df2\u516c\u5f00\u53d1\u5e03\u3002", "summary_cn": "\u68ee\u6797\u76d1\u6d4b\u5bf9\u51cf\u7f13\u6c14\u5019\u53d8\u5316\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5168\u7403\u6811\u9ad8\u56fe\u4ec5\u63d0\u4f9b\u9759\u6001\u5feb\u7167\uff0c\u65e0\u6cd5\u6355\u6349\u5bf9\u7cbe\u786e\u78b3\u6838\u7b97\u81f3\u5173\u91cd\u8981\u7684\u68ee\u6797\u65f6\u95f4\u52a8\u6001\u53d8\u5316\u3002\u6211\u4eec\u63d0\u51fa\u4e86 ECHOSAT\u2014\u2014\u4e00\u4e2a\u5206\u8fa8\u7387\u4e3a10\u7c73\u3001\u8986\u76d6\u591a\u5e74\u4efd\u7684\u5168\u7403\u4e00\u81f4\u6027\u6811\u9ad8\u52a8\u6001\u5730\u56fe\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5229\u7528\u591a\u6e90\u536b\u661f\u6570\u636e\u8bad\u7ec3\u4e86\u4e00\u4e2a\u4e13\u7528\u7684\u89c6\u89c9Transformer\u6a21\u578b\uff0c\u4ee5\u5b9e\u73b0\u50cf\u7d20\u7ea7\u7684\u65f6\u95f4\u5e8f\u5217\u56de\u5f52\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u81ea\u76d1\u7763\u7684\u201c\u751f\u957f\u635f\u5931\u201d\u51fd\u6570\uff0c\u4f7f\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u9075\u5faa\u7b26\u5408\u81ea\u7136\u6811\u6728\u751f\u957f\u89c4\u5f8b\u7684\u53d8\u5316\u66f2\u7ebf\uff0c\u5305\u62ec\u968f\u65f6\u95f4\u9010\u6e10\u589e\u9ad8\uff0c\u4ee5\u53ca\u56e0\u706b\u707e\u7b49\u68ee\u6797\u635f\u5931\u4e8b\u4ef6\u5f15\u8d77\u7684\u9aa4\u7136\u4e0b\u964d\u3002\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u5355\u5e74\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u7cbe\u5ea6\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u8fd8\u9996\u6b21\u63d0\u4f9b\u4e86\u53ef\u5728\u5168\u7403\u5c3a\u5ea6\u4e0a\u51c6\u786e\u91cf\u5316\u6811\u6728\u751f\u957f\u4e0e\u6270\u52a8\u4e8b\u4ef6\u7684\u591a\u5e74\u4efd\u6811\u9ad8\u56fe\u3002\u6211\u4eec\u671f\u671b ECHOSAT \u80fd\u591f\u63a8\u52a8\u5168\u7403\u78b3\u76d1\u6d4b\u4e0e\u6270\u52a8\u8bc4\u4f30\u5de5\u4f5c\u3002\u76f8\u5173\u5730\u56fe\u53ef\u901a\u8fc7 https://github.com/ai4forest/echosat \u83b7\u53d6\u3002"}}
