{"id": "2602.16713", "pdf": "https://arxiv.org/pdf/2602.16713", "abs": "https://arxiv.org/abs/2602.16713", "authors": ["Shuo Wang", "Shuo Wang", "Xin Nie", "Yasutaka Narazaki", "Thomas Matiki", "Billie F. Spencer"], "title": "Three-dimensional Damage Visualization of Civil Structures via Gaussian Splatting-enabled Digital Twins", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in civil infrastructure inspections underscore the need for precise three-dimensional (3D) damage visualization on digital twins, transcending traditional 2D image-based damage identifications. Compared to conventional photogrammetric 3D reconstruction techniques, modern approaches such as Neural Radiance Field (NeRF) and Gaussian Splatting (GS) excel in scene representation, rendering quality, and handling featureless regions. Among them, GS stands out for its efficiency, leveraging discrete anisotropic 3D Gaussians to represent radiance fields, unlike NeRF's continuous implicit model. This study introduces a GS-enabled digital twin method tailored for effective 3D damage visualization. The method's key contributions include: 1) utilizing GS-based 3D reconstruction to visualize 2D damage segmentation results while reducing segmentation errors; 2) developing a multi-scale reconstruction strategy to balance efficiency and damage detail; 3) enabling digital twin updates as damage evolves over time. Demonstrated on an open-source synthetic dataset for post-earthquake inspections, the proposed approach offers a promising solution for comprehensive 3D damage visualization in civil infrastructure digital twins.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u6cfc\u6e85\uff08Gaussian Splatting, GS\uff09\u7684\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u9ad8\u6548\u3001\u51c6\u786e\u5730\u53ef\u89c6\u5316\u571f\u6728\u57fa\u7840\u8bbe\u65bd\u635f\u4f24\uff0c\u5e76\u652f\u6301\u968f\u65f6\u95f4\u6f14\u5316\u7684\u635f\u4f24\u66f4\u65b0\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4e8c\u7ef4\u56fe\u50cf\u7684\u635f\u4f24\u8bc6\u522b\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u5bf9\u571f\u6728\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u7cbe\u786e\u4e09\u7ef4\u635f\u4f24\u53ef\u89c6\u5316\u7684\u9700\u8981\uff1b\u800c\u73b0\u6709\u4e09\u7ef4\u91cd\u5efa\u6280\u672f\uff08\u5982NeRF\uff09\u5728\u6548\u7387\u6216\u5904\u7406\u65e0\u7eb9\u7406\u533a\u57df\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u9ad8\u6548\u3001\u9ad8\u8d28\u91cf\u7684\u4e09\u7ef4\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9ad8\u65af\u6cfc\u6e85\uff08GS\uff09\u8fdb\u884c\u4e09\u7ef4\u91cd\u5efa\uff0c\u5c06\u4e8c\u7ef4\u635f\u4f24\u5206\u5272\u7ed3\u679c\u6620\u5c04\u5230\u4e09\u7ef4\u6a21\u578b\u4e0a\u4ee5\u51cf\u5c11\u5206\u5272\u8bef\u5dee\uff1b\u63d0\u51fa\u591a\u5c3a\u5ea6\u91cd\u5efa\u7b56\u7565\u4ee5\u517c\u987e\u6548\u7387\u4e0e\u7ec6\u8282\uff1b\u5e76\u652f\u6301\u968f\u65f6\u95f4\u52a8\u6001\u66f4\u65b0\u6570\u5b57\u5b6a\u751f\u4e2d\u7684\u635f\u4f24\u72b6\u6001\u3002", "result": "\u5728\u5f00\u6e90\u5408\u6210\u5730\u9707\u540e\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u9ad8\u4fdd\u771f\u3001\u7ec6\u8282\u4e30\u5bcc\u7684\u4e09\u7ef4\u635f\u4f24\u53ef\u89c6\u5316\u3002", "conclusion": "\u57fa\u4e8eGS\u7684\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\u4e3a\u571f\u6728\u57fa\u7840\u8bbe\u65bd\u635f\u4f24\u7684\u4e09\u7ef4\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u652f\u6301\u52a8\u6001\u66f4\u65b0\u7684\u65b0\u9014\u5f84\u3002", "summary_cn": "\u8fd1\u671f\u571f\u6728\u57fa\u7840\u8bbe\u65bd\u68c0\u6d4b\u9886\u57df\u7684\u8fdb\u5c55\u51f8\u663e\u4e86\u5728\u6570\u5b57\u5b6a\u751f\u4e2d\u5b9e\u73b0\u7cbe\u786e\u4e09\u7ef4\u635f\u4f24\u53ef\u89c6\u5316\u7684\u91cd\u8981\u6027\uff0c\u8fd9\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u57fa\u4e8e\u4e8c\u7ef4\u56fe\u50cf\u7684\u635f\u4f24\u8bc6\u522b\u65b9\u6cd5\u3002\u4e0e\u4f20\u7edf\u7684\u6444\u5f71\u6d4b\u91cf\u4e09\u7ef4\u91cd\u5efa\u6280\u672f\u76f8\u6bd4\uff0c\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u548c\u9ad8\u65af\u6cfc\u6e85\uff08GS\uff09\u7b49\u73b0\u4ee3\u65b9\u6cd5\u5728\u573a\u666f\u8868\u793a\u3001\u6e32\u67d3\u8d28\u91cf\u4ee5\u53ca\u5904\u7406\u65e0\u7279\u5f81\u533a\u57df\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u5176\u4e2d\uff0cGS\u56e0\u5176\u9ad8\u6548\u6027\u8131\u9896\u800c\u51fa\uff0c\u5b83\u5229\u7528\u79bb\u6563\u7684\u5404\u5411\u5f02\u6027\u4e09\u7ef4\u9ad8\u65af\u5206\u5e03\u6765\u8868\u793a\u8f90\u5c04\u573a\uff0c\u4e0d\u540c\u4e8eNeRF\u7684\u8fde\u7eed\u9690\u5f0f\u6a21\u578b\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGS\u7684\u6570\u5b57\u5b6a\u751f\u65b9\u6cd5\uff0c\u4e13\u95e8\u7528\u4e8e\u9ad8\u6548\u7684\u4e09\u7ef4\u635f\u4f24\u53ef\u89c6\u5316\u3002\u8be5\u65b9\u6cd5\u7684\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a1\uff09\u5229\u7528\u57fa\u4e8eGS\u7684\u4e09\u7ef4\u91cd\u5efa\u5c06\u4e8c\u7ef4\u635f\u4f24\u5206\u5272\u7ed3\u679c\u53ef\u89c6\u5316\uff0c\u540c\u65f6\u51cf\u5c11\u5206\u5272\u8bef\u5dee\uff1b2\uff09\u5f00\u53d1\u591a\u5c3a\u5ea6\u91cd\u5efa\u7b56\u7565\uff0c\u4ee5\u5728\u6548\u7387\u4e0e\u635f\u4f24\u7ec6\u8282\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff1b3\uff09\u652f\u6301\u968f\u7740\u635f\u4f24\u968f\u65f6\u95f4\u6f14\u53d8\u800c\u66f4\u65b0\u6570\u5b57\u5b6a\u751f\u3002\u5728\u7528\u4e8e\u9707\u540e\u68c0\u6d4b\u7684\u5f00\u6e90\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u571f\u6728\u57fa\u7840\u8bbe\u65bd\u6570\u5b57\u5b6a\u751f\u4e2d\u7684\u5168\u9762\u4e09\u7ef4\u635f\u4f24\u53ef\u89c6\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.16856", "pdf": "https://arxiv.org/pdf/2602.16856", "abs": "https://arxiv.org/abs/2602.16856", "authors": ["Boda Lin", "Yongjie Zhu", "Wenyu Qin", "Meng Wang", "Pengfei Wan"], "title": "Analytic Score Optimization for Multi Dimension Video Quality Assessment", "categories": ["cs.CV"], "comment": "18 pages", "summary": "Video Quality Assessment (VQA) is evolving beyond single-number mean opinion score toward richer, multi-faceted evaluations of video content. In this paper, we present a large-scale multi-dimensional VQA dataset UltraVQA that encompasses diverse User-Generated Content~(UGC) annotated across five key quality dimensions: Motion Quality, Motion Amplitude, Aesthetic Quality, Content Quality, and Clarity Quality. Each video in our dataset is scored by over 3 human raters on these dimensions, with fine-grained sub-attribute labels, and accompanied by an explanatory rationale generated by GPT based on the collective human judgments. To better leverage these rich annotations and improve discrete quality score assessment, we introduce Analytic Score Optimization (ASO), a theoretically grounded post-training objective derived for multi-dimensional VQA. By reframing quality assessment as a regularized decision-making process, we obtain a closed-form solution that naturally captures the ordinal nature of human ratings, ensuring alignment with human ranking preferences. In experiments, our method outperforms most baselines including closed-source APIs and open-source models, while also reducing mean absolute error (MAE) in quality prediction. Our work highlights the importance of multi-dimensional, interpretable annotations and reinforcement-based alignment in advancing video quality assessment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u7ef4\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\u6570\u636e\u96c6UltraVQA\uff0c\u5e76\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u4f18\u5316\u65b9\u6cd5Analytic Score Optimization\uff08ASO\uff09\uff0c\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u591a\u7ef4\u5ea6\u89c6\u9891\u8d28\u91cf\u8bc4\u5206\u4e0a\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\uff08VQA\uff09\u4e3b\u8981\u4f9d\u8d56\u5355\u4e00\u7684\u5e73\u5747\u610f\u89c1\u5206\u6570\uff08MOS\uff09\uff0c\u96be\u4ee5\u5168\u9762\u53cd\u6620\u7528\u6237\u751f\u6210\u5185\u5bb9\uff08UGC\uff09\u7684\u590d\u6742\u8d28\u91cf\u7279\u6027\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u6db5\u76d6\u591a\u4e2a\u8d28\u91cf\u7ef4\u5ea6\u7684\u7ec6\u7c92\u5ea6\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5e76\u5f00\u53d1\u76f8\u5e94\u65b9\u6cd5\u4ee5\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u4e30\u5bcc\u6807\u6ce8\uff0c\u63a8\u52a8VQA\u5411\u66f4\u5168\u9762\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u5411\u53d1\u5c55\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u5305\u542b\u4e94\u7ef4\u8d28\u91cf\u6807\u6ce8\uff08\u8fd0\u52a8\u8d28\u91cf\u3001\u8fd0\u52a8\u5e45\u5ea6\u3001\u7f8e\u5b66\u8d28\u91cf\u3001\u5185\u5bb9\u8d28\u91cf\u548c\u6e05\u6670\u5ea6\uff09\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6UltraVQA\uff0c\u6bcf\u6bb5\u89c6\u9891\u5747\u7531\u81f3\u5c113\u540d\u8bc4\u5206\u8005\u6253\u5206\uff0c\u5e76\u9644\u6709\u57fa\u4e8e\u4eba\u7c7b\u5224\u65ad\u7531GPT\u751f\u6210\u7684\u89e3\u91ca\u6027\u7406\u7531\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51faAnalytic Score Optimization\uff08ASO\uff09\u65b9\u6cd5\uff0c\u5c06\u8d28\u91cf\u8bc4\u4f30\u5efa\u6a21\u4e3a\u5e26\u6b63\u5219\u5316\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u63a8\u5bfc\u51fa\u95ed\u5f0f\u89e3\u4ee5\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u8bc4\u5206\u7684\u5e8f\u6570\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff08\u5305\u62ec\u95ed\u6e90API\u548c\u5f00\u6e90\u6a21\u578b\uff09\uff0c\u5e76\u5728\u8d28\u91cf\u9884\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u3002", "conclusion": "\u591a\u7ef4\u5ea6\u3001\u53ef\u89e3\u91ca\u7684\u6807\u6ce8\u7ed3\u5408\u57fa\u4e8e\u5f3a\u5316\u5bf9\u9f50\u7684\u4f18\u5316\u7b56\u7565\uff0c\u5bf9\u63d0\u5347\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u4e0e\u5b9e\u7528\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "summary_cn": "\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\uff08VQA\uff09\u6b63\u4ece\u5355\u4e00\u7684\u5e73\u5747\u610f\u89c1\u5206\u6570\uff08MOS\uff09\u5411\u5bf9\u89c6\u9891\u5185\u5bb9\u66f4\u4e30\u5bcc\u3001\u591a\u7ef4\u5ea6\u7684\u8bc4\u4f30\u6f14\u8fdb\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u7ef4\u5ea6VQA\u6570\u636e\u96c6UltraVQA\uff0c\u8be5\u6570\u636e\u96c6\u6db5\u76d6\u591a\u6837\u5316\u7684\u7528\u6237\u751f\u6210\u5185\u5bb9\uff08UGC\uff09\uff0c\u5e76\u5728\u4e94\u4e2a\u5173\u952e\u8d28\u91cf\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u4e86\u6807\u6ce8\uff1a\u8fd0\u52a8\u8d28\u91cf\u3001\u8fd0\u52a8\u5e45\u5ea6\u3001\u7f8e\u5b66\u8d28\u91cf\u3001\u5185\u5bb9\u8d28\u91cf\u548c\u6e05\u6670\u5ea6\u8d28\u91cf\u3002\u6570\u636e\u96c6\u4e2d\u6bcf\u6bb5\u89c6\u9891\u5747\u7531\u8d85\u8fc73\u540d\u4eba\u5de5\u8bc4\u5206\u8005\u5728\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u6253\u5206\uff0c\u5e76\u914d\u6709\u7ec6\u7c92\u5ea6\u7684\u5b50\u5c5e\u6027\u6807\u7b7e\uff0c\u540c\u65f6\u9644\u6709\u57fa\u4e8e\u96c6\u4f53\u4eba\u7c7b\u5224\u65ad\u7531GPT\u751f\u6210\u7684\u89e3\u91ca\u6027\u7406\u7531\u3002\u4e3a\u4e86\u66f4\u597d\u5730\u5229\u7528\u8fd9\u4e9b\u4e30\u5bcc\u7684\u6807\u6ce8\u4fe1\u606f\u5e76\u6539\u8fdb\u79bb\u6563\u8d28\u91cf\u8bc4\u5206\u7684\u8bc4\u4f30\u6548\u679c\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u5206\u6790\u6027\u8bc4\u5206\u4f18\u5316\uff08Analytic Score Optimization, ASO\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4e3a\u591a\u7ef4VQA\u8bbe\u8ba1\u7684\u3001\u5177\u6709\u7406\u8bba\u4f9d\u636e\u7684\u540e\u8bad\u7ec3\u76ee\u6807\u3002\u901a\u8fc7\u5c06\u8d28\u91cf\u8bc4\u4f30\u91cd\u65b0\u8868\u8ff0\u4e3a\u4e00\u4e2a\u6b63\u5219\u5316\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6211\u4eec\u5f97\u5230\u4e86\u4e00\u4e2a\u95ed\u5f0f\u89e3\uff0c\u8be5\u89e3\u81ea\u7136\u5730\u6355\u6349\u4e86\u4eba\u7c7b\u8bc4\u5206\u7684\u5e8f\u6570\u7279\u6027\uff0c\u786e\u4fdd\u4e0e\u4eba\u7c7b\u6392\u5e8f\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u5927\u591a\u6570\u57fa\u7ebf\u6a21\u578b\uff08\u5305\u62ec\u95ed\u6e90API\u548c\u5f00\u6e90\u6a21\u578b\uff09\uff0c\u540c\u65f6\u5728\u8d28\u91cf\u9884\u6d4b\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u3002\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u591a\u7ef4\u5ea6\u3001\u53ef\u89e3\u91ca\u6807\u6ce8\u4ee5\u53ca\u57fa\u4e8e\u5f3a\u5316\u5bf9\u9f50\u7b56\u7565\u5728\u63a8\u52a8\u89c6\u9891\u8d28\u91cf\u8bc4\u4f30\u53d1\u5c55\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.16872", "pdf": "https://arxiv.org/pdf/2602.16872", "abs": "https://arxiv.org/abs/2602.16872", "authors": ["Sean Man", "Roy Ganz", "Roi Ronen", "Shahar Tsiper", "Shai Mazor", "Niv Nayman"], "title": "DODO: Discrete OCR Diffusion Models", "categories": ["cs.CV"], "comment": null, "summary": "Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge between visual data and textual understanding. While modern Vision-Language Models (VLM) have achieved high accuracy in this domain, they predominantly rely on autoregressive decoding, which becomes computationally expensive and slow for long documents as it requires a sequential forward pass for every generated token. We identify a key opportunity to overcome this bottleneck: unlike open-ended generation, OCR is a highly deterministic task where the visual input strictly dictates a unique output sequence, theoretically enabling efficient, parallel decoding via diffusion models. However, we show that existing masked diffusion models fail to harness this potential; those introduce structural instabilities that are benign in flexible tasks, like captioning, but catastrophic for the rigid, exact-match requirements of OCR. To bridge this gap, we introduce DODO, the first VLM to utilize block discrete diffusion and unlock its speedup potential for OCR. By decomposing generation into blocks, DODO mitigates the synchronization errors of global diffusion. Empirically, our method achieves near state-of-the-art accuracy while enabling up to 3x faster inference compared to autoregressive baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDODO\uff0c\u9996\u4e2a\u57fa\u4e8e\u5757\u79bb\u6563\u6269\u6563\u673a\u5236\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\uff0c\u7528\u4e8e\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u63a5\u8fd1SOTA\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u5b9e\u73b0\u6700\u9ad83\u500d\u7684\u63a8\u7406\u52a0\u901f\u3002", "motivation": "\u5f53\u524dOCR\u4efb\u52a1\u4e2d\u4e3b\u6d41\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u81ea\u56de\u5f52\u89e3\u7801\uff0c\u5bfc\u81f4\u957f\u6587\u6863\u5904\u7406\u65f6\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u901f\u5ea6\u6162\u3002\u5c3d\u7ba1OCR\u5177\u6709\u9ad8\u5ea6\u786e\u5b9a\u6027\uff08\u8f93\u5165\u56fe\u50cf\u552f\u4e00\u51b3\u5b9a\u8f93\u51fa\u6587\u672c\uff09\uff0c\u7406\u8bba\u4e0a\u9002\u5408\u5e76\u884c\u89e3\u7801\uff0c\u4f46\u73b0\u6709\u63a9\u7801\u6269\u6563\u6a21\u578b\u56e0\u7ed3\u6784\u4e0d\u7a33\u5b9a\uff0c\u65e0\u6cd5\u6ee1\u8db3OCR\u5bf9\u7cbe\u786e\u5339\u914d\u7684\u4e25\u683c\u8981\u6c42\u3002", "method": "\u63d0\u51faDODO\u6a21\u578b\uff0c\u9996\u6b21\u5c06\u5757\u79bb\u6563\u6269\u6563\uff08block discrete diffusion\uff09\u5f15\u5165OCR\u4efb\u52a1\u3002\u901a\u8fc7\u5c06\u6587\u672c\u751f\u6210\u5206\u89e3\u4e3a\u591a\u4e2a\u5757\uff0c\u5e76\u884c\u8fdb\u884c\u6269\u6563\u8fc7\u7a0b\uff0c\u4ece\u800c\u7f13\u89e3\u5168\u5c40\u6269\u6563\u4e2d\u7684\u540c\u6b65\u9519\u8bef\u95ee\u9898\uff0c\u517c\u987e\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "result": "DODO\u5728\u591a\u4e2aOCR\u57fa\u51c6\u4e0a\u8fbe\u5230\u63a5\u8fd1\u5f53\u524d\u6700\u4f18\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u63a8\u7406\u901f\u5ea6\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u5feb\u6700\u591a3\u500d\u3002", "conclusion": "\u5757\u79bb\u6563\u6269\u6563\u673a\u5236\u80fd\u6709\u6548\u89e3\u51b3OCR\u4efb\u52a1\u4e2d\u6269\u6563\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u9ad8\u6548OCR\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002", "summary_cn": "\u5149\u5b66\u5b57\u7b26\u8bc6\u522b\uff08OCR\uff09\u662f\u4fe1\u606f\u6570\u5b57\u5316\u7684\u4e00\u9879\u57fa\u7840\u4efb\u52a1\uff0c\u662f\u8fde\u63a5\u89c6\u89c9\u6570\u636e\u4e0e\u6587\u672c\u7406\u89e3\u7684\u5173\u952e\u6865\u6881\u3002\u5c3d\u7ba1\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u6b64\u9886\u57df\u5df2\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u5b83\u4eec\u4e3b\u8981\u4f9d\u8d56\u81ea\u56de\u5f52\u89e3\u7801\u65b9\u5f0f\uff0c\u5bf9\u4e8e\u957f\u6587\u6863\u800c\u8a00\uff0c\u7531\u4e8e\u6bcf\u4e2a\u751f\u6210\u7684\u8bcd\u5143\u90fd\u9700\u8981\u4f9d\u6b21\u8fdb\u884c\u524d\u5411\u4f20\u64ad\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u4e14\u901f\u5ea6\u7f13\u6162\u3002\u6211\u4eec\u53d1\u73b0\u4e00\u4e2a\u5173\u952e\u673a\u9047\u53ef\u4ee5\u7a81\u7834\u8fd9\u4e00\u74f6\u9888\uff1a\u4e0e\u5f00\u653e\u5f0f\u751f\u6210\u4e0d\u540c\uff0cOCR\u662f\u4e00\u9879\u9ad8\u5ea6\u786e\u5b9a\u6027\u7684\u4efb\u52a1\uff0c\u5176\u89c6\u89c9\u8f93\u5165\u4e25\u683c\u51b3\u5b9a\u4e86\u552f\u4e00\u7684\u8f93\u51fa\u5e8f\u5217\uff0c\u7406\u8bba\u4e0a\u53ef\u901a\u8fc7\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u9ad8\u6548\u7684\u5e76\u884c\u89e3\u7801\u3002\u7136\u800c\uff0c\u6211\u4eec\u6307\u51fa\uff0c\u73b0\u6709\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u672a\u80fd\u53d1\u6325\u8fd9\u4e00\u6f5c\u529b\uff1b\u5b83\u4eec\u5f15\u5165\u7684\u7ed3\u6784\u6027\u4e0d\u7a33\u5b9a\u6027\u5728\u56fe\u50cf\u63cf\u8ff0\u7b49\u7075\u6d3b\u4efb\u52a1\u4e2d\u5f71\u54cd\u8f83\u5c0f\uff0c\u4f46\u5728OCR\u8fd9\u79cd\u8981\u6c42\u4e25\u683c\u7cbe\u786e\u5339\u914d\u7684\u4efb\u52a1\u4e2d\u5374\u662f\u707e\u96be\u6027\u7684\u3002\u4e3a\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u63d0\u51fa\u4e86DODO\u2014\u2014\u9996\u4e2a\u91c7\u7528\u5757\u79bb\u6563\u6269\u6563\u673a\u5236\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u6210\u529f\u91ca\u653e\u4e86\u6269\u6563\u6a21\u578b\u5728OCR\u4e2d\u7684\u52a0\u901f\u6f5c\u529b\u3002\u901a\u8fc7\u5c06\u751f\u6210\u8fc7\u7a0b\u5206\u89e3\u4e3a\u591a\u4e2a\u5757\uff0cDODO\u6709\u6548\u7f13\u89e3\u4e86\u5168\u5c40\u6269\u6563\u4e2d\u7684\u540c\u6b65\u9519\u8bef\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8fbe\u5230\u63a5\u8fd1\u6700\u5148\u8fdb\u6c34\u5e73\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6700\u9ad8\u8fbe3\u500d\u7684\u63a8\u7406\u52a0\u901f\u3002"}}
{"id": "2602.16915", "pdf": "https://arxiv.org/pdf/2602.16915", "abs": "https://arxiv.org/abs/2602.16915", "authors": ["Zeyu Ren", "Xiang Li", "Yiran Wang", "Zeyu Zhang", "Hao Tang"], "title": "StereoAdapter-2: Globally Structure-Consistent Underwater Stereo Depth Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Stereo depth estimation is fundamental to underwater robotic perception, yet suffers from severe domain shifts caused by wavelength-dependent light attenuation, scattering, and refraction. Recent approaches leverage monocular foundation models with GRU-based iterative refinement for underwater adaptation; however, the sequential gating and local convolutional kernels in GRUs necessitate multiple iterations for long-range disparity propagation, limiting performance in large-disparity and textureless underwater regions. In this paper, we propose StereoAdapter-2, which replaces the conventional ConvGRU updater with a novel ConvSS2D operator based on selective state space models. The proposed operator employs a four-directional scanning strategy that naturally aligns with epipolar geometry while capturing vertical structural consistency, enabling efficient long-range spatial propagation within a single update step at linear computational complexity. Furthermore, we construct UW-StereoDepth-80K, a large-scale synthetic underwater stereo dataset featuring diverse baselines, attenuation coefficients, and scattering parameters through a two-stage generative pipeline combining semantic-aware style transfer and geometry-consistent novel view synthesis. Combined with dynamic LoRA adaptation inherited from StereoAdapter, our framework achieves state-of-the-art zero-shot performance on underwater benchmarks with 17% improvement on TartanAir-UW and 7.2% improvment on SQUID, with real-world validation on the BlueROV2 platform demonstrates the robustness of our approach. Code: https://github.com/AIGeeksGroup/StereoAdapter-2. Website: https://aigeeksgroup.github.io/StereoAdapter-2.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStereoAdapter-2\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684ConvSS2D\u7b97\u5b50\u66ff\u4ee3\u4f20\u7edfConvGRU\uff0c\u5b9e\u73b0\u5355\u6b65\u9ad8\u6548\u957f\u8ddd\u79bb\u89c6\u5dee\u4f20\u64ad\uff0c\u5e76\u6784\u5efa\u5927\u89c4\u6a21\u5408\u6210\u6c34\u4e0b\u53cc\u76ee\u6570\u636e\u96c6UW-StereoDepth-80K\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u663e\u8457\u63d0\u5347\u6c34\u4e0b\u6df1\u5ea6\u4f30\u8ba1\u6027\u80fd\u3002", "motivation": "\u6c34\u4e0b\u7acb\u4f53\u6df1\u5ea6\u4f30\u8ba1\u53d7\u6ce2\u957f\u76f8\u5173\u5149\u8870\u51cf\u3001\u6563\u5c04\u548c\u6298\u5c04\u5f15\u8d77\u7684\u4e25\u91cd\u57df\u504f\u79fb\u5f71\u54cd\uff1b\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u57fa\u4e8eGRU\u7684\u8fed\u4ee3\u4f18\u5316\uff0c\u4f46\u5176\u987a\u5e8f\u95e8\u63a7\u548c\u5c40\u90e8\u5377\u79ef\u6838\u9700\u591a\u6b21\u8fed\u4ee3\u624d\u80fd\u4f20\u64ad\u957f\u8ddd\u79bb\u89c6\u5dee\uff0c\u5728\u5927\u89c6\u5dee\u548c\u65e0\u7eb9\u7406\u533a\u57df\u8868\u73b0\u53d7\u9650\u3002", "method": "\u63d0\u51faStereoAdapter-2\u6846\u67b6\uff1a1\uff09\u7528\u65b0\u578bConvSS2D\u7b97\u5b50\uff08\u57fa\u4e8e\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff09\u66ff\u4ee3ConvGRU\uff0c\u91c7\u7528\u56db\u5411\u626b\u63cf\u7b56\u7565\u5bf9\u9f50\u6781\u7ebf\u51e0\u4f55\u5e76\u6355\u6349\u5782\u76f4\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u5b9e\u73b0\u5355\u6b65\u7ebf\u6027\u590d\u6742\u5ea6\u7684\u957f\u7a0b\u4f20\u64ad\uff1b2\uff09\u6784\u5efa\u5927\u89c4\u6a21\u5408\u6210\u6c34\u4e0b\u53cc\u76ee\u6570\u636e\u96c6UW-StereoDepth-80K\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u751f\u6210\u6d41\u7a0b\uff08\u8bed\u4e49\u611f\u77e5\u98ce\u683c\u8fc1\u79fb+\u51e0\u4f55\u4e00\u81f4\u65b0\u89c6\u89d2\u5408\u6210\uff09\u6db5\u76d6\u591a\u6837\u57fa\u7ebf\u3001\u8870\u51cf\u7cfb\u6570\u548c\u6563\u5c04\u53c2\u6570\uff1b3\uff09\u7ed3\u5408StereoAdapter\u4e2d\u7684\u52a8\u6001LoRA\u9002\u914d\u673a\u5236\u3002", "result": "\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0cTartanAir-UW\u4e0a\u63d0\u534717%\uff0cSQUID\u4e0a\u63d0\u53477.2%\uff0c\u5e76\u5728BlueROV2\u5e73\u53f0\u5b9e\u73b0\u5b9e\u65f6\u9a8c\u8bc1\uff0c\u8bc1\u660e\u65b9\u6cd5\u9c81\u68d2\u6027\u3002", "conclusion": "StereoAdapter-2\u901a\u8fc7\u65b0\u578b\u72b6\u6001\u7a7a\u95f4\u7b97\u5b50\u548c\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u6709\u6548\u89e3\u51b3\u4e86\u6c34\u4e0b\u6df1\u5ea6\u4f30\u8ba1\u4e2d\u7684\u957f\u7a0b\u4f20\u64ad\u4e0e\u57df\u9002\u5e94\u95ee\u9898\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "summary_cn": "\u7acb\u4f53\u6df1\u5ea6\u4f30\u8ba1\u662f\u6c34\u4e0b\u673a\u5668\u4eba\u611f\u77e5\u7684\u57fa\u7840\uff0c\u4f46\u5374\u53d7\u5230\u7531\u6ce2\u957f\u76f8\u5173\u5149\u8870\u51cf\u3001\u6563\u5c04\u548c\u6298\u5c04\u6240\u5f15\u8d77\u7684\u4e25\u91cd\u57df\u504f\u79fb\u5f71\u54cd\u3002\u8fd1\u671f\u65b9\u6cd5\u5229\u7528\u5355\u76ee\u57fa\u7840\u6a21\u578b\u7ed3\u5408\u57fa\u4e8eGRU\u7684\u8fed\u4ee3\u4f18\u5316\u8fdb\u884c\u6c34\u4e0b\u9002\u5e94\uff1b\u7136\u800c\uff0cGRU\u4e2d\u7684\u987a\u5e8f\u95e8\u63a7\u673a\u5236\u548c\u5c40\u90e8\u5377\u79ef\u6838\u9700\u8981\u591a\u6b21\u8fed\u4ee3\u624d\u80fd\u5b9e\u73b0\u957f\u8ddd\u79bb\u89c6\u5dee\u4f20\u64ad\uff0c\u5728\u5927\u89c6\u5dee\u548c\u65e0\u7eb9\u7406\u7684\u6c34\u4e0b\u533a\u57df\u6027\u80fd\u53d7\u9650\u3002\u672c\u6587\u63d0\u51faStereoAdapter-2\uff0c\u7528\u4e00\u79cd\u57fa\u4e8e\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u65b0\u578bConvSS2D\u7b97\u5b50\u66ff\u4ee3\u4f20\u7edf\u7684ConvGRU\u66f4\u65b0\u5668\u3002\u8be5\u7b97\u5b50\u91c7\u7528\u56db\u5411\u626b\u63cf\u7b56\u7565\uff0c\u81ea\u7136\u5bf9\u9f50\u6781\u7ebf\u51e0\u4f55\u5e76\u6355\u6349\u5782\u76f4\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u53ef\u5728\u5355\u6b21\u66f4\u65b0\u6b65\u9aa4\u4e2d\u4ee5\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u5b9e\u73b0\u9ad8\u6548\u7684\u957f\u8ddd\u79bb\u7a7a\u95f4\u4f20\u64ad\u3002\u6b64\u5916\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u5408\u6210\u6c34\u4e0b\u7acb\u4f53\u6570\u636e\u96c6UW-StereoDepth-80K\uff0c\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u611f\u77e5\u98ce\u683c\u8fc1\u79fb\u4e0e\u51e0\u4f55\u4e00\u81f4\u7684\u65b0\u89c6\u89d2\u5408\u6210\u7684\u4e24\u9636\u6bb5\u751f\u6210\u6d41\u7a0b\uff0c\u6db5\u76d6\u591a\u6837\u5316\u7684\u57fa\u7ebf\u3001\u8870\u51cf\u7cfb\u6570\u548c\u6563\u5c04\u53c2\u6570\u3002\u7ed3\u5408StereoAdapter\u4e2d\u7ee7\u627f\u7684\u52a8\u6001LoRA\u9002\u914d\u673a\u5236\uff0c\u6211\u4eec\u7684\u6846\u67b6\u5728\u6c34\u4e0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0c\u5728TartanAir-UW\u4e0a\u63d0\u534717%\uff0c\u5728SQUID\u4e0a\u63d0\u53477.2%\uff0c\u5e76\u5728BlueROV2\u5e73\u53f0\u4e0a\u7684\u771f\u5b9e\u573a\u666f\u9a8c\u8bc1\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.16917", "pdf": "https://arxiv.org/pdf/2602.16917", "abs": "https://arxiv.org/abs/2602.16917", "authors": ["Sakib Ahammed", "Xia Cui", "Xinqi Fan", "Wenqi Lu", "Moi Hoon Yap"], "title": "SemCovNet: Towards Fair and Semantic Coverage-Aware Learning for Underrepresented Visual Concepts", "categories": ["cs.CV"], "comment": null, "summary": "Modern vision models increasingly rely on rich semantic representations that extend beyond class labels to include descriptive concepts and contextual attributes. However, existing datasets exhibit Semantic Coverage Imbalance (SCI), a previously overlooked bias arising from the long-tailed semantic representations. Unlike class imbalance, SCI occurs at the semantic level, affecting how models learn and reason about rare yet meaningful semantics. To mitigate SCI, we propose Semantic Coverage-Aware Network (SemCovNet), a novel model that explicitly learns to correct semantic coverage disparities. SemCovNet integrates a Semantic Descriptor Map (SDM) for learning semantic representations, a Descriptor Attention Modulation (DAM) module that dynamically weights visual and concept features, and a Descriptor-Visual Alignment (DVA) loss that aligns visual features with descriptor semantics. We quantify semantic fairness using a Coverage Disparity Index (CDI), which measures the alignment between coverage and error. Extensive experiments across multiple datasets demonstrate that SemCovNet enhances model reliability and substantially reduces CDI, achieving fairer and more equitable performance. This work establishes SCI as a measurable and correctable bias, providing a foundation for advancing semantic fairness and interpretable vision learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSemCovNet\u6a21\u578b\uff0c\u901a\u8fc7\u8bed\u4e49\u63cf\u8ff0\u56fe\u3001\u6ce8\u610f\u529b\u8c03\u5236\u6a21\u5757\u548c\u5bf9\u9f50\u635f\u5931\uff0c\u89e3\u51b3\u89c6\u89c9\u6a21\u578b\u4e2d\u957f\u671f\u88ab\u5ffd\u89c6\u7684\u8bed\u4e49\u8986\u76d6\u4e0d\u5e73\u8861\uff08SCI\uff09\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u8bed\u4e49\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u8bed\u4e49\u8986\u76d6\u4e0d\u5e73\u8861\uff08SCI\uff09\u95ee\u9898\uff0c\u5373\u8bed\u4e49\u8868\u793a\u5448\u957f\u5c3e\u5206\u5e03\uff0c\u5bfc\u81f4\u6a21\u578b\u96be\u4ee5\u5b66\u4e60\u7a00\u6709\u4f46\u6709\u610f\u4e49\u7684\u8bed\u4e49\u6982\u5ff5\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u516c\u5e73\u6027\u4e0e\u53ef\u9760\u6027\u3002\u8fd9\u4e00\u95ee\u9898\u4e0d\u540c\u4e8e\u4f20\u7edf\u7684\u7c7b\u522b\u4e0d\u5e73\u8861\uff0c\u9700\u5728\u8bed\u4e49\u5c42\u9762\u8fdb\u884c\u6821\u6b63\u3002", "method": "\u63d0\u51faSemantic Coverage-Aware Network (SemCovNet)\uff0c\u5305\u542b\uff1a1\uff09\u8bed\u4e49\u63cf\u8ff0\u56fe\uff08SDM\uff09\u7528\u4e8e\u5b66\u4e60\u8bed\u4e49\u8868\u793a\uff1b2\uff09\u63cf\u8ff0\u7b26\u6ce8\u610f\u529b\u8c03\u5236\u6a21\u5757\uff08DAM\uff09\u52a8\u6001\u52a0\u6743\u89c6\u89c9\u4e0e\u6982\u5ff5\u7279\u5f81\uff1b3\uff09\u63cf\u8ff0-\u89c6\u89c9\u5bf9\u9f50\u635f\u5931\uff08DVA\uff09\u5bf9\u9f50\u89c6\u89c9\u7279\u5f81\u4e0e\u8bed\u4e49\u63cf\u8ff0\u3002\u540c\u65f6\u5f15\u5165\u8986\u76d6\u5dee\u5f02\u6307\u6570\uff08CDI\uff09\u91cf\u5316\u8bed\u4e49\u516c\u5e73\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSemCovNet\u663e\u8457\u964d\u4f4e\u4e86CDI\u6307\u6807\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u8bed\u4e49\u516c\u5e73\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u5747\u8861\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5c06\u8bed\u4e49\u8986\u76d6\u4e0d\u5e73\u8861\uff08SCI\uff09\u5b9a\u4e49\u4e3a\u53ef\u5ea6\u91cf\u3001\u53ef\u6821\u6b63\u7684\u504f\u5dee\uff0c\u4e3a\u63a8\u52a8\u8bed\u4e49\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u7684\u89c6\u89c9\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u57fa\u7840\u3002", "summary_cn": "\u73b0\u4ee3\u89c6\u89c9\u6a21\u578b\u65e5\u76ca\u4f9d\u8d56\u8d85\u8d8a\u7c7b\u522b\u6807\u7b7e\u7684\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\uff0c\u5305\u62ec\u63cf\u8ff0\u6027\u6982\u5ff5\u548c\u4e0a\u4e0b\u6587\u5c5e\u6027\u3002\u7136\u800c\uff0c\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u201c\u8bed\u4e49\u8986\u76d6\u4e0d\u5e73\u8861\u201d\uff08Semantic Coverage Imbalance, SCI\uff09\u2014\u2014\u4e00\u79cd\u6b64\u524d\u88ab\u5ffd\u89c6\u7684\u504f\u5dee\uff0c\u6e90\u4e8e\u8bed\u4e49\u8868\u793a\u7684\u957f\u5c3e\u5206\u5e03\u3002\u4e0e\u7c7b\u522b\u4e0d\u5e73\u8861\u4e0d\u540c\uff0cSCI\u53d1\u751f\u5728\u8bed\u4e49\u5c42\u9762\uff0c\u5f71\u54cd\u6a21\u578b\u5bf9\u7a00\u6709\u4f46\u6709\u610f\u4e49\u8bed\u4e49\u7684\u5b66\u4e60\u4e0e\u63a8\u7406\u80fd\u529b\u3002\u4e3a\u7f13\u89e3SCI\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u8bed\u4e49\u8986\u76d6\u611f\u77e5\u7f51\u7edc\uff08SemCovNet\uff09\uff0c\u8be5\u6a21\u578b\u663e\u5f0f\u5730\u5b66\u4e60\u6821\u6b63\u8bed\u4e49\u8986\u76d6\u5dee\u5f02\u3002SemCovNet\u6574\u5408\u4e86\u7528\u4e8e\u5b66\u4e60\u8bed\u4e49\u8868\u793a\u7684\u8bed\u4e49\u63cf\u8ff0\u56fe\uff08SDM\uff09\u3001\u52a8\u6001\u52a0\u6743\u89c6\u89c9\u4e0e\u6982\u5ff5\u7279\u5f81\u7684\u63cf\u8ff0\u7b26\u6ce8\u610f\u529b\u8c03\u5236\u6a21\u5757\uff08DAM\uff09\uff0c\u4ee5\u53ca\u5bf9\u9f50\u89c6\u89c9\u7279\u5f81\u4e0e\u63cf\u8ff0\u8bed\u4e49\u7684\u63cf\u8ff0-\u89c6\u89c9\u5bf9\u9f50\u635f\u5931\uff08DVA\uff09\u3002\u6211\u4eec\u901a\u8fc7\u8986\u76d6\u5dee\u5f02\u6307\u6570\uff08CDI\uff09\u91cf\u5316\u8bed\u4e49\u516c\u5e73\u6027\uff0c\u8be5\u6307\u6807\u8861\u91cf\u8986\u76d6\u5ea6\u4e0e\u8bef\u5dee\u4e4b\u95f4\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cSemCovNet\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u53ef\u9760\u6027\u5e76\u5927\u5e45\u964d\u4f4eCDI\uff0c\u5b9e\u73b0\u4e86\u66f4\u516c\u5e73\u3001\u66f4\u5747\u8861\u7684\u6027\u80fd\u3002\u672c\u7814\u7a76\u786e\u7acb\u4e86SCI\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6d4b\u91cf\u4e14\u53ef\u6821\u6b63\u7684\u504f\u5dee\uff0c\u4e3a\u63a8\u8fdb\u8bed\u4e49\u516c\u5e73\u6027\u4e0e\u53ef\u89e3\u91ca\u7684\u89c6\u89c9\u5b66\u4e60\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.16918", "pdf": "https://arxiv.org/pdf/2602.16918", "abs": "https://arxiv.org/abs/2602.16918", "authors": ["Shlok Mishra", "Tsung-Yu Lin", "Linda Wang", "Hongli Xu", "Yimin Liu", "Michael Hsu", "Chaitanya Ahuja", "Hao Yuan", "Jianpeng Cheng", "Hong-You Chen", "Haoyuan Xu", "Chao Li", "Abhijeet Awasthi", "Jihye Moon", "Don Husa", "Michael Ge", "Sumedha Singla", "Arkabandhu Chowdhury", "Phong Dingh", "Satya Narayan Shukla", "Yonghuan Yang", "David Jacobs", "Qi Guo", "Jun Xiao", "Xiangjun Fan", "Aashu Singh"], "title": "Xray-Visual Models: Scaling Vision models on Industry Scale Data", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data curation pipelines that incorporate balancing and noise suppression strategies to maximize semantic diversity while minimizing label noise. We introduce a three-stage training pipeline that combines self-supervised MAE, semi-supervised hashtag classification, and CLIP-style contrastive learning to jointly optimize image and video modalities. Our architecture builds on a Vision Transformer backbone enhanced with efficient token reorganization (EViT) for improved computational efficiency. Extensive experiments demonstrate that Xray-Visual achieves state-of-the-art performance across diverse benchmarks, including ImageNet for image classification, Kinetics and HMDB51 for video understanding, and MSCOCO for cross-modal retrieval. The model exhibits strong robustness to domain shift and adversarial perturbations. We further demonstrate that integrating large language models as text encoders (LLM2CLIP) significantly enhances retrieval performance and generalization capabilities, particularly in real-world environments. Xray-Visual establishes new benchmarks for scalable, multimodal vision models, while maintaining superior accuracy and computational efficiency.", "AI": {"tldr": "Xray-Visual \u662f\u4e00\u4e2a\u5728\u5927\u89c4\u6a21\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u7edf\u4e00\u89c6\u89c9\u6a21\u578b\uff0c\u5728\u56fe\u50cf\u548c\u89c6\u9891\u7406\u89e3\u4efb\u52a1\u4e2d\u8fbe\u5230 SOTA\uff0c\u5177\u5907\u9ad8\u9c81\u68d2\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5f15\u5165 LLM \u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u6a21\u578b\u5728\u5904\u7406\u5927\u89c4\u6a21\u3001\u591a\u6a21\u6001\uff08\u56fe\u50cf\u4e0e\u89c6\u9891\uff09\u6570\u636e\u65f6\u9762\u4e34\u8bed\u4e49\u591a\u6837\u6027\u4e0d\u8db3\u3001\u6807\u7b7e\u566a\u58f0\u9ad8\u3001\u8ba1\u7b97\u6548\u7387\u4f4e\u4ee5\u53ca\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u5f31\u7b49\u6311\u6218\u3002\u4f5c\u8005\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u4ee5\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u793e\u4ea4\u5a92\u4f53\u573a\u666f\u4e2d\u7684\u590d\u6742\u9700\u6c42\u3002", "method": "Xray-Visual \u57fa\u4e8e Vision Transformer \u4e3b\u5e72\u7f51\u7edc\uff0c\u5f15\u5165\u9ad8\u6548 token \u91cd\u7ec4\uff08EViT\uff09\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002\u8bad\u7ec3\u91c7\u7528\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u81ea\u76d1\u7763 MAE \u9884\u8bad\u7ec3\u3001\u534a\u76d1\u7763 hashtag \u5206\u7c7b\u548c CLIP \u5f0f\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5229\u7528\u8d85\u8fc7 150 \u4ebf\u56fe\u50cf-\u6587\u672c\u5bf9\u548c 100 \u4ebf\u89c6\u9891-hashtag \u5bf9\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u5e73\u8861\u4e0e\u53bb\u566a\u7b56\u7565\u4f18\u5316\u6570\u636e\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u63a2\u7d22\u5c06\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\uff08LLM2CLIP\uff09\u4ee5\u589e\u5f3a\u68c0\u7d22\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "result": "Xray-Visual \u5728 ImageNet\uff08\u56fe\u50cf\u5206\u7c7b\uff09\u3001Kinetics \u4e0e HMDB51\uff08\u89c6\u9891\u7406\u89e3\uff09\u3001MSCOCO\uff08\u8de8\u6a21\u6001\u68c0\u7d22\uff09\u7b49\u591a\u4e2a\u57fa\u51c6\u4e0a\u8fbe\u5230 SOTA \u6027\u80fd\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u5bf9\u57df\u504f\u79fb\u548c\u5bf9\u6297\u6270\u52a8\u7684\u5f3a\u5927\u9c81\u68d2\u6027\u3002LLM2CLIP \u7684\u5f15\u5165\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u9645\u573a\u666f\u4e0b\u7684\u68c0\u7d22\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Xray-Visual \u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u517c\u5177\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u6548\u7387\u548c\u5f3a\u9c81\u68d2\u6027\u7684\u53ef\u6269\u5c55\u591a\u6a21\u6001\u89c6\u89c9\u6a21\u578b\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u5927\u89c4\u6a21\u89c6\u89c9\u7406\u89e3\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\uff0c\u5e76\u9a8c\u8bc1\u4e86 LLM \u4e0e\u89c6\u89c9\u6a21\u578b\u878d\u5408\u7684\u6709\u6548\u6027\u3002", "summary_cn": "\u6211\u4eec\u63d0\u51fa\u4e86 Xray-Visual\uff0c\u8fd9\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u89c4\u6a21\u56fe\u50cf\u548c\u89c6\u9891\u7406\u89e3\u7684\u7edf\u4e00\u89c6\u89c9\u6a21\u578b\u67b6\u6784\uff0c\u5176\u5728\u5de5\u4e1a\u7ea7\u89c4\u6a21\u7684\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u6211\u4eec\u7684\u6a21\u578b\u5229\u7528\u4e86\u6765\u81ea Facebook \u548c Instagram \u7684\u8d85\u8fc7 150 \u4ebf\u4e2a\u7ecf\u8fc7\u7b5b\u9009\u7684\u56fe\u50cf-\u6587\u672c\u5bf9\u4ee5\u53ca 100 \u4ebf\u4e2a\u89c6\u9891-hashtag \u5bf9\uff0c\u5e76\u91c7\u7528\u5f3a\u5927\u7684\u6570\u636e\u7b5b\u9009\u6d41\u7a0b\uff0c\u7ed3\u5408\u6570\u636e\u5e73\u8861\u4e0e\u566a\u58f0\u6291\u5236\u7b56\u7565\uff0c\u5728\u6700\u5927\u5316\u8bed\u4e49\u591a\u6837\u6027\u7684\u540c\u65f6\u6700\u5c0f\u5316\u6807\u7b7e\u566a\u58f0\u3002\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e86\u81ea\u76d1\u7763\u7684 MAE\u3001\u534a\u76d1\u7763\u7684 hashtag \u5206\u7c7b\u4ee5\u53ca CLIP \u98ce\u683c\u7684\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ee5\u8054\u5408\u4f18\u5316\u56fe\u50cf\u548c\u89c6\u9891\u6a21\u6001\u3002\u8be5\u67b6\u6784\u57fa\u4e8e Vision Transformer \u4e3b\u5e72\u7f51\u7edc\uff0c\u5e76\u901a\u8fc7\u9ad8\u6548\u7684 token \u91cd\u7ec4\uff08EViT\uff09\u6280\u672f\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cXray-Visual \u5728\u591a\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5305\u62ec\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u7684 ImageNet\u3001\u7528\u4e8e\u89c6\u9891\u7406\u89e3\u7684 Kinetics \u548c HMDB51\uff0c\u4ee5\u53ca\u7528\u4e8e\u8de8\u6a21\u6001\u68c0\u7d22\u7684 MSCOCO\u3002\u8be5\u6a21\u578b\u5bf9\u57df\u504f\u79fb\u548c\u5bf9\u6297\u6270\u52a8\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002\u6211\u4eec\u8fdb\u4e00\u6b65\u8bc1\u660e\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u6587\u672c\u7f16\u7801\u5668\uff08LLM2CLIP\uff09\u80fd\u591f\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u3002Xray-Visual \u4e3a\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u89c6\u89c9\u6a21\u578b\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5353\u8d8a\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.16950", "pdf": "https://arxiv.org/pdf/2602.16950", "abs": "https://arxiv.org/abs/2602.16950", "authors": ["Kibon Ku", "Talukder Z. Jubery", "Adarsh Krishnamurthy", "Baskar Ganapathysubramanian"], "title": "HS-3D-NeRF: 3D Surface and Hyperspectral Reconstruction From Stationary Hyperspectral Images Using Multi-Channel NeRFs", "categories": ["cs.CV"], "comment": "16 pages, 14 figures, 3 tables", "summary": "Advances in hyperspectral imaging (HSI) and 3D reconstruction have enabled accurate, high-throughput characterization of agricultural produce quality and plant phenotypes, both essential for advancing agricultural sustainability and breeding programs. HSI captures detailed biochemical features of produce, while 3D geometric data substantially improves morphological analysis. However, integrating these two modalities at scale remains challenging, as conventional approaches involve complex hardware setups incompatible with automated phenotyping systems. Recent advances in neural radiance fields (NeRF) offer computationally efficient 3D reconstruction but typically require moving-camera setups, limiting throughput and reproducibility in standard indoor agricultural environments. To address these challenges, we introduce HSI-SC-NeRF, a stationary-camera multi-channel NeRF framework for high-throughput hyperspectral 3D reconstruction targeting postharvest inspection of agricultural produce. Multi-view hyperspectral data is captured using a stationary camera while the object rotates within a custom-built Teflon imaging chamber providing diffuse, uniform illumination. Object poses are estimated via ArUco calibration markers and transformed to the camera frame of reference through simulated pose transformations, enabling standard NeRF training on stationary-camera data. A multi-channel NeRF formulation optimizes reconstruction across all hyperspectral bands jointly using a composite spectral loss, supported by a two-stage training protocol that decouples geometric initialization from radiometric refinement. Experiments on three agricultural produce samples demonstrate high spatial reconstruction accuracy and strong spectral fidelity across the visible and near-infrared spectrum, confirming the suitability of HSI-SC-NeRF for integration into automated agricultural workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHSI-SC-NeRF\uff0c\u4e00\u79cd\u57fa\u4e8e\u56fa\u5b9a\u76f8\u673a\u7684\u591a\u901a\u9053\u795e\u7ecf\u8f90\u5c04\u573a\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u901a\u91cf\u7684\u519c\u4e1a\u4ea7\u54c1\u9ad8\u5149\u8c31\u4e09\u7ef4\u91cd\u5efa\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u786c\u4ef6\u590d\u6742\u3001\u96be\u4ee5\u96c6\u6210\u5230\u81ea\u52a8\u5316\u8868\u578b\u7cfb\u7edf\u4e2d\u7684\u95ee\u9898\u3002", "motivation": "\u9ad8\u5149\u8c31\u6210\u50cf\uff08HSI\uff09\u548c3D\u91cd\u5efa\u6280\u672f\u867d\u80fd\u6709\u6548\u8868\u5f81\u519c\u4ea7\u54c1\u54c1\u8d28\u4e0e\u690d\u7269\u8868\u578b\uff0c\u4f46\u4e8c\u8005\u7684\u5927\u89c4\u6a21\u878d\u5408\u4ecd\u9762\u4e34\u6311\u6218\uff1a\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u786c\u4ef6\u8bbe\u7f6e\uff0c\u4e0d\u9002\u7528\u4e8e\u81ea\u52a8\u5316\u8868\u578b\u7cfb\u7edf\uff1b\u800c\u73b0\u6709NeRF\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u79fb\u52a8\u76f8\u673a\uff0c\u5728\u6807\u51c6\u5ba4\u5185\u519c\u4e1a\u73af\u5883\u4e2d\u96be\u4ee5\u5b9e\u73b0\u9ad8\u901a\u91cf\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51faHSI-SC-NeRF\u6846\u67b6\uff0c\u91c7\u7528\u56fa\u5b9a\u76f8\u673a\u914d\u5408\u65cb\u8f6c\u7269\u4f53\u7684\u65b9\u5f0f\u91c7\u96c6\u591a\u89c6\u89d2\u9ad8\u5149\u8c31\u6570\u636e\uff0c\u5e76\u5728\u7279\u5236\u7684\u805a\u56db\u6c1f\u4e59\u70ef\u6210\u50cf\u8154\u5185\u63d0\u4f9b\u5747\u5300\u6f2b\u5c04\u7167\u660e\u3002\u901a\u8fc7ArUco\u6807\u5b9a\u6807\u8bb0\u4f30\u8ba1\u7269\u4f53\u4f4d\u59ff\uff0c\u5e76\u7ecf\u6a21\u62df\u4f4d\u59ff\u53d8\u6362\u5c06\u5176\u8f6c\u6362\u81f3\u76f8\u673a\u5750\u6807\u7cfb\uff0c\u4ece\u800c\u652f\u6301\u6807\u51c6NeRF\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u591a\u901a\u9053NeRF\u7ed3\u6784\uff0c\u7ed3\u5408\u590d\u5408\u5149\u8c31\u635f\u5931\u51fd\u6570\u8054\u5408\u4f18\u5316\u6240\u6709\u9ad8\u5149\u8c31\u6ce2\u6bb5\u7684\u91cd\u5efa\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u5c06\u51e0\u4f55\u521d\u59cb\u5316\u4e0e\u8f90\u5c04\u7cbe\u70bc\u89e3\u8026\u3002", "result": "\u5728\u4e09\u79cd\u519c\u4ea7\u54c1\u6837\u672c\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u89c1\u5149\u4e0e\u8fd1\u7ea2\u5916\u6ce2\u6bb5\u5747\u5b9e\u73b0\u4e86\u9ad8\u7a7a\u95f4\u91cd\u5efa\u7cbe\u5ea6\u548c\u826f\u597d\u7684\u5149\u8c31\u4fdd\u771f\u5ea6\u3002", "conclusion": "HSI-SC-NeRF\u5177\u5907\u9ad8\u901a\u91cf\u3001\u9ad8\u7cbe\u5ea6\u548c\u826f\u597d\u5149\u8c31\u4e00\u81f4\u6027\uff0c\u9002\u5408\u96c6\u6210\u5230\u81ea\u52a8\u5316\u519c\u4e1a\u5de5\u4f5c\u6d41\u4e2d\uff0c\u4e3a\u519c\u4ea7\u54c1\u4ea7\u540e\u68c0\u6d4b\u548c\u690d\u7269\u8868\u578b\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "summary_cn": "\u9ad8\u5149\u8c31\u6210\u50cf\uff08HSI\uff09\u548c\u4e09\u7ef4\u91cd\u5efa\u6280\u672f\u7684\u8fdb\u6b65\u4f7f\u5f97\u5bf9\u519c\u4ea7\u54c1\u54c1\u8d28\u548c\u690d\u7269\u8868\u578b\u8fdb\u884c\u51c6\u786e\u3001\u9ad8\u901a\u91cf\u7684\u8868\u5f81\u6210\u4e3a\u53ef\u80fd\uff0c\u8fd9\u5bf9\u4e8e\u63a8\u52a8\u519c\u4e1a\u53ef\u6301\u7eed\u53d1\u5c55\u548c\u80b2\u79cd\u8ba1\u5212\u81f3\u5173\u91cd\u8981\u3002HSI\u80fd\u591f\u6355\u6349\u519c\u4ea7\u54c1\u8be6\u7ec6\u7684\u751f\u5316\u7279\u5f81\uff0c\u800c\u4e09\u7ef4\u51e0\u4f55\u6570\u636e\u5219\u663e\u8457\u63d0\u5347\u4e86\u5f62\u6001\u5b66\u5206\u6790\u80fd\u529b\u3002\u7136\u800c\uff0c\u5927\u89c4\u6a21\u878d\u5408\u8fd9\u4e24\u79cd\u6a21\u6001\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u590d\u6742\u7684\u786c\u4ef6\u8bbe\u7f6e\uff0c\u96be\u4ee5\u4e0e\u81ea\u52a8\u5316\u8868\u578b\u7cfb\u7edf\u517c\u5bb9\u3002\u8fd1\u671f\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7684\u53d1\u5c55\u867d\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u7684\u4e09\u7ef4\u91cd\u5efa\u624b\u6bb5\uff0c\u4f46\u901a\u5e38\u9700\u8981\u79fb\u52a8\u76f8\u673a\u8bbe\u7f6e\uff0c\u9650\u5236\u4e86\u5176\u5728\u6807\u51c6\u5ba4\u5185\u519c\u4e1a\u73af\u5883\u4e2d\u7684\u901a\u91cf\u548c\u53ef\u91cd\u590d\u6027\u3002\u4e3a\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86HSI-SC-NeRF\u2014\u2014\u4e00\u79cd\u9762\u5411\u519c\u4ea7\u54c1\u4ea7\u540e\u68c0\u6d4b\u7684\u56fa\u5b9a\u76f8\u673a\u591a\u901a\u9053NeRF\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u901a\u91cf\u9ad8\u5149\u8c31\u4e09\u7ef4\u91cd\u5efa\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u56fa\u5b9a\u76f8\u673a\u91c7\u96c6\u65cb\u8f6c\u7269\u4f53\u7684\u591a\u89c6\u89d2\u9ad8\u5149\u8c31\u6570\u636e\uff0c\u7269\u4f53\u7f6e\u4e8e\u7279\u5236\u7684\u805a\u56db\u6c1f\u4e59\u70ef\u6210\u50cf\u8154\u5185\u4ee5\u83b7\u5f97\u5747\u5300\u6f2b\u5c04\u7167\u660e\u3002\u901a\u8fc7ArUco\u6807\u5b9a\u6807\u8bb0\u4f30\u8ba1\u7269\u4f53\u4f4d\u59ff\uff0c\u5e76\u501f\u52a9\u6a21\u62df\u4f4d\u59ff\u53d8\u6362\u5c06\u5176\u8f6c\u6362\u81f3\u76f8\u673a\u53c2\u8003\u5750\u6807\u7cfb\uff0c\u4ece\u800c\u652f\u6301\u5728\u56fa\u5b9a\u76f8\u673a\u6570\u636e\u4e0a\u8fdb\u884c\u6807\u51c6NeRF\u8bad\u7ec3\u3002\u6240\u63d0\u51fa\u7684\u591a\u901a\u9053NeRF\u6a21\u578b\u901a\u8fc7\u590d\u5408\u5149\u8c31\u635f\u5931\u51fd\u6570\u8054\u5408\u4f18\u5316\u6240\u6709\u9ad8\u5149\u8c31\u6ce2\u6bb5\u7684\u91cd\u5efa\u6548\u679c\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5c06\u51e0\u4f55\u521d\u59cb\u5316\u4e0e\u8f90\u5c04\u7cbe\u70bc\u8fc7\u7a0b\u89e3\u8026\u3002\u5728\u4e09\u79cd\u519c\u4ea7\u54c1\u6837\u672c\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u89c1\u5149\u4e0e\u8fd1\u7ea2\u5916\u6ce2\u6bb5\u5747\u5b9e\u73b0\u4e86\u9ad8\u7a7a\u95f4\u91cd\u5efa\u7cbe\u5ea6\u548c\u4f18\u5f02\u7684\u5149\u8c31\u4fdd\u771f\u5ea6\uff0c\u9a8c\u8bc1\u4e86HSI-SC-NeRF\u9002\u7528\u4e8e\u96c6\u6210\u5230\u81ea\u52a8\u5316\u519c\u4e1a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002"}}
{"id": "2602.16968", "pdf": "https://arxiv.org/pdf/2602.16968", "abs": "https://arxiv.org/abs/2602.16968", "authors": ["Dahye Kim", "Deepti Ghadiyaram", "Raghudeep Gadde"], "title": "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\\times$ and $3.2\\times$ speedup on FLUX-1.Dev and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u5206\u8bcd\u7b56\u7565\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u5185\u5bb9\u590d\u6742\u5ea6\u548c\u53bb\u566a\u65f6\u95f4\u6b65\u52a8\u6001\u8c03\u6574\u56fe\u50cf/\u89c6\u9891\u751f\u6210\u4e2d\u7684patch\u5927\u5c0f\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u800c\u4e0d\u635f\u5931\u751f\u6210\u8d28\u91cf\u3002", "motivation": "Diffusion Transformers\uff08DiTs\uff09\u5728\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u4e3b\u8981\u6e90\u4e8e\u56fa\u5b9a\u5927\u5c0f\u7684patch\u5206\u8bcd\u7b56\u7565\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u53bb\u566a\u9636\u6bb5\u5bf9\u7ec6\u8282\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u5206\u8bcd\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6839\u636e\u53bb\u566a\u65f6\u95f4\u6b65\u548c\u5185\u5bb9\u590d\u6742\u5ea6\u52a8\u6001\u8c03\u6574patch\u5927\u5c0f\uff1a\u65e9\u671f\u4f7f\u7528\u8f83\u5927patch\u5efa\u6a21\u5168\u5c40\u7ed3\u6784\uff0c\u540e\u671f\u4f7f\u7528\u8f83\u5c0fpatch\u7ec6\u5316\u5c40\u90e8\u7ec6\u8282\u3002", "result": "\u5728FLUX-1.Dev\u548cWan 2.1\u4e0a\u5206\u522b\u5b9e\u73b0\u6700\u9ad83.52\u500d\u548c3.2\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u548c\u63d0\u793a\u4e00\u81f4\u6027\u3002", "conclusion": "\u52a8\u6001\u5206\u8bcd\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u6d4b\u8bd5\u65f6\u7b56\u7565\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u611f\u77e5\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u5927\u5e45\u964d\u4f4eDiT\u63a8\u7406\u6210\u672c\u3002", "summary_cn": "\u6269\u6563Transformer\uff08DiTs\uff09\u5728\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f46\u5176\u6210\u529f\u662f\u4ee5\u9ad8\u6602\u7684\u8ba1\u7b97\u5f00\u9500\u4e3a\u4ee3\u4ef7\u7684\u3002\u8fd9\u79cd\u4f4e\u6548\u6027\u4e3b\u8981\u6e90\u4e8e\u56fa\u5b9a\u7684\u5206\u8bcd\u8fc7\u7a0b\u2014\u2014\u5728\u6574\u4e2a\u53bb\u566a\u9636\u6bb5\u59cb\u7ec8\u4f7f\u7528\u56fa\u5b9a\u5927\u5c0f\u7684\u56fe\u50cf\u5757\uff08patch\uff09\uff0c\u800c\u5ffd\u7565\u4e86\u5185\u5bb9\u590d\u6742\u5ea6\u7684\u53d8\u5316\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6d4b\u8bd5\u65f6\u52a8\u6001\u5206\u8bcd\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u6839\u636e\u5185\u5bb9\u590d\u6742\u5ea6\u548c\u53bb\u566a\u65f6\u95f4\u6b65\u52a8\u6001\u8c03\u6574patch\u5927\u5c0f\u3002\u6211\u4eec\u7684\u6838\u5fc3\u6d1e\u5bdf\u662f\uff1a\u5728\u53bb\u566a\u65e9\u671f\u9636\u6bb5\uff0c\u4ec5\u9700\u8f83\u7c97\u7c92\u5ea6\uff08\u8f83\u5927\uff09\u7684patch\u6765\u5efa\u6a21\u5168\u5c40\u7ed3\u6784\uff1b\u800c\u5728\u540e\u671f\u9636\u6bb5\uff0c\u5219\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\uff08\u8f83\u5c0f\uff09\u7684patch\u4ee5\u7cbe\u70bc\u5c40\u90e8\u7ec6\u8282\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u56fe\u50cf\u548c\u89c6\u9891\u751f\u6210\u7684\u4e0d\u540c\u53bb\u566a\u6b65\u9aa4\u4e2d\u52a8\u6001\u91cd\u65b0\u5206\u914dpatch\u5927\u5c0f\uff0c\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u826f\u597d\u7684\u611f\u77e5\u751f\u6210\u8d28\u91cf\u3002\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff1a\u5728FLUX-1.Dev\u548cWan 2.1\u6a21\u578b\u4e0a\uff0c\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u9ad83.52\u500d\u548c3.2\u500d\u7684\u52a0\u901f\uff0c\u4e14\u672a\u727a\u7272\u751f\u6210\u8d28\u91cf\u4e0e\u63d0\u793a\u9075\u5faa\u80fd\u529b\u3002"}}
{"id": "2602.16979", "pdf": "https://arxiv.org/pdf/2602.16979", "abs": "https://arxiv.org/abs/2602.16979", "authors": ["Divyam Madaan", "Sumit Chopra", "Kyunghyun Cho"], "title": "Characterizing the Predictive Impact of Modalities with Supervised Latent-Variable Modeling", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": null, "summary": "Despite the recent success of Multimodal Large Language Models (MLLMs), existing approaches predominantly assume the availability of multiple modalities during training and inference. In practice, multimodal data is often incomplete because modalities may be missing, collected asynchronously, or available only for a subset of examples. In this work, we propose PRIMO, a supervised latent-variable imputation model that quantifies the predictive impact of any missing modality within the multimodal learning setting. PRIMO enables the use of all available training examples, whether modalities are complete or partial. Specifically, it models the missing modality through a latent variable that captures its relationship with the observed modality in the context of prediction. During inference, we draw many samples from the learned distribution over the missing modality to both obtain the marginal predictive distribution (for the purpose of prediction) and analyze the impact of the missing modalities on the prediction for each instance. We evaluate PRIMO on a synthetic XOR dataset, Audio-Vision MNIST, and MIMIC-III for mortality and ICD-9 prediction. Across all datasets, PRIMO obtains performance comparable to unimodal baselines when a modality is fully missing and to multimodal baselines when all modalities are available. PRIMO quantifies the predictive impact of a modality at the instance level using a variance-based metric computed from predictions across latent completions. We visually demonstrate how varying completions of the missing modality result in a set of plausible labels.", "AI": {"tldr": "PRIMO\u662f\u4e00\u79cd\u76d1\u7763\u5f0f\u6f5c\u5728\u53d8\u91cf\u63d2\u8865\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u6a21\u6001\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5efa\u6a21\u7f3a\u5931\u6a21\u6001\u4e0e\u89c2\u6d4b\u6a21\u6001\u7684\u5173\u7cfb\uff0c\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u5145\u5206\u5229\u7528\u4e0d\u5b8c\u6574\u6570\u636e\uff0c\u5e76\u80fd\u91cf\u5316\u6bcf\u4e2a\u6837\u672c\u4e2d\u7f3a\u5931\u6a21\u6001\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709MLLM\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u6240\u6709\u6a21\u6001\u90fd\u53ef\u7528\uff0c\u4f46\u5b9e\u9645\u4e2d\u591a\u6a21\u6001\u6570\u636e\u5e38\u56e0\u91c7\u96c6\u5f02\u6b65\u3001\u90e8\u5206\u7f3a\u5931\u7b49\u539f\u56e0\u800c\u4e0d\u5b8c\u6574\uff0c\u4e9f\u9700\u80fd\u6709\u6548\u5229\u7528\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u6570\u636e\u5e76\u8bc4\u4f30\u7f3a\u5931\u6a21\u6001\u5f71\u54cd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faPRIMO\u6a21\u578b\uff0c\u5c06\u7f3a\u5931\u6a21\u6001\u5efa\u6a21\u4e3a\u6f5c\u5728\u53d8\u91cf\uff0c\u8be5\u53d8\u91cf\u5728\u9884\u6d4b\u4efb\u52a1\u80cc\u666f\u4e0b\u6355\u6349\u5176\u4e0e\u89c2\u6d4b\u6a21\u6001\u7684\u5173\u7cfb\u3002\u8bad\u7ec3\u65f6\u5229\u7528\u6240\u6709\u6837\u672c\uff08\u65e0\u8bba\u6a21\u6001\u662f\u5426\u5b8c\u6574\uff09\uff0c\u63a8\u7406\u65f6\u4ece\u5b66\u4e60\u5230\u7684\u7f3a\u5931\u6a21\u6001\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u4ee5\u83b7\u5f97\u8fb9\u7f18\u9884\u6d4b\u5206\u5e03\u5e76\u5206\u6790\u7f3a\u5931\u6a21\u6001\u5bf9\u6bcf\u4e2a\u5b9e\u4f8b\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "result": "\u5728\u5408\u6210XOR\u6570\u636e\u96c6\u3001Audio-Vision MNIST\u548cMIMIC-III\uff08\u6b7b\u4ea1\u7387\u548cICD-9\u9884\u6d4b\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\u5f53\u67d0\u4e00\u6a21\u6001\u5b8c\u5168\u7f3a\u5931\u65f6\uff0cPRIMO\u6027\u80fd\u4e0e\u5355\u6a21\u6001\u57fa\u7ebf\u76f8\u5f53\uff1b\u5f53\u6240\u6709\u6a21\u6001\u90fd\u53ef\u7528\u65f6\uff0c\u6027\u80fd\u4e0e\u591a\u6a21\u6001\u57fa\u7ebf\u76f8\u5f53\u3002\u6b64\u5916\uff0cPRIMO\u53ef\u901a\u8fc7\u57fa\u4e8e\u65b9\u5dee\u7684\u6307\u6807\u91cf\u5316\u6bcf\u4e2a\u5b9e\u4f8b\u4e2d\u6a21\u6001\u7684\u9884\u6d4b\u5f71\u54cd\uff0c\u5e76\u53ef\u89c6\u5316\u5c55\u793a\u4e0d\u540c\u7f3a\u5931\u6a21\u6001\u8865\u5168\u65b9\u5f0f\u6240\u5bfc\u81f4\u7684\u591a\u79cd\u5408\u7406\u6807\u7b7e\u3002", "conclusion": "PRIMO\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6a21\u6001\u7f3a\u5931\u95ee\u9898\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u6a21\u578b\u5728\u4e0d\u5b8c\u6574\u6570\u636e\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5bf9\u7f3a\u5931\u6a21\u6001\u9884\u6d4b\u8d21\u732e\u7684\u7ec6\u7c92\u5ea6\u7406\u89e3\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "summary_cn": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u8fd1\u671f\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6240\u6709\u6a21\u6001\u5747\u53ef\u7528\u3002\u7136\u800c\u5728\u5b9e\u8df5\u4e2d\uff0c\u591a\u6a21\u6001\u6570\u636e\u5e38\u5e38\u662f\u4e0d\u5b8c\u6574\u7684\uff0c\u56e0\u4e3a\u67d0\u4e9b\u6a21\u6001\u53ef\u80fd\u7f3a\u5931\u3001\u5f02\u6b65\u91c7\u96c6\uff0c\u6216\u4ec5\u5728\u90e8\u5206\u6837\u672c\u4e2d\u53ef\u7528\u3002\u672c\u6587\u63d0\u51fa\u4e86PRIMO\uff0c\u4e00\u79cd\u76d1\u7763\u5f0f\u7684\u6f5c\u5728\u53d8\u91cf\u63d2\u8865\u6a21\u578b\uff0c\u7528\u4e8e\u91cf\u5316\u591a\u6a21\u6001\u5b66\u4e60\u573a\u666f\u4e2d\u4efb\u610f\u7f3a\u5931\u6a21\u6001\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\u3002PRIMO\u80fd\u591f\u5229\u7528\u6240\u6709\u53ef\u7528\u7684\u8bad\u7ec3\u6837\u672c\uff0c\u65e0\u8bba\u5176\u6a21\u6001\u662f\u5426\u5b8c\u6574\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u4e00\u4e2a\u6f5c\u5728\u53d8\u91cf\u6765\u5efa\u6a21\u7f3a\u5931\u6a21\u6001\uff0c\u8be5\u53d8\u91cf\u5728\u9884\u6d4b\u4efb\u52a1\u7684\u4e0a\u4e0b\u6587\u4e2d\u6355\u6349\u5176\u4e0e\u89c2\u6d4b\u6a21\u6001\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u6211\u4eec\u4ece\u6240\u5b66\u4e60\u7684\u7f3a\u5931\u6a21\u6001\u5206\u5e03\u4e2d\u62bd\u53d6\u591a\u4e2a\u6837\u672c\uff0c\u65e2\u7528\u4e8e\u83b7\u5f97\u8fb9\u7f18\u9884\u6d4b\u5206\u5e03\uff08\u7528\u4e8e\u6700\u7ec8\u9884\u6d4b\uff09\uff0c\u4e5f\u7528\u4e8e\u5206\u6790\u6bcf\u4e2a\u6837\u672c\u4e2d\u7f3a\u5931\u6a21\u6001\u5bf9\u9884\u6d4b\u7ed3\u679c\u7684\u5f71\u54cd\u3002\u6211\u4eec\u5728\u5408\u6210XOR\u6570\u636e\u96c6\u3001Audio-Vision MNIST\u4ee5\u53caMIMIC-III\uff08\u7528\u4e8e\u6b7b\u4ea1\u7387\u548cICD-9\u9884\u6d4b\uff09\u4e0a\u8bc4\u4f30\u4e86PRIMO\u3002\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\uff0c\u5f53\u67d0\u4e00\u6a21\u6001\u5b8c\u5168\u7f3a\u5931\u65f6\uff0cPRIMO\u7684\u6027\u80fd\u4e0e\u5355\u6a21\u6001\u57fa\u7ebf\u76f8\u5f53\uff1b\u5f53\u6240\u6709\u6a21\u6001\u90fd\u53ef\u7528\u65f6\uff0c\u5176\u6027\u80fd\u5219\u4e0e\u591a\u6a21\u6001\u57fa\u7ebf\u76f8\u5f53\u3002PRIMO\u5229\u7528\u57fa\u4e8e\u65b9\u5dee\u7684\u6307\u6807\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u6f5c\u5728\u8865\u5168\u7ed3\u679c\u4e0a\u7684\u9884\u6d4b\u6765\u91cf\u5316\u6bcf\u4e2a\u6837\u672c\u4e2d\u6a21\u6001\u7684\u9884\u6d4b\u5f71\u54cd\u3002\u6211\u4eec\u8fd8\u901a\u8fc7\u53ef\u89c6\u5316\u5c55\u793a\u4e86\u7f3a\u5931\u6a21\u6001\u7684\u4e0d\u540c\u8865\u5168\u65b9\u5f0f\u5982\u4f55\u4ea7\u751f\u4e00\u7ec4\u5408\u7406\u7684\u6807\u7b7e\u3002"}}
{"id": "2602.17030", "pdf": "https://arxiv.org/pdf/2602.17030", "abs": "https://arxiv.org/abs/2602.17030", "authors": ["Eric Chen", "Patricia Alves-Oliveira"], "title": "Patch-Based Spatial Authorship Attribution in Human-Robot Collaborative Paintings", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "As agentic AI becomes increasingly involved in creative production, documenting authorship has become critical for artists, collectors, and legal contexts. We present a patch-based framework for spatial authorship attribution within human-robot collaborative painting practice, demonstrated through a forensic case study of one human artist and one robotic system across 15 abstract paintings. Using commodity flatbed scanners and leave-one-painting-out cross-validation, the approach achieves 88.8% patch-level accuracy (86.7% painting-level via majority vote), outperforming texture-based and pretrained-feature baselines (68.0%-84.7%). For collaborative artworks, where ground truth is inherently ambiguous, we use conditional Shannon entropy to quantify stylistic overlap; manually annotated hybrid regions exhibit 64% higher uncertainty than pure paintings (p=0.003), suggesting the model detects mixed authorship rather than classification failure. The trained model is specific to this human-robot pair but provides a methodological grounding for sample-efficient attribution in data-scarce human-AI creative workflows that, in the future, has the potential to extend authorship attribution to any human-robot collaborative painting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u50cf\u5757\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4eba\u673a\u534f\u4f5c\u7ed8\u753b\u4e2d\u8fdb\u884c\u7a7a\u95f4\u4f5c\u8005\u5f52\u5c5e\uff0c\u901a\u8fc715\u5e45\u62bd\u8c61\u753b\u4f5c\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5728\u56fe\u50cf\u5757\u7ea7\u522b\u8fbe\u523088.8%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u5229\u7528\u6761\u4ef6\u9999\u519c\u71b5\u91cf\u5316\u98ce\u683c\u91cd\u53e0\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u80fd\u6709\u6548\u8bc6\u522b\u6df7\u5408\u4f5c\u8005\u8eab\u4efd\u3002", "motivation": "\u968f\u7740\u5177\u8eabAI\u8d8a\u6765\u8d8a\u591a\u5730\u53c2\u4e0e\u521b\u610f\u751f\u4ea7\uff0c\u660e\u786e\u8bb0\u5f55\u4f5c\u8005\u8eab\u4efd\u5bf9\u827a\u672f\u5bb6\u3001\u6536\u85cf\u5bb6\u548c\u6cd5\u5f8b\u573a\u666f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u4eba\u673a\u534f\u4f5c\u521b\u4f5c\u4e2d\uff0c\u4f5c\u8005\u5f52\u5c5e\u5b58\u5728\u56fa\u6709\u6a21\u7cca\u6027\uff0c\u4e9f\u9700\u53ef\u9760\u7684\u6280\u672f\u624b\u6bb5\u8fdb\u884c\u8bc6\u522b\u4e0e\u91cf\u5316\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u56fe\u50cf\u5757\uff08patch-based\uff09\u7684\u5206\u6790\u6846\u67b6\uff0c\u5229\u7528\u666e\u901a\u5e73\u677f\u626b\u63cf\u4eea\u83b7\u53d6\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u201c\u7559\u4e00\u753b\u4f5c\u4ea4\u53c9\u9a8c\u8bc1\u201d\u7b56\u7565\u8bad\u7ec3\u6a21\u578b\uff1b\u4f7f\u7528\u6761\u4ef6\u9999\u519c\u71b5\u8861\u91cf\u4eba\u7c7b\u4e0e\u673a\u5668\u4eba\u98ce\u683c\u4e4b\u95f4\u7684\u91cd\u53e0\u7a0b\u5ea6\uff0c\u5e76\u5bf9\u6bd4\u7eb9\u7406\u7279\u5f81\u548c\u9884\u8bad\u7ec3\u7279\u5f81\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u56fe\u50cf\u5757\u7ea7\u522b\u8fbe\u523088.8%\u7684\u51c6\u786e\u7387\uff08\u753b\u4f5c\u7ea7\u522b\u4e3a86.7%\uff09\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0868.0%-84.7%\uff09\uff1b\u6df7\u5408\u533a\u57df\u7684\u6761\u4ef6\u71b5\u6bd4\u7eaf\u4eba\u7c7b\u6216\u7eaf\u673a\u5668\u4eba\u4f5c\u54c1\u9ad864%\uff08p=0.003\uff09\uff0c\u8868\u660e\u6a21\u578b\u80fd\u6709\u6548\u8bc6\u522b\u6df7\u5408\u4f5c\u8005\u8eab\u4efd\u3002", "conclusion": "\u867d\u7136\u5f53\u524d\u6a21\u578b\u4ec5\u9002\u7528\u4e8e\u7279\u5b9a\u7684\u4eba\u673a\u7ec4\u5408\uff0c\u4f46\u8be5\u65b9\u6cd5\u4e3a\u6570\u636e\u7a00\u7f3a\u7684\u4eba-AI\u521b\u610f\u534f\u4f5c\u63d0\u4f9b\u4e86\u6837\u672c\u9ad8\u6548\u7684\u4f5c\u8005\u5f52\u5c5e\u8def\u5f84\uff0c\u672a\u6765\u6709\u671b\u63a8\u5e7f\u81f3\u66f4\u5e7f\u6cdb\u7684\u4eba\u673a\u534f\u4f5c\u7ed8\u753b\u573a\u666f\u3002", "summary_cn": "\u968f\u7740\u5177\u8eab\u4eba\u5de5\u667a\u80fd\u8d8a\u6765\u8d8a\u591a\u5730\u53c2\u4e0e\u521b\u610f\u751f\u4ea7\uff0c\u8bb0\u5f55\u4f5c\u8005\u8eab\u4efd\u5bf9\u827a\u672f\u5bb6\u3001\u6536\u85cf\u5bb6\u4ee5\u53ca\u6cd5\u5f8b\u573a\u666f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u50cf\u5757\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4eba\u673a\u534f\u4f5c\u7ed8\u753b\u5b9e\u8df5\u4e2d\u8fdb\u884c\u7a7a\u95f4\u4f5c\u8005\u5f52\u5c5e\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u5305\u542b\u4e00\u4f4d\u4eba\u7c7b\u827a\u672f\u5bb6\u4e0e\u4e00\u4e2a\u673a\u5668\u4eba\u7cfb\u7edf\u5171\u540c\u521b\u4f5c\u768415\u5e45\u62bd\u8c61\u753b\u4f5c\u7684\u6cd5\u8bc1\u6848\u4f8b\u7814\u7a76\u52a0\u4ee5\u9a8c\u8bc1\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u666e\u901a\u5e73\u677f\u626b\u63cf\u4eea\u91c7\u96c6\u6570\u636e\uff0c\u5e76\u91c7\u7528\u201c\u7559\u4e00\u753b\u4f5c\u4ea4\u53c9\u9a8c\u8bc1\u201d\u7b56\u7565\uff0c\u5728\u56fe\u50cf\u5757\u7ea7\u522b\u8fbe\u5230\u4e8688.8%\u7684\u51c6\u786e\u7387\uff08\u901a\u8fc7\u591a\u6570\u6295\u7968\u5728\u753b\u4f5c\u7ea7\u522b\u8fbe\u523086.7%\uff09\uff0c\u4f18\u4e8e\u57fa\u4e8e\u7eb9\u7406\u548c\u9884\u8bad\u7ec3\u7279\u5f81\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0868.0%\u201384.7%\uff09\u3002\u9488\u5bf9\u4f5c\u8005\u8eab\u4efd\u672c\u5c31\u6a21\u7cca\u7684\u534f\u4f5c\u827a\u672f\u4f5c\u54c1\uff0c\u6211\u4eec\u4f7f\u7528\u6761\u4ef6\u9999\u519c\u71b5\u6765\u91cf\u5316\u98ce\u683c\u91cd\u53e0\uff1b\u4eba\u5de5\u6807\u6ce8\u7684\u6df7\u5408\u533a\u57df\u8868\u73b0\u51fa\u6bd4\u7eaf\u4eba\u7c7b\u6216\u7eaf\u673a\u5668\u4eba\u4f5c\u54c1\u9ad864%\u7684\u4e0d\u786e\u5b9a\u6027\uff08p=0.003\uff09\uff0c\u8868\u660e\u6a21\u578b\u68c0\u6d4b\u5230\u7684\u662f\u6df7\u5408\u4f5c\u8005\u8eab\u4efd\uff0c\u800c\u975e\u5206\u7c7b\u5931\u8d25\u3002\u5c3d\u7ba1\u8bad\u7ec3\u6240\u5f97\u6a21\u578b\u4ec5\u9002\u7528\u4e8e\u8fd9\u4e00\u7279\u5b9a\u7684\u4eba\u673a\u7ec4\u5408\uff0c\u4f46\u5b83\u4e3a\u6570\u636e\u7a00\u7f3a\u7684\u4eba\u5de5\u667a\u80fd\u521b\u610f\u5de5\u4f5c\u6d41\u7a0b\u63d0\u4f9b\u4e86\u6837\u672c\u9ad8\u6548\u7684\u4f5c\u8005\u5f52\u5c5e\u65b9\u6cd5\u57fa\u7840\uff0c\u672a\u6765\u6709\u671b\u6269\u5c55\u81f3\u4efb\u4f55\u4eba\u673a\u534f\u4f5c\u7ed8\u753b\u7684\u4f5c\u8005\u5f52\u5c5e\u4efb\u52a1\u3002"}}
